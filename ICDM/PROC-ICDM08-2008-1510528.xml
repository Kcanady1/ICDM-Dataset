<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>12-15-2008</start_date>
		<end_date>12-19-2008</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url>http://computer.org/proceedings/icdm/2008/3502</conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES11036</series_id>
		<series_title><![CDATA[ICDM]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1510528</proc_id>
	<acronym>ICDM '08</acronym>
	<proc_desc>Proceedings of the 2008 Eighth IEEE International Conference on Data Mining</proc_desc>
	<conference_number></conference_number>
	<proc_class>conference</proc_class>
	<proc_title></proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn13>978-0-7695-3502-9</isbn13>
	<issn>1550-4786</issn>
	<eissn></eissn>
	<copyright_year>2008</copyright_year>
	<publication_date>12-15-2008</publication_date>
	<pages></pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB769</publisher_id>
		<publisher_code>IEEEW</publisher_code>
		<publisher_name>IEEE Computer Society</publisher_name>
		<publisher_address>1730 Massachusetts Ave., NW             Washington, DC</publisher_address>
		<publisher_city></publisher_city>
		<publisher_state></publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>20036-1992</publisher_zip_code>
		<publisher_contact></publisher_contact>
		<publisher_phone></publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url></publisher_url>
	</publisher>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>1511435</article_id>
		<sort_key>10</sort_key>
		<display_label>Page</display_label>
		<pages>C4,C1</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Cover Art]]></title>
		<page_from>C1</page_from>
		<doi_number>10.1109/ICDM.2008.162</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511435</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511436</article_id>
		<sort_key>20</sort_key>
		<display_label>Page</display_label>
		<pages>i</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Title Page i]]></title>
		<page_from>i</page_from>
		<doi_number>10.1109/ICDM.2008.1</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511436</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511437</article_id>
		<sort_key>30</sort_key>
		<display_label>Page</display_label>
		<pages>iii</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Title Page iii]]></title>
		<page_from>iii</page_from>
		<doi_number>10.1109/ICDM.2008.2</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511437</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511438</article_id>
		<sort_key>40</sort_key>
		<display_label>Page</display_label>
		<pages>iv</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Copyright Page]]></title>
		<page_from>iv</page_from>
		<doi_number>10.1109/ICDM.2008.3</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511438</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511439</article_id>
		<sort_key>60</sort_key>
		<display_label>Page</display_label>
		<pages>xiv</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Welcome Message from the Conference Chairs]]></title>
		<page_from>xiv</page_from>
		<doi_number>10.1109/ICDM.2008.4</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511439</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511440</article_id>
		<sort_key>70</sort_key>
		<display_label>Pages</display_label>
		<pages>xv-xvi</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Welcome to ICDM 2008]]></title>
		<page_from>xv</page_from>
		<page_to>xvi</page_to>
		<doi_number>10.1109/ICDM.2008.5</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511440</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511441</article_id>
		<sort_key>110</sort_key>
		<display_label>Pages</display_label>
		<pages>xxvi-xxix</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Non-PC Reviewers]]></title>
		<page_from>xxvi</page_from>
		<page_to>xxix</page_to>
		<doi_number>10.1109/ICDM.2008.9</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511441</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511442</article_id>
		<sort_key>120</sort_key>
		<display_label>Page</display_label>
		<pages>xxx</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Corporate Sponsors]]></title>
		<page_from>xxx</page_from>
		<doi_number>10.1109/ICDM.2008.10</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511442</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511443</article_id>
		<sort_key>130</sort_key>
		<display_label>Page</display_label>
		<pages>xxxi</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Invited Talks]]></title>
		<page_from>xxxi</page_from>
		<doi_number>10.1109/ICDM.2008.156</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511443</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511294</article_id>
		<sort_key>140</sort_key>
		<display_label>Pages</display_label>
		<pages>xxxii-xxxiii</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Tutorials]]></title>
		<page_from>xxxii</page_from>
		<page_to>xxxiii</page_to>
		<doi_number>10.1109/ICDM.2008.157</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511294</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511295</article_id>
		<sort_key>160</sort_key>
		<display_label>Page</display_label>
		<pages>xxxvii</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Panel Session]]></title>
		<page_from>xxxvii</page_from>
		<doi_number>10.1109/ICDM.2008.159</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511295</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511296</article_id>
		<sort_key>170</sort_key>
		<display_label>Pages</display_label>
		<pages>3-12</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[On-line LDA]]></title>
		<subtitle><![CDATA[Adaptive Topic Models for Mining Text Streams with Applications to Topic Detection and Tracking]]></subtitle>
		<page_from>3</page_from>
		<page_to>12</page_to>
		<doi_number>10.1109/ICDM.2008.140</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511296</url>
		<abstract>
			<par><![CDATA[This paper presents Online Topic Model (OLDA), a topic model that automatically captures the thematic patterns and identifies emerging topics of text streams and their changes over time. Our approach allows the topic modeling framework, specifically the Latent Dirichlet Allocation (LDA) model, to work in an online fashion such that it incrementally builds an up-to-date model (mixture of topics per document and mixture of words per topic) when a new document (or a set of documents) appears. A solution based on the Empirical Bayes method is proposed. The idea is to incrementally update the current model according to the information inferred from the new stream of data with no need to access previous data. The dynamics of the proposed approach also provide an efficient mean to track the topics over time and detect the emerging topics in real time. Our method is evaluated both qualitatively and quantitatively using benchmark datasets. In our experiments, the OLDA has discovered interesting patterns by just analyzing a fraction of data at a time. Our tests also prove the ability of OLDA to align the topics across the epochs with which the evolution of the topics over time is captured. The OLDA is also comparable to, and sometimes better than, the original LDA in predicting the likelihood of unseen documents.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382881</person_id>
				<author_profile_id><![CDATA[81414620238]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Loulwah]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[AlSumait]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382882</person_id>
				<author_profile_id><![CDATA[81100273432]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barbar&#225;]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382883</person_id>
				<author_profile_id><![CDATA[81100062921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Carlotta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Domeniconi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511297</article_id>
		<sort_key>180</sort_key>
		<display_label>Pages</display_label>
		<pages>13-22</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Unsupervised Cross-Domain Learning by Interaction Information Co-clustering]]></title>
		<page_from>13</page_from>
		<page_to>22</page_to>
		<doi_number>10.1109/ICDM.2008.92</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511297</url>
		<abstract>
			<par><![CDATA[In real-world data mining applications, one often has access to multiple datasets that are relevant to the task at hand. However, learning from such datasets can be difficult as they are often drawn from different domains, i.e., not identically distributed or differ in class or feature sets. In this paper, we consider the problem of learning the class structures %, unique and shared, of related domains in an unsupervised manner. Its setting generalizes that of information filtering and novelty detection applications which addresses both known and unknown classes. We propose a co-clustering framework for estimating and adapting the class structures of two related domains, {enabling the analyses of shared and unique classes.} We define an objective function using interaction information to take account of the divergence between the corresponding clusters of respective domains. We present an iterative algorithm which alternates object and feature clustering and converges to a local minimum of the objective function. We present empirical results using text benchmarks, comparing the proposed algorithm and combinations of conventional approaches in problems of partitioning documents and detecting unknown topics.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[information theoretic clustering, Minority Clustering, co-clustering, domain adaptation, interactive information]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381279</person_id>
				<author_profile_id><![CDATA[81100486044]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ando]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381280</person_id>
				<author_profile_id><![CDATA[81100183879]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Einoshin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Suzuki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511298</article_id>
		<sort_key>190</sort_key>
		<display_label>Pages</display_label>
		<pages>23-32</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Paired Learners for Concept Drift]]></title>
		<page_from>23</page_from>
		<page_to>32</page_to>
		<doi_number>10.1109/ICDM.2008.119</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511298</url>
		<abstract>
			<par><![CDATA[To cope with concept drift, we paired a stable online learner with a reactive one. A stable learner predicts based on all of its experience, whereas are active learner predicts based on its experience over a short, recent window of time. The method of paired learning uses differences in accuracy between the two learners over this window to determine when to replace the current stable learner, since the stable learner performs worse than does there active learner when the target concept changes. While the method uses the reactive learner as an indicator of drift, it uses the stable learner to predict, since the stable learner performs better than does the reactive learner when acquiring target concept. Experimental results support these assertions. We evaluated the method by making direct comparisons to dynamic weighted majority, accuracy weighted ensemble, and streaming ensemble algorithm (SEA) using two synthetic problems, the Stagger concepts and the SEA concepts, and three real-world data sets: meeting scheduling, electricity prediction, and malware detection. Results suggest that, on these problems, paired learners outperformed or performed comparably to methods more costly in time and space.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[online learning, concept drift, time-changing data streams]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383462</person_id>
				<author_profile_id><![CDATA[81414609245]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Bach]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383463</person_id>
				<author_profile_id><![CDATA[81414605146]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Marcus]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Maloof]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511299</article_id>
		<sort_key>200</sort_key>
		<display_label>Pages</display_label>
		<pages>33-42</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Predicting Future Decision Trees from Evolving Data]]></title>
		<page_from>33</page_from>
		<page_to>42</page_to>
		<doi_number>10.1109/ICDM.2008.90</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511299</url>
		<abstract>
			<par><![CDATA[Recognizing and analyzing change is an important human virtue because it enables us to anticipate future scenarios and thus allows us to act pro-actively. One approach to understand change within a domain is to analyze how modelsand patterns evolve. Knowing how a model changes over time is suggesting to ask: Can we use this knowledge to learn a model in anticipation, such that it better reflects the near-future characteristics of an evolving domain? In this paper we provide an answer to this question by presenting an algorithm which predicts future decision trees based ona model of change. In particular, this algorithm encompasses a novel approach to change mining which is based on analyzing the changes of the decisions made during model learning. The proposed approach can also be applied to other types of classifiers and thus provides a basis for future research. We present our first experimental results which show that anticipated decision trees have the potential to outperform trees learned on the most recent data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Decision Trees, Change Mining, Evolving Data]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382884</person_id>
				<author_profile_id><![CDATA[81381603471]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mirko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[B&#246;ttcher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382885</person_id>
				<author_profile_id><![CDATA[81100439330]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Spott]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382886</person_id>
				<author_profile_id><![CDATA[81100122826]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Rudolf]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kruse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511300</article_id>
		<sort_key>210</sort_key>
		<display_label>Pages</display_label>
		<pages>43-52</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[A Randomized Approach for Approximating the Number of Frequent Sets]]></title>
		<page_from>43</page_from>
		<page_to>52</page_to>
		<doi_number>10.1109/ICDM.2008.85</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511300</url>
		<abstract>
			<par><![CDATA[We investigate the problem of counting the number of frequent (item)sets---a problem known to be intractable in terms of an exact polynomial time computation. In this paper, we show that it is in general also hard to approximate. Subsequently, a randomized counting algorithm is developed using the Markov chain Monte Carlo method. While for general inputs an exponential running time is needed in order to guarantee a certain approximation bound, we empirically show that the algorithm still has the desired accuracy on real-world datasets when its running time is capped polynomially.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[frequent itemset mining, counting, approximation, randomized algorithms]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384537</person_id>
				<author_profile_id><![CDATA[81384606148]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mario]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Boley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384538</person_id>
				<author_profile_id><![CDATA[81100094006]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Henrik]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grosskreutz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511307</article_id>
		<sort_key>220</sort_key>
		<display_label>Pages</display_label>
		<pages>53-62</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[A Non-parametric Semi-supervised Discretization Method]]></title>
		<page_from>53</page_from>
		<page_to>62</page_to>
		<doi_number>10.1109/ICDM.2008.35</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511307</url>
		<abstract>
			<par><![CDATA[Semi-supervised classification methods aim to exploit labelled and unlabelled examples to train a predictive model. Most of these approaches make assumptions on the distribution of classes. This article first proposes a new semi-supervised discretization method which adopts very low informative prior on data. This method discretizes the numerical domain of a continuous input variable, while keeping the information relative to the prediction of classes. Then, an in-depth comparison of this semi-supervised method with the original supervised MODL approach is presented. We demonstrate that the semi-supervised approach is asymptotically equivalent to the supervised approach, improved with a post-optimizationof the intervals bounds location.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Non-parametric, Semi-supervised, Discretization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384060</person_id>
				<author_profile_id><![CDATA[81460644164]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bondu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384061</person_id>
				<author_profile_id><![CDATA[81100634695]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Boulle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384062</person_id>
				<author_profile_id><![CDATA[81100130104]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[V.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lemaire]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384063</person_id>
				<author_profile_id><![CDATA[81100252192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Loiseau]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384064</person_id>
				<author_profile_id><![CDATA[81100325489]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Duval]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511308</article_id>
		<sort_key>230</sort_key>
		<display_label>Pages</display_label>
		<pages>63-72</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Non-negative Matrix Factorization on Manifold]]></title>
		<page_from>63</page_from>
		<page_to>72</page_to>
		<doi_number>10.1109/ICDM.2008.57</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511308</url>
		<abstract>
			<par><![CDATA[Recently Non-negative Matrix Factorization (NMF) has received a lot of attentions in information retrieval, computer vision and pattern recognition. NMF aims to find two non-negative matrices whose product can well approximate the original matrix. The sizes of these two matrices are usually smaller than the original matrix. This results in a compressed version of the original data matrix. The solution of NMF yields a natural parts-based representation for the data. When NMF is applied for data representation, a major disadvantage is that it fails to consider the geometric structure in the data. In this paper, we develop a graph based approach for parts-based data representation in order to overcome this limitation. We construct an affinity graph to encode the geometrical information and seek a matrix factorization which respects the graph structure. We demonstrate the success of this novel algorithm by applying it on real world problems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381809</person_id>
				<author_profile_id><![CDATA[81100430245]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Deng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381810</person_id>
				<author_profile_id><![CDATA[81418598002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xiaofei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381811</person_id>
				<author_profile_id><![CDATA[81414617039]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xiaoyun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381812</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511309</article_id>
		<sort_key>240</sort_key>
		<display_label>Pages</display_label>
		<pages>73-82</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Anti-monotonic Overlap-Graph Support Measures]]></title>
		<page_from>73</page_from>
		<page_to>82</page_to>
		<doi_number>10.1109/ICDM.2008.114</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511309</url>
		<abstract>
			<par><![CDATA[In graph mining, a frequency measure is anti-monotonic if the frequency of a pattern never exceeds the frequency of a subpattern. The efficiency and correctness of most graph pattern miners relies critically on this property. We study the case where the dataset is a single graph. Vanetik, Gudes and Shimony already gave sufficient and necessary conditions for anti-monotonicity of measures depending only on the edge-overlaps between the intances of the pattern in a labeled graph. We extend these results to homomorphisms, isomorphisms and homeomorphisms on both labeled and unlabeled, directed and undirected graphs, for vertex and edge overlap. We show a set of reductions between the different morphisms that preserve overlap. We also prove that the popular maximum independent set measure assigns the minimal possible meaningful frequency, introduce a new measure based on the minimum clique partition that assigns the maximum possible meaningful frequency and introduce a new measure sandwiched between the former two based on the poly-time computable Lovasz theta-function.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graph support measure, overlap graph, anti-monotinicity]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381813</person_id>
				<author_profile_id><![CDATA[81100650328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Toon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Calders]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381814</person_id>
				<author_profile_id><![CDATA[81100088078]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ramon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381815</person_id>
				<author_profile_id><![CDATA[81453647270]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dries]]></first_name>
				<middle_name><![CDATA[Van]]></middle_name>
				<last_name><![CDATA[Dyck]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511310</article_id>
		<sort_key>250</sort_key>
		<display_label>Pages</display_label>
		<pages>83-92</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[SeqStream]]></title>
		<subtitle><![CDATA[Mining Closed Sequential Patterns over Stream Sliding Windows]]></subtitle>
		<page_from>83</page_from>
		<page_to>92</page_to>
		<doi_number>10.1109/ICDM.2008.36</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511310</url>
		<abstract>
			<par><![CDATA[Previous studies have shown mining closed patterns provides more benefits than mining the complete set of frequent patterns, since closed pattern mining leads to more compact results and more efficient algorithms. It is quite useful in a data stream environment where memory and computation power are major concerns. This paper studies the problem of mining closed sequential patterns over data stream sliding windows. A synopsis structure IST (Inverse Closed Sequence Tree) is designed to keep inverse closed sequential patterns in current window. An efficient algorithm SeqStream is developed to mine closed sequential patterns in stream windows incrementally, and various novel strategies are adopted in SeqStream to prune search space aggressively. Extensive experiments on both real and synthetic data sets show that SeqStream outperforms PrefixSpan, CloSpan and BIDE by a factor of about one to two orders of magnitude.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[SeqStream, closed sequential pattern, data stream, sliding window]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383493</person_id>
				<author_profile_id><![CDATA[81413597761]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383494</person_id>
				<author_profile_id><![CDATA[81100212828]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tengjiao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383495</person_id>
				<author_profile_id><![CDATA[81452599778]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dongqing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383496</person_id>
				<author_profile_id><![CDATA[81413599503]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Luan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511311</article_id>
		<sort_key>260</sort_key>
		<display_label>Pages</display_label>
		<pages>93-102</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[SPARCL]]></title>
		<subtitle><![CDATA[Efficient and Effective Shape-Based Clustering]]></subtitle>
		<page_from>93</page_from>
		<page_to>102</page_to>
		<doi_number>10.1109/ICDM.2008.73</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511311</url>
		<abstract>
			<par><![CDATA[Clustering is one of the fundamental data mining tasks. Many different clustering paradigms have been developed over the years, which include partitional, hierarchical, mixture model based, density-based, spectral, subspace, and so on. The focus of this paper is on full-dimensional, arbitrary shaped clusters. Existing methods for this problem suffer either in terms of the memory or time complexity (quadratic or even cubic). This shortcoming has restricted these algorithms to datasets of moderate sizes. In this paper we propose SPARCL, a simple and scalable algorithm for finding clusters with arbitrary shapes and sizes, and it has linear space and time complexity. SPARCL consists of two stages -- the first stage runs a carefully initialized version of the Kmeans algorithm to generate many small seed clusters. The second stage iteratively merges the generated clusters to obtain the final shape-based clusters. Experiments were conducted on a variety of datasets to highlight the effectiveness, efficiency, and scalability of our approach. On the large datasets SPARCL is an order of magnitude faster than the best existing approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384579</person_id>
				<author_profile_id><![CDATA[81361609414]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Vineet]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chaoji]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384580</person_id>
				<author_profile_id><![CDATA[81418593670]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mohammad]]></first_name>
				<middle_name><![CDATA[Al]]></middle_name>
				<last_name><![CDATA[Hasan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384581</person_id>
				<author_profile_id><![CDATA[81375599301]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Saeed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Salem]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384582</person_id>
				<author_profile_id><![CDATA[81548027493]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Mohammed]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Zaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511319</article_id>
		<sort_key>270</sort_key>
		<display_label>Pages</display_label>
		<pages>103-112</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Graph OLAP]]></title>
		<subtitle><![CDATA[Towards Online Analytical Processing on Graphs]]></subtitle>
		<page_from>103</page_from>
		<page_to>112</page_to>
		<doi_number>10.1109/ICDM.2008.30</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511319</url>
		<abstract>
			<par><![CDATA[OLAP (On-Line Analytical Processing) is an important notion in data analysis. Recently, more and more graph or networked data sources come into being. There exists a similar need to deploy graph analysis from different perspectives and with multiple granularities. However, traditional OLAP technology cannot handle such demands because it does not consider the links among individual data tuples. In this paper, we develop a novel graph OLAP framework, which presents a multi-dimensional and multi-level view over graphs. The contributions of this work are two-fold. First, starting from basic definitions, i.e., what are dimensions and measures in the graph OLAP scenario, we develop a conceptual framework for data cubes on graphs. We also look into different semantics of OLAP operations, and classify the framework into two major subcases: informational OLAP and topological OLAP. Then, with more emphasis on informational OLAP (topological OLAP will be covered in a future study due to the lack of space), we show how a graph cube can be materialized by calculating a special kind of measure called aggregated graph and how to implement it efficiently. This includes both full materialization and partial materialization where constraints are enforced to obtain an iceberg cube. We can see that the aggregated graphs, which depend on the graph properties of underlying networks, are much harder to compute than their traditional OLAP counterparts, due to the increased structural complexity of data. Empirical studies show insightful results on real datasets and demonstrate the efficiency of our proposed optimizations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385135</person_id>
				<author_profile_id><![CDATA[81375599868]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385136</person_id>
				<author_profile_id><![CDATA[81100044779]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xifeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385137</person_id>
				<author_profile_id><![CDATA[81313483490]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Feida]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385138</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385139</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511320</article_id>
		<sort_key>280</sort_key>
		<display_label>Pages</display_label>
		<pages>113-122</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Exploiting Local and Global Invariants for the Management of Large Scale Information Systems]]></title>
		<page_from>113</page_from>
		<page_to>122</page_to>
		<doi_number>10.1109/ICDM.2008.51</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511320</url>
		<abstract>
			<par><![CDATA[This paper presents a data oriented approach to modeling the complex computing systems, in which an ensemble of correlation models are discovered to represent the system status. If the discovered correlations can continually hold under different user scenarios and workloads, they are regarded as invariants of the information system. In our previous work, we have developed an algorithm to automatically search the invariants between any pair of system attributes, which we call local invariants. However that method is unable to deal with the high order dependency models due to the combinatorial explosion of search space. In this paper we use Bayesian regression technique to discover those high order correlation models, called global invariants. We treat each attribute as a response variable in turn and express its dependency with the other attributes in a regression model. By adding the prior constraint of Laplacian distribution to the regression coefficients, we can find the solution in which only the correlated attributes with respect to the response have nonzero regression coefficients. After that we further consider the temporal dependencies of those extracted attributes by incorporating their past observations. We also provide a confidence metric and a validation procedure to measure the reliability of learned models. If the model does not break down in the validation, it is regarded as a true invariant of the system. Experimental results on a real wireless networking system show that the discovered invariants can be used to effectively detect system failures as well as provide valuable information about the failure source.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[system management, dependency, Bayesian regression, failure detection, failure diagnosis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381855</person_id>
				<author_profile_id><![CDATA[81100114583]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Haifeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381856</person_id>
				<author_profile_id><![CDATA[81367595256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haibin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cheng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381857</person_id>
				<author_profile_id><![CDATA[81336489979]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Guofei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381858</person_id>
				<author_profile_id><![CDATA[81100362995]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Kenji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yoshihira]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511321</article_id>
		<sort_key>290</sort_key>
		<display_label>Pages</display_label>
		<pages>123-132</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[DECK]]></title>
		<subtitle><![CDATA[Detecting Events from Web Click-Through Data]]></subtitle>
		<page_from>123</page_from>
		<page_to>132</page_to>
		<doi_number>10.1109/ICDM.2008.78</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511321</url>
		<abstract>
			<par><![CDATA[In the past few years there has been increased research interest in detecting previously unidentified events from Web resources. Our focus in this paper is to detect events from the click-through data generated by Web search engines. Existing event detection algorithms, which mainly study the news archive data, cannot be employed directly because of the following two unique features of click-through data: 1) the information provided by click-through data is quite limited; 2) not every query issued to a Web search engine corresponds to an event in the real world. In this paper, we address this problem by proposing an effective algorithm which Detects Events from ClicK-through data DECK. We firstly transform click-through data to the 2D polar space by considering the semantic dimension and temporal dimension of queries. Robust subspace estimation is performed to detect subspaces such that each subspace consists of queries of similar semantics. Next, we prune uninteresting subspaces which do not contain queries corresponding to real events by simultaneously considering the respective distribution of queries along the semantic dimension and the temporal dimension in each subspace. Finally, events are detected from interesting subspaces using a nonparametric clustering technique. Compared with an existing approach, our experimental results based on real-life data have shown that the proposed approach is more accurate and effective in detecting real events from click-through data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382939</person_id>
				<author_profile_id><![CDATA[81100108811]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ling]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382940</person_id>
				<author_profile_id><![CDATA[81309486813]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yiqun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382941</person_id>
				<author_profile_id><![CDATA[81100488409]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wolfgang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nejdl]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511312</article_id>
		<sort_key>300</sort_key>
		<display_label>Pages</display_label>
		<pages>133-142</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Mining Order-Preserving Submatrices from Data with Repeated Measurements]]></title>
		<page_from>133</page_from>
		<page_to>142</page_to>
		<doi_number>10.1109/ICDM.2008.12</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511312</url>
		<abstract>
			<par><![CDATA[Order-preserving submatrices (OPSM's) have been shown useful in capturing concurrent patterns in data when the relative magnitudes of data items are more important than their absolute values. To cope with data noise, repeated experiments are often conducted to collect multiple measurements. We propose and study a more robust version of OPSM, where each data item is represented by a set of values obtained from replicated experiments. We call the new problem OPSM-RM (OPSM with repeated measurements). We define OPSM-RM based on a number of practical requirements. We discuss the computational challenges of OPSM-RM and propose a generic mining algorithm. We further propose a series of techniques to speed up two time-dominating components of the algorithm. We clearly show the effectiveness of our methods through a series of experiments conducted on real microarray data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[OPSM, sequence mining, gene expression]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384065</person_id>
				<author_profile_id><![CDATA[81100204322]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chun]]></first_name>
				<middle_name><![CDATA[Kit]]></middle_name>
				<last_name><![CDATA[Chui]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384066</person_id>
				<author_profile_id><![CDATA[81100519737]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ben]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384067</person_id>
				<author_profile_id><![CDATA[81100065286]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[Y.]]></middle_name>
				<last_name><![CDATA[Yip]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384068</person_id>
				<author_profile_id><![CDATA[81414595609]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Sau]]></first_name>
				<middle_name><![CDATA[Dan]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511322</article_id>
		<sort_key>310</sort_key>
		<display_label>Pages</display_label>
		<pages>143-152</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Start Globally, Optimize Locally, Predict Globally]]></title>
		<subtitle><![CDATA[Improving Performance on Imbalanced Data]]></subtitle>
		<page_from>143</page_from>
		<page_to>152</page_to>
		<doi_number>10.1109/ICDM.2008.87</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511322</url>
		<abstract>
			<par><![CDATA[Class imbalance is a ubiquitous problem in supervised learning and has gained wide-scale attention in the literature. Perhaps the most prevalent solution is to applysampling to training data in order improve classi&#64257;er performance. The typical approach will apply uniform levels of sampling globally. However, we believe that datais typically multi-modal, which suggests sampling shouldbe treated locally rather than globally. It is the purposeof this paper to propose a framework which &#64257;rst identi&#64257;es meaningful regions of data and then proceeds to &#64257;ndoptimal sampling levels within each. This paper demonstrates that a global classi&#64257;er trained on data locally sampled produces superior rank-orderings on a wide range ofreal-world and arti&#64257;cial datasets as compared to contemporary global sampling methods.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Class imbalance, local sampling, SMOTE]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382942</person_id>
				<author_profile_id><![CDATA[81350572439]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Cieslak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382943</person_id>
				<author_profile_id><![CDATA[81100002770]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nitesh]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Chawla]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511329</article_id>
		<sort_key>320</sort_key>
		<display_label>Pages</display_label>
		<pages>153-162</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Generalized Framework for Syntax-Based Relation Mining]]></title>
		<page_from>153</page_from>
		<page_to>162</page_to>
		<doi_number>10.1109/ICDM.2008.153</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511329</url>
		<abstract>
			<par><![CDATA[Supervised approaches to Data Mining are particularly appealing as they allow for the extraction of complex relations from data objects. In order to facilitate their application in different areas, ranging from protein to protein interaction in bioinformatics to text mining in computational linguistics research, a modular and general mining framework is needed. The major constraint to the generalization process concerns the feature design for the description of relational data. In this paper, we present a machine learning framework for the automatic mining of relations, where the target objects are structurally organized in a tree. Object types are generalized by means of the use of roles, whereas the relation properties are described by means of the underlying tree structure. The latter is encoded in the learning algorithm thanks to kernel methods for structured data, which represent structures in terms of their all possible subparts. This approach can be applied to any kind of data disregarding their very nature. Experiments with Support Vector Machines on two text mining datasets for relation extraction, i.e. the PropBank and FrameNet corpora, show both that our approach is general, and that it reaches state-of-the-art accuracy.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[relation mining, kernel methods, semantic role labeling, frame recognition]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382407</person_id>
				<author_profile_id><![CDATA[81418593860]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bonaventura]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Coppola]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382408</person_id>
				<author_profile_id><![CDATA[81100511871]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alessandro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moschitti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382409</person_id>
				<author_profile_id><![CDATA[81384594131]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Daniele]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pighin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511330</article_id>
		<sort_key>330</sort_key>
		<display_label>Pages</display_label>
		<pages>163-172</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Formal Models for Expert Finding on DBLP Bibliography Data]]></title>
		<page_from>163</page_from>
		<page_to>172</page_to>
		<doi_number>10.1109/ICDM.2008.29</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511330</url>
		<abstract>
			<par><![CDATA[Finding relevant experts in a specific field is often crucial for consulting, both in industry and in academia. The aim of this paper is to address the expert-finding task in a real world academic field. We present three models for expert finding based on the large-scale DBLP bibliography and Google Scholar for data supplementation. The first, a novel weighted language model, models an expert candidate based on the relevance and importance of associated documents by introducing a document prior probability, and achieves much better results than the basic language model. The second, a topic-based model, represents each candidate as a weighted sum of multiple topics, whilst the third, a hybrid model, combines the language model and the topic-based model. We evaluate our system using a benchmark dataset based on human relevance judgments of how well the expertise of proposed experts matches a query topic. Evaluation results show that our hybrid model outperforms other models in nearly all metrics.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Expert finding, DBLP, language models, topic-based model]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384093</person_id>
				<author_profile_id><![CDATA[81413600167]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hongbo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Deng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384094</person_id>
				<author_profile_id><![CDATA[81100193887]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Irwin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[King]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384095</person_id>
				<author_profile_id><![CDATA[81100033051]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Lyu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511331</article_id>
		<sort_key>340</sort_key>
		<display_label>Pages</display_label>
		<pages>173-182</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[ReDSOM]]></title>
		<subtitle><![CDATA[Relative Density Visualization of Temporal Changes in Cluster Structures Using Self-Organizing Maps]]></subtitle>
		<page_from>173</page_from>
		<page_to>182</page_to>
		<doi_number>10.1109/ICDM.2008.34</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511331</url>
		<abstract>
			<par><![CDATA[We introduce a Self-Organizing Map (SOM) based visualization method that compares cluster structures in temporal datasets using Relative Density SOM (ReDSOM) visualization. Our method, combined with a distance matrix-based visualization, is capable of visually identifying emerging clusters, disappearing clusters, enlarging clusters, contracting clusters, the shifting of cluster centroids, and changes in cluster density. For example, when a region in a SOM becomes significantly more dense compared to an earlier SOM, and well separated from other regions, then the new region can be said to represent a new cluster. The capabilities of ReDSOM are demonstrated using synthetic datasets, as well as real-life datasets from the World Bank and the Australian Taxation Office. The results on the real-life datasets demonstrate that changes identified interactively can be related to actual changes. The identification of such cluster changes is important in many contexts, including the exploration of changes in population behavior in the context of compliance and fraud in taxation.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Self-Organizing Map, Temporal Cluster Analysis, visual analytics, change analysis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381375</person_id>
				<author_profile_id><![CDATA[81351607909]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Denny]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381376</person_id>
				<author_profile_id><![CDATA[81414614241]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Graham]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381377</person_id>
				<author_profile_id><![CDATA[81100259455]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Christen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511332</article_id>
		<sort_key>350</sort_key>
		<display_label>Pages</display_label>
		<pages>183-192</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Nonnegative Matrix Factorization for Combinatorial Optimization]]></title>
		<subtitle><![CDATA[Spectral Clustering, Graph Matching, and Clique Finding]]></subtitle>
		<page_from>183</page_from>
		<page_to>192</page_to>
		<doi_number>10.1109/ICDM.2008.130</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511332</url>
		<abstract>
			<par><![CDATA[Nonnegative matrix factorization (NMF) is a versatile model for data clustering. In this paper, we propose several NMF inspired algorithms to solve different data mining problems. They include (1) multi-way normalized cut spectral clustering, (2) graph matching of both undirected and directed graphs, and (3) maximal clique finding on both graphs and bipartite graphs. Key features of these algorithms are (a) they are extremely simple to implement; and (b) they are provably convergent. We conduct experiments to demonstrate the effectiveness of these new algorithms. We also derive a new spectral bound for the size of maximal edge bicliques as a byproduct of our approach.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Nonnegative matrix factorization, clustering, graph matching, clique finding]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381378</person_id>
				<author_profile_id><![CDATA[81100136610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ding]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381379</person_id>
				<author_profile_id><![CDATA[81100475528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381380</person_id>
				<author_profile_id><![CDATA[81339507945]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Jordan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511333</article_id>
		<sort_key>360</sort_key>
		<display_label>Pages</display_label>
		<pages>193-202</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[Space Efficient String Mining under Frequency Constraints]]></title>
		<page_from>193</page_from>
		<page_to>202</page_to>
		<doi_number>10.1109/ICDM.2008.32</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511333</url>
		<abstract>
			<par><![CDATA[Let $\db_1$ and $\db_2$ be two databases (i.e. multisets) of $d$ strings, over an alphabet $\Sigma$, with overall length $n$. We study the problem of mining discriminative patterns between $\db_1$ and $\db_2$ --- e.g., patterns that are frequent in one database but not in the other, emerging patterns, or patterns satisfying other frequency-related constraints. Using the algorithmic framework by Hui (CPM 1992), one can solve several variants of this problem in the optimal linear time with the aid of suffix trees or suffix arrays. This stands in high contrast to other pattern domains such as itemsets or subgraphs, where super-linear lower bounds are known. However, the space requirement of existing solutions is $O(n \log n)$ bits, which is not optimal for $|\Sigma]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[|constraint based string mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385155</person_id>
				<author_profile_id><![CDATA[81321491592]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Johannes]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fischer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385156</person_id>
				<author_profile_id><![CDATA[81100185693]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Veli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[M&#228;kinen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385157</person_id>
				<author_profile_id><![CDATA[81414591793]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Niki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[V&#228;lim&#228;ki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511334</article_id>
		<sort_key>370</sort_key>
		<display_label>Pages</display_label>
		<pages>203-212</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Efficient Discovery of Statistically Significant Association Rules]]></title>
		<page_from>203</page_from>
		<page_to>212</page_to>
		<doi_number>10.1109/ICDM.2008.144</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511334</url>
		<abstract>
			<par><![CDATA[Searching statistically significant association rules is an important but neglected problem. Traditional association rules do not capture the idea of statistical dependence and the resulting rules can be spurious, while the most significant rules may be missing. This leads to erroneous models and predictions which often become expensive.The problem is computationally very difficult, because the significance is not a monotonic property. However, in this paper we prove several other properties, which can be used for pruning the search space. The properties are implemented in the StatApriori algorithm, which searches statistically significant, non-redundant association rules. Based on both theoretical and empirical observations, the resulting rules are very accurate compared to traditional association rules. In addition, StatApriori can work with extremely low frequencies, thus finding new interesting rules.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[association rule, statistical significance, StatApriori algorithm]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381893</person_id>
				<author_profile_id><![CDATA[81464646148]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wilhelmiina]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[H&#228;m&#228;l&#228;inen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381894</person_id>
				<author_profile_id><![CDATA[81100535229]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Matti]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nyk&#228;nen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511341</article_id>
		<sort_key>380</sort_key>
		<display_label>Pages</display_label>
		<pages>213-222</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Interpreting PET Scans by Structured Patient Data]]></title>
		<subtitle><![CDATA[A Data Mining Case Study in Dementia Research]]></subtitle>
		<page_from>213</page_from>
		<page_to>222</page_to>
		<doi_number>10.1109/ICDM.2008.128</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511341</url>
		<abstract>
			<par><![CDATA[One of the goals of medical research in the area of dementia is to correlate images of the brain with other variables, for instance, demographic information or outcomes of clinical tests. The usual approach is to select a subset of patients based on such variables and analyze the images associated with those patients. In this paper, we apply data mining techniques to take the opposite approach: We start with the images and explain the differences and commonalities in terms of the other variables. In the first step, we cluster PET scans of patients to form groups sharing similar features in brain metabolism. To the best of our knowledge, it is the first time ever that clustering is applied to whole PET scans. In the second step, we explain the clusters by relating them to non-image variables. To do so, we employ RSD, an algorithm for relational subgroup discovery, with the cluster membership of patients as target variable. Our results enable interesting interpretations of differences in brain metabolism in terms of demographic and clinical variables. The approach was implemented and tested on an exceptionally large pre-existing data collection of patients with different types of dementia. It comprises 10 GB of image data from 454 PET scans, and 42 variables from psychological and demographical data organized in 11 relations of a relational database. We believe that explaining medical images in terms of other variables (patient records, demographic information, etc.) is a challenging new and rewarding area for data mining research.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[clustering, PET, subgroup discovery, alzheimer's disease, dementia, brain, neuro imaging, structured data]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382444</person_id>
				<author_profile_id><![CDATA[81414620888]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andreas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hapfelmeier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382445</person_id>
				<author_profile_id><![CDATA[81414599883]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jana]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schmidt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382446</person_id>
				<author_profile_id><![CDATA[81414608707]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Marianne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mueller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382447</person_id>
				<author_profile_id><![CDATA[81100175708]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kramer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382448</person_id>
				<author_profile_id><![CDATA[81414620871]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perneczky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382449</person_id>
				<author_profile_id><![CDATA[81414617835]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kurz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382450</person_id>
				<author_profile_id><![CDATA[81414621047]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Drzezga]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511342</article_id>
		<sort_key>390</sort_key>
		<display_label>Pages</display_label>
		<pages>223-232</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[Inlier-Based Outlier Detection via Direct Density Ratio Estimation]]></title>
		<page_from>223</page_from>
		<page_to>232</page_to>
		<doi_number>10.1109/ICDM.2008.49</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511342</url>
		<abstract>
			<par><![CDATA[We propose a new statistical approach to the problem of inlier-based outlier detection, i.e.,finding outliers in the test set based on the training set consisting only of inliers. Our key idea is to use the ratio of training and test data densities as an outlier score; we estimate the ratio directly in a semi-parametric fashion without going through density estimation. Thus our approach is expected to have better performance in high-dimensional problems. Furthermore, the applied algorithm for density ratio estimation is equipped with a natural cross-validation procedure, allowing us to objectively optimize the value of tuning parameters such as the regularization parameter and the kernel width. The algorithm offers a closed-form solution as well as a closed-form formula for the leave-one-out error. Thanks to this, the proposed outlier detection me thod is computationally very efficient and is scalable to massive datasets. Simulations with benchmark and real-world datasets illustrate the usefulness of the proposed approach.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[outlier detection, density ratio, importance]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383011</person_id>
				<author_profile_id><![CDATA[81414611778]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shohei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hido]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383012</person_id>
				<author_profile_id><![CDATA[81329492590]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yuta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsuboi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383013</person_id>
				<author_profile_id><![CDATA[81100105757]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hisashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kashima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383014</person_id>
				<author_profile_id><![CDATA[81100105605]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Masashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sugiyama]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383015</person_id>
				<author_profile_id><![CDATA[81100604817]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Takafumi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kanamori]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511343</article_id>
		<sort_key>400</sort_key>
		<display_label>Pages</display_label>
		<pages>233-242</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Supervised Inductive Learning with Lotka-Volterra Derived Models]]></title>
		<page_from>233</page_from>
		<page_to>242</page_to>
		<doi_number>10.1109/ICDM.2008.108</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511343</url>
		<abstract>
			<par><![CDATA[We present a classification algorithm built on our adaptation of the Generalized Lotka-Volterra model, well-known in mathematical ecology. The training algorithm itself consists only of computing several scalars, per each training vector, using a single global user parameter and then solving a linear system of equations. Construction of the system matrix is driven by our model and based on kernel functions. The model allows an interesting point of view of kernels' role in the inductive learning process. We describe the model through axiomatic postulates. Finally, we present the results of the preliminary validation experiments.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[classification, supervised inductive machine-learning, model-driven algorithm, data mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381940</person_id>
				<author_profile_id><![CDATA[81414619056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Karen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hovsepian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381941</person_id>
				<author_profile_id><![CDATA[81414591842]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Anselmo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381942</person_id>
				<author_profile_id><![CDATA[81100471920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Subhasish]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mazumdar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511344</article_id>
		<sort_key>410</sort_key>
		<display_label>Pages</display_label>
		<pages>243-252</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[A Novel Language-Model-Based Approach for Image Object Mining and Re-ranking]]></title>
		<page_from>243</page_from>
		<page_to>252</page_to>
		<doi_number>10.1109/ICDM.2008.83</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511344</url>
		<abstract>
			<par><![CDATA[One leading framework for image object mining is the bag-of-words (BOW) approach. The idea is to encode an image as a collection of visual words of the quantized local patches. Objects in the image can then be retrieved through inferring the semantic topics associated with the set of visual words. However, the visual BOW mining framework is apt to suffer from the so-called term-mismatch problem (a.k.a. vocabulary problem). This is caused by the poverty of query information, and consequently becomes an obstacle to deal with synonymy (i.e., different visual words for describing the same object). In this paper, we propose a novel language-model-based approach with pseudo-relevance feedback for addressing the vocabulary problem in visual BOW mining. We employ the pseudo positive images produced in response to the original query as a set of &#8220;cues&#8221; to gradually refine the query language model. Unlike traditional approaches that only ruggedly append feedback information into the original query, the proposed approach reconstructs the query language model with finer granularities so that the query concepts can be captured more accurately. The proposed approach is experimentally evaluated using two different types of image object databases. Our algorithms are shown to bring significant improvement in the retrieval accuracy over a non-feedback baseline, and achieve better performance than conventional feedback approaches.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Bag of words, Image object retrieval, Language model, Pseudo relevance feedback]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383592</person_id>
				<author_profile_id><![CDATA[81332505111]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jen-Hao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hsiao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383593</person_id>
				<author_profile_id><![CDATA[81100119964]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chu-Song]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383594</person_id>
				<author_profile_id><![CDATA[81414598889]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ming-Syan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511345</article_id>
		<sort_key>420</sort_key>
		<display_label>Pages</display_label>
		<pages>253-262</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[Maximum Margin Clustering with Pairwise Constraints]]></title>
		<page_from>253</page_from>
		<page_to>262</page_to>
		<doi_number>10.1109/ICDM.2008.65</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511345</url>
		<abstract>
			<par><![CDATA[Maximum margin clustering (MMC), which extends the theory of support vector machine to unsupervised learning, has been attracting considerable attention recently. The existing approaches mainly focus on reducing the computational complexity of MMC. The accuracy of these methods, however, has not always been guaranteed. In this paper, we propose to incorporate additional side-information, which is in the form of pairwise constraints, into MMC to further improve its performance. A set of pairwise loss functions are introduced into the clustering objective function which effectively penalize the violation of the given constraints. We show that the resulting optimization problem can be easily solved via constrained concave-convex procedure (CCCP). Moreover, for constrained multi-class MMC, we present an efficient cutting-plane algorithm to solve the sub-problem in each iteration of CCCP. The experiments demonstrate that the pairwise constrained MMC algorithms considerably outperform the unconstrained MMC algorithms and two other clustering algorithms that exploit the same type of side-information.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383595</person_id>
				<author_profile_id><![CDATA[81414609272]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383596</person_id>
				<author_profile_id><![CDATA[81414610670]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jingdong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383597</person_id>
				<author_profile_id><![CDATA[81337495039]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Nenghai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383598</person_id>
				<author_profile_id><![CDATA[81100533893]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Xian-Sheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hua]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511352</article_id>
		<sort_key>430</sort_key>
		<display_label>Pages</display_label>
		<pages>263-272</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Collaborative Filtering for Implicit Feedback Datasets]]></title>
		<page_from>263</page_from>
		<page_to>272</page_to>
		<doi_number>10.1109/ICDM.2008.22</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511352</url>
		<abstract>
			<par><![CDATA[A common task of recommender systems is to improve customer experience through personalized recommendations based on prior implicit feedback. These systems passively track different sorts of user behavior, such as purchase history, watching habits and browsing activity, in order to model user preferences. Unlike the much more extensively researched explicit feedback, we do not have any direct input from the users regarding their preferences. In particular, we lack substantial evidence on which products consumer dislike. In this work we identify unique properties of implicit feedback datasets. We propose treating the data as indication of positive and negative preference associated with vastly varying confidence levels. This leads to a factor model which is especially tailored for implicit feedback recommenders. We also suggest a scalable optimization procedure, which scales linearly with the data size. The algorithm is used successfully within a recommender system for television shows. It compares favorably with well tuned implementations of other known methods. In addition, we offer a novel way to give explanations to recommendations given by this factor model.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Collaborative filtering, recommender system, implicit feedback]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383033</person_id>
				<author_profile_id><![CDATA[81413597153]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yifan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383034</person_id>
				<author_profile_id><![CDATA[81100202295]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yehuda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Koren]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383035</person_id>
				<author_profile_id><![CDATA[81100242006]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Volinsky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511353</article_id>
		<sort_key>440</sort_key>
		<display_label>Pages</display_label>
		<pages>273-282</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[Semi-supervised Learning from General Unlabeled Data]]></title>
		<page_from>273</page_from>
		<page_to>282</page_to>
		<doi_number>10.1109/ICDM.2008.61</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511353</url>
		<abstract>
			<par><![CDATA[We consider the problem of Semi-supervised Learning (SSL) from general unlabeled data, which may contain irrelevant samples. Within the binary setting, our model manages to better utilize the information from unlabeled data by formulating them as a three-class ($-1,+1, 0$) mixture, where class $0$ represents the irrelevant data. This distinguishes our work from the traditional SSL problem where unlabeled data are assumed to contain relevant samples only, either $+1$ or $-1$, which are forced to be the same as the given labeled samples. This work is also different from another family of popular models, universum learning (universum means "irrelevant" data), in that the universum need not to be specified beforehand. One significant contribution of our proposed framework is that such irrelevant samples can be automatically detected from the available unlabeled data, even though they are mixed with relevant data. This hence presents a general SSL framework that does not force "clean" unlabeled data.More importantly, we formulate this general learning framework as a Semi-definite Programming problem, making it solvable in polynomial time. A series of experiments demonstrate that the proposed framework can outperform the traditional SSL on both synthetic and real data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Semi-supervised Learning, General Unlabeled Data, SDP]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385216</person_id>
				<author_profile_id><![CDATA[81339505908]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kaizhu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385217</person_id>
				<author_profile_id><![CDATA[81384603634]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zenglin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385218</person_id>
				<author_profile_id><![CDATA[81100193887]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Irwin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[King]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385219</person_id>
				<author_profile_id><![CDATA[81100033051]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Lyu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511354</article_id>
		<sort_key>450</sort_key>
		<display_label>Pages</display_label>
		<pages>283-292</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[Metropolis Algorithms for Representative Subgraph Sampling]]></title>
		<page_from>283</page_from>
		<page_to>292</page_to>
		<doi_number>10.1109/ICDM.2008.124</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511354</url>
		<abstract>
			<par><![CDATA[While data mining in chemoinformatics studied graph data with dozens of nodes, systems biology and the Internet are now generating graph data with thousands and millions of nodes. Hence data mining faces the algorithmic challenge of coping with this significant increase in graph size: Classic algorithms for data analysis are often too expensive and too slow on large graphs. While one strategy to overcome this problem is to design novel efficient algorithms, the other is to 'reduce' the size of the large graph by sampling. This is the scope of this paper: We will present novel Metropolis algorithms for sampling a 'representative' small subgraph from the original large graph, with 'representative' describing the requirement that the sample shall preserve crucial graph properties of the original graph. In our experiments, we improve over the pioneering work of Leskovec and Faloutsos (KDD 2006), by producing representative subgraph samples that are both smaller and of higher quality than those produced by other methods from the literature.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Metropolis, graph mining, representative subgraph sampling, Markov Chain Monte Carlo]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382473</person_id>
				<author_profile_id><![CDATA[81414618765]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[H&#252;bler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382474</person_id>
				<author_profile_id><![CDATA[81414593328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kriegel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382475</person_id>
				<author_profile_id><![CDATA[81100155678]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Karsten]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Borgwardt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382476</person_id>
				<author_profile_id><![CDATA[81100572858]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Zoubin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ghahramani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511355</article_id>
		<sort_key>460</sort_key>
		<display_label>Pages</display_label>
		<pages>293-302</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[Learning on Weighted Hypergraphs to Integrate Protein Interactions and Gene Expressions for Cancer Outcome Prediction]]></title>
		<page_from>293</page_from>
		<page_to>302</page_to>
		<doi_number>10.1109/ICDM.2008.37</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511355</url>
		<abstract>
			<par><![CDATA[Building reliable predictive models from multiple complementary genomic data for cancer study is a crucial step towards successful cancer treatment and a full understanding of the underlying biological principles. To tackle this challenging data integration problem, we propose a hypergraph-based learning algorithm called HyperGene to integrate microarray gene expressions and protein-protein interactions for cancer outcome prediction and biomarker identification. HyperGene is a robust two-step iterative method that alternatively finds the optimal outcome prediction and the optimal weighting of the marker genes guided by a protein-protein interaction network. Under the hypothesis that cancer-related genes tend to interact with each other, the HyperGene algorithm uses a protein-protein interaction network as prior knowledge by imposing a consistent weighting of interacting genes. Our experimental results on two large-scale breast cancer gene expression datasets show that HyperGene utilizing a curated protein-protein interaction network achieves significantly improved cancer outcome prediction. Moreover, HyperGene can also retrieve many known cancer genes as highly weighted marker genes.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[spectral graph learning, semi-supervised learning, biomarker identification, cancer genomics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385220</person_id>
				<author_profile_id><![CDATA[81448593689]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[TaeHyun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hwang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385221</person_id>
				<author_profile_id><![CDATA[81388597486]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ze]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385222</person_id>
				<author_profile_id><![CDATA[81414621118]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Rui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuangy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385223</person_id>
				<author_profile_id><![CDATA[81388594984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jean-Pierre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kocher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511356</article_id>
		<sort_key>470</sort_key>
		<display_label>Pages</display_label>
		<pages>303-312</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[A Fast Method to Mine Frequent Subsequences from Graph Sequence Data]]></title>
		<page_from>303</page_from>
		<page_to>312</page_to>
		<doi_number>10.1109/ICDM.2008.106</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511356</url>
		<abstract>
			<par><![CDATA[In recent years, the mining of a complete set of frequent subgraphs from labeled graph data has been extensively studied.However, to our best knowledge, almost no methods have been proposed to find frequent subsequences of graphs from a set of graph sequences. In this paper, we define a novel class of graph subsequences by introducing axiomatic rules of graph transformation, their admissibility constraints and a union graph. Then we propose an efficient approach named "GTRACE'' to enumerate frequent transformation subsequences (FTSs) of graphs from a given set of graph sequences. Its fundamental performance has been evaluated by using artificial datasets, and its practicality has been confirmed through the experiments using real world datasets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Frequent Pattern, Graph Sequence, Transformation Rule, Admissibility]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384679</person_id>
				<author_profile_id><![CDATA[81100361535]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Akihiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Inokuchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384680</person_id>
				<author_profile_id><![CDATA[81100117705]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Takashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Washio]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511364</article_id>
		<sort_key>480</sort_key>
		<display_label>Pages</display_label>
		<pages>313-322</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[Overlapping Matrix Pattern Visualization]]></title>
		<subtitle><![CDATA[A Hypergraph Approach]]></subtitle>
		<page_from>313</page_from>
		<page_to>322</page_to>
		<doi_number>10.1109/ICDM.2008.102</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511364</url>
		<abstract>
			<par><![CDATA[In this work, we study a visual data mining problem: Given a set of discovered overlapping submatrices of interest, how can we order the rows and columns of the data matrix to best display these submatrices and their relationships? We find this problem can be converted to the hypergraph ordering problem, which generalizes the traditional minimal linear arrangement (or graph ordering) problem and then we are able to prove the NP-hardness of this problem. We propose a novel iterative algorithm which utilize the existing graph ordering algorithm to solve the optimal visualization problem. This algorithm can always converge to a local minimum. The detailed experimental evaluation using a set of publicly available transactional datasets demonstrates the effectiveness and efficiency of the proposed algorithm.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Matrix Pattern Visualization, Hypergraph, Hyperrectangle, Minimum Linear Arrangement Problem]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382511</person_id>
				<author_profile_id><![CDATA[81100054574]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ruoming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382512</person_id>
				<author_profile_id><![CDATA[81452605036]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382513</person_id>
				<author_profile_id><![CDATA[81350586594]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fuhry]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382514</person_id>
				<author_profile_id><![CDATA[81448599698]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Feodor]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Dragan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511365</article_id>
		<sort_key>490</sort_key>
		<display_label>Pages</display_label>
		<pages>323-332</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>44</seq_no>
		<title><![CDATA[A Robust Discriminative Term Weighting Based Linear Discriminant Method for Text Classification]]></title>
		<page_from>323</page_from>
		<page_to>332</page_to>
		<doi_number>10.1109/ICDM.2008.26</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511365</url>
		<abstract>
			<par><![CDATA[Text classification is widely used in applications ranging from e-mail filtering to review classification. Many of these applications demand that the classification method be efficient and robust, yet produce accurate categorizations by using the terms in the documents only. We present a supervised text classification method based on discriminative term weighting, discrimination information pooling, and linear discrimination. Terms in the documents are assigned weights according to the discrimination information they provide for one category over the others. These weights also serve to partition the terms into two sets. A linear opinion pool is adopted for combining the discrimination information provided by each set of terms yielding a two-dimensional feature space. Subsequently, a linear discriminant function is learned to categorize the documents in the feature space. We provide intuitive and empirical evidence of the robustness of our method with three term weighting strategies. Experimental results are presented for data sets from three different application areas. The results show that our method's accuracy is higher than other popular methods, especially when there is a distribution shift from training to testing sets. Moreover, our method is simple yet robust to different application domains and small training set sizes.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[text classification, term weighting, generative-discriminative algorithm]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381993</person_id>
				<author_profile_id><![CDATA[81361606039]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Khurum]]></first_name>
				<middle_name><![CDATA[Nazir]]></middle_name>
				<last_name><![CDATA[Junejo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381994</person_id>
				<author_profile_id><![CDATA[81318498394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Asim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Karim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511366</article_id>
		<sort_key>500</sort_key>
		<display_label>Pages</display_label>
		<pages>333-342</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>45</seq_no>
		<title><![CDATA[Clustering Uncertain Data Using Voronoi Diagrams]]></title>
		<page_from>333</page_from>
		<page_to>342</page_to>
		<doi_number>10.1109/ICDM.2008.31</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511366</url>
		<abstract>
			<par><![CDATA[We study the problem of clustering uncertain objects whose locations are described by probability density functions (pdf). We show that the UK-means algorithm, which generalises the k-means algorithm to handle uncertain objects, is very inefficient. The inefficiency comes from the fact that UK-means computes expected distances (ED) between objects and cluster representatives. For arbitrary pdf's, expected distances are computed by numerical integrations, which are costly operations. We propose pruning techniques that are based on Voronoi diagrams to reduce the number of expected distance calculation. These techniques are analytically proven to be more effective than the basic bounding-box-based technique previous known in the literature. We conduct experiments to evaluate the effectiveness of our pruning techniques and to show that our techniques significantly outperform previous methods.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[k-means, UK-means, uncertain data, classification, Voronoi diagram]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385241</person_id>
				<author_profile_id><![CDATA[81100519737]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ben]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385242</person_id>
				<author_profile_id><![CDATA[81100411220]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sau]]></first_name>
				<middle_name><![CDATA[Dan]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385243</person_id>
				<author_profile_id><![CDATA[81100460281]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Cheung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385244</person_id>
				<author_profile_id><![CDATA[81100316993]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wai-Shing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385245</person_id>
				<author_profile_id><![CDATA[81414601689]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Chan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511367</article_id>
		<sort_key>510</sort_key>
		<display_label>Pages</display_label>
		<pages>343-352</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>46</seq_no>
		<title><![CDATA[SCS]]></title>
		<subtitle><![CDATA[A New Similarity Measure for Categorical Sequences]]></subtitle>
		<page_from>343</page_from>
		<page_to>352</page_to>
		<doi_number>10.1109/ICDM.2008.43</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511367</url>
		<abstract>
			<par><![CDATA[Measuring the similarity between categorical sequences is a fundamental process in many data mining applications. A key issue is to extract and make use of significant features hidden behind the chronological and structural dependencies found in these sequences. Almost all existing algorithms designed to perform this task are based on the matching of patterns in chronological order, but such sequences often have similar structural features in chronologically different positions. In this paper we propose SCS, a novel method for measuring the similarity between categorical sequences, based on an original pattern matching scheme that makes it possible to capture chronological and non-chronological dependencies. SCS captures significant patterns that represent the natural structure of sequences, and reduces the influence of those representing noise. It constitutes an effective approach for measuring the similarity of data such as biological sequences, natural language texts and financial transactions. To show its effectiveness, we have tested SCS extensively on a range of datasets, and compared the results with those obtained by various mainstream algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385246</person_id>
				<author_profile_id><![CDATA[81414620815]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Abdellali]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kelil]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385247</person_id>
				<author_profile_id><![CDATA[81100216088]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shengrui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511368</article_id>
		<sort_key>520</sort_key>
		<display_label>Pages</display_label>
		<pages>353-362</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>47</seq_no>
		<title><![CDATA[Toward Faster Nonnegative Matrix Factorization]]></title>
		<subtitle><![CDATA[A New Algorithm and Comparisons]]></subtitle>
		<page_from>353</page_from>
		<page_to>362</page_to>
		<doi_number>10.1109/ICDM.2008.149</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511368</url>
		<abstract>
			<par><![CDATA[Nonnegative Matrix Factorization (NMF) is a dimension reduction method that has been widely used for various tasks including text mining, pattern analysis, clustering, and cancer class discovery. The mathematical formulation for NMF appears as a non-convex optimization problem, and various types of algorithms have been devised to solve the problem. The alternating nonnegative least squares (ANLS) framework is a block coordinate descent approach for solving NMF, which was recently shown to be theoretically sound and empirically efficient. In this paper, we present a novel algorithm for NMF based on the ANLS framework. Our new algorithm builds upon the block principal pivoting method for the nonnegativity constrained least squares problem that overcomes some limitations of active set methods. We introduce ideas to efficiently extend the block principal pivoting method within the context of NMF computation. Our algorithm inherits the convergence theory of the ANLS framework and can easily be extended to other constrained NMF formulations. Comparisons of algorithms using datasets that are from real life applications as well as those artificially generated show that the proposed new algorithm outperforms existing ones in computational speed.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[nonnegative matrix factorization, nonnegativity constrained least squares, block principal pivoting]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383059</person_id>
				<author_profile_id><![CDATA[81414601200]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jingu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383060</person_id>
				<author_profile_id><![CDATA[81414609293]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haesun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511376</article_id>
		<sort_key>530</sort_key>
		<display_label>Pages</display_label>
		<pages>363-372</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>48</seq_no>
		<title><![CDATA[Scalable Tensor Decompositions for Multi-aspect Data Mining]]></title>
		<page_from>363</page_from>
		<page_to>372</page_to>
		<doi_number>10.1109/ICDM.2008.89</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511376</url>
		<abstract>
			<par><![CDATA[Modern applications such as Internet traffic, telecommunication records, and large-scale social networks generate massive amounts of data with multiple aspects and high dimensionalities. Tensors (i.e., multi-way arrays) provide a natural representation for such data. Consequently, tensor decompositions such as Tucker become important tools for summarization and analysis.One major challenge is how to deal with high-dimensional, sparse data. In other words, how do we compute decompositions of tensors where most of the entries of the tensor are zero. Specialized techniques are needed for computing the Tucker decompositions for sparse tensors because standard algorithms do not account for the sparsity of the data. As a result, a surprising phenomenon is observed by practitioners: Despite the fact that there is enough memory to store both the input tensors and the factorized output tensors, memory overflows occur during the tensor factorization process. To address this intermediate blowup problem, we propose Memory-Efficient Tucker (MET). Based on the available memory, MET adaptively selects the right execution strategy during the decomposition. We provide quantitative and qualitative evaluation of MET on real tensors. It achieves over 1000X space reduction without sacrificing speed; it also allows us to work with much larger tensors that were too big to handle before. Finally, we demonstrate a data mining case-study using MET.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Data mining, Tensor Decomposition, Tucker Decomposition, Sparse data]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385262</person_id>
				<author_profile_id><![CDATA[81100225962]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tamara]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Kolda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385263</person_id>
				<author_profile_id><![CDATA[81455605573]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jimeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511377</article_id>
		<sort_key>540</sort_key>
		<display_label>Pages</display_label>
		<pages>373-382</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>49</seq_no>
		<title><![CDATA[Mining Periodic Behavior in Dynamic Social Networks]]></title>
		<page_from>373</page_from>
		<page_to>382</page_to>
		<doi_number>10.1109/ICDM.2008.104</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511377</url>
		<abstract>
			<par><![CDATA[Social interactions that occur regularly typically correspond to significant yet often infrequent and hard to detect interaction patterns. To identify such regular behavior, we propose a new mining problem of finding periodic or near periodic subgraphs in dynamic social networks. We analyze the computational complexity of theproblem, showing that, unlike any of the related subgraph mining problems, it is polynomial. We propose a practical, efficient and scalable algorithm to find such subgraphs that takes imperfect periodicity into account. We demonstrate the applicability of our approach on severalreal-world networks and extract meaningful and interesting periodic interaction patterns.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[social networks, pattern mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382022</person_id>
				<author_profile_id><![CDATA[81414594093]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mayank]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lahiri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382023</person_id>
				<author_profile_id><![CDATA[81100625676]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tanya]]></first_name>
				<middle_name><![CDATA[Y.]]></middle_name>
				<last_name><![CDATA[Berger-Wolf]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511378</article_id>
		<sort_key>550</sort_key>
		<display_label>Pages</display_label>
		<pages>383-392</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>50</seq_no>
		<title><![CDATA[Unsupervised Face Annotation by Mining the Web]]></title>
		<page_from>383</page_from>
		<page_to>392</page_to>
		<doi_number>10.1109/ICDM.2008.47</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511378</url>
		<abstract>
			<par><![CDATA[Searching for images of people is an essential task for image and video search engines. However, current search engines have limited capabilities for this task since they rely on text associated with images and video, and such text is likely to return many irrelevant results. We propose a method for retrieving relevant faces of one person by learning the visual consistency among results retrieved from text correlation-based search engines. The method consists of two steps. In the first step, each candidate face obtained from a text-based search engine is ranked with a score that measures the distribution of visual similarities among the faces. Faces that are possibly very relevant or irrelevant are ranked at the top or bottom of the list, respectively. The second step improves this ranking by treating this problem as a classification problem in which input faces are classified as &#8217;person-X&#8217; or &#8217;non-person-X&#8217;; and the faces are re-ranked according to their relevant score inferred from the classifier&#8217;s probability output. To train this classifier, we use a bagging-based framework to combine results from multiple weak classifiers trained using different subsets. These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step. In this way, the accuracy of the ranked list increases after a number of iterations. Experimental results on various face sets retrieved from captions of news photos show that the retrieval performance improved after each iteration, with the final performance being higher than those of the existing algorithms.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[face retrieval, face annotation, ensemble learning, visual consistency, unsupervised learning]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383676</person_id>
				<author_profile_id><![CDATA[81319495311]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Duy-Dinh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Le]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383677</person_id>
				<author_profile_id><![CDATA[81100094722]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shin'ichi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Satoh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511379</article_id>
		<sort_key>560</sort_key>
		<display_label>Pages</display_label>
		<pages>393-402</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>51</seq_no>
		<title><![CDATA[Border Sampling through Coupling Markov Chain Monte Carlo]]></title>
		<page_from>393</page_from>
		<page_to>402</page_to>
		<doi_number>10.1109/ICDM.2008.52</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511379</url>
		<abstract>
			<par><![CDATA[Recently, Progressive Border Sampling (PBS) was proposed for sample selection in supervised learning by progressively learning an augmented full border from small labeled datasets. However, this quadratic learning algorithm is inapplicable to large datasets. In this paper, we incorporate the PBS to a state of the art technique called Coupling Markov Chain Monte Carlo (CMCMC) in an attempt to scale the original algorithm up on large labeled datasets. The CMCMC can produce an exact sample while a naive strategy for Markov Chain Monte Carlo cannot guarantee the convergence to a stationary distribution. The resulting CMCMC-PBS algorithm is thus proposed for border sampling on large datasets. CMCMC-PBS exhibits several remarkable characteristics: linear time complexity, learner-independence, and a consistent convergence to an optimal sample from the original training sets by learning from their subsamples. Our experimental results on the 33 either small or large labeled datasets from the UCIKDD repository and a nuclear security application show that our new approach outperforms many previous sampling techniques for sample selection.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[sample selection, border identification, markov chain monte carlo]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382024</person_id>
				<author_profile_id><![CDATA[81442602493]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Guichong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382025</person_id>
				<author_profile_id><![CDATA[81100572099]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nathalie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Japkowicz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382026</person_id>
				<author_profile_id><![CDATA[81414621528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Trevor]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Stocki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382027</person_id>
				<author_profile_id><![CDATA[81414620678]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[Kurt]]></middle_name>
				<last_name><![CDATA[Ungar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511380</article_id>
		<sort_key>570</sort_key>
		<display_label>Pages</display_label>
		<pages>403-412</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>52</seq_no>
		<title><![CDATA[Computationally Efficient Estimators for Dimension Reductions Using Stable Random Projections]]></title>
		<page_from>403</page_from>
		<page_to>412</page_to>
		<doi_number>10.1109/ICDM.2008.95</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511380</url>
		<abstract>
			<par><![CDATA[The method of stable random projections is an efficient tool for computing the l&#945; distances using low memory, where 0 < &#945; &#8804; 2 may be viewed as a tuning parameter. This method boils down to a statistical estimation task and various estimators have been proposed, based on the geometric mean, harmonic mean, and fractional power etc. This study proposes the optimal quantile estimator, whose main operation is selecting, which is considerably less expensive than taking fractional power, the main operation in previous estimators. Our experiments report that this estimator is nearly one order of magnitude more computationally efficient than previous estimators. For large-scale tasks in which storing and computing pairwise distances is a serious bottleneck, this estimator should be desirable. In addition to its computational advantage, the optimal quantile estimator exhibits nice theoretical properties. It is more accurate than previous estimators when &#945; > 1. We derive its theoretical error bound and establish the explicit (i.e., no hidden constants) sample complexity bound.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383678</person_id>
				<author_profile_id><![CDATA[81414610936]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511387</article_id>
		<sort_key>580</sort_key>
		<display_label>Pages</display_label>
		<pages>413-422</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>53</seq_no>
		<title><![CDATA[Isolation Forest]]></title>
		<page_from>413</page_from>
		<page_to>422</page_to>
		<doi_number>10.1109/ICDM.2008.17</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511387</url>
		<abstract>
			<par><![CDATA[Most existing model-based approaches to anomaly detection construct a profile of normal instances, then identify instances that do not conform to the normal profile as anomalies. This paper proposes a fundamentally different model-based method that explicitly isolates anomalies instead of profiles normal points. To our best knowledge, the concept of isolation has not been explored in current literature. The use of isolation enables the proposed method, iForest, to exploit sub-sampling to an extent that is not feasible in existing methods, creating an algorithm which has a linear time complexity with a low constant and a low memory requirement. Our empirical evaluation shows that iForest performs favourably to ORCA, a near-linear time complexity distance-based method, LOF and Random Forests in terms of AUC and processing time, and especially in large data sets. iForest also works well in high dimensional problems which have a large number of irrelevant attributes, and in situations where training set does not contain any anomalies.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[anomaly detection, outlier detection, novelty detection, isolation forest, binary trees, model based]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385302</person_id>
				<author_profile_id><![CDATA[81443594111]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fei]]></first_name>
				<middle_name><![CDATA[Tony]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385303</person_id>
				<author_profile_id><![CDATA[81100367824]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kai]]></first_name>
				<middle_name><![CDATA[Ming]]></middle_name>
				<last_name><![CDATA[Ting]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385304</person_id>
				<author_profile_id><![CDATA[81451593001]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Zhi-Hua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511388</article_id>
		<sort_key>590</sort_key>
		<display_label>Pages</display_label>
		<pages>423-432</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>54</seq_no>
		<title><![CDATA[TEFE]]></title>
		<subtitle><![CDATA[A Time-Efficient Approach to Feature Extraction]]></subtitle>
		<page_from>423</page_from>
		<page_to>432</page_to>
		<doi_number>10.1109/ICDM.2008.48</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511388</url>
		<abstract>
			<par><![CDATA[With the rapid evolution of internet applications, people all over the world are sharing pictures, videos and audios online, and thus, content-based analysis is often demanded. Test efficiency is crucial to the success of online information processing. One obstacle to high-speed testing is the time cost of feature extraction for test objects, particularly for objects with complex representation such as images, videos and audios. In this paper, we study the problem of reducing test time cost by extracting cheap but sufficient features. We propose the TEFE (Time-Efficient Feature Extraction) approach, which balances between the test accuracy and test time cost by extracting a proper subset of features for each test object. In the implementation, TEFE trains a sequence of support vector machines and classifies each test object cascadingly. Empirical study shows that TEFE is time efficient while holding a classification accuracy close to that of using all features. It also shows that the test time is linearly adjustable in TEFE.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384229</person_id>
				<author_profile_id><![CDATA[81414605682]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Li-Ping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384230</person_id>
				<author_profile_id><![CDATA[81414608696]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384231</person_id>
				<author_profile_id><![CDATA[81414616861]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384232</person_id>
				<author_profile_id><![CDATA[81544248656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Zhi-Hua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511389</article_id>
		<sort_key>600</sort_key>
		<display_label>Pages</display_label>
		<pages>433-442</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>55</seq_no>
		<title><![CDATA[Transductive Component Analysis]]></title>
		<page_from>433</page_from>
		<page_to>442</page_to>
		<doi_number>10.1109/ICDM.2008.101</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511389</url>
		<abstract>
			<par><![CDATA[In this paper, we study semi-supervised linear dimensionality reduction. Beyond conventional supervised methods which merely consider labeled instances, the semi-supervised scheme allows to leverage abundant and ample unlabeled instances into learning so as to achieve better generalization performance. Under semi-supervised settings, our objective is to learn a smooth as well as discriminative subspace and linear dimensionality reduction is thus achieved by mapping all samples into the subspace. Specifically, we present the Transductive Component Analysis (TCA) algorithm to generate such a subspace founded on a graph-theoretic framework.Considering TCA is non-orthogonal, we further present the Orthogonal Transductive Component Analysis (OTCA) algorithm to iteratively produce a series of orthogonal basis vectors. OTCA has better discriminating power than TCA. Experiments carried out on synthetic and real-world datasets by OTCA show a clear improvement over the results of representative dimensionality reduction algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385305</person_id>
				<author_profile_id><![CDATA[81375601156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385306</person_id>
				<author_profile_id><![CDATA[81100159571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dacheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385307</person_id>
				<author_profile_id><![CDATA[81452603630]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jianzhuang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511390</article_id>
		<sort_key>610</sort_key>
		<display_label>Pages</display_label>
		<pages>443-452</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>56</seq_no>
		<title><![CDATA[Modeling and Predicting the Helpfulness of Online Reviews]]></title>
		<page_from>443</page_from>
		<page_to>452</page_to>
		<doi_number>10.1109/ICDM.2008.94</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511390</url>
		<abstract>
			<par><![CDATA[Online reviews provide a valuable resource for potential customers to make purchase decisions. However, the sheer volume of available reviews as well as the large variations in the review quality present a big impediment to the effective use of the reviews, as the most helpful reviews may be buried in the large amount of low quality reviews. The goal of this paper is to develop models and algorithms for predicting the helpfulness of reviews, which provides the basis for discovering the most helpful reviews for given products. We first show that the helpfulness of a review depends on three important factors: the reviewer&#8217;s expertise, the writing style of the review, and the timeliness of the review. Based on the analysis of those factors, we present a nonlinear regression model for helpfulness prediction. Our empirical study on the IMDB movie reviews dataset demonstrates that the proposed approach is highly effective.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Review mining, Helpfulness prediction]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383102</person_id>
				<author_profile_id><![CDATA[81350592631]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383103</person_id>
				<author_profile_id><![CDATA[81100080207]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xiangji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383104</person_id>
				<author_profile_id><![CDATA[81100329796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Aijun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[An]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383105</person_id>
				<author_profile_id><![CDATA[81309496986]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Xiaohui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511391</article_id>
		<sort_key>620</sort_key>
		<display_label>Pages</display_label>
		<pages>453-461</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>57</seq_no>
		<title><![CDATA[LBF]]></title>
		<subtitle><![CDATA[A Labeled-Based Forecasting Algorithm and Its Application to Electricity Price Time Series]]></subtitle>
		<page_from>453</page_from>
		<page_to>461</page_to>
		<doi_number>10.1109/ICDM.2008.129</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511391</url>
		<abstract>
			<par><![CDATA[A new approach is presented in this work with the aim of predicting time series behaviors. A previous labeling of the samples is obtained utilizing clustering techniques and the forecasting is applied using the information provided by the clustering. Thus, the whole data set is discretized with the labels assigned to each data point and the main novelty is that only these labels are used to predict the future behavior of the time series, avoiding using the real values of the time series until the process ends. The results returned by the algorithm, however, are not labels but the nominal value of the point that is required to be predicted. The algorithm based on labeled (LBF) has been tested in several energy-related time series and a notable improvement in the prediction has been achieved.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Clustering, time series, forecasting, neighbourhood]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383713</person_id>
				<author_profile_id><![CDATA[81330495130]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Francisco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mart&#237;nez-&#193;lvarez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383714</person_id>
				<author_profile_id><![CDATA[81460649956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alicia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Troncoso]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383715</person_id>
				<author_profile_id><![CDATA[81100568011]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jos&#233;]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Riquelme]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383716</person_id>
				<author_profile_id><![CDATA[81310482853]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jes&#250;s]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Aguilar-Ruiz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511399</article_id>
		<sort_key>630</sort_key>
		<display_label>Pages</display_label>
		<pages>462-471</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>58</seq_no>
		<title><![CDATA[Enhancing the Stability of Spectral Ordering with Sparsification and Partial Supervision]]></title>
		<subtitle><![CDATA[Application to Paleontological Data]]></subtitle>
		<page_from>462</page_from>
		<page_to>471</page_to>
		<doi_number>10.1109/ICDM.2008.120</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511399</url>
		<abstract>
			<par><![CDATA[Recent studies have demonstrated the prospects of data mining algorithms for addressing the task of seriation in paleontological data (i.e. the age-based ordering of the sites of excavation). A prominent approach is spectral ordering that computes a similarity measure between the sites and orders them such that similar sites become adjacent and dissimilar sites are placed far apart. In the paleontological domain, the similarity measure is based on the mammal genera whose remains are retrieved at each site of excavation. Although spectral ordering achieves good performance in the seriation task, it ignores the background knowledge that is naturally present in the domain, as paleontologists can derive the ages of the sites of excavation within some accuracy. On the other hand, the age information is uncertain, so the best approach would be to combine the background knowledge with the information on mammal co-occurrences. Motivated by this kind of partial supervision we propose a novel semi-supervised spectral ordering algorithm. Our algorithm modifies the Laplacian matrix used in spectral ordering, such that domain knowledge of the ordering is taken into account. Also, it performs feature selection (sparsification) by discarding features that contribute most to the unwanted variability of the data in bootstrap sampling. The theoretical properties of the proposed algorithm are thoroughly analyzed and it is demonstrated that the proposed framework enhances the stability of the spectral ordering output and induces computational gains.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[spectral ordering, Laplacian, feature selection, eigengap, supervision]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381540</person_id>
				<author_profile_id><![CDATA[81384612275]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dimitrios]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mavroeidis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381541</person_id>
				<author_profile_id><![CDATA[81100555689]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ella]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bingham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511392</article_id>
		<sort_key>640</sort_key>
		<display_label>Pages</display_label>
		<pages>472-481</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>59</seq_no>
		<title><![CDATA[Scaling up Classifiers to Cloud Computers]]></title>
		<page_from>472</page_from>
		<page_to>481</page_to>
		<doi_number>10.1109/ICDM.2008.99</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511392</url>
		<abstract>
			<par><![CDATA[As the size of available datasets has grown from Megabytes to Gigabytes and now into Terabytes, machine learning algorithms and computing infrastructures have continuously evolved in an effort to keep pace. But at large scales, mining for useful patterns still presents challenges in terms of data management as well as computation. These issues can be addressed by dividing both data and computation to build ensembles of classifiers in a distributed fashion, but trade-offs in cost, performance, and accuracy must be considered when designing or selecting an appropriate architecture. In this paper, we present an abstraction for scalable data mining that allows us to explore these trade-offs. Data and computation are distributed to a computing cloud with minimal effort from the user, and multiple models for data management are available depending on the workload and system configuration. We demonstrate the performance and scalability characteristics of our ensembles using a wide variety of datasets and algorithms on a Condor-based pool with Chirp to handle the storage.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Ensemble Learning, Cloud Computing, Scalability, Distributed Data Mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384233</person_id>
				<author_profile_id><![CDATA[81100392296]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moretti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384234</person_id>
				<author_profile_id><![CDATA[81392619081]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Karsten]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Steinhaeuser]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384235</person_id>
				<author_profile_id><![CDATA[81100437970]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Douglas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thain]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384236</person_id>
				<author_profile_id><![CDATA[81100002770]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Nitesh]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Chawla]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511400</article_id>
		<sort_key>650</sort_key>
		<display_label>Pages</display_label>
		<pages>482-491</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>60</seq_no>
		<title><![CDATA[What Sperner Family Concept Class is Easy to Be Enumerated?]]></title>
		<page_from>482</page_from>
		<page_to>491</page_to>
		<doi_number>10.1109/ICDM.2008.131</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511400</url>
		<abstract>
			<par><![CDATA[We study the problem of enumerating concepts in a Sperner family concept class using subconcept queries, which is a general problem including maximal frequent itemset mining as its instance. Though even the theoretically best known algorithm needs quasi-polynomial time to solve this problem in the worst case, there exist practically fast algorithms for this problem. This is because many instances of this problem in real world have low complexity in some measures. In this paper, we characterize the complexity of Sperner family concept class by the VC dimension of its intersection closure and its characteristic dimension, and analyze the worst case time complexity on the enumeration problem of its concepts in terms of the VC dimension. We also showed that the VC dimension of real data used in data mining is actually small by calculating the VC dimension of some real datasets using a new algorithm closely related to the introduced two measures, which does not only solve the problem but also let us know the VC dimension of the intersection closure of the target concept class.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Sperner family, enumeration, maxumal frequent itemset, simple hypergraph]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383141</person_id>
				<author_profile_id><![CDATA[81100584851]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Atsuyoshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nakamura]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383142</person_id>
				<author_profile_id><![CDATA[81100510802]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mineichi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kudo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511401</article_id>
		<sort_key>660</sort_key>
		<display_label>Pages</display_label>
		<pages>492-501</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>61</seq_no>
		<title><![CDATA[Learning by Propagability]]></title>
		<page_from>492</page_from>
		<page_to>501</page_to>
		<doi_number>10.1109/ICDM.2008.53</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511401</url>
		<abstract>
			<par><![CDATA[In this paper, we present a novel feature extraction framework, called learning by propagability. The whole learning process is driven by the philosophy that the data labels and optimal feature representation can constitute a harmonic system, namely, the data labels are invariant with respect to the propagation on the similarity-graph constructed by the optimal feature representation. Based on this philosophy, a unified formulation for learning by propagability is proposed for both supervised and semi-supervised configurations. Specifically, this formulation offers the semi-supervised learning two characteristics: 1) unlike conventional semi-supervised learning algorithms which mostly include at least two parameters, this formulation is parameter-free; and 2) the formulation unifies the label propagation and optimal representation pursuing, and thus the label propagation is enhanced by benefiting from the graph constructed with the derived optimal representation instead of the original representation. Extensive experiments on UCI toy data, handwritten digit recognition, and face recognition all validate the effectiveness of our proposed learning framework compared with the state-of-the-art methods for feature extraction and semi-supervised learning.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[learning by propagability, optimal feature representation, dimensionality reduction]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381542</person_id>
				<author_profile_id><![CDATA[81414611206]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bingbing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ni]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381543</person_id>
				<author_profile_id><![CDATA[81100044797]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shuicheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381544</person_id>
				<author_profile_id><![CDATA[81100320032]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ashraf]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kassim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381545</person_id>
				<author_profile_id><![CDATA[81100292730]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Loong]]></first_name>
				<middle_name><![CDATA[Fah]]></middle_name>
				<last_name><![CDATA[Cheong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511402</article_id>
		<sort_key>670</sort_key>
		<display_label>Pages</display_label>
		<pages>502-511</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>62</seq_no>
		<title><![CDATA[One-Class Collaborative Filtering]]></title>
		<page_from>502</page_from>
		<page_to>511</page_to>
		<doi_number>10.1109/ICDM.2008.16</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511402</url>
		<abstract>
			<par><![CDATA[Many applications of collaborative filtering (CF), such as news item recommendation and bookmark recommendation, are most naturally thought of as one-class collaborative filtering (OCCF) problems. In these problems, the training data usually consist simply of binary data reflecting a user's action or inaction, such as page visitation in the case of news item recommendation or webpage bookmarking in the bookmarking scenario. Usually this kind of data are extremely sparse (a small fraction are positive examples), therefore ambiguity arises in the interpretation of the non-positive examples. Negative examples and unlabeled positive examples are mixed together and we are typically unable to distinguish them. For example, we cannot really attribute a user not bookmarking a page to a lack of interest or lack of awareness of the page. Previous research addressing this one-class problem only considered it as a classification task. In this paper, we consider the one-class problem under the CF setting. We propose two frameworks to tackle OCCF. One is based on weighted low rank approximation; the other is based on negative example sampling. The experimental results show that our approaches significantly outperform the baselines.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Collaborative Filtering, One-Class, Low-Rank Approximations, Alternating Least Squares]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382066</person_id>
				<author_profile_id><![CDATA[81100484433]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382067</person_id>
				<author_profile_id><![CDATA[81414600143]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yunhong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382068</person_id>
				<author_profile_id><![CDATA[81100130445]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382069</person_id>
				<author_profile_id><![CDATA[81363596428]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Nathan]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382070</person_id>
				<author_profile_id><![CDATA[81100187538]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Rajan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lukose]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382071</person_id>
				<author_profile_id><![CDATA[81100253041]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scholz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382072</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511406</article_id>
		<sort_key>680</sort_key>
		<display_label>Pages</display_label>
		<pages>512-521</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>63</seq_no>
		<title><![CDATA[DisCo]]></title>
		<subtitle><![CDATA[Distributed Co-clustering with Map-Reduce: A Case Study towards Petabyte-Scale End-to-End Mining]]></subtitle>
		<page_from>512</page_from>
		<page_to>521</page_to>
		<doi_number>10.1109/ICDM.2008.142</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511406</url>
		<abstract>
			<par><![CDATA[Huge datasets are becoming prevalent; even as researchers, we now routinely have to work with datasets that are up to a few terabytes in size. Interesting real-world applications produce huge volumes of messy data. The mining process involves several steps, starting from pre-processing the raw data to estimating the final models. As data become more abundant, scalable and easy-to-use tools for distributed processing are also emerging. Among those, Map-Reduce has been widely embraced by both academia and industry. In database terms, Map-Reduce is a simple yet powerful execution engine, which can be complemented with other data storage and management components, as necessary. In this paper we describe our experiences and findings in applying Map-Reduce, from raw data to final models, on an important mining task. In particular, we focus on co-clustering, which has been studied in many applications such as text mining, collaborative filtering, bio-informatics, graph mining. We propose the Distributed Co-clustering (DisCo) framework, which introduces practical approaches for distributed data pre-processing, and co-clustering. We develop DisCo using Hadoop, an open source Map-Reduce implementation. We show that DisCo can scale well and efficiently process and analyze extremely large datasets (up to several hundreds of gigabytes) on commodity hardware.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graphs, mapreduce, co-clustering, data mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384845</person_id>
				<author_profile_id><![CDATA[81100631405]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Spiros]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Papadimitriou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384846</person_id>
				<author_profile_id><![CDATA[81455605573]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jimeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511407</article_id>
		<sort_key>690</sort_key>
		<display_label>Pages</display_label>
		<pages>522-529</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>64</seq_no>
		<title><![CDATA[Learning Bayesian Networks]]></title>
		<subtitle><![CDATA[A MAP Criterion for Joint Selection of Model Structure and Parameter]]></subtitle>
		<page_from>522</page_from>
		<page_to>529</page_to>
		<doi_number>10.1109/ICDM.2008.14</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511407</url>
		<abstract>
			<par><![CDATA[For learning Bayesian Network (BN) structures, it has become common practice to use the Bayesian Dirichlet (BD) scoring criterion. In contrast to most other scoring metrics that functionally can be interpreted as regularized maximum likelihood criteria, the BD metric cannot be considered as such. The functional dissimilarity of the BD metric compared to other metrics is an obstacle from an analytical point of view; this is for instance becomes clear in the context of the Structural EM algorithm for learning BNs from incomplete data. Also, it is not easy to pin-point why exactly and to what extend regularization is taken care of by applying the BD metric. We introduce a Bayesian scoring criterion that is closely related to the BD metric, but solves the obvious disadvantages of the BD metric. We arrive at this result by using the same basic assumptions as for the BD metric, but in contrast to the BD metric, where focus is on learning the model structure only, we aim at learning the most probable BN pair jointly, i.e., model structure and the parameter are selected as a pair. This approach yields a scoring metric that has the functional form of a regularized maximum likelihood metric. We perform experiments, and show that this MAP BN metric also yields better results than the BIC and BD metrics on independent test data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Learning, Bayesian Networks, Scoring Criterion, BD metric, Bayesian Statistics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381576</person_id>
				<author_profile_id><![CDATA[81436597099]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Carsten]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Riggelsen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511403</article_id>
		<sort_key>700</sort_key>
		<display_label>Pages</display_label>
		<pages>530-539</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>65</seq_no>
		<title><![CDATA[Bayesian Co-clustering]]></title>
		<page_from>530</page_from>
		<page_to>539</page_to>
		<doi_number>10.1109/ICDM.2008.91</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511403</url>
		<abstract>
			<par><![CDATA[In recent years, co-clustering has emerged as a powerful data mining tool that can analyze dyadic data connecting two entities. However, almost all existing co-clustering techniques are partitional, and allow individual rows and columns of a data matrix to belong to only one cluster. Several current applications, such as recommendation systems and market basket analysis, can substantially benefit from a mixed membership of rows and columns. In this paper, we present Bayesian co-clustering (BCC) models, that allow a mixed membership in row and column clusters. BCC maintains separate Dirichlet priors for rows and columns over the mixed membership and assumes each observation to be generated by an exponential family distribution corresponding to its row and column clusters. We propose a fast variational algorithm for inference and parameter estimation. The model is designed to naturally handle sparse matrices as the inference is done only based on the non-missing entries. In addition to finding a co-cluster structure in observations, the model outputs a low dimensional co-embedding, and accurately predicts missing values in the original matrix. We demonstrate the efficacy of the model through experiments on both simulated and real data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383143</person_id>
				<author_profile_id><![CDATA[81375593685]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hanhuai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383144</person_id>
				<author_profile_id><![CDATA[81100144629]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Arindam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Banerjee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511408</article_id>
		<sort_key>710</sort_key>
		<display_label>Pages</display_label>
		<pages>540-549</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>66</seq_no>
		<title><![CDATA[Temporal-Relational Classifiers for Prediction in Evolving Domains]]></title>
		<page_from>540</page_from>
		<page_to>549</page_to>
		<doi_number>10.1109/ICDM.2008.125</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511408</url>
		<abstract>
			<par><![CDATA[Many relational domains contain temporal information and dynamics that are important to model (e.g., social networks, protein networks). However, past work in relational learning has focused primarily on modeling static "snapshots" of the data and has largely ignored the temporal dimension of these data. In this work, we extend relational techniques to temporally-evolving domains and outline a representational framework that is capable of modeling both temporal and relational dependencies in the data. We develop efficient learning and inference techniques within the framework by considering a restricted set of temporal-relational dependencies and using parameter-tying methods to generalize across relationships and entities. More specifically, we model dynamic relational data with a two-phase process, first summarizing the temporal-relational information with kernel smoothing, and then moderating attribute dependencies with the summarized relational information. We develop a number of novel temporal-relational models using the framework and then show that the current approaches to modeling static relational data are special cases within the framework. We compare the new models to the competing static relational methods on three real-world datasets and show that the temporal-relational models consistently outperform the relational models that ignore temporal information - achieving significant reductions in error ranging from 15% to 70%.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385350</person_id>
				<author_profile_id><![CDATA[81392611481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Umang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sharan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385351</person_id>
				<author_profile_id><![CDATA[81100563777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jennifer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Neville]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511409</article_id>
		<sort_key>720</sort_key>
		<display_label>Pages</display_label>
		<pages>550-559</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>67</seq_no>
		<title><![CDATA[xCrawl]]></title>
		<subtitle><![CDATA[A High-Recall Crawling Method for Web Mining]]></subtitle>
		<page_from>550</page_from>
		<page_to>559</page_to>
		<doi_number>10.1109/ICDM.2008.121</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511409</url>
		<abstract>
			<par><![CDATA[Web Mining Systems exploit the redundancy of data published on the Web to automatically extract information from existing web documents. The first step in the Information Extraction process is thus to locate within a limited period of time as many web pages as possible that contain relevant information, a task which is commonly accomplished by applying focused crawling techniques. The performance of such a crawler can be measured by its "recall", i.e. the percentage of documents found and identified as relevant compared to the number of existing documents. A higher recall value implies that more redundant data is available, which in turn leads to better results in the subsequent fact extraction phase. In this paper, we propose xCrawl, a new focused crawling method which outperforms state-of-the-art approaches with respect to recall values achievable within a given period of time. This method is based on a new combination of ideas and techniques used to identify and exploit navigational structures of websites, such as hierarchies, lists or maps. In addition, automatic query generation is applied to rapidly collect web sources containing target documents. The proposed crawling technique was inspired by the requirements of a Web Mining System developed to extract product and service descriptions and was evaluated in different application scenarios. Comparisons with existing focused crawling techniques reveal that the new crawling method leads to a significant increase in recall whilst maintaining precision.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Web mining, focused crawling, authorative sources]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381577</person_id>
				<author_profile_id><![CDATA[81331504196]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kostyantyn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shchekotykhin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381578</person_id>
				<author_profile_id><![CDATA[81100081930]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dietmar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jannach]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381579</person_id>
				<author_profile_id><![CDATA[81100594391]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Gerhard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Friedrich]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511410</article_id>
		<sort_key>730</sort_key>
		<display_label>Pages</display_label>
		<pages>560-569</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>68</seq_no>
		<title><![CDATA[Comparison of Cluster Representations from Partial Second- to Full Fourth-Order Cross Moments for Data Stream Clustering]]></title>
		<page_from>560</page_from>
		<page_to>569</page_to>
		<doi_number>10.1109/ICDM.2008.143</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511410</url>
		<abstract>
			<par><![CDATA[Under seven external clustering evaluation measures, a comparison is made for cluster representations from the partial second order to the fourth order in data stream clustering. Two external clustering evaluation measures, purity and cross entropy, adopted for data stream clustering performance evaluation in the past, penalize the performance of an algorithm when each hypothesized cluster contains points in different target classes or true clusters, while ignoring the issue of points in a target class falling into different hypothesized clusters. The seven measures will address both sides of the clustering performance. The represented geometry by the partial second-order statistics of a cluster is non-oblique ellipsoidal and cannot describe the orientation, asymmetry, or peakedness of a cluster. The higher-order cluster representation presented in this paper introduces the third and fourth cross moments, enabling the cluster geometry to be beyond an ellipsoid. The higher-order statistics allow two clusters with different representations to merge into a multivariate normal cluster, using normality tests based on multivariate skewness and kurtosis. The clustering performance under the seven external clustering evaluation measures with a synthetic and two real data streams demonstrates the effectiveness of the higher-order cluster representations.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Data stream clustering, Cluster representation, Cross moment, Gaussian mixture model]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382129</person_id>
				<author_profile_id><![CDATA[81414597867]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mingzhou]]></first_name>
				<middle_name><![CDATA[(Joe)]]></middle_name>
				<last_name><![CDATA[Song]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382130</person_id>
				<author_profile_id><![CDATA[81414592106]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511411</article_id>
		<sort_key>740</sort_key>
		<display_label>Pages</display_label>
		<pages>570-579</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>69</seq_no>
		<title><![CDATA[Web Mining for Understanding Stories through Graph Visualisation]]></title>
		<page_from>570</page_from>
		<page_to>579</page_to>
		<doi_number>10.1109/ICDM.2008.138</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511411</url>
		<abstract>
			<par><![CDATA[Rich information spaces (like the Web or scientific publications) are full of "stories": sets of statements that evolve over time, manifested as, for example, collections of newspaper articles reporting events relating to an evolving crime investigation, sets of news articles and blog posts accompanying the development of a political election campaign, or sequences of scientific papers on a topic. In this paper, we propose a method and a visualisation tool for mapping and interacting with such stories. In contrast to existing approaches, our method concentrates on relational information and on local patterns rather than on the occurrence of individual concepts and global models. In addition, we present an evaluation framework. A real-life case study is used to illustrate and evaluate the method and tool.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[temporal text mining, web mining, text summarization and visualization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384865</person_id>
				<author_profile_id><![CDATA[81414619075]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ilija]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Suba&#154;ic]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384866</person_id>
				<author_profile_id><![CDATA[81100222863]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bettina]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Berendt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511412</article_id>
		<sort_key>750</sort_key>
		<display_label>Pages</display_label>
		<pages>580-587</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>70</seq_no>
		<title><![CDATA[Balancing Spectral Clustering for Segmenting Spatio-temporal Observations of Multi-agent Systems]]></title>
		<page_from>580</page_from>
		<page_to>587</page_to>
		<doi_number>10.1109/ICDM.2008.88</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511412</url>
		<abstract>
			<par><![CDATA[We examine the application of spectral clustering for breaking up the behavior of a multi-agent system in space and time into smaller, independent elements. We cluster observations of individualentities in order to identify significant changes in the parameter space (like spatial position)and detect temporal alterations of behavior within the same framework. Data is also influenced byknowledge about important events. Clusters are pre-processed at each step of the iterative subdivision to make the algorithm invariant against spatial scaling, rotation, replay speed andvarying sampling frequency. A method is presented to balance spatial and temporal segmentation based on the expected group size. We demonstrate our results by analyzing the outcomes of acomputer game.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[spectral clustering, data mining in multi-agent systems]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383795</person_id>
				<author_profile_id><![CDATA[81414601447]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[B&#225;lint]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tak&#225;cs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383796</person_id>
				<author_profile_id><![CDATA[81100095668]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yiannis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Demiris]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511413</article_id>
		<sort_key>760</sort_key>
		<display_label>Pages</display_label>
		<pages>588-597</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>71</seq_no>
		<title><![CDATA[Finding Good Itemsets by Packing Data]]></title>
		<page_from>588</page_from>
		<page_to>597</page_to>
		<doi_number>10.1109/ICDM.2008.39</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511413</url>
		<abstract>
			<par><![CDATA[The problem of selecting small groups of itemsets that represent the data well has recently gained a lot of attention. We approach the problem by searching for the itemsets that compress the data efficiently. As a compression technique we use decision trees combined with a refined version of MDL. More formally, assuming that the items are ordered, we create a decision tree for each item that may only depend on the previous items. Our approach allows us to find complex interactions between the attributes, not just co-occurrences of 1s. Further, we present a link between the itemsets and the decision trees and use this link to export the itemsets from the decision trees. In this paper we present two algorithms. The first one is a simple greedy approach that builds a family of itemsets directly from data. The second one, given a collection of candidate itemsets, selects a small subset of these itemsets. Our experiments show that these approaches result in compact and high quality descriptions of the data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384867</person_id>
				<author_profile_id><![CDATA[81363600602]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nikolaj]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tatti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384868</person_id>
				<author_profile_id><![CDATA[81335499054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jilles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vreeken]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511414</article_id>
		<sort_key>770</sort_key>
		<display_label>Pages</display_label>
		<pages>598-607</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>72</seq_no>
		<title><![CDATA[Measuring Proximity on Graphs with Side Information]]></title>
		<page_from>598</page_from>
		<page_to>607</page_to>
		<doi_number>10.1109/ICDM.2008.42</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511414</url>
		<abstract>
			<par><![CDATA[This paper studies how to incorporate side information (such as users' feedback) in measuring node proximity on large graphs. Our method (ProSIN) is motivated by the well-studied random walk with restart (RWR). The basic idea behind ProSIN is to leverage side information to refine the graph structure so that the random walk is biased towards/away from some specific zones on the graph. Our case studies demonstrate that ProSIN is well-suited in a variety of applications, including neighborhood search, center-piece subgraphs, and image caption. Given the potential computational complexity of ProSIN, we also propose a fast algorithm (Fast-ProSIN) that exploits the smoothness of the graph structures with/without side information. Our experimental evaluation shows that Fast-ProSIN achieves significant speedups (up to 49x) over straightforward implementations.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Proximity, Side Information, Graph Mining, Scalability]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385363</person_id>
				<author_profile_id><![CDATA[81337494052]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hanghang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385364</person_id>
				<author_profile_id><![CDATA[81310483642]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Huiming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Qu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385365</person_id>
				<author_profile_id><![CDATA[81100086465]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hani]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jamjoom]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511415</article_id>
		<sort_key>780</sort_key>
		<display_label>Pages</display_label>
		<pages>608-617</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>73</seq_no>
		<title><![CDATA[Fast Counting of Triangles in Large Real Networks without Counting]]></title>
		<subtitle><![CDATA[Algorithms and Laws]]></subtitle>
		<page_from>608</page_from>
		<page_to>617</page_to>
		<doi_number>10.1109/ICDM.2008.72</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511415</url>
		<abstract>
			<par><![CDATA[Triangles are important for real world social networks, lying at the heart of the clustering coefficient and of the transitivity ratio. However, straight-forward and even approximate counting algorithms can be slow, trying to execute or approximate the equivalent of a 3-way database join. In this paper, we provide two algorithms, the Eigen Triangle for counting the total number of triangles in a graph, and the Eigen Triangle Local algorithm that gives the count of triangles that contain a desired node. Additional contributions include the following:(a) We show that both algorithms achieve excellent accuracy, with up to ~1000x faster execution time, on several, real graphs and (b) we discover two new power laws (Degree-Triangle and Triangle Participation laws) with surprising properties.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Graph Mining, Triangles, Power laws, Graph Generators]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383797</person_id>
				<author_profile_id><![CDATA[81384619692]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Charalampos]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Tsourakakis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511416</article_id>
		<sort_key>790</sort_key>
		<display_label>Pages</display_label>
		<pages>618-627</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>74</seq_no>
		<title><![CDATA[Improving Collaborative Filtering Recommendations Using External Data]]></title>
		<page_from>618</page_from>
		<page_to>627</page_to>
		<doi_number>10.1109/ICDM.2008.44</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511416</url>
		<abstract>
			<par><![CDATA[This paper describes an approach for incorporating externally specified aggregate ratings information into certain types of collaborative filtering (CF) methods. For a statistical model-based CF approach, we formally showed that this additional aggregated information provides more accurate recommendations of individual items to individual users. Furthermore, theoretical insights gained from the analysis of this model-based method suggested a way to incorporate aggregate information into the heuristic item-based CF method. Both the model-based and the heuristic item-based CF methods were empirically tested on several datasets, and the experiments uniformly confirmed that the aggregate rating information indeed improves CF recommendations. These results also show the power of theory by demonstrating how the insights gained from theoretical developments can shed light on proper selection of good heuristic methods. We also showed the way to introduce scalability and parallelization into the estimation procedure and reported the running time for steps of the estimation procedure for large datasets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Recommender systems, collaborative filtering, predictive models, OLAP ratings, external ratings]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382144</person_id>
				<author_profile_id><![CDATA[81381592437]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Akhmed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Umyarov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382145</person_id>
				<author_profile_id><![CDATA[81100364633]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tuzhilin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511417</article_id>
		<sort_key>800</sort_key>
		<display_label>Pages</display_label>
		<pages>628-637</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>75</seq_no>
		<title><![CDATA[A Generative Probabilistic Model for Multi-label Classification]]></title>
		<page_from>628</page_from>
		<page_to>637</page_to>
		<doi_number>10.1109/ICDM.2008.86</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511417</url>
		<abstract>
			<par><![CDATA[Traditional discriminative classification method makes little attempt to reveal the probabilistic structure and the correlation within both input and output spaces. In the scenario of multi-label classification, most of the classifiers simply assume the predefined classes are independently distributed, which would definitely hinder the classification performance when there are intrinsic correlations between the classes. In this article, we propose a generative probabilistic model, the Correlated Labeling Model (CoL Model), to formulate the correlation between different classes. The CoL model is presented to capture the correlation between classes and the underlying structures via the latent random variables in a supervised manner. We develop a variational procedure to approximate the posterior distribution and employ the EM algorithm for the empirical Bayes parameter estimation. In our evaluations, the proposed model achieved promising results on various data sets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[multi-label classification, generative model, variational inference, text classification]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382670</person_id>
				<author_profile_id><![CDATA[81414608273]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hongning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382671</person_id>
				<author_profile_id><![CDATA[81414591875]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Minlie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382672</person_id>
				<author_profile_id><![CDATA[81438595316]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xiaoyan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511418</article_id>
		<sort_key>810</sort_key>
		<display_label>Pages</display_label>
		<pages>638-647</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>76</seq_no>
		<title><![CDATA[SpecVAT]]></title>
		<subtitle><![CDATA[Enhanced Visual Cluster Analysis]]></subtitle>
		<page_from>638</page_from>
		<page_to>647</page_to>
		<doi_number>10.1109/ICDM.2008.18</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511418</url>
		<abstract>
			<par><![CDATA[Given a pairwise dissimilarity matrix $\bm{D}$ of a set ofobjects, visual methods such as the VAT algorithm (for visual analysis of cluster tendency) represent $\bm{D}$ as an image $\mathrm{I}(\tilde{\bm{D}})$ where the objects are reordered to highlight cluster structure as dark blocks along the diagonal of the image. A major limitation of such visual methods is their inability to highlight cluster structure in $\mathrm{I}(\tilde{\bm{D}})$ when $\bm{D}$ contains clusters with highly complex structure. In this paper, we address this limitation by proposing a Spectral VAT (SpecVAT) algorithm, where $\bm{D}$ is mapped to $\bm{D'}$ in an embedding space by spectral decomposition of the Laplacian matrix, and then reordered to $\bm{\tilde{D'}}$ using the VAT algorithm. We also propose astrategy to automatically determine the number of clusters in $\mathrm{I}(\bm{\tilde{D'}})$, as well as a method for cluster formation from $\mathrm{I}(\bm{\tilde{D'}})$ based on the difference between diagonal blocks and off-diagonal blocks. We demonstrate the effectiveness of our algorithms on several synthetic and real-world data sets that are not amenable to analysis via traditional VAT.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383846</person_id>
				<author_profile_id><![CDATA[81319503954]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Liang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383847</person_id>
				<author_profile_id><![CDATA[81538855856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Geng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383848</person_id>
				<author_profile_id><![CDATA[81100644208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bezdek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383849</person_id>
				<author_profile_id><![CDATA[81100389595]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leckie]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383850</person_id>
				<author_profile_id><![CDATA[81100368542]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Ramamohanarao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kotagiri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511419</article_id>
		<sort_key>820</sort_key>
		<display_label>Pages</display_label>
		<pages>648-657</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>77</seq_no>
		<title><![CDATA[Dirichlet Process Based Evolutionary Clustering]]></title>
		<page_from>648</page_from>
		<page_to>657</page_to>
		<doi_number>10.1109/ICDM.2008.23</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511419</url>
		<abstract>
			<par><![CDATA[Evolutionary Clustering has emerged as an important research topic in recent literature of data mining, and solutions to this problem have found a wide spectrum of applications, particularly in social network analysis. In this paper, based on the recent literature on Dirichlet processes, we have developed two different and specific models as solutions to this problem: DPChain and HDP-EVO. Both models substantially advance the literature on evolutionary clustering in the sense that not only they both perform better than the existing literature, but more importantly they are capable of automatically learning the cluster numbers and structures during the evolution. Extensive evaluations have demonstrated the effectiveness and promise of these models against the state-of-the-art literature.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Evolutionary Clustering, Dirichlet Process, DPChain, HDP-EVO]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382146</person_id>
				<author_profile_id><![CDATA[81414604360]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tianbing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382147</person_id>
				<author_profile_id><![CDATA[81414604262]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zhongfei]]></first_name>
				<middle_name><![CDATA[(Mark)]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382148</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382149</person_id>
				<author_profile_id><![CDATA[81375607652]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Bo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Long]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511420</article_id>
		<sort_key>830</sort_key>
		<display_label>Pages</display_label>
		<pages>658-667</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>78</seq_no>
		<title><![CDATA[Evolutionary Clustering by Hierarchical Dirichlet Process with Hidden Markov State]]></title>
		<page_from>658</page_from>
		<page_to>667</page_to>
		<doi_number>10.1109/ICDM.2008.24</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511420</url>
		<abstract>
			<par><![CDATA[This paper studies evolutionary clustering, which is a recently hot topic with many important applications, noticeably in social network analysis. In this paper, based on the recent literature on Hierarchical Dirichlet Process (HDP) and Hidden Markov Model (HMM), we have developed a statistical model HDP-HTM that combines HDP with a Hierarchical Transition Matrix (HTM) based on the proposed Infinite Hierarchical Hidden Markov State model (iH$^2$MS) as an effective solution to this problem. The HDP-HTM model substantially advances the literature on evolutionary clustering in the sense that not only it performs better than the existing literature, but more importantly it is capable of automatically learning the cluster numbers and structures and at the same time explicitly addresses the correspondence issue during the evolution. Extensive evaluations have demonstrated the effectiveness and promise of this solution against the state-of-the-art literature.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Evolutionary Clustering, Hierarchical Dirichlet Process, Infinite Hidden Markov Model, HDP-HTM]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382150</person_id>
				<author_profile_id><![CDATA[81414604360]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tianbing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382151</person_id>
				<author_profile_id><![CDATA[81414604262]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zhongfei]]></first_name>
				<middle_name><![CDATA[(Mark)]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382152</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382153</person_id>
				<author_profile_id><![CDATA[81375607652]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Bo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Long]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511421</article_id>
		<sort_key>840</sort_key>
		<display_label>Pages</display_label>
		<pages>668-677</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>79</seq_no>
		<title><![CDATA[TOFA]]></title>
		<subtitle><![CDATA[Trace Oriented Feature Analysis in Text Categorization]]></subtitle>
		<page_from>668</page_from>
		<page_to>677</page_to>
		<doi_number>10.1109/ICDM.2008.67</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511421</url>
		<abstract>
			<par><![CDATA[Dimension reduction for large-scale text data is attracting much attention lately due to the rapid growth of World Wide Web. We can consider dimension reduction algorithms in two categories: feature extraction and feature selection. An important problem remains: it has been difficult to integrate these two algorithm categories into a single framework, making it difficult to reap the benefit of both. In this paper, we formulate the two algorithm categories through a unified optimization framework. Under this framework, we develop a novel feature selection algorithm called Trace Oriented Feature Analysis (TOFA). The novel objective function of TOFA is a unified framework that integrates many prominent feature extraction algorithms such as unsupervised Principal Component Analysis and supervised Maximum Margin Criterion are special cases of it. Thus TOFA can process not only supervised problem but also unsupervised and semi-supervised problems. Experimental results on real text datasets demonstrate the effectiveness and efficiency of TOFA.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Feature Analysis, Text Categorization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384893</person_id>
				<author_profile_id><![CDATA[81375615225]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384894</person_id>
				<author_profile_id><![CDATA[81392606688]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384895</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384896</person_id>
				<author_profile_id><![CDATA[81381591210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Weiguo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384897</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511422</article_id>
		<sort_key>850</sort_key>
		<display_label>Pages</display_label>
		<pages>678-687</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>80</seq_no>
		<title><![CDATA[Clustering Distributed Time Series in Sensor Networks]]></title>
		<page_from>678</page_from>
		<page_to>687</page_to>
		<doi_number>10.1109/ICDM.2008.58</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511422</url>
		<abstract>
			<par><![CDATA[Event detection is a critical task in sensor networks, especially for environmental monitoring applications. Traditional solutions to event detection are based on analyzing one-shot data points, which might incur a high false alarm rate because sensor data is inherently unreliable and noisy. To address this issue, we proposea novel Distributed Single-pass Incremental Clustering (DSIC) technique to cluster the time series obtained at sensor nodes based on their underlying trends. In order to achieve scalability and energy-efficiency, our DSIC technique uses a hierarchical structure of sensor networks as the underlying infrastructure. The algorithm first compresses the time series produced at individual sensor nodes into a compact representation using Haar wavelettransform, and then, based on dynamic time warping distances, hierarchically groups the approximate time series into a global clustering model in an incremental manner. Experimental results on both real data and synthetic data demonstrate that our DSIC algorithm is accurate, energy-efficient and robust with respect tonetwork topology changes.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Distributed Clustering, Time Series, Sensor Networks]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384364</person_id>
				<author_profile_id><![CDATA[81414606871]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384365</person_id>
				<author_profile_id><![CDATA[81100237158]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mohamed]]></first_name>
				<middle_name><![CDATA[Medhat]]></middle_name>
				<last_name><![CDATA[Gaber]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511423</article_id>
		<sort_key>860</sort_key>
		<display_label>Pages</display_label>
		<pages>688-697</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>81</seq_no>
		<title><![CDATA[M3MIML]]></title>
		<subtitle><![CDATA[A Maximum Margin Method for Multi-instance Multi-label Learning]]></subtitle>
		<page_from>688</page_from>
		<page_to>697</page_to>
		<doi_number>10.1109/ICDM.2008.27</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511423</url>
		<abstract>
			<par><![CDATA[Multi-instance multi-label learning (MIML) deals with the problem where each training example is associated with not only multiple instances but also multiple class labels. Previous MIML algorithms work by identifying its equivalence in degenerated versions of multi-instance multi-label learning. However, useful information encoded in training examples may get lost during the identification process. In this paper, a maximum margin method is proposed for MIML which directly exploits the connections between instances and labels. The learning task is formulated as a quadratic programming (QP) problem and implemented in its dual form. Applications to scene classification and text categorization show that the proposed approach achieves superior performance over existing MIML methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383295</person_id>
				<author_profile_id><![CDATA[81423595920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Min-Ling]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383296</person_id>
				<author_profile_id><![CDATA[81451593001]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zhi-Hua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511424</article_id>
		<sort_key>870</sort_key>
		<display_label>Pages</display_label>
		<pages>701-706</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>82</seq_no>
		<title><![CDATA[RTM]]></title>
		<subtitle><![CDATA[Laws and a Recursive Generator for Weighted Time-Evolving Graphs]]></subtitle>
		<page_from>701</page_from>
		<page_to>706</page_to>
		<doi_number>10.1109/ICDM.2008.123</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511424</url>
		<abstract>
			<par><![CDATA[How do real, weighted graphs change over time? What patterns, if any, do they obey? Earlier studies focus on unweighted graphs, and, with few exceptions, they focus on static snapshots. Here, we report patterns we discover on several real, weighted, time-evolving graphs. The reported patterns can help in detecting anomalies in natural graphs, in making link prediction and in providing more criteria for evaluation of synthetic graph generators. We further propose an intuitive and easy way to construct weighted, time-evolving graphs. In fact, we prove that our generator will produce graphs which obey many patterns and laws observed to date. We also provide empirical evidence to support our claims.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graph generators, power laws, tensors, kronecker product]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384366</person_id>
				<author_profile_id><![CDATA[81414592499]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Leman]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Akoglu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384367</person_id>
				<author_profile_id><![CDATA[81367599088]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mary]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McGlohon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384368</person_id>
				<author_profile_id><![CDATA[81100373169]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Christos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Faloutsos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511425</article_id>
		<sort_key>880</sort_key>
		<display_label>Pages</display_label>
		<pages>707-712</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>83</seq_no>
		<title><![CDATA[A Shrinkage Approach for Modeling Non-stationary Relational Autocorrelation]]></title>
		<page_from>707</page_from>
		<page_to>712</page_to>
		<doi_number>10.1109/ICDM.2008.147</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511425</url>
		<abstract>
			<par><![CDATA[Recent research has shown that collective classification in relational data often exhibit significant performance gains over conventional approaches that classify instances individually. This is primarily due to the presence of autocorrelation in relational datasets, meaning that the class labels of related entities are correlated and inferences about one instance can be used to improve inferences about linked instances. Statistical relational learning techniques exploit relational autocorrelation by modeling global autocorrelation dependencies under the assumption that the level of autocorrelation is stationary throughout the dataset. To date, there has been no work examining the appropriateness of this stationarity assumption. In this paper, we examine two real-world datasets and show that there is significant variance in the autocorrelation dependencies throughout the relational data graphs. We develop a shrinkage technique for modeling this non-stationary autocorrelation and show that it achieves significant accuracy gains over competing techniques that model either local or global autocorrelation dependencies in isolation.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Relational learning, collective classification, shrinkage]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384369</person_id>
				<author_profile_id><![CDATA[81464642868]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pelin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Angin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384370</person_id>
				<author_profile_id><![CDATA[81100563777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jennifer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Neville]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511426</article_id>
		<sort_key>890</sort_key>
		<display_label>Pages</display_label>
		<pages>713-718</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>84</seq_no>
		<title><![CDATA[Latent Dirichlet Allocation and Singular Value Decomposition Based Multi-document Summarization]]></title>
		<page_from>713</page_from>
		<page_to>718</page_to>
		<doi_number>10.1109/ICDM.2008.55</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511426</url>
		<abstract>
			<par><![CDATA[Multi-Document Summarization deals with computing a summary for a set of related articles such that they give the user a general view about the events. One of the objectives is that the sentences should cover the different events in the documents with the information covered in as few sentences as possible. Latent Dirichlet Allocation can breakdown these documents into different topics or events. However to reduce the common information content the sentences of the summary need to be orthogonal to each other since orthogonal vectors have the lowest possible similarity and correlation between them. Singular Value Decompositions used to get the orthogonal representations of vectors and representing sentences as vectors, we can get the sentences that are orthogonal to each other in the LDA mixture model weighted term domain. Thus using LDA we find the different topics in the documents and using SVD we find the sentences that best represent these topics. Finally we present the evaluation of the algorithms on the DUC2002 Corpus multi-document summarization tasks using the ROUGE evaluator to evaluate the summaries. Compared to DUC 2002 winners, our algorithms gave significantly better ROUGE-1 recall measures.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Natural Language Processing, Multi-Document Summarization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383297</person_id>
				<author_profile_id><![CDATA[81363601610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rachit]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Arora]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383298</person_id>
				<author_profile_id><![CDATA[81100369344]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Balaraman]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ravindran]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511427</article_id>
		<sort_key>900</sort_key>
		<display_label>Pages</display_label>
		<pages>719-724</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>85</seq_no>
		<title><![CDATA[INSCY]]></title>
		<subtitle><![CDATA[Indexing Subspace Clusters with In-Process-Removal of Redundancy]]></subtitle>
		<page_from>719</page_from>
		<page_to>724</page_to>
		<doi_number>10.1109/ICDM.2008.46</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511427</url>
		<abstract>
			<par><![CDATA[Subspace clustering aims at detecting clusters in any subspace projection of a high dimensional space. As the number of projections is exponential in the number of dimensions, efficiency is crucial. Moreover, the resulting subspace clusters are often highly redundant, i.e. many clusters are detected multiply in several projections. We propose a novel index for efficient subspace clustering in a novel depth-first processing with in-process-removal of redundant clusters for better pruning. Thorough experiments on real and synthetic data show that INSCY yields substantial efficiency and quality improvements.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[subspace clustering, high dimensional data, redundancy removal, depth-first processing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382706</person_id>
				<author_profile_id><![CDATA[81100257752]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ira]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Assent]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382707</person_id>
				<author_profile_id><![CDATA[81331496997]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ralph]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Krieger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382708</person_id>
				<author_profile_id><![CDATA[81350600194]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Emmanuel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[M&#252;ller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382709</person_id>
				<author_profile_id><![CDATA[81100145971]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Seidl]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511428</article_id>
		<sort_key>910</sort_key>
		<display_label>Pages</display_label>
		<pages>725-730</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>86</seq_no>
		<title><![CDATA[A Conservative Feature Subset Selection Algorithm with Missing Data]]></title>
		<page_from>725</page_from>
		<page_to>730</page_to>
		<doi_number>10.1109/ICDM.2008.82</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511428</url>
		<abstract>
			<par><![CDATA[This paper introduces a novel conservative feature subset selection method with incomplete data sets. The method is conservative in the sense that it selects the minimal subset of features that renders the rest of the features independent of the target (the class variable) without making any assumption about the missing data mechanism. This is achieved in the context of determining the Markov blanket of the target that reflects the worst-case assumption about the missing data mechanism, including the case when data is not missing at random. An application of the method on synthetic incomplete data is carried out to illustrate its practical relevance. The method is compared against state-of-the-art approaches such as the {expectation maximization} (EM) algorithm and the available case technique.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Feature selection, bayesian networks]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383912</person_id>
				<author_profile_id><![CDATA[81100175657]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alex]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aussem]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383913</person_id>
				<author_profile_id><![CDATA[81458658550]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sergio]]></first_name>
				<middle_name><![CDATA[Rodrigues de]]></middle_name>
				<last_name><![CDATA[Morais]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511429</article_id>
		<sort_key>920</sort_key>
		<display_label>Pages</display_label>
		<pages>731-736</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>87</seq_no>
		<title><![CDATA[Nonparametric Monotone Classification with MOCA]]></title>
		<page_from>731</page_from>
		<page_to>736</page_to>
		<doi_number>10.1109/ICDM.2008.54</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511429</url>
		<abstract>
			<par><![CDATA[We describe a monotone classification algorithm called MOCA that attemptsto minimize the mean absolute prediction error for classification problems with ordered class labels.We first find a monotone classifier with minimum L1 loss on the training sample, and then use a simpleinterpolation scheme to predict the class labels for attribute vectors not present in the training data.We compare MOCA to the Ordinal Stochastic Dominance Learner (OSDL), on artificial as well asreal data sets. We show that MOCA often outperforms OSDL with respect to mean absolute prediction error.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Classification, Monotonicity Constraint]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382192</person_id>
				<author_profile_id><![CDATA[81414606452]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nicola]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barile]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382193</person_id>
				<author_profile_id><![CDATA[81100162409]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Feelders]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511430</article_id>
		<sort_key>930</sort_key>
		<display_label>Pages</display_label>
		<pages>737-742</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>88</seq_no>
		<title><![CDATA[Mining Large Networks with Subgraph Counting]]></title>
		<page_from>737</page_from>
		<page_to>742</page_to>
		<doi_number>10.1109/ICDM.2008.109</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511430</url>
		<abstract>
			<par><![CDATA[The problem of mining frequent patterns in networks has many applications, including analysis of complex networks, clustering of graphs, finding communities in social networks, and indexing of graphical and biological databases. Despite this wealth of applications, the current state of the art lacks algorithmic tools for counting the number of subgraphs contained in a large network. In this paper we develop data-stream algorithms that approximate the number of all subgraphs of three and four vertices in directed and undirected networks. We use the frequency of occurrence of all subgraphs to prove their significance in order to characterize different kinds of networks: we achieve very good precision in clustering networks with similar structure. The significance of our method is supported by the fact that such high precision cannot be achieved when performing clustering based on simpler topological properties, such as degree, assortativity, and eigenvector distributions. We have also tested our techniques using swap randomization.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Streaming algorithms, graph algorithms, network characterization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383312</person_id>
				<author_profile_id><![CDATA[81392617487]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ilaria]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bordino]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383313</person_id>
				<author_profile_id><![CDATA[81321491135]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Debora]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Donato]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383314</person_id>
				<author_profile_id><![CDATA[81100631289]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Aristides]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gionis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383315</person_id>
				<author_profile_id><![CDATA[81330494272]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Stefano]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leonardi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511431</article_id>
		<sort_key>940</sort_key>
		<display_label>Pages</display_label>
		<pages>743-748</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>89</seq_no>
		<title><![CDATA[Comparative Evaluation of Anomaly Detection Techniques for Sequence Data]]></title>
		<page_from>743</page_from>
		<page_to>748</page_to>
		<doi_number>10.1109/ICDM.2008.151</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511431</url>
		<abstract>
			<par><![CDATA[We present a comparative evaluation of a large number of anomaly detection techniques on a variety of publicly available as well as artificially generated data sets. Many of these are existing techniques while some are slight variants and/or adaptations of traditional anomaly detection techniques to sequence data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Anomaly Detection, Sequences]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382746</person_id>
				<author_profile_id><![CDATA[81309510517]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Varun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chandola]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382747</person_id>
				<author_profile_id><![CDATA[81414619757]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Varun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mithal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382748</person_id>
				<author_profile_id><![CDATA[81452613746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Vipin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511432</article_id>
		<sort_key>950</sort_key>
		<display_label>Pages</display_label>
		<pages>749-754</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>90</seq_no>
		<title><![CDATA[On Locally Linear Classification by Pairwise Coupling]]></title>
		<page_from>749</page_from>
		<page_to>754</page_to>
		<doi_number>10.1109/ICDM.2008.137</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511432</url>
		<abstract>
			<par><![CDATA[Locally linear classification by pairwise coupling addresses a nonlinear classification problem by three basic phases: decompose the classes of complex concepts into linearly separable subclasses, learn a linear classifier for each pair, and combine pairwise classifiers into a single classifier. A number of methods have been proposed in this framework. However, these methods have two major deficiencies: 1) lack of systematic evaluation of this framework; 2) naive application of clustering algorithms to generate subclasses. This paper proves the equivalence between three popular combination schemas under general settings, defines several global criterion functions for measuring the goodness of subclasses, and presents a supervised greedy clustering algorithm to optimize the proposed criterion functions. Extensive experiments were conducted to validate the effectiveness of the proposed techniques.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Locally Linear Classification, Pair-wise Coupling, Support Vector Machines]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381677</person_id>
				<author_profile_id><![CDATA[81385597838]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Feng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381678</person_id>
				<author_profile_id><![CDATA[81100053980]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chang-Tien]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381679</person_id>
				<author_profile_id><![CDATA[81313483653]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Arnold]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Boedihardjo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511433</article_id>
		<sort_key>960</sort_key>
		<display_label>Pages</display_label>
		<pages>755-760</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>91</seq_no>
		<title><![CDATA[A Probability Model for Projective Clustering on High Dimensional Data]]></title>
		<page_from>755</page_from>
		<page_to>760</page_to>
		<doi_number>10.1109/ICDM.2008.15</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511433</url>
		<abstract>
			<par><![CDATA[Clustering high dimensional data is a big challenge in data mining due to the curse of dimensionality. To solve this problem, projective clustering has been defined as an extension of traditional clustering that seeks to find projected clusters in subsets of dimensions of a data space. In this paper, the problem of modeling projected clusters is first discussed, and an extended Gaussian model is proposed. Second, a general objective criterion used with $k$-means type projective clustering is presented based on the model. Finally, the expressions to learn model parameters are derived and then used in a new algorithm named FPC to perform fuzzy clustering on high dimensional data. The experimental results on document clustering show the effectiveness of the proposed clustering model.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385428</person_id>
				<author_profile_id><![CDATA[81464669422]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lifei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385429</person_id>
				<author_profile_id><![CDATA[81442600907]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Qingshan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385430</person_id>
				<author_profile_id><![CDATA[81100216088]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shengrui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511434</article_id>
		<sort_key>970</sort_key>
		<display_label>Pages</display_label>
		<pages>761-766</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>92</seq_no>
		<title><![CDATA[Estimating Aggregates over Multiple Sets]]></title>
		<page_from>761</page_from>
		<page_to>766</page_to>
		<doi_number>10.1109/ICDM.2008.110</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511434</url>
		<abstract>
			<par><![CDATA[Many datasets, including market basket data, text or hypertext documents, and measurement data collected in different nodes or time periods, are modeled as a collection of sets over a ground set of (weighted) items. We consider the problem of estimating basic aggregates such as the weight or selectivity of a subpopulation of the items. We extend classic summarization techniques based on sampling to this scenario when we have multiple sets and selection predicates based on membership in particular sets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[sampling, approximate query processing, similarity, sketching]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385431</person_id>
				<author_profile_id><![CDATA[81100146149]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Edith]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385432</person_id>
				<author_profile_id><![CDATA[81100155392]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaplan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511444</article_id>
		<sort_key>980</sort_key>
		<display_label>Pages</display_label>
		<pages>767-772</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>93</seq_no>
		<title><![CDATA[A Joint Matrix Factorization Approach to Unsupervised Action Categorization]]></title>
		<page_from>767</page_from>
		<page_to>772</page_to>
		<doi_number>10.1109/ICDM.2008.59</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511444</url>
		<abstract>
			<par><![CDATA[In this paper, a novel unsupervised approach to mining categories from action video sequences is presented. This approach consists of two modules: action representation and learning model. Videos are regarded as spatially distributed dynamic pixel time series, which are quantized into pixel prototypes. After replacing the pixel time eries with their corresponding prototype labels, the video sequences are compressed into 2D action matrices. We put these matrices together to form an multi-action tensor, and propose the joint matrix factorization method to simultaneously cluster the pixel prototypes into pixel signatures, and matrices into action classes. The approach is tested on public and popular Weizmann data set, and promising results are achieved.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Action categorization, Joint matrix factorization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385447</person_id>
				<author_profile_id><![CDATA[81413596063]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cui]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385448</person_id>
				<author_profile_id><![CDATA[81414592439]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385449</person_id>
				<author_profile_id><![CDATA[81100446876]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Li-Feng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385450</person_id>
				<author_profile_id><![CDATA[81309510016]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Shi-Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511445</article_id>
		<sort_key>990</sort_key>
		<display_label>Pages</display_label>
		<pages>773-778</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>94</seq_no>
		<title><![CDATA[Finding Alternative Clusterings Using Constraints]]></title>
		<page_from>773</page_from>
		<page_to>778</page_to>
		<doi_number>10.1109/ICDM.2008.141</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511445</url>
		<abstract>
			<par><![CDATA[The aim of data mining is to find novel and actionable insights. However, most algorithms typically just find a single explanation of the data even though alternatives could exist. In this work, we explore a general purpose approach to find an alternative clustering of the data with the aid of must-link and cannot-link constraints. This problem has received little attention in the literature and since our approach can be incorporated into the many clustering algorithms that use a distance function, compares favorably with existing work.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[clustering, constraints]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382209</person_id>
				<author_profile_id><![CDATA[81100099431]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Davidson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382210</person_id>
				<author_profile_id><![CDATA[81436593639]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zijie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Qi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511446</article_id>
		<sort_key>1000</sort_key>
		<display_label>Pages</display_label>
		<pages>779-784</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>95</seq_no>
		<title><![CDATA[Efficient Feature Selection in the Presence of Multiple Feature Classes]]></title>
		<page_from>779</page_from>
		<page_to>784</page_to>
		<doi_number>10.1109/ICDM.2008.56</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511446</url>
		<abstract>
			<par><![CDATA[We present an information theoretic approach to feature selection when the data possesses feature classes. Feature classes are pervasive in real data. For example, in gene expression data, the genes which serve as features may be divided into classes based on their membership in gene families or pathways. When doing word sense disambiguation or named entity extraction, features fall into classes including adjacent words, their parts of speech, and the topic and venue of the document the word is in. When predictive features occur predominantly in a small number of feature classes, our information theoretic approach significantly improves feature selection. Experiments on real and synthetic data demonstrate substantial improvement in predictive accuracy over the standard $L_0$ penalty-based stepwise and stream wise feature selection methods as well as over Lasso and Elastic Nets, all of which are oblivious to the existence of feature classes.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Feature Selection, Minimum Description Length Coding]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384436</person_id>
				<author_profile_id><![CDATA[81414592249]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paramveer]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Dhillon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384437</person_id>
				<author_profile_id><![CDATA[81100120952]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dean]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Foster]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384438</person_id>
				<author_profile_id><![CDATA[81100365076]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Lyle]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Ungar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511447</article_id>
		<sort_key>1010</sort_key>
		<display_label>Pages</display_label>
		<pages>785-790</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>96</seq_no>
		<title><![CDATA[Why Stacked Models Perform Effective Collective Classification]]></title>
		<page_from>785</page_from>
		<page_to>790</page_to>
		<doi_number>10.1109/ICDM.2008.126</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511447</url>
		<abstract>
			<par><![CDATA[Collective classification techniques jointly infer all class labels of a relational data set, using the inferences about one class label to influence inferences about related class labels. Kou and Cohen recently introduced an efficient relational model based on stacking that, despite its simplicity, has equivalent accuracy to more sophisticated joint inference approaches. Using experiments on both real and synthetic data, we show that the primary cause for the performance of the stacked model is the reduction in bias from learning the stacked model on inferred labels rather than true labels. The reduction in variance due to conditional inference also contributes to the effect but it is not as strong. In addition, we show that the performance of the joint inference and stacked learners can be attributed to an implicit weighting of local and relational features at learning time.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[collective classification, stacking, bias/variance]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381691</person_id>
				<author_profile_id><![CDATA[81100455954]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fast]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381692</person_id>
				<author_profile_id><![CDATA[81100640362]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511448</article_id>
		<sort_key>1020</sort_key>
		<display_label>Pages</display_label>
		<pages>791-796</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>97</seq_no>
		<title><![CDATA[Multiplicative Mixture Models for Overlapping Clustering]]></title>
		<page_from>791</page_from>
		<page_to>796</page_to>
		<doi_number>10.1109/ICDM.2008.103</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511448</url>
		<abstract>
			<par><![CDATA[The problem of overlapping clustering, where a point is allowed to belong to multiple clusters, is becoming increasingly important in a variety of applications. In this paper, we present an overlapping clustering algorithm based on multiplicative mixture models. We analyze a general setting where each component of the multiplicative mixture is from an exponential family, and present an efficient alternating maximization algorithm to learn the model and infer overlapping clusters. We also show that when each component is assumed to be a Gaussian, we can apply the kernel trick leading to non-linear cluster separators and obtain better clustering quality. The efficacy of the proposed algorithms is demonstrated usingexperiments on both UCI benchmark datasets and a microarray gene expression dataset.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384988</person_id>
				<author_profile_id><![CDATA[81414617732]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384989</person_id>
				<author_profile_id><![CDATA[81100144629]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Arindam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Banerjee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511449</article_id>
		<sort_key>1030</sort_key>
		<display_label>Pages</display_label>
		<pages>797-802</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>98</seq_no>
		<title><![CDATA[Anomaly Detection Support Vector Machine and Its Application to Fault Diagnosis]]></title>
		<page_from>797</page_from>
		<page_to>802</page_to>
		<doi_number>10.1109/ICDM.2008.69</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511449</url>
		<abstract>
			<par><![CDATA[We address the issue of classification problems in the following situation: test data include data belonging to unlearned classes. To address this issue, most previous works have taken two-stage strategies where unclear data are detected using an anomaly detection algorithm in the first stage while the rest of data are classified into learned classes using a classification algorithm in the second stage. In this study, we propose Anomaly Detection Support Vector Machine (ADSVM) which unifies classification and anomaly detection. ADSVM is unique in comparison with the previous work in that it addresses the two problems simultaneously. We also propose a multiclass extension of ADSVM that uses a pairwise voting strategy. We empirically present that ADSVM outperforms two-stage algorithms in application to an real automobile fault dataset, as well as to UCI benchmark datasets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Anomaly Detection, Classification, Fault Diagnosis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382211</person_id>
				<author_profile_id><![CDATA[81414600529]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ryohei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fujimaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511450</article_id>
		<sort_key>1040</sort_key>
		<display_label>Pages</display_label>
		<pages>803-808</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>99</seq_no>
		<title><![CDATA[A Recommendation System for Preconditioned Iterative Solvers]]></title>
		<page_from>803</page_from>
		<page_to>808</page_to>
		<doi_number>10.1109/ICDM.2008.105</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511450</url>
		<abstract>
			<par><![CDATA[Preconditioned iterative methods are often used to solve very large sparse systems of linear systems that arise in many scientific and engineering applications. The performance and robustness of these solvers is extremely sensitive to the choice of multiple preconditioner and solver parameters. Users of iterative methods often encounter an overwhelming number of combinations of choices for solvers, matrix preprocessing steps, preconditioners, and their parameters. The lack of a unified theoretical analysis of preconditioners coupled with limited knowledge of their interaction with linear systems makes it highly challenging for practitioners to choose good solver configurations. In this paper, we propose a novel, multi-stage learning based methodology for determining the best solver configurations to optimize the desired performance behavior for any given linear system. Empirical results over real performance data for the Hypre iterative solver package demonstrate the efficacy and flexibility of the proposed approach.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[solvers, recommendation system, linear systems, preconditioners, classification, regression, clustering, top-k ranking]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383338</person_id>
				<author_profile_id><![CDATA[81100355539]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[George]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383339</person_id>
				<author_profile_id><![CDATA[81100032672]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Anshul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383340</person_id>
				<author_profile_id><![CDATA[81100396930]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Vivek]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sarin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511301</article_id>
		<sort_key>1050</sort_key>
		<display_label>Pages</display_label>
		<pages>809-814</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>100</seq_no>
		<title><![CDATA[Cost-Sensitive Parsimonious Linear Regression]]></title>
		<page_from>809</page_from>
		<page_to>814</page_to>
		<doi_number>10.1109/ICDM.2008.76</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511301</url>
		<abstract>
			<par><![CDATA[We examine linear regression problems where some features may only be observable at a cost (e.g., in medical domains where features may correspond to diagnostic tests that take time and costs money). This can be important in the context of data mining, in order to obtain the best predictions from the data on a limited cost budget. We define a parsimonious linear regression objective criterion that jointly minimizes prediction error and feature cost. We modify least angle regression algorithms commonly used for sparse linear regression to produce the ParLiR algorithm, whichnot only provides an efficient and parsimonious solution as we demonstrate empirically, but it also provides formal guarantees that we prove theoretically.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Cost sensitivity, regression, linear regression, sparsity]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381281</person_id>
				<author_profile_id><![CDATA[81388601165]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robby]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goetschalckx]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381282</person_id>
				<author_profile_id><![CDATA[81100650504]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kurt]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Driessens]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381283</person_id>
				<author_profile_id><![CDATA[81363592163]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Scott]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sanner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511302</article_id>
		<sort_key>1060</sort_key>
		<display_label>Pages</display_label>
		<pages>815-820</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>101</seq_no>
		<title><![CDATA[Text Mining in Radiology Reports]]></title>
		<page_from>815</page_from>
		<page_to>820</page_to>
		<doi_number>10.1109/ICDM.2008.150</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511302</url>
		<abstract>
			<par><![CDATA[Medical text mining has gained increasing interest in recent years. Radiology reports contain rich information describing radiologist&#8217;s observations on the patient&#8217;s medical conditions in the associated medical images. However, as most reports are in free text format, the valuable information contained in those reports cannot be easily accessed and used, unless proper text mining has been applied. In this paper, we propose a text mining system to extract and use the information in radiology reports. The system consists of three main modules: a medical finding extractor, a report and image retriever, and a text-assisted image feature extractor. In evaluation, the overall precision and recall for medical finding extraction are 95.5% and 87.9% respectively, and for all modifiers of the medical findings 88.2% and 82.8% respectively. The overall result of report and image retrieval module and text-assisted image feature extraction module is satisfactory to radiologists.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Text Mining, Medical Informatics]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384539</person_id>
				<author_profile_id><![CDATA[81414596303]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tianxia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384540</person_id>
				<author_profile_id><![CDATA[81414607389]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chew]]></first_name>
				<middle_name><![CDATA[Lim]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384541</person_id>
				<author_profile_id><![CDATA[81100240571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tze]]></first_name>
				<middle_name><![CDATA[Yun]]></middle_name>
				<last_name><![CDATA[Leong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384542</person_id>
				<author_profile_id><![CDATA[81414611158]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Cheng]]></first_name>
				<middle_name><![CDATA[Kiang]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384543</person_id>
				<author_profile_id><![CDATA[81414608873]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Boon]]></first_name>
				<middle_name><![CDATA[Chuan]]></middle_name>
				<last_name><![CDATA[Pang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384544</person_id>
				<author_profile_id><![CDATA[81414610873]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[C.  Tchoyoson]]></middle_name>
				<last_name><![CDATA[Lim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384545</person_id>
				<author_profile_id><![CDATA[81423592672]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Qi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384546</person_id>
				<author_profile_id><![CDATA[81414612655]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Suisheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384547</person_id>
				<author_profile_id><![CDATA[81414604261]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[Zhuo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511303</article_id>
		<sort_key>1070</sort_key>
		<display_label>Pages</display_label>
		<pages>821-826</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>102</seq_no>
		<title><![CDATA[A Hierarchical Algorithm for Clustering Uncertain Data via an Information-Theoretic Approach]]></title>
		<page_from>821</page_from>
		<page_to>826</page_to>
		<doi_number>10.1109/ICDM.2008.115</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511303</url>
		<abstract>
			<par><![CDATA[In recent years there has been a growing interest in clustering uncertain data. In contrast to traditional, "sharp" data representation models, uncertain data objects can be represented in terms of an uncertainty region over which a probability density function (pdf) is defined. In this context, the focus has been mainly on partitional and density-based approaches, whereas hierarchical clustering schemes have drawn less attention.We propose a centroid-linkage-based agglomerative hierarchical algorithm for clustering uncertain objects, named U-AHC. The cluster merging criterion is based on an information-theoretic measure to compute the distance between cluster prototypes. These prototypes are represented as mixture densities that summarize the pdfs of all the uncertain objects in the clusters. Experiments have shown that our method outperforms state-of-the-art clustering algorithms from an accuracy viewpoint while achieving reasonably good efficiency.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[uncertain data management, hierarchical clustering, information-theoretic distance measures]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385065</person_id>
				<author_profile_id><![CDATA[81335491254]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Francesco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gullo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385066</person_id>
				<author_profile_id><![CDATA[81335496174]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Giovanni]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ponti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385067</person_id>
				<author_profile_id><![CDATA[81100286971]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Andrea]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tagarelli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385068</person_id>
				<author_profile_id><![CDATA[81100249636]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Sergio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greco]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511304</article_id>
		<sort_key>1080</sort_key>
		<display_label>Pages</display_label>
		<pages>827-832</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>103</seq_no>
		<title><![CDATA[Discovering Significant Patterns in Multi-stream Sequences]]></title>
		<page_from>827</page_from>
		<page_to>832</page_to>
		<doi_number>10.1109/ICDM.2008.146</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511304</url>
		<abstract>
			<par><![CDATA[Discovering significant patterns in synchronized multi-stream sequences also known as multi-attribute event sequences (multi-sequences), is an important problem in many domains, including monitoring systems and information retrieval. In this paper we propose a new approach for assessing significance of multi-stream patterns in multi-attribute event sequences. In experiments on physiological multi-stream data we show applicability of our method.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[multi-stream data mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385069</person_id>
				<author_profile_id><![CDATA[81343493912]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gwadera]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385070</person_id>
				<author_profile_id><![CDATA[81100211564]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fabio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Crestani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511305</article_id>
		<sort_key>1090</sort_key>
		<display_label>Pages</display_label>
		<pages>833-838</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>104</seq_no>
		<title><![CDATA[Graph-Based Rare Category Detection]]></title>
		<page_from>833</page_from>
		<page_to>838</page_to>
		<doi_number>10.1109/ICDM.2008.122</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511305</url>
		<abstract>
			<par><![CDATA[Rare category detection is the task of identifying examples from rare classes in an unlabeled data set. It is an open challenge in machine learning and plays key roles in real applications such as financial fraud detection, network intrusion detection, astronomy, spam image detection, etc. In this paper, we develop a new graph-based method for rare category detection named GRADE. It makes use of the global similarity matrix motivated by the manifold ranking algorithm, which results in more compact clusters for the minority classes; by selecting examples from the regions where probability density changes the most, it relaxes the assumption that the majority classes and the minority classes are separable. Furthermore, when detailed information about the data set is not available, we develop a modified version of GRADE named GRADE-LI, which only needs an upper bound on the proportion of each minority class as input. Besides working with data with structured features, both GRADE and GRADE-LI can also work with graph data, which can not be handled by existing rare category detection methods. Experimental results on both synthetic and real data sets demonstrate the effectiveness of the GRADE and GRADE-LI algorithms.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[rare category detection, graph]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384044</person_id>
				<author_profile_id><![CDATA[81540269856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jingrui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384045</person_id>
				<author_profile_id><![CDATA[81418597820]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384046</person_id>
				<author_profile_id><![CDATA[81100574279]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lawrence]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511306</article_id>
		<sort_key>1100</sort_key>
		<display_label>Pages</display_label>
		<pages>839-844</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>105</seq_no>
		<title><![CDATA[Clustering Documents with Active Learning Using Wikipedia]]></title>
		<page_from>839</page_from>
		<page_to>844</page_to>
		<doi_number>10.1109/ICDM.2008.80</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511306</url>
		<abstract>
			<par><![CDATA[Wikipedia has been applied as a background knowledge base to various text mining problems, but very few attempts have been made to utilize it for document clustering. In this paper we propose to exploit the semantic knowledge in Wikipedia for clustering, enabling the automatic grouping of documents with similar themes. Although clustering is intrinsically unsupervised, recent research has shown that incorporating supervision improves clustering performance, even when limited supervision is provided. The approach presented in this paper applies supervision using active learning. We first utilize Wikipedia to create a concept-based representation of a text document, with each concept associated to a Wikipedia article. We then exploit the semantic relatedness between Wikipedia concepts to find pair-wise instance-level constraints for supervised clustering, guiding clustering towards the direction indicated by the constraints. We test our approach on three standard text document datasets. Empirical results show that our basic document representation strategy yields comparable performance to previous attempts; and adding constraints improves clustering performance further by up to 20%.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[document representation, text clustering, active learning, Wikipedia]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381284</person_id>
				<author_profile_id><![CDATA[81418592688]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Anna]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381285</person_id>
				<author_profile_id><![CDATA[81340491525]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Milne]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381286</person_id>
				<author_profile_id><![CDATA[81100370197]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Eibe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Frank]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381287</person_id>
				<author_profile_id><![CDATA[81100252005]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Witten]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511313</article_id>
		<sort_key>1110</sort_key>
		<display_label>Pages</display_label>
		<pages>845-850</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>106</seq_no>
		<title><![CDATA[Direct Zero-Norm Optimization for Feature Selection]]></title>
		<page_from>845</page_from>
		<page_to>850</page_to>
		<doi_number>10.1109/ICDM.2008.60</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511313</url>
		<abstract>
			<par><![CDATA[Zero-norm, defined as the number of non-zero elements in a vector, is an ideal quantity for feature selection. However, minimization of zero-norm is generally regarded as a combinatorially difficult optimization problem. In contrast to previous methods that usually optimize a surrogate of zero-norm, we propose a direct optimizationmethod to achieve zero-norm for feature selection in this paper. Based on Expectation Maximization (EM), this method boils down to solving a sequence of Quadratic Programming problems and hence can be practically optimized in polynomial time. We show that the proposed optimization technique has a nice Bayesian interpretation and converges to the true zero norm asymptotically, provided that agood starting point is given. Following the scheme of our proposed zero-norm, we even show that an arbitrary-norm based Support Vector Machine can be achieved in polynomial time. A series of experiments demonstrate that our proposed EM based zero-norm outperforms other state-of-the-art methods for feature selection on biological microarray data and UCI data, in terms of both the accuracy and the learning efficiency.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382342</person_id>
				<author_profile_id><![CDATA[81339505908]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kaizhu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382343</person_id>
				<author_profile_id><![CDATA[81100193887]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Irwin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[King]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382344</person_id>
				<author_profile_id><![CDATA[81100033051]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Lyu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511314</article_id>
		<sort_key>1120</sort_key>
		<display_label>Pages</display_label>
		<pages>851-856</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>107</seq_no>
		<title><![CDATA[Discovering Flow Anomalies]]></title>
		<subtitle><![CDATA[A SWEET Approach]]></subtitle>
		<page_from>851</page_from>
		<page_to>856</page_to>
		<doi_number>10.1109/ICDM.2008.117</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511314</url>
		<abstract>
			<par><![CDATA[Given a percentage-threshold and readings from a pair of consecutive upstream and downstream sensors, flow anomaly discovery identifies dominant time intervals where the fraction of time instants of significantly mis-matched sensor readings exceed the given percentage-threshold. Discovering flow anomalies (FA) is an important problem in environmental flow monitoring networks and early warning detection systems for water quality problems. However, mining FAs is computationally expensive because of the large (potentially infinite) number of time instants of measurement and potentially long delays due to stagnant (e.g. lakes) or slow moving (e.g. wetland) water bodies between consecutive sensors. Traditional outlier detection methods (e.g. t-test) are suited for detecting transient FAs (i.e., time instants of significant mis-matches across consecutive sensors) and cannot detect persistent FAs (i.e., long variable time-windows with a high fraction of time instant transient FAs) due to a lack of a pre-defined window size. In contrast, we propose a Smart Window Enumeration and Evaluation of persistence-Thresholds (SWEET) method to efficiently explore the search space of all possible window lengths. Computation overhead is brought down significantly by restricting the start and end points of a window to coincide with transient FAs, using a smart counter and efficient pruning techniques. Experimental evaluation using a real dataset shows our proposed approach outperforms Na&#305;ve alternatives.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384583</person_id>
				<author_profile_id><![CDATA[81375616137]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Kang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384584</person_id>
				<author_profile_id><![CDATA[81100610476]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shekhar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384585</person_id>
				<author_profile_id><![CDATA[81414619557]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Christine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wennen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384586</person_id>
				<author_profile_id><![CDATA[81414606909]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Paige]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Novak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511315</article_id>
		<sort_key>1130</sort_key>
		<display_label>Pages</display_label>
		<pages>857-862</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>108</seq_no>
		<title><![CDATA[Boosting Relational Sequence Alignments]]></title>
		<page_from>857</page_from>
		<page_to>862</page_to>
		<doi_number>10.1109/ICDM.2008.127</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511315</url>
		<abstract>
			<par><![CDATA[The task of aligning sequences arises in many applications. Classical dynamic programming approaches require the explicit state enumeration in the reward model. This is often impractical: the number of states grows very quickly with the number of domain objects and relations among these objects. Relational sequence alignment aims at exploiting symbolic structure to avoid the full enumeration. This comes at the expense of a more complex reward model selection problem: virtually infinitely many abstraction levels have to be explored. In this paper, we apply gradient-based boosting to leverage this problem. Specifically, we show how to reduce the learning problem to a series of relational regressions problems. The main benefit of this is that interactions between states variables are introduced only as needed, so that the potentially infinite search space is not explicitly considered. As our experimental results show, this boosting approach can significantly improve upon established results in challenging applications.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Relational Sequences, Boosting]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382923</person_id>
				<author_profile_id><![CDATA[81100552915]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andreas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Karwath]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382924</person_id>
				<author_profile_id><![CDATA[81337490510]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kristian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kersting]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382925</person_id>
				<author_profile_id><![CDATA[81330493648]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Niels]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Landwehr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511316</article_id>
		<sort_key>1140</sort_key>
		<display_label>Pages</display_label>
		<pages>863-868</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>109</seq_no>
		<title><![CDATA[Support Vector Regression for Censored Data (SVRc)]]></title>
		<subtitle><![CDATA[A Novel Tool for Survival Analysis]]></subtitle>
		<page_from>863</page_from>
		<page_to>868</page_to>
		<doi_number>10.1109/ICDM.2008.50</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511316</url>
		<abstract>
			<par><![CDATA[A crucial challenge in predictive modeling for survival analysis is managing censored observations in the data. The Cox proportional hazards model is the standard tool for the analysis of continuous censored survival data. We propose a novel machine learning algorithm, Support Vector Regression for Censored Data (SVRc) for improved analysis of medical survival data. SVRc leverages the high-dimensional capabilities of traditional SVR while adapting it for use with censored data through a modified asymmetric loss/penalty function which allows censored (left and right censored) data to be processed. We applied the new algorithm to predict the recurrence and disease progression of prostate cancer, breast cancer and lung cancer. Compared with the traditional Cox model, SVRc achieves significant improvement in overall accuracy as well as in the ability to identify high-risk and low-risk patient populations.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Support vector, survival analysis, Cox model, censored, cancer prognosis, asymmetric loss and penalty, concordance index]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383497</person_id>
				<author_profile_id><![CDATA[81414616715]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Faisal]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Khan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383498</person_id>
				<author_profile_id><![CDATA[81100321344]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Valentina]]></first_name>
				<middle_name><![CDATA[Bayer]]></middle_name>
				<last_name><![CDATA[Zubek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511317</article_id>
		<sort_key>1150</sort_key>
		<display_label>Pages</display_label>
		<pages>869-874</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>110</seq_no>
		<title><![CDATA[Nearest Neighbour Classifiers for Streaming Data with Delayed Labelling]]></title>
		<page_from>869</page_from>
		<page_to>874</page_to>
		<doi_number>10.1109/ICDM.2008.33</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511317</url>
		<abstract>
			<par><![CDATA[We study streaming data where the true labels come with a delay. The question is whether the online nearest neighbour classifier (IB2 and IB3 here) should employ the unlabelled data. Three strategies are examined: do-nothing, replace and forget. Experiments with 28 data sets show that IB2 benefits from unlabelled data, while IB3 does not.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Pattern recognition, online learning, incremental learning, nearest neighbour classifier, streaming data, delayed labelling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382345</person_id>
				<author_profile_id><![CDATA[81100442435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ludmila]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Kuncheva]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382346</person_id>
				<author_profile_id><![CDATA[81414616666]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[Salvador]]></middle_name>
				<last_name><![CDATA[S&#225;nchez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511318</article_id>
		<sort_key>1160</sort_key>
		<display_label>Pages</display_label>
		<pages>875-880</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>111</seq_no>
		<title><![CDATA[WiFIsViz]]></title>
		<subtitle><![CDATA[Effective Visualization of Frequent Itemsets]]></subtitle>
		<page_from>875</page_from>
		<page_to>880</page_to>
		<doi_number>10.1109/ICDM.2008.93</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511318</url>
		<abstract>
			<par><![CDATA[Frequent itemset mining plays an essential role in the mining of many different patterns. Most existing frequent itemset mining algorithms return the mined results--namely, frequent itemsets--in the form of textual lists. However, the use of visual representation can enhance the user understanding of the inherent relations in a collection of frequent itemsets. In this paper, we propose an effective visualizer, called WiFIsViz, to display the mined frequent itemsets. WiFIsViz provides users with an overview and details about the itemsets. Moreover, this visualizer is also equipped with several interactive features for effective visualization of the frequent itemsets mined from various real-life applications.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Frequent itemset mining, Frequent patterns, Visualization of mining results]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381311</person_id>
				<author_profile_id><![CDATA[81339512271]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Carson]]></first_name>
				<middle_name><![CDATA[Kai-Sang]]></middle_name>
				<last_name><![CDATA[Leung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381312</person_id>
				<author_profile_id><![CDATA[81100459517]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pourang]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Irani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381313</person_id>
				<author_profile_id><![CDATA[81414614127]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Carmichael]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511323</article_id>
		<sort_key>1170</sort_key>
		<display_label>Pages</display_label>
		<pages>881-886</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>112</seq_no>
		<title><![CDATA[Fast and Memory Efficient Mining of High Utility Itemsets in Data Streams]]></title>
		<page_from>881</page_from>
		<page_to>886</page_to>
		<doi_number>10.1109/ICDM.2008.107</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511323</url>
		<abstract>
			<par><![CDATA[Efficient mining of high utility itemsets has become one of the most interesting data mining tasks with broad applications. In this paper, we proposed two efficient one-pass algorithms, MHUI-BIT and MHUI-TID, for mining high utility itemsets from data streams within a transaction-sensitive sliding window. Two effective representations of item information and an extended lexicographical tree-based summary data structure are developed to improve the efficiency of mining high utility itemsets. Experimental results show that the proposed algorithms outperform than the existing algorithms for mining high utility itemsets from data streams.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Data mining, data streams, utility itemset mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381859</person_id>
				<author_profile_id><![CDATA[81100480124]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hua-Fu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381860</person_id>
				<author_profile_id><![CDATA[81414602533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hsin-Yun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381861</person_id>
				<author_profile_id><![CDATA[81414614355]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yi-Cheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381862</person_id>
				<author_profile_id><![CDATA[81414612023]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Yu-Jiun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381863</person_id>
				<author_profile_id><![CDATA[81375596142]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Suh-Yin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511324</article_id>
		<sort_key>1180</sort_key>
		<display_label>Pages</display_label>
		<pages>887-892</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>113</seq_no>
		<title><![CDATA[HIREL]]></title>
		<subtitle><![CDATA[An Incremental Clustering Algorithm for Relational Datasets]]></subtitle>
		<page_from>887</page_from>
		<page_to>892</page_to>
		<doi_number>10.1109/ICDM.2008.116</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511324</url>
		<abstract>
			<par><![CDATA[Traditional clustering approaches usually analyze static datasets in which objects are kept unchanged after being processed, but many practical datasets are dynamically modified which means some previously learned patterns have to be updated accordingly. Re-clustering the whole dataset from scratch is not a good choice due to the frequent data modifications and the limited out-of-service time, so the development of incremental clustering approaches is highly desirable. Besides that, propositional clustering algorithms are not suitable for relational datasets because of their quadratic computational complexity. In this paper, we propose an incremental clustering algorithm that requires only one pass of the relational dataset. The utilization of the Representative Objects and the balanced Search Tree greatly accelerate the learning procedure. Experimental results prove the effectiveness of our algorithm.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Clustering, Relational, Incremental]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383523</person_id>
				<author_profile_id><![CDATA[81414604084]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383524</person_id>
				<author_profile_id><![CDATA[81100232025]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sarabjot]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Anand]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511325</article_id>
		<sort_key>1190</sort_key>
		<display_label>Pages</display_label>
		<pages>893-898</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>114</seq_no>
		<title><![CDATA[Time Sensitive Ranking with Application to Publication Search]]></title>
		<page_from>893</page_from>
		<page_to>898</page_to>
		<doi_number>10.1109/ICDM.2008.155</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511325</url>
		<abstract>
			<par><![CDATA[Link-based ranking has contributed significantly to the success of Web search. PageRank and HITS are the best known link-based ranking algorithms. These algorithms do not consider an important dimension, the temporal dimension. They favor older pages because these pages have many in-links accumulated over time. Bringing new and quality pages to the users is important because most users want the latest information. Existing remedies to PageRank are mostly heuristic approaches. This paper investigates the temporal aspect of ranking with application to publication search, and proposes a principled method based on the stationary probability distribution of the Markov Chain. The proposed techniques are evaluated empirically using a large collection of high energy particle physics publication. The results show that the proposed methods are highly effective.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[time sensitive, publication, ranking, search]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381350</person_id>
				<author_profile_id><![CDATA[81414606056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381351</person_id>
				<author_profile_id><![CDATA[81414615421]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381352</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511326</article_id>
		<sort_key>1200</sort_key>
		<display_label>Pages</display_label>
		<pages>899-904</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>115</seq_no>
		<title><![CDATA[Releasing the SVM Classifier with Privacy-Preservation]]></title>
		<page_from>899</page_from>
		<page_to>904</page_to>
		<doi_number>10.1109/ICDM.2008.19</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511326</url>
		<abstract>
			<par><![CDATA[Support vector machine (SVM) is a widely used tool in classification problem. SVM solves a quadratic optimization problem to decide which instances of training dataset are support vectors, i.e., the necessarily informative instances to form the classifier. The support vectors are intact tuples taken from the training dataset. Releasing the SVM classifier to public use or shipping the SVM classifier to clients will disclose the private content of support vectors, violating the privacy-preservation requirement in some legal or commercial reasons. To the best of our knowledge, there has not been work extending the notion of privacy-preservation to releasing the SVM classifier. In this paper, we propose an approximation approach which post-processes the SVM classifier to protect the private content of support vectors. This approach is designed for the commonly used Gaussian radial basis function kernel. By applying this post-processor on the SVM classifier, the resulted privacy-preserving SVM classifier can be publicly released without exposing the private content of support vectors and is able to provide comparable classification accuracy to the original SVM classifier.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Privacy-Preserving, Support vector machine]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381353</person_id>
				<author_profile_id><![CDATA[81466645898]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Keng-Pei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381354</person_id>
				<author_profile_id><![CDATA[81450594725]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ming-Syan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511327</article_id>
		<sort_key>1210</sort_key>
		<display_label>Pages</display_label>
		<pages>905-910</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>116</seq_no>
		<title><![CDATA[Text Cube]]></title>
		<subtitle><![CDATA[Computing IR Measures for Multidimensional Text Database Analysis]]></subtitle>
		<page_from>905</page_from>
		<page_to>910</page_to>
		<doi_number>10.1109/ICDM.2008.135</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511327</url>
		<abstract>
			<par><![CDATA[Since Jim Gray introduced the concept of &#8221;data cube&#8221; in 1997, data cube, associated with online analytical processing (OLAP), has become a driving engine in data warehouse industry. Because the boom of Internet has given rise to an ever increasing amount of text data associated with other multidimensional information, it is natural to propose a data cube model that integrates the power of traditional OLAP and IR techniques for text. In this paper, we propose a Text-Cube model on multidimensional text database and study effective OLAP over such data. Two kinds of hierarchies are distinguishable inside: dimensional hierarchy and term hierarchy. By incorporating these hierarchies, we conduct systematic studies on efficient text-cube implementation, OLAP execution and query processing. Our performance study shows the high promise of our methods.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Cube, Text, OLAP]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385140</person_id>
				<author_profile_id><![CDATA[81384612004]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cindy]]></first_name>
				<middle_name><![CDATA[Xide]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385141</person_id>
				<author_profile_id><![CDATA[81318493333]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bolin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ding]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385142</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385143</person_id>
				<author_profile_id><![CDATA[81313483490]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Feida]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385144</person_id>
				<author_profile_id><![CDATA[81100535698]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Bo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511328</article_id>
		<sort_key>1220</sort_key>
		<display_label>Pages</display_label>
		<pages>911-916</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>117</seq_no>
		<title><![CDATA[Multi-Space-Mapped SVMs for Multi-class Classification]]></title>
		<page_from>911</page_from>
		<page_to>916</page_to>
		<doi_number>10.1109/ICDM.2008.13</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511328</url>
		<abstract>
			<par><![CDATA[In SVMs-based multiple classification, it is not always possible to find an appropriate kernel function to map all the classes from different distribution functions into a feature space where they are linearly separable from each other. This is even worse if the number of classes is very large. As a result, the classification accuracy is not as good as expected. In order to improve the performance of SVMs-based multi-classifiers, this paper proposes a method, named multi-space-mapped SVMs, to map the classes into different feature spaces and then classify them. The proposed method reduces the requirements for the kernel function. Substantial experiments have been conducted on One-against-All, One-against-One, FSVM, DDAG algorithms and our algorithm using six UCI data sets. The statistical results show that the proposed method has a higher probability of finding appropriate kernel functions than traditional methods and outperforms others.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[support vector machine, multiple classification]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383525</person_id>
				<author_profile_id><![CDATA[81328489008]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383526</person_id>
				<author_profile_id><![CDATA[81451595792]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Longbing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383527</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383528</person_id>
				<author_profile_id><![CDATA[81350601426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Chengqi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511335</article_id>
		<sort_key>1230</sort_key>
		<display_label>Pages</display_label>
		<pages>917-922</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>118</seq_no>
		<title><![CDATA[Spotting Significant Changing Subgraphs in Evolving Graphs]]></title>
		<page_from>917</page_from>
		<page_to>922</page_to>
		<doi_number>10.1109/ICDM.2008.112</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511335</url>
		<abstract>
			<par><![CDATA[Graphs are popularly used to model structural relationships between objects. In many application domains such as social networks, sensor networks and telecommunication, graphs evolve over time. In this paper, we study a new problem of discovering the subgraphs that exhibit significant changes in evolving graphs. This problem is challenging since it is hard to define changing regions that are closely related to the actual changes (i.e., additions/deletions of edges/nodes) in graphs. We formalize the problem, and design an efficient algorithm that is able to identify the changing subgraphs incrementally. Our experimental results on real datasets show that our solution is very efficient and the resultant subgraphs are of high quality.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384096</person_id>
				<author_profile_id><![CDATA[81485653303]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384097</person_id>
				<author_profile_id><![CDATA[81447600785]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jeffrey]]></first_name>
				<middle_name><![CDATA[Xu]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384098</person_id>
				<author_profile_id><![CDATA[81313481134]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yiping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384099</person_id>
				<author_profile_id><![CDATA[81414597412]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Xuemin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384100</person_id>
				<author_profile_id><![CDATA[81414617657]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Lei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511336</article_id>
		<sort_key>1240</sort_key>
		<display_label>Pages</display_label>
		<pages>923-928</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>119</seq_no>
		<title><![CDATA[Classifying High-Dimensional Text and Web Data Using Very Short Patterns]]></title>
		<page_from>923</page_from>
		<page_to>928</page_to>
		<doi_number>10.1109/ICDM.2008.139</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511336</url>
		<abstract>
			<par><![CDATA[In this paper, we propose the "Democratic Classifier", a simple pattern-based classification algorithm that uses very short patterns for classification, and does not rely on the minimum support threshold. Borrowing ideas from democracy, our training phase allows each training instance to vote for an equal number of candidate size-2 patterns. The training instances select patterns by effectively balancing between local, class, and global significance of patterns. The selected patterns are simultaneously added to the model for all applicable classes and a novel power law based weighing scheme adjusts their weights with respect of each class. Results of experiments performed on 121 common text and web datasets show that our algorithm almost always outperforms state of the art classification algorithms, without any parameter tuning. On 100 real-life web datasets, the average absolute classification accuracy improvement was as great as 9.4% over SVM, Harmony, C4.5 and KNN. Also, our algorithm ran about 3.5 times faster than the fastest existing pattern-based classification algorithm.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Classification, interestingness measures, text classification, pattern-based classification, feature selection]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381895</person_id>
				<author_profile_id><![CDATA[81315490626]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hassan]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Malik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381896</person_id>
				<author_profile_id><![CDATA[81100113385]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Kender]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511337</article_id>
		<sort_key>1250</sort_key>
		<display_label>Pages</display_label>
		<pages>929-934</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>120</seq_no>
		<title><![CDATA[A Practical Approach to Classify Evolving Data Streams]]></title>
		<subtitle><![CDATA[Training with Limited Amount of Labeled Data]]></subtitle>
		<page_from>929</page_from>
		<page_to>934</page_to>
		<doi_number>10.1109/ICDM.2008.152</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511337</url>
		<abstract>
			<par><![CDATA[Recent approaches in classifying evolving data streams are based on supervised learning algorithms, which can be trained with labeled data only. Manual labeling of data is both costly and time consuming. Therefore, in a real streaming environment, where huge volumes of data appear at a high speed, labeled data may be very scarce. Thus, only a limited amount of training data may be available for building the classification models, leading to poorly trained classifiers. We apply a novel technique to overcome this problem by building a classification model from a training set having both unlabeled and a small amount of labeled instances. This model is built as micro-clusters using semisupervised clustering technique and classification is performed with &#954;-nearest neighbor algorithm. An ensemble of these models is used to classify the unlabeled data. Empirical evaluation on both synthetic data and real botnet traffic reveals that our approach, using only a small amount of labeled data for training, outperforms state-of-the-art stream classification algorithms that use twenty times more labeled data than our approach.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Data stream, semi-supervised clustering, ensemble classification]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381897</person_id>
				<author_profile_id><![CDATA[81350592477]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mohammad]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Masud]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381898</person_id>
				<author_profile_id><![CDATA[81314494134]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381899</person_id>
				<author_profile_id><![CDATA[81100344538]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Latifur]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Khan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381900</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381901</person_id>
				<author_profile_id><![CDATA[81100621824]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Bhavani]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thuraisingham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511338</article_id>
		<sort_key>1260</sort_key>
		<display_label>Pages</display_label>
		<pages>935-940</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>121</seq_no>
		<title><![CDATA[Spatiotemporal Relational Probability Trees]]></title>
		<subtitle><![CDATA[An Introduction]]></subtitle>
		<page_from>935</page_from>
		<page_to>940</page_to>
		<doi_number>10.1109/ICDM.2008.134</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511338</url>
		<abstract>
			<par><![CDATA[We introduce spatiotemporal relational probability trees (SRPTs), probability estimation trees for relational data that can vary in both space and time. The SRPT algorithm addresses the exponential increase in search complexity through sampling. We validate the SRPT using a simulated data set and we empirically demonstrate the SRPT algorithm on two real-world data sets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[spatiotemporal, statistical relational data mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383563</person_id>
				<author_profile_id><![CDATA[81100298011]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Amy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McGovern]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383564</person_id>
				<author_profile_id><![CDATA[81414619622]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nathan]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Hiers]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383565</person_id>
				<author_profile_id><![CDATA[81414607435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Collier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383566</person_id>
				<author_profile_id><![CDATA[81414600129]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Gagne II]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383567</person_id>
				<author_profile_id><![CDATA[81479655289]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Rodger]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Brown]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511339</article_id>
		<sort_key>1270</sort_key>
		<display_label>Pages</display_label>
		<pages>941-946</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>122</seq_no>
		<title><![CDATA[Stream Sequential Pattern Mining with Precise Error Bounds]]></title>
		<page_from>941</page_from>
		<page_to>946</page_to>
		<doi_number>10.1109/ICDM.2008.154</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511339</url>
		<abstract>
			<par><![CDATA[Sequential pattern mining is an interesting data mining problem with many real-world applications. This problem has been studied extensively in static databases. However, in recent years, emerging applications have introduced a new form of data called data stream. In a data stream, new elements are generated continuously. This poses additional constraints on the methods used for mining such data: memory usage is restricted, the infinitely flowing original dataset cannot be scanned multiple times, and current results should be available on demand.This paper introduces two effective methods for mining sequential patterns from data streams: the SS-BE method and the SS-MB method. The proposed methods break the stream into batches and only process each batch once. The two methods use different pruning strategies that restrict the memory usage but can still guarantee that all true sequential patterns are output at the end of any batch. Both algorithms scale linearly in execution time as the number of sequences grows, making them effective methods for sequential pattern mining in data streams. The experimental results also show that our methods are very accurate in that only a small fraction of the patterns that are output are false positives. Even for these false positives, SS-BE guarantees that their true support is above a pre-defined threshold.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[sequential pattern mining, data stream mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381381</person_id>
				<author_profile_id><![CDATA[81414618624]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Luiz]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Mendes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381382</person_id>
				<author_profile_id><![CDATA[81318493333]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bolin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ding]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381383</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511340</article_id>
		<sort_key>1280</sort_key>
		<display_label>Pages</display_label>
		<pages>947-952</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>123</seq_no>
		<title><![CDATA[Organic Pie Charts]]></title>
		<page_from>947</page_from>
		<page_to>952</page_to>
		<doi_number>10.1109/ICDM.2008.64</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511340</url>
		<abstract>
			<par><![CDATA[We present a new visualization of the distance and cluster structure of high dimensional data. It is particularly well suited for analysis tasks of users unfamiliar with complex data analysis techniques as it builds on the well known concept of pie charts. The non-linear projection capabilities of Emergent Self-Organizing Maps (ESOM) are used to generate a topology-preserving ordering of the data points on a circle. The distance structure within the high dimensional space is visualized on the circle analogously to the U-Matrix method for two-dimensional SOM. The resulting display resembles pie charts but has an organic structure that naturally emerges from the data. Pie segments correspond to groups of similar data points. Boundaries between segments represent low density regions with larger distances among neighboring points in the high dimensional space. The representation of distances in the form of a periodic sequence of values makes time series segmentation applicable to automated clustering of the data that is in sync with the visualization. We discuss the usefulness of the method on a variety of data sets to demonstrate the applicability in applications such as document analysis or customer segmentation.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[visualization, pie chart, clustering, self-organizing maps, time series segmentation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383568</person_id>
				<author_profile_id><![CDATA[81317489092]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fabian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moerchen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511346</article_id>
		<sort_key>1290</sort_key>
		<display_label>Pages</display_label>
		<pages>953-958</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>124</seq_no>
		<title><![CDATA[Frequent Subgraph Retrieval in Geometric Graph Databases]]></title>
		<page_from>953</page_from>
		<page_to>958</page_to>
		<doi_number>10.1109/ICDM.2008.38</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511346</url>
		<abstract>
			<par><![CDATA[Discovery of knowledge from geometric graph databases is of particular importance in chemistry and biology, because chemical compounds and proteins are represented as graphs with 3D geometric coordinates. In such applications, scientists are not interested in the statistics of the whole database. Instead they need information about a novel drug candidate or protein at hand, represented as a query graph. We propose a polynomial-delay algorithm for geometric frequent subgraph retrieval. It enumerates all subgraphs of a single given query graph which are frequent geometric $\epsilon$-subgraphs under the entire class of rigid geometric transformations in a database. By using geometric$\epsilon$-subgraphs, we achieve tolerance against variations in geometry. We compare the proposed algorithm to gSpan on chemical compound data, and we show that for a given minimum support the total number of frequent patterns is substantially limited by requiring geometric matching. Although the computation time per pattern is larger than for non-geometric graph mining,the total time is within a reasonable level even for small minimum support.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[geometric graph mining, frequent graph mining, geometric patterns]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384646</person_id>
				<author_profile_id><![CDATA[81414597536]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sebastian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nowozin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384647</person_id>
				<author_profile_id><![CDATA[81100030766]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Koji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsuda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511347</article_id>
		<sort_key>1300</sort_key>
		<display_label>Pages</display_label>
		<pages>959-964</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>125</seq_no>
		<title><![CDATA[Alert Detection in System Logs]]></title>
		<page_from>959</page_from>
		<page_to>964</page_to>
		<doi_number>10.1109/ICDM.2008.132</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511347</url>
		<abstract>
			<par><![CDATA[We present Nodeinfo, an unsupervised algorithm for anomaly detection in system logs. We demonstrate Nodeinfo's effectiveness on data from four of the world's most powerful supercomputers: using logs representing over 746 million processor-hours, in which anomalous events called alerts were manually tagged for scoring, we aim to automatically identify the regions of the log containing those alerts. We formalize the alert detection task in these terms, describe how Nodeinfo uses the information entropy of message terms to identify alerts, and present an online version of this algorithm, which is now in production use. This is the first work to investigate alert detection on (several) publicly-available supercomputer system logs, thereby providing a reproducible performance baseline.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[anomaly detection, log analysis, hpc, information theory, fault detection]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381403</person_id>
				<author_profile_id><![CDATA[81320493718]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Adam]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Oliner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381404</person_id>
				<author_profile_id><![CDATA[81100399954]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alex]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aiken]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381405</person_id>
				<author_profile_id><![CDATA[81330498917]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stearley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511348</article_id>
		<sort_key>1310</sort_key>
		<display_label>Pages</display_label>
		<pages>965-970</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>126</seq_no>
		<title><![CDATA[Variance Minimization Least Squares Support Vector Machines for Time Series Analysis]]></title>
		<page_from>965</page_from>
		<page_to>970</page_to>
		<doi_number>10.1109/ICDM.2008.79</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511348</url>
		<abstract>
			<par><![CDATA[Here we propose a novel machine learning method for time series forecasting which is based on the widely-used Least Squares Support Vector Machine (LS-SVM) approach. The objective function of our method contains a weighted variance minimization part as well. This modification makes the method more efficient in time series forecasting, as this paper will show. The proposed method is a generalization of the well-known LS-SVM algorithm. It has similar advantages like the applicability of the kernel-trick, it has a linear and unique solution, and a short computational time, but can perform better in certain scenarios. The main purpose of this paper is to introduce the novel Variance Minimization Least Squares Support Vector Machine (VMLS-SVM) method and to show its superiority through experimental results using standard benchmark time series prediction datasets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[SVM, Least Squares SVM, Time Series]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383599</person_id>
				<author_profile_id><![CDATA[81384617848]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R&#243;bert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Orm&#225;ndi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511349</article_id>
		<sort_key>1320</sort_key>
		<display_label>Pages</display_label>
		<pages>971-976</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>127</seq_no>
		<title><![CDATA[Quantitative Association Analysis Using Tree Hierarchies]]></title>
		<page_from>971</page_from>
		<page_to>976</page_to>
		<doi_number>10.1109/ICDM.2008.100</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511349</url>
		<abstract>
			<par><![CDATA[Association analysis arises in many important applications such as bioinformatics and business intelligence. Given a large collection of measurements over a set of samples, association analysis aims to find dependencies of target variables to subsets of measurements. Most previous algorithms adopt a two-stage approach; they first group samples based on the similarity in the subset of measurements, and then they examine the association between these groups and the specified target variables without considering the inter-group similarities or alternative groupings. This can lead to cases where the strength of association depends significantly on arbitrary clustering choices. In this paper, we propose a tree-based method for quantitative association analysis. Tree hierarchies derived from sample similarities represent many possible sample groupings. They also provide a natural way to incorporate domain knowledge such as ontologies and to identify and remove outliers. Given a tree hierarchy, our association analysis evaluates all possible groupings and selects the one with strongest association to the target variable. We introduce an efficient algorithm, TreeQA, to systematically explore the search-space of all possible groupings in a set of input trees, with integrated permutation tests. Experimental results show that TreeQA is able to handlelarge-scale association analysis very efficiently and is more effective and robust in association analysis than previous methods.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Association Analysis, Tree Hierarchies]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385172</person_id>
				<author_profile_id><![CDATA[81100484594]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Feng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385173</person_id>
				<author_profile_id><![CDATA[81414611278]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lynda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385174</person_id>
				<author_profile_id><![CDATA[81100137780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Leonard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McMillan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385175</person_id>
				<author_profile_id><![CDATA[81464673715]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Fernando]]></first_name>
				<middle_name><![CDATA[Pardo Manuel de]]></middle_name>
				<last_name><![CDATA[Villena]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385176</person_id>
				<author_profile_id><![CDATA[81375614640]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Threadgill]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385177</person_id>
				<author_profile_id><![CDATA[81375595421]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511350</article_id>
		<sort_key>1330</sort_key>
		<display_label>Pages</display_label>
		<pages>977-982</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>128</seq_no>
		<title><![CDATA[Sparse Maximum Margin Logistic Regression for Credit Scoring]]></title>
		<page_from>977</page_from>
		<page_to>982</page_to>
		<doi_number>10.1109/ICDM.2008.84</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511350</url>
		<abstract>
			<par><![CDATA[The objective of credit scoring model is to categorizethe applicants as either accepted or rejected debtors prior to granting credit. A modified logistic loss function is proposed which can approximate hinge loss and therefore the resulting model, maximum margin logistic regression (MMLR), has the classification capability of support vector machine (SVM) with low computational cost. Finally, to classify credit applicants, an efficient algorithm is also described for MMLR based on epsilon-boosting which can provide sparse estimation of coefficients for better stability and interpretability.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381943</person_id>
				<author_profile_id><![CDATA[81414593652]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sabyasachi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Patra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381944</person_id>
				<author_profile_id><![CDATA[81430601906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kripa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shanker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381945</person_id>
				<author_profile_id><![CDATA[81414608889]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Debasis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kundu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511351</article_id>
		<sort_key>1340</sort_key>
		<display_label>Pages</display_label>
		<pages>983-988</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>129</seq_no>
		<title><![CDATA[Similarity Learning for Nearest Neighbor Classification]]></title>
		<page_from>983</page_from>
		<page_to>988</page_to>
		<doi_number>10.1109/ICDM.2008.81</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511351</url>
		<abstract>
			<par><![CDATA[In this paper, we propose an algorithm for learning a general class of similarity measures for kNN classification. This class encompasses, among others, the standard cosine measure, as well as the Dice and Jaccard coefficients. The algorithm we propose is an extension of the voted perceptron algorithm and allows one to learn different types of similarity functions (either based on diagonal, symmetric or asymmetric similarity matrices). The results we obtained show that learning similarity measures yields significant improvements on several collections, for two prediction rules: the standard kNN rule, which was our primary goal, and a symmetric version of it.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Similarity Learning, Data Mining, Nearest Neighbor Classification, Machine Learning]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1385178</person_id>
				<author_profile_id><![CDATA[81414617002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ali]]></first_name>
				<middle_name><![CDATA[Mustafa]]></middle_name>
				<last_name><![CDATA[Qamar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385179</person_id>
				<author_profile_id><![CDATA[81100467616]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gaussier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385180</person_id>
				<author_profile_id><![CDATA[81340488349]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jean-Pierre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chevallet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1385181</person_id>
				<author_profile_id><![CDATA[81100398871]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Joo]]></first_name>
				<middle_name><![CDATA[Hwee]]></middle_name>
				<last_name><![CDATA[Lim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511357</article_id>
		<sort_key>1350</sort_key>
		<display_label>Pages</display_label>
		<pages>989-994</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>130</seq_no>
		<title><![CDATA[RBNBC]]></title>
		<subtitle><![CDATA[Repeat Based Naive Bayes Classifier for Biological Sequences]]></subtitle>
		<page_from>989</page_from>
		<page_to>994</page_to>
		<doi_number>10.1109/ICDM.2008.66</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511357</url>
		<abstract>
			<par><![CDATA[In this paper, we present RBNBC, a Repeat Based Naive Bayes Classifier of bio-sequences that uses maximal frequent subsequences as features. RBNBC's design is based on generic ideas that can apply to other domains where the data is organized as collections of sequences. Specifically, RBNBC uses a novel formulation of Naive Bayes that incorporates repeated occurrences of subsequences within each sequence. Our extensive experiments on two collections of protein families show that it performs as well as existing state-of-the-art probabilistic classifiers for bio-sequences. This is surprising as it is a pure data mining based generic classifier that does not require domain-specific background knowledge. We note that domain-specific ideas could further increase its performance.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Data Mining, Classification, Biological Sequence, Naive Bayes]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381969</person_id>
				<author_profile_id><![CDATA[81414612559]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pratibha]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381970</person_id>
				<author_profile_id><![CDATA[81100417587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vikram]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pudi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511358</article_id>
		<sort_key>1360</sort_key>
		<display_label>Pages</display_label>
		<pages>995-1000</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>131</seq_no>
		<title><![CDATA[Multi-label Classification Using Ensembles of Pruned Sets]]></title>
		<page_from>995</page_from>
		<page_to>1000</page_to>
		<doi_number>10.1109/ICDM.2008.74</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511358</url>
		<abstract>
			<par><![CDATA[This paper presents a Pruned Sets method (PS) for multi-label classification. It is centred on the concept of treating sets of labels as single labels. This allows the classification process to inherently take into account correlations between labels. By pruning these sets, PS focuses only on the most important correlations, which reduces complexity and improves accuracy. By combining pruned sets in an ensemble scheme (EPS), new label sets can be formed to adapt to irregular or complex data. The results from experimental evaluation on a variety of multi-label datasets show that [E]PS can achieve better performance and train much faster than other multi-label methods.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[multi-label classification, problem transformation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384681</person_id>
				<author_profile_id><![CDATA[81414611234]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jesse]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Read]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384682</person_id>
				<author_profile_id><![CDATA[81100151066]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bernhard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pfahringer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384683</person_id>
				<author_profile_id><![CDATA[81100345733]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Geoff]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Holmes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511359</article_id>
		<sort_key>1370</sort_key>
		<display_label>Pages</display_label>
		<pages>1001-1006</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>132</seq_no>
		<title><![CDATA[Active Learning of Equivalence Relations by Minimizing the Expected Loss Using Constraint Inference]]></title>
		<page_from>1001</page_from>
		<page_to>1006</page_to>
		<doi_number>10.1109/ICDM.2008.41</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511359</url>
		<abstract>
			<par><![CDATA[Selecting promising queries is the key to effective active learning. In this paper, we investigate selection techniques for the task of learning an equivalence relation where the queries are about pairs of objects. As the target relation satisfies the axioms of transitivity, from one queried pair additional constraints can be inferred. We derive both the upper and lower bound on the number of queries needed to converge to the optimal solution. Besides restricting the set of possible solutions, constraints can be used as training data for learning a similarity measure. For selecting queries that result in a large number of meaningful constraints, we present an approximative optimal selection technique that greedily minimizes the expected loss in each round of active learning. This technique makes use of inference of expected constraints. Besides the theoretical results, an extensive evaluation for the application of record linkage shows empirically that the proposed selection method leads to both interesting and a high number of constraints.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Active Learning, Equivalence Relation, Record Linkage]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383622</person_id>
				<author_profile_id><![CDATA[81321497327]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steffen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rendle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383623</person_id>
				<author_profile_id><![CDATA[81332525921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lars]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schmidt-Thieme]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511360</article_id>
		<sort_key>1380</sort_key>
		<display_label>Pages</display_label>
		<pages>1007-1012</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>133</seq_no>
		<title><![CDATA[Iterative Subgraph Mining for Principal Component Analysis]]></title>
		<page_from>1007</page_from>
		<page_to>1012</page_to>
		<doi_number>10.1109/ICDM.2008.62</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511360</url>
		<abstract>
			<par><![CDATA[Graph mining methods enumerate frequent subgraphs efficiently, but they are not necessarily good features for machine learning due to high correlation among features. Thus it makes sense to perform principal component analysis to reducethe dimensionality and create decorrelated features. We present a novel iterative mining algorithm that captures informative patterns corresponding to major entries of top principal components. It repeatedly callsweighted substructure mining where example weights are updated in each iteration. The Lanczos algorithm, a standard algorithm of eigen decomposition, is employed to update the weights. In experiments, our patterns are shown to approximate the principal components obtained by frequent mining.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graph mining, PCA, lanczos algorithm, summarization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383036</person_id>
				<author_profile_id><![CDATA[81314491999]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hiroto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Saigo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383037</person_id>
				<author_profile_id><![CDATA[81100030766]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Koji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsuda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511361</article_id>
		<sort_key>1390</sort_key>
		<display_label>Pages</display_label>
		<pages>1013-1018</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>134</seq_no>
		<title><![CDATA[Clustering Geospatial Objects via Hidden Markov Random Fields]]></title>
		<page_from>1013</page_from>
		<page_to>1018</page_to>
		<doi_number>10.1109/ICDM.2008.70</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511361</url>
		<abstract>
			<par><![CDATA[This paper addresses the problem of clustering objects located and correlated geographically and containing multiple attributes. For the clustering problem, it is necessary to consider both the similarities of the attributes and the spatial dependencies of the objects. A new clustering framework using hidden Markov random fields (HMRFs) and Gaussian distributions and new potential models of HMRFs for irregularly located geospatial objects are proposed in this paper. Experimental results for systematic data and two real-world data showed the availability of the proposed algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381435</person_id>
				<author_profile_id><![CDATA[81414593417]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Makoto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sato]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381436</person_id>
				<author_profile_id><![CDATA[81414619057]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shuuichiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Imahara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511362</article_id>
		<sort_key>1400</sort_key>
		<display_label>Pages</display_label>
		<pages>1019-1024</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>135</seq_no>
		<title><![CDATA[Collective Latent Dirichlet Allocation]]></title>
		<page_from>1019</page_from>
		<page_to>1024</page_to>
		<doi_number>10.1109/ICDM.2008.75</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511362</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a new variant of Latent Dirichlet Allocation (LDA): Collective LDA (C-LDA), for multiple corpora modeling. C-LDA combines multiple corpora during learning such that it can transfer knowledge from one corpus to another; meanwhile it keeps a discriminative node which represents the corpus ID to constrain the learned topics in each corpus. Compared with LDA locally applied to the target corpus, C-LDA results in refined topic-word distribution, while compared with applying LDA globally and straightforwardly to the combined corpus, C-LDA keeps each topic only for one corpus. We demonstrate that C-LDA has improved performance with these advantages by experiments on several benchmark document data sets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[collective LDA]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381437</person_id>
				<author_profile_id><![CDATA[81392598013]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zhi-Yong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381438</person_id>
				<author_profile_id><![CDATA[81392599651]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381439</person_id>
				<author_profile_id><![CDATA[81450594087]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yi-Dong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511363</article_id>
		<sort_key>1410</sort_key>
		<display_label>Pages</display_label>
		<pages>1025-1030</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>136</seq_no>
		<title><![CDATA[Document-Word Co-regularization for Semi-supervised Sentiment Analysis]]></title>
		<page_from>1025</page_from>
		<page_to>1030</page_to>
		<doi_number>10.1109/ICDM.2008.113</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511363</url>
		<abstract>
			<par><![CDATA[The goal of sentiment prediction is to automatically identify whether a given piece of text expresses positive or negative opinion towards a topic of interest. One can pose sentiment prediction as a standard text categorization problem, but gathering labeled data turns out to be a bottleneck. Fortunately, background knowledge is often available in the form of prior information about the sentiment polarity of words in a lexicon. Moreover, in many applications abundant unlabeled data is also available. In this paper, we propose a novel semi-supervised sentiment prediction algorithm that utilizes lexical prior knowledge in conjunction with unlabeled examples. Our method is based on joint sentiment analysis of documents and words based on a bipartite graph representation of the data. We present an empirical study on a diverse collection of sentiment prediction problems which confirms that our semi-supervised lexical models significantly outperform purely supervised and competing semi-supervised techniques.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Semi-supervised Learning, Graph Transduction, Linear models, Sentiment Analysis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381440</person_id>
				<author_profile_id><![CDATA[81309499649]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Vikas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sindhwani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381441</person_id>
				<author_profile_id><![CDATA[81100590712]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Prem]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Melville]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511369</article_id>
		<sort_key>1420</sort_key>
		<display_label>Pages</display_label>
		<pages>1031-1036</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>137</seq_no>
		<title><![CDATA[A Non-parametric Approach to Pair-Wise Dynamic Topic Correlation Detection]]></title>
		<page_from>1031</page_from>
		<page_to>1036</page_to>
		<doi_number>10.1109/ICDM.2008.20</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511369</url>
		<abstract>
			<par><![CDATA[We introduce dynamic correlated topic models (DCTM) for analyzing discrete data over time. This model is inspired by the hierarchical Gaussian process latent variable models (GP-LVM). DCTM is essentially a non-linear dimension reduction technique which is capable of (1) detecting topic evolution within a document corpus,(2) discovering topic correlations between document corpora, and (3) monitoring topic and correlation trends dynamically. Unlike generative aspect models such like LDA, DCTM demonstrates a much faster converging rate with better model fitting to the data. We empirically assess our approach using 268,231 scientific documents, from the year 1988 to 2005. Posterior inferences suggest that DCTM is useful for capturing topic and correlation dynamics, as well as predicting their trends.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[topic models, Gaussian processes, correlation analysis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381469</person_id>
				<author_profile_id><![CDATA[81414614113]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Song]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381470</person_id>
				<author_profile_id><![CDATA[81384591647]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381471</person_id>
				<author_profile_id><![CDATA[81501675486]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[Lee]]></middle_name>
				<last_name><![CDATA[Giles]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511370</article_id>
		<sort_key>1430</sort_key>
		<display_label>Pages</display_label>
		<pages>1037-1042</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>138</seq_no>
		<title><![CDATA[Block-Iterative Algorithms for Non-negative Matrix Approximation]]></title>
		<page_from>1037</page_from>
		<page_to>1042</page_to>
		<doi_number>10.1109/ICDM.2008.77</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511370</url>
		<abstract>
			<par><![CDATA[In this paper we present new algorithms for non-negative matrix approximation (NMA), commonly known as the NMF problem. Our methods improve upon the well-known methods of Lee \& Seung~\cite{lee00} for both the Frobenius norm as well the Kullback-Leibler divergence versions of the problem. For the latter problem, our results are especially interesting because it seems to have witnessed much lesser algorithmic progress as compared to the Frobenius norm NMA problem. Our algorithms are based on a particular \textbf {block-iterative} acceleration technique for EM, which preserves the multiplicative nature of the updates and also ensures monotonicity. Furthermore, our algorithms also naturally apply to the Bregman-divergence NMA algorithms of~\cite{suv.nips}. Experimentally, we show that our algorithms outperform the traditional Lee/Seung approach most of the time.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Nonnegative matrix factorization, block-iterative algorithms, approximations, Bregman divergence, low-rank approximation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384715</person_id>
				<author_profile_id><![CDATA[81100115933]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Suvrit]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511371</article_id>
		<sort_key>1440</sort_key>
		<display_label>Pages</display_label>
		<pages>1043-1048</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>139</seq_no>
		<title><![CDATA[A Novel Method of Combined Feature Extraction for Recognition]]></title>
		<page_from>1043</page_from>
		<page_to>1048</page_to>
		<doi_number>10.1109/ICDM.2008.28</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511371</url>
		<abstract>
			<par><![CDATA[Multimodal recognition is an emerging technique to overcome the non-robustness of the unimodal recognition in real applications. Canonical correlation analysis (CCA) has been employed as a powerful tool for feature fusion in the realization of such multimodal system. However, CCA is the unsupervised feature extraction and it does not utilize the class information of the samples, resulting in the constraint of the recognition performance. In this paper, the class information is incorporated into the framework of CCA for combined feature extraction, and a novel method of combined feature extraction for multimodal recognition, called discriminative canonical correlation analysis (DCCA), is proposed. The experiments show that DCCA outperforms some related methods of both unimodal recognition and multimodal recognition.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383061</person_id>
				<author_profile_id><![CDATA[81350599904]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tingkai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383062</person_id>
				<author_profile_id><![CDATA[81451598761]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Songcan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383063</person_id>
				<author_profile_id><![CDATA[81414592046]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jingyu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383064</person_id>
				<author_profile_id><![CDATA[81414596863]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Pengfei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511372</article_id>
		<sort_key>1450</sort_key>
		<display_label>Pages</display_label>
		<pages>1049-1054</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>140</seq_no>
		<title><![CDATA[Prediction of Skin Penetration Using Machine Learning Methods]]></title>
		<page_from>1049</page_from>
		<page_to>1054</page_to>
		<doi_number>10.1109/ICDM.2008.97</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511372</url>
		<abstract>
			<par><![CDATA[Improving predictions of the skin permeability coefficient is a difficult problem. It is also an important issue with the increasing use of skin patches as a means of drug delivery. In this work, we apply K-nearest-neighbour regression, single layer networks, mixture of experts and Gaussian processes to predict the permeability coefficient. We obtain a considerable improvement over the quantitative structure-activity relationship (QSARs) predictors. We show that using five features, which are molecular weight, solubility parameter, lipophilicity, the number of hydrogen bonding acceptor and donor groups, can produce better predictions than the one using only lipophilicity and the molecular weight. The Gaussian process regression with five compound features gives the best performance in this work.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Gaussian processes, skin permeability coefficient, regression]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384174</person_id>
				<author_profile_id><![CDATA[81100448563]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384175</person_id>
				<author_profile_id><![CDATA[81414615456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gary]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Moss]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384176</person_id>
				<author_profile_id><![CDATA[81414619523]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Maria]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Prapopoulou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384177</person_id>
				<author_profile_id><![CDATA[81100312956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Rod]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Adams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384178</person_id>
				<author_profile_id><![CDATA[81414597878]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[B.]]></middle_name>
				<last_name><![CDATA[Brown]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384179</person_id>
				<author_profile_id><![CDATA[81100552849]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Neil]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Davey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511373</article_id>
		<sort_key>1460</sort_key>
		<display_label>Pages</display_label>
		<pages>1055-1060</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>141</seq_no>
		<title><![CDATA[A Topic Modeling Approach and Its Integration into the Random Walk Framework for Academic Search]]></title>
		<page_from>1055</page_from>
		<page_to>1060</page_to>
		<doi_number>10.1109/ICDM.2008.71</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511373</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a unified topic modeling approach and its integration into the random walk framework for academic search. Specifically, we present a topic model for simultaneously modeling papers, authors, and publication venues. We combine the proposed topic model into the random walk framework. Experimental results show that our proposed approach for academic search significantly outperforms the baseline methods of using BM25 and language model, and those of using the existing topic models (including pLSI, LDA, and the AT model).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384180</person_id>
				<author_profile_id><![CDATA[81350588685]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384181</person_id>
				<author_profile_id><![CDATA[81100054574]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ruoming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384182</person_id>
				<author_profile_id><![CDATA[81408596200]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511374</article_id>
		<sort_key>1470</sort_key>
		<display_label>Pages</display_label>
		<pages>1061-1066</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>142</seq_no>
		<title><![CDATA[Sequence Mining Automata]]></title>
		<subtitle><![CDATA[A New Technique for Mining Frequent Sequences under Regular Expressions]]></subtitle>
		<page_from>1061</page_from>
		<page_to>1066</page_to>
		<doi_number>10.1109/ICDM.2008.111</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511374</url>
		<abstract>
			<par><![CDATA[In this paper we study the problem of mining frequent sequences satisfying a given regular expression. Previous approaches to solve this problem were focusing on its search space, pushing (in some way) the given regular expression to prune unpromising candidate patterns. On the contrary, we focus completely on the given input data and regular expression. We introduce Sequence Mining Automata ($SMA$), a specialized kind of Petri Net that while reading input sequences, it produces for each sequence all and only the patterns contained in the sequence and that satisfy the given regular expression. Based on this automaton, we develop a family of algorithms. Our thorough experimentation on different datasets and application domains confirms that in many cases our methods outperform the current state of the art of frequent sequence mining algorithms using regular expressions (in some cases of orders of magnitude).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383065</person_id>
				<author_profile_id><![CDATA[81313481541]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Roberto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Trasarti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383066</person_id>
				<author_profile_id><![CDATA[81100305585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Francesco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bonchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383067</person_id>
				<author_profile_id><![CDATA[81100529915]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bart]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goethals]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511375</article_id>
		<sort_key>1480</sort_key>
		<display_label>Pages</display_label>
		<pages>1067-1072</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>143</seq_no>
		<title><![CDATA[Filling in the Blanks - Krimp Minimisation for Missing Data]]></title>
		<page_from>1067</page_from>
		<page_to>1072</page_to>
		<doi_number>10.1109/ICDM.2008.40</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511375</url>
		<abstract>
			<par><![CDATA[Many data sets are incomplete. For correct analysis of such data, one can either use algorithms that are designed to handle missing data or use imputation. Imputation has the benefit that it allows for any type of data analysis. Obviously, this can only lead to proper conclusions if the provided data completion is both highly accurate and maintains all statistics of the original data. In this paper, we present three data completion methods that are built on the MDL-based {\sc Krimp} algorithm. Here, we also follow the MDL principle, i.e. the completed database that can be compressed best, is the best completion because it adheres best to the patterns in the data. By using local patterns, as opposed to a global model, Krimp captures the structure of the data in detail. Experiments show that both in terms of accuracy and expected differences of any marginal, better data reconstructions are provided than the state of the art, Structural EM.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[MDL, local patterns, imputation, missing data estimation, Krimp]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384183</person_id>
				<author_profile_id><![CDATA[81335499054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jilles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vreeken]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384184</person_id>
				<author_profile_id><![CDATA[81100532533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Arno]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Siebes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511381</article_id>
		<sort_key>1490</sort_key>
		<display_label>Pages</display_label>
		<pages>1073-1078</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>144</seq_no>
		<title><![CDATA[Computational Discovery of Motifs Using Hierarchical Clustering Techniques]]></title>
		<page_from>1073</page_from>
		<page_to>1078</page_to>
		<doi_number>10.1109/ICDM.2008.21</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511381</url>
		<abstract>
			<par><![CDATA[Discovery of motifs plays a key role in understanding gene regulation in organisms. Existing tools for motif discovery demonstrate some weaknesses in dealing with reliability and scalability. Therefore, development of advanced algorithms for resolving this problem will be useful. This paper aims to develop data mining techniques for discovering motifs. A mismatch based hierarchical clustering algorithm is proposed in this paper, where three heuristic rules for classifying clusters and a post-processing for ranking and refining the clusters are employed in the algorithm. Our algorithm is evaluated using two sets of DNA sequences with comparisons. Results demonstrate that the proposed techniques in this paper outperform MEME, AlignACE and SOMBRERO for most of the testing datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384759</person_id>
				<author_profile_id><![CDATA[81414592915]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dianhui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384760</person_id>
				<author_profile_id><![CDATA[81464660657]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nung]]></first_name>
				<middle_name><![CDATA[Kion]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511382</article_id>
		<sort_key>1500</sort_key>
		<display_label>Pages</display_label>
		<pages>1079-1084</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>145</seq_no>
		<title><![CDATA[Inference Analysis in Privacy-Preserving Data Re-publishing]]></title>
		<page_from>1079</page_from>
		<page_to>1084</page_to>
		<doi_number>10.1109/ICDM.2008.118</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511382</url>
		<abstract>
			<par><![CDATA[Privacy-Preserving Data Re-publishing (PPDR) deals with publishing microdata in dynamic scenarios. Due to privacy concerns, data must be disguised before being published. Research in privacy-preserving data publishing (PPDP) has proposed many such methods on static data. In PPDR, multiple appeared records can be used to infer private information of other records. Therefore, inference channels exist among different releases. To understand the privacy property of data re-publishing, we need to analyze the impact of these inference channels. Previous studies show such analysis when data are updated or disguised in special ways, however, no general method has been proposed. Using the Maximum Entropy Modeling method, we have developed a general solution. Our method can conduct inference analysis when data are arbitrarily updated or arbitrarily disguised using either generalization or bucketization, two most common data disguise methods in PPDR. Through analysis and experiments, we demonstrate the advantage and the effectiveness of our method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384761</person_id>
				<author_profile_id><![CDATA[81460653135]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Guan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384762</person_id>
				<author_profile_id><![CDATA[81460653468]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zutao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384763</person_id>
				<author_profile_id><![CDATA[81451597756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wenliang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Du]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384764</person_id>
				<author_profile_id><![CDATA[81321499128]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Zhouxuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Teng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511383</article_id>
		<sort_key>1510</sort_key>
		<display_label>Pages</display_label>
		<pages>1085-1090</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>146</seq_no>
		<title><![CDATA[Using Wikipedia for Co-clustering Based Cross-Domain Text Classification]]></title>
		<page_from>1085</page_from>
		<page_to>1090</page_to>
		<doi_number>10.1109/ICDM.2008.136</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511383</url>
		<abstract>
			<par><![CDATA[Traditional approaches to document classification requires labeled data in order to construct reliable and accurate classifiers. Unfortunately, labeled data are seldom available, and often too expensive to obtain. Given a learning task for which training data are not available, abundant labeled data may exist for a different but related domain. One would like to use the related labeled data as auxiliary information to accomplish the classification task in the target domain. Recently, the paradigm of transfer learning has been introduced to enable effective learning strategies when auxiliary data obey a different probability distribution. A co-clustering based classification algorithm has been previously proposed to tackle cross-domain text classification. In this work, we extend the idea underlying this approach by making the latent semantic relationship between the two domains explicit. This goal is achieved with the use of Wikipedia. As a result, the pathway that allows to propagate labels between the two domains not only captures common words, but also semantic concepts based on the content of documents. We empirically demonstrate the efficacy of our semantic-based approach to cross-domain classification using a variety of real data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Cross-domain text classification, Co-clustering, Transfer learning, Wikipedia]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1381486</person_id>
				<author_profile_id><![CDATA[81435603235]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381487</person_id>
				<author_profile_id><![CDATA[81100062921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Carlotta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Domeniconi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1381488</person_id>
				<author_profile_id><![CDATA[81329489404]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511384</article_id>
		<sort_key>1520</sort_key>
		<display_label>Pages</display_label>
		<pages>1091-1096</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>147</seq_no>
		<title><![CDATA[Iterative Set Expansion of Named Entities Using the Web]]></title>
		<page_from>1091</page_from>
		<page_to>1096</page_to>
		<doi_number>10.1109/ICDM.2008.145</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511384</url>
		<abstract>
			<par><![CDATA[Set expansion refers to expanding a partial set of "seed" objects into a more complete set. One system that does set expansion is SEAL (Set Expander for Any Language), which expands entities automatically by utilizing resources from the Web in a language independent fashion. In a previous study, SEAL showed good set expansion performance using three seed entities; however, when given a larger set of seeds (e.g., ten), SEAL's expansion method performs poorly. In this paper, we present Iterative SEAL (iSEAL), which allows a user to provide many seeds. Briefly, iSEAL makes several calls to SEAL, each call using a small number of seeds. We also show that iSEAL can be used in a "bootstrapping" manner, where each call to SEAL uses a mixture of user-provided and self-generated seeds. We show that the bootstrapping version of iSEAL obtains better results than SEAL even when using fewer user-provided seeds. In addition, we compare the performance of various ranking algorithms used in iSEAL, and show that the choice of ranking method has a small effect on performance when all seeds are user-provided, but a large effect when iSEAL is bootstrapped. In particular, we show that Random Walk with Restart is nearly as good as Bayesian Sets with user-provided seeds, and performs best with bootstrapped seeds.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[seal, set expansion, bootstrapping, named entities]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384765</person_id>
				<author_profile_id><![CDATA[81100212462]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384766</person_id>
				<author_profile_id><![CDATA[81100145736]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511385</article_id>
		<sort_key>1530</sort_key>
		<display_label>Pages</display_label>
		<pages>1097-1102</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>148</seq_no>
		<title><![CDATA[Experimental Evaluation of the Value of Structure]]></title>
		<subtitle><![CDATA[How to Efficiently Exploit Interdependencies in Sequence Labeling]]></subtitle>
		<page_from>1097</page_from>
		<page_to>1102</page_to>
		<doi_number>10.1109/ICDM.2008.96</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511385</url>
		<abstract>
			<par><![CDATA[Many problems in natural language processing, information extraction or bioinformatics consist in predicting a label for each element of a sequence of observations. The sequence of labels generally presents multiple dependencies that restrict the possible labels the elements can take. Therefore, relations between labels intuitively provide information valuable for the prediction. Several approaches have been proposed to take advantage of this additional information. However, experimental results show that taking relations into account does not always improve prediction performances, while it significantly increases the computational cost of both learning and prediction. In this work, we aim at both explaining these surprising results and proposing a simple but computationnaly efficient approach for labeling sequences.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382028</person_id>
				<author_profile_id><![CDATA[81384598613]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Guillaume]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wisniewski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382029</person_id>
				<author_profile_id><![CDATA[81100169573]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Patrick]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gallinari]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511393</article_id>
		<sort_key>1540</sort_key>
		<display_label>Pages</display_label>
		<pages>1103-1108</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>149</seq_no>
		<title><![CDATA[Pseudolikelihood EM for Within-network Relational Learning]]></title>
		<page_from>1103</page_from>
		<page_to>1108</page_to>
		<doi_number>10.1109/ICDM.2008.148</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511393</url>
		<abstract>
			<par><![CDATA[In this work, we study the problem of \emph{within-network} relational learning and inference, where models are learned on a partially labeled relational dataset and then are applied to predict the classes of unlabeled instances in the same graph. We categorize recent work in statistical relational learning into three alternative approaches for this setting: disjoint learning with disjoint inference, disjoint learning with collective inference, and collective learning with collective inference. Models from each of these categories has been employed previously in different settings, but to our knowledge there has been no systematic comparison of models from all three categories. In this paper, we develop a novel pseudolikelihood EM method that facilitates more general \emph{collective learning} and \emph{collective inference} on partially labeled relational networks. We then compare this method to competing methods from the other categories on both synthetic and real-world data. We show that collective learning and inference with the pseudolikelihood EM approach achieves significantly higher accuracy than the other types of models when there are a moderate number of labeled examples in the data graph.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384237</person_id>
				<author_profile_id><![CDATA[81343508887]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rongjing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384238</person_id>
				<author_profile_id><![CDATA[81100563777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jennifer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Neville]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511386</article_id>
		<sort_key>1550</sort_key>
		<display_label>Pages</display_label>
		<pages>1109-1114</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>150</seq_no>
		<title><![CDATA[Publishing Sensitive Transactions for Itemset Utility]]></title>
		<page_from>1109</page_from>
		<page_to>1114</page_to>
		<doi_number>10.1109/ICDM.2008.98</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511386</url>
		<abstract>
			<par><![CDATA[We consider the problem of publishing sensitive transaction data with privacy preservation. High dimensionality of transaction data poses unique challenges on data privacy and data utility. On one hand, re-identification attacks tend to use a subset of items that infrequently occur in transactions, called moles. On the other hand, data mining applications typically depend on subsets of items that frequently occur in transactions, called nuggets. Thus the problem is how to eliminate all moles while retaining nuggets as much as possible. A challenge is that moles and nuggets are multi-dimensional with exponential growth and are tangled together by shared items. We present a novel and scalable solution to this problem. The novelty lies in a compact border data structure that eliminates the need of generating all moles and nuggets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[privacy-perservation, data publishing, transaction, itemset utility]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382030</person_id>
				<author_profile_id><![CDATA[81384612266]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yabo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382031</person_id>
				<author_profile_id><![CDATA[81327488637]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Benjamin]]></first_name>
				<middle_name><![CDATA[C.  M.]]></middle_name>
				<last_name><![CDATA[Fung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382032</person_id>
				<author_profile_id><![CDATA[81350574174]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382033</person_id>
				<author_profile_id><![CDATA[81414604835]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ada]]></first_name>
				<middle_name><![CDATA[W.  C.]]></middle_name>
				<last_name><![CDATA[Fu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382034</person_id>
				<author_profile_id><![CDATA[81100323054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511394</article_id>
		<sort_key>1560</sort_key>
		<display_label>Pages</display_label>
		<pages>1115-1120</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>151</seq_no>
		<title><![CDATA[Learning the Latent Semantic Space for Ranking in Text Retrieval]]></title>
		<page_from>1115</page_from>
		<page_to>1120</page_to>
		<doi_number>10.1109/ICDM.2008.68</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511394</url>
		<abstract>
			<par><![CDATA[Subspace learning techniques for text analysis, such as Latent Semantic Indexing (LSI), have been widely studied in the past decade. However, to our best knowledge, no previous study has leveraged the rank information for subspace learning in ranking tasks. In this paper, we propose a novel algorithm, called Learning Latent Semantics for Ranking (LLSR), to seek the optimal Latent Semantic Space tailored to the ranking tasks. We first present a dual explanation for the classical Latent Semantic Indexing (LSI) algorithm, namely learning the so-called Latent Semantic Space (LSS) to encode the data information. Then, to handle the increasing amount of training data for the practical ranking tasks, we propose a novel objective function to derive the optimal LSS for ranking. Experimental results on two SMART sub-collections and a TREC dataset show that LLSR effectively improves the ranking performance compared with the classical LSI algorithm and ranking without subspace learning.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Latent Semantic Space, Ranking]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382566</person_id>
				<author_profile_id><![CDATA[81375615225]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382567</person_id>
				<author_profile_id><![CDATA[81100044797]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shuicheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382568</person_id>
				<author_profile_id><![CDATA[81392606688]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382569</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511395</article_id>
		<sort_key>1570</sort_key>
		<display_label>Pages</display_label>
		<pages>1121-1126</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>152</seq_no>
		<title><![CDATA[Robust Time-Referenced Segmentation of Moving Object Trajectories]]></title>
		<page_from>1121</page_from>
		<page_to>1126</page_to>
		<doi_number>10.1109/ICDM.2008.133</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511395</url>
		<abstract>
			<par><![CDATA[Trajectory segmentation is the process of partitioning a given trajectory into a small number of homogeneous segments w.r.t. some criteria. Conventional segmentation techniques only focus on the spatial features of the movement and could lead to spatially homogeneous segments but with presumably dissimilar temporal structures. Furthermore, trajectories could be over-segmented in the presence of outliers. In this paper, we propose a family of three trajectory segmentation methods that takes into account both geospatial and temporal structures of movement for the segmentation and is also robust with respect to time-referenced spatial outliers. The effectiveness of our methods is empirically demonstrated over three real-world datasets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Segmentation, spatio-temporal, trajectory, outlier]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383106</person_id>
				<author_profile_id><![CDATA[81414614305]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hyunjin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yoon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383107</person_id>
				<author_profile_id><![CDATA[81100616904]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Cyrus]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shahabi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511396</article_id>
		<sort_key>1580</sort_key>
		<display_label>Pages</display_label>
		<pages>1127-1132</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>153</seq_no>
		<title><![CDATA[Maximum Margin Embedding]]></title>
		<page_from>1127</page_from>
		<page_to>1132</page_to>
		<doi_number>10.1109/ICDM.2008.25</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511396</url>
		<abstract>
			<par><![CDATA[We propose a new dimensionality reduction method called Maximum Margin Embedding (MME), which targets to projecting data samples into the most discriminative subspace, where clusters are most well-separated. Specifically, MME projects input patterns onto the normal of the maximum margin separating hyperplanes. As a result, MME only depends on the geometry of the optimal decision boundary and not on the distribution of those data points lying further away from this boundary. Technically, MME is formulated as an integer programming problem and we propose a cutting plane algorithm to solve it. Moreover, we prove theoretically that the computational time of MME scales linearly with the dataset size. Experimental results on both toy and real world datasets demonstrate the effectiveness of MME.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1382570</person_id>
				<author_profile_id><![CDATA[81100535703]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382571</person_id>
				<author_profile_id><![CDATA[81408592258]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1382572</person_id>
				<author_profile_id><![CDATA[81372592002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Changshui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511397</article_id>
		<sort_key>1590</sort_key>
		<display_label>Pages</display_label>
		<pages>1133-1138</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>154</seq_no>
		<title><![CDATA[Graph-Based Iterative Hybrid Feature Selection]]></title>
		<page_from>1133</page_from>
		<page_to>1138</page_to>
		<doi_number>10.1109/ICDM.2008.63</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511397</url>
		<abstract>
			<par><![CDATA[When the number of labeled examples is limited, traditional supervised feature selection techniques often fail due to sample selection bias or unrepresentative sample problem. To solve this, semi-supervised feature selection techniques exploit the statistical information of both labeled and unlabeled examples in the same time. However, the results of semi-supervised feature selection can be at times unsatisfactory, and the culprit is on how to effectively use the unlabeled data. Quite different from both supervised and semi-supervised feature selection, we propose a &#8220;hybrid&#8221;framework based on graph models. We first apply supervised methods to select a small set of most critical features from the labeled data. Importantly, these initial features might otherwise be missed when selection is performed onthe labeled and unlabeled examples simultaneously. Next,this initial feature set is expanded and corrected with the use of unlabeled data. We formally analyze why the expected performance of the hybrid framework is better than both supervised and semi-supervised feature selection. Experimental results demonstrate that the proposed method outperforms both traditional supervised and state-of-the-art semisupervised feature selection algorithms by at least 10% inaccuracy on a number of text and biomedical problems with thousands of features to choose from. Software and dataset is available from the authors.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[feature selection, semi-supervised, hybrid, graph, high dimension]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1384790</person_id>
				<author_profile_id><![CDATA[81436592458]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[ErHeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384791</person_id>
				<author_profile_id><![CDATA[81418598329]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sihong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xie]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384792</person_id>
				<author_profile_id><![CDATA[81367591181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384793</person_id>
				<author_profile_id><![CDATA[81384605407]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jiangtao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ren]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384794</person_id>
				<author_profile_id><![CDATA[81414597890]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1384795</person_id>
				<author_profile_id><![CDATA[81367592566]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Kun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511398</article_id>
		<sort_key>1600</sort_key>
		<display_label>Pages</display_label>
		<pages>1139-1144</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>155</seq_no>
		<title><![CDATA[Cleansing Noisy Data Streams]]></title>
		<page_from>1139</page_from>
		<page_to>1144</page_to>
		<doi_number>10.1109/ICDM.2008.45</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511398</url>
		<abstract>
			<par><![CDATA[In this paper, we identify a new research problem on cleansing noisy data streams which contain incorrectly labeled training examples. The objective is to accurately identify and remove mislabeled data, such that the prediction models built from the cleansed streams can be more accurate than the ones trained from the raw noisy streams. For this purpose, we first use bias-variance decomposition to derive a maximum variance margin (MVM) principle for stream data cleansing. Following this principle, we further propose a local and global filtering (LgF) framework to combine the strength of local noise filtering (within one single data chunk) and global noise filtering (across a number of adjacent data chunks) to identify erroneous data. Experimental results on six data streams (including two real-world data streams) demonstrate that LgF significantly outperforms simple methods in identifying noisy examples.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Data mining, classification, data streams, data cleansing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1383108</person_id>
				<author_profile_id><![CDATA[81452600756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xingquan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383109</person_id>
				<author_profile_id><![CDATA[81384603947]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383110</person_id>
				<author_profile_id><![CDATA[81452596585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xindong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383111</person_id>
				<author_profile_id><![CDATA[81466645464]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383112</person_id>
				<author_profile_id><![CDATA[81453613239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Chengqi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1383113</person_id>
				<author_profile_id><![CDATA[81409595544]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Yong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511404</article_id>
		<sort_key>1610</sort_key>
		<display_label>Pages</display_label>
		<pages>1145-1150</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>156</seq_no>
		<title><![CDATA[Author Index]]></title>
		<page_from>1145</page_from>
		<page_to>1150</page_to>
		<doi_number>10.1109/ICDM.2008.160</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511404</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1511405</article_id>
		<sort_key>1620</sort_key>
		<display_label>Page</display_label>
		<pages>1152</pages>
		<article_publication_date>12-15-2008</article_publication_date>
		<seq_no>157</seq_no>
		<title><![CDATA[Publisher's Information]]></title>
		<page_from>1152</page_from>
		<doi_number>10.1109/ICDM.2008.161</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1511405</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
</content>
</proceeding>

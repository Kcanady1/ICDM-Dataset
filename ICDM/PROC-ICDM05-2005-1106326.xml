<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>11-27-2005</start_date>
		<end_date>11-30-2005</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url>http://computer.org/proceedings/icdm/2005/2278</conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES11036</series_id>
		<series_title><![CDATA[ICDM]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1106326</proc_id>
	<acronym>ICDM '05</acronym>
	<proc_desc>Proceedings of the Fifth IEEE International Conference</proc_desc>
	<conference_number></conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Data Mining</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-7695-2278-5</isbn>
	<issn>1550-4786</issn>
	<eissn></eissn>
	<copyright_year>2005</copyright_year>
	<publication_date>11-27-2005</publication_date>
	<pages></pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB769</publisher_id>
		<publisher_code>IEEEW</publisher_code>
		<publisher_name>IEEE Computer Society</publisher_name>
		<publisher_address>1730 Massachusetts Ave., NW             Washington, DC</publisher_address>
		<publisher_city></publisher_city>
		<publisher_state></publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>20036-1992</publisher_zip_code>
		<publisher_contact></publisher_contact>
		<publisher_phone></publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url></publisher_url>
	</publisher>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>1106464</article_id>
		<sort_key>.15</sort_key>
		<display_label></display_label>
		<pages>xv</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Welcome Message from the Conference Chairs]]></title>
		<page_from>.15</page_from>
		<doi_number>10.1109/ICDM.2005.153</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106464</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1106465</article_id>
		<sort_key>.16</sort_key>
		<display_label></display_label>
		<pages>xvi-xvii</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Welcome to ICDM 2005]]></title>
		<page_from>.16</page_from>
		<page_to>xvii</page_to>
		<doi_number>10.1109/ICDM.2005.154</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106465</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1106467</article_id>
		<sort_key>.18</sort_key>
		<display_label></display_label>
		<pages>xviii-xix</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Conference Organization]]></title>
		<page_from>.18</page_from>
		<page_to>xix</page_to>
		<doi_number>10.1109/ICDM.2005.47</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106467</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1106468</article_id>
		<sort_key>.2</sort_key>
		<display_label></display_label>
		<pages>xx</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Steering Committee]]></title>
		<page_from>.20</page_from>
		<doi_number>10.1109/ICDM.2005.136</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106468</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1106469</article_id>
		<sort_key>.21</sort_key>
		<display_label></display_label>
		<pages>xxi-xxiv</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Program Committee]]></title>
		<page_from>.21</page_from>
		<page_to>xxiv</page_to>
		<doi_number>10.1109/ICDM.2005.124</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106469</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1106470</article_id>
		<sort_key>.25</sort_key>
		<display_label></display_label>
		<pages>xxv-xxvi</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Non-PC Reviewers]]></title>
		<page_from>.25</page_from>
		<page_to>xxvi</page_to>
		<doi_number>10.1109/ICDM.2005.104</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106470</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1106475</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<pages>3-9</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Handling Generalized Cost Functions in the Partitioning Optimization Problem through Sequential Binary Programming]]></title>
		<page_from>3</page_from>
		<page_to>9</page_to>
		<doi_number>10.1109/ICDM.2005.74</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106475</url>
		<abstract>
			<par><![CDATA[This paper proposes a framework for cost-sensitive classification under a generalized cost function. By combining decision trees with sequential binary programming, we can handle unequal misclassification costs, constrained classification, and complex objective functions that other methods cannot. Our approach has two main contributions. First, it provides a new method for cost-sensitive classification that outperforms a traditional, accuracy-based method and some current cost-sensitive approaches. Second, and more important, our approach can handle a generalized cost function, instead of the simpler misclassification cost matrix to which other approaches are limited.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003716</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003716</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044389</person_id>
				<author_profile_id><![CDATA[81100439178]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Abrahams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762960</person_id>
				<author_profile_id><![CDATA[81309487024]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Adrian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Becker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36031691</person_id>
				<author_profile_id><![CDATA[81309509423]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fleder]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763039</person_id>
				<author_profile_id><![CDATA[81421600251]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[MacMillan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pennsylvania]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Artin, Michael, <i>Algebra</i>, Prentice Hall, New Jersey, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Breiman, Leo, Jerome H. Friedman, Richard A. Olshen, and Charles J. Stone, <i>Classification and Regression Trees</i>, Wadsworth International Group, Belmont, California, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Demirsoy, Ipek, Jean-Jacques Fotzeu, and Lisa Worthington, "Caravan Insurance Polices Modeling", Department of Operations and Information Management, University of Pennsylvania, Philadelphia, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312220</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Domingos, Pedro. "MetaCost: A General Method for Making Classifiers Cost Sensitive." Proceedings of the Fifth International Conference on Knowledge Discovery and Data Mining. pp.155-164. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642224</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Elkan, Charles, "The Foundations of Cost-Sensitive Learning", Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>851846</ref_obj_id>
				<ref_obj_pid>850928</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Fan, Wei, Haixun Wang, Philip Yu, Salvatore Stolfo, "A Fully Distributed Framework for Cost-Sensitive Data Mining, Proceedings of the 22nd International Conference on Distributed Computing Systems", 1063-6927/02 &#169; 2002 IEEE.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Granger, C. W. J. 1969. "Prediction with a Generalized Cost of Error Function". Operational Research Quarterly 20(2):199- 207.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Ingargiola, Giorgio, "Building Classification Models: ID3 and C4.5", Temple University, Available http://www.cis.temple.edu/~ingargio/cis587/readings/id3- c45.html, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Komarek, Paul and Andrew Moore. "Making Logistic Regression a Core Data Mining Tool." Tech. Report CMU-RI-TR- 05-27, Robotics Institute, Carnegie Mellon University, May, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>756426</ref_obj_id>
				<ref_obj_pid>645328</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kwedlo, Wojciech, and Marek Kretowski, L. De Raedt, and P. Flach (eds.), "An Evolutionary Algorithm for Cost-Sensitive Decision Rule Learning", ECML 2001, LNAI 2167, Springer-Verlag Berlin Heidelberg, pp.288-299, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015369</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Ling, Charles X., Qiang Yang, Jianning Wang, and Shichao Zhang, "Decision Trees with Minimal Costs", Proceedings of the 21st International Conference on Machine Learning, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650055</ref_obj_id>
				<ref_obj_pid>645329</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Margineantu, Dragos D., "Class Probability Estimation and Cost-Sensitive Classification Decisions", Proceedings, Machine Learning: ECML 2002: 13th European Conference on Machine Learning, Helsinki, Finland, pp.270-281, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pigatti, Alexandre, Marcus Poggi de Arag&#227;o, and Eduardo Uchoa, "Stabilized Branch-and-cut-and-price for the Generalized Assignment Problem", Departmento de Inform&#225;tica, PUC do Rio de Janeiro, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Quinlan, Ross J., <i>C4.5 Programs for Machine Learning</i>, Morgan Kaufmann Publishers, San Mateo, California, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>178734</ref_obj_id>
				<ref_obj_pid>178732</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Tan, M. 1993. "Cost-Sensitive Learning of Classification Knowledge and its Applications in Robotics". Machine Learning 13:7-33.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Ting, K.M, "An Instance Weighting Method to Induce Cost-Sensitive Trees", Paper in International Conference on Data Mining, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622838</ref_obj_id>
				<ref_obj_pid>1622826</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Turney, Peter D., "Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Algorithm", Journal of Artificial Intelligence Research 2 (1995) p.369-409.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>712300</ref_obj_id>
				<ref_obj_pid>646964</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Webb, Geoffrey I., "Cost Sensitive Specialization", Proceedings of the Pacific Rim International Conference on Artificial Intelligence, Cairns, Springer-Verlag, pp.23-24, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Van Der Putten, Peter, and M. Van Someren (eds), "CoIL Challenge 2000: The Insurance Company Case", Published by Sentient Machine Research, Amsterdam. Also a Leiden Institute of Advanced Computer Science Technical Report 2000-09. June 22, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655658</ref_obj_id>
				<ref_obj_pid>645530</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Zadrozny, Bianca, and Charles Elkan, "Obtaining Calibrated Probability Estimates from Decision Trees and Na&#239;ve Bayes Classifiers", Proceedings of the Eighteenth International Conference on Machine Learning (ICML'01), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>979225</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Zadrozny, Bianca, "Policy Mining: Learning Decision Policies from Fixed Sets of Data", Ph.D. Thesis, University of California, San Diego, 2003a.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952181</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Zadrozny, Bianca, John Langford, and Naoki Abe, "Cost-Sensitive Learning by Cost-Proportionate Example Weighting", Proceedings of the Third IEEE International Conference on Data Mining, p.435, 2003b.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106476</article_id>
		<sort_key>10</sort_key>
		<display_label></display_label>
		<pages>10-17</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Online Hierarchical Clustering in a Data Warehouse Environment]]></title>
		<page_from>10</page_from>
		<page_to>17</page_to>
		<doi_number>10.1109/ICDM.2005.111</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106476</url>
		<abstract>
			<par><![CDATA[Many important industrial applications rely on data mining methods to uncover patterns and trends in large data warehouse environments. Since a data warehouse is typically updated periodically in a batch mode, the mined patterns have to be updated as well. This requires not only accuracy from data mining methods but also fast availability of up-to-date knowledge, particularly in the presence of a heavy update load. To cope with this problem, we propose the use of online data mining algorithms which permanently store the discovered knowledge in suitable data structures and enable an efficient adaptation of these structures after insertions and deletions on the raw data. In this paper, we demonstrate how hierarchical clustering methods can be reformulated as online algorithms based on the hierarchical clustering method OPTICS, using a density estimator for data grouping. We also discuss how this algorithmic schema can be specialized for efficient online single-link clustering. A broad experimental evaluation demonstrates that the efficiency is superior with significant speed-up factors even for large bulk insertions and deletions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Data warehouse and repository</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>B.4.2</cat_node>
				<descriptor>Data terminals and printers</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>E.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>H.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011710</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Data structures and algorithms for data management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010591</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Displays and imagers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152.10003161</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems->Record storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10010594</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Printers</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011024.10011028</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language features->Data types and structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010031</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Data structures design and analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002971</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Data structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152.10003161</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems->Record storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003219.10003242</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Information integration->Data warehouses</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003242</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Data warehouses</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763016</person_id>
				<author_profile_id><![CDATA[81309499133]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Elke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Achtert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043368</person_id>
				<author_profile_id><![CDATA[81100395758]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bohm]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15034628</person_id>
				<author_profile_id><![CDATA[81100512920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kriegel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042374</person_id>
				<author_profile_id><![CDATA[81332509808]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Peer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kroger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>304187</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander. "OPTICS: Ordering Points to Identify the Clustering Structure". In <i>Proc. ACM SIGMOD</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507519</ref_obj_id>
				<ref_obj_pid>507515</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Barbara. "Requirements for Clustering Data Streams". <i>SIGKDD Explorations</i>, 3:23-27, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673502</ref_obj_id>
				<ref_obj_pid>645922</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Berchtold, D. A. Keim, and H.-P. Kriegel. "The X-Tree: An Index Structure for High-Dimensional Data". In <i>Proc. VLDB</i>, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375672</ref_obj_id>
				<ref_obj_pid>375663</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. M. Breunig, H.-P. Kriegel, P. Kr&#246;ger, and J. Sander. "Data Bubbles: Quality Preserving Performance Boosting for Hierarchical Clustering". In <i>Proc. ACM SIGMOD</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>759118</ref_obj_id>
				<ref_obj_pid>646420</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Chen, S. Hwang, and Y. Oyang. "An Incremental Hierarchical Data Clustering Algorithm Based on Gravity Theory". In <i>Proc. PAKDD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Defays. "CLINK: An Efficient Algorithm for the Complete Link Cluster Method". <i>The Computer Journal</i>, 20(4):364-366, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507517</ref_obj_id>
				<ref_obj_pid>507515</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[V. Ganti, J. Gehrke, and R. Ramakrishnan. "Mining Data Steams under Block Evolution". <i>SIGKDD Explorations</i>, 3:1-10, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076797</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Han and M. Kamber. <i>Data Mining: Concepts and Techniques</i>. Academic Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[H.-P. Kriegel, P. Kr&#246;ger, and I. Gotlibovich. "Incremental OPTICS: Efficient Computation of Updates in a Hierarchical Cluster Ordering". In <i>Proc. DaWaK</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007621</ref_obj_id>
				<ref_obj_pid>1007568</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. Nassar, J. Sander, and C. Cheng. "Incremental and Effective Data Summerization for Dynamic Hierarchical Clustering". In <i>Proc. ACM SIGMOD</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847369</ref_obj_id>
				<ref_obj_pid>846219</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[P. Ram and L. Do. "Extracting Delta for Incremental Data Warehouse Maintenance". In <i>Proc. ICDE</i>, pages 220-229, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1760906</ref_obj_id>
				<ref_obj_pid>1760894</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Sander, X. Qin, Z. Lu, N. Niu, and A. Kovarsky. "Automatic Extraction of Clusters from Hierarchical Clustering Representations". In <i>Proc. PAKDD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[R. Sibson. "SLINK: An Optimally Efficient Algorithm for the Single-Link Cluster Method". <i>The Computer Journal</i>, 16(1):30-34, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844777</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[D. H. Widyantoro, T. R. Ioerger, and J. Yen. "An Incremental Approach to Building a Cluster Hierarchy". In <i>Proc. ICDM</i>, pages 705-708, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1315491</ref_obj_id>
				<ref_obj_pid>1315451</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. Zhou and J. Sander. "Data Bubbles for Non-Vector Data: Speeding-up Hierarchical Clustering in Arbitrary Metric Spaces". In <i>Proc. VLDB</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106477</article_id>
		<sort_key>18</sort_key>
		<display_label></display_label>
		<pages>18-25</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[eMailSift]]></title>
		<subtitle><![CDATA[Email Classification Based on Structure and Content]]></subtitle>
		<page_from>18</page_from>
		<page_to>25</page_to>
		<doi_number>10.1109/ICDM.2005.58</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106477</url>
		<abstract>
			<par><![CDATA[In this paper we propose a novel approach that uses structure as well as the content of emails in a folder for email classification. Our approach is based on the premise that representative &#8212; common and recurring &#8212; structures/patterns can be extracted from a pre-classified email folder and the same can be used effectively for classifying incoming emails. A number of factors that influence representative structure extraction and the classification are analyzed conceptually and validated experimentally. In our approach, the notion of inexact graph match is leveraged for deriving structures that provide coverage for characterizing folder contents. Extensive experimentation validate the selection of parameters and the effectiveness of our approach for email classification.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.4.3</cat_node>
				<descriptor>Electronic mail</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Structural</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Text processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003260.10003282.10003286.10003287</concept_id>
				<concept_desc>CCS->Information systems->World Wide Web->Web applications->Internet communications tools->Email</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044436</person_id>
				<author_profile_id><![CDATA[81309507509]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Manu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aery]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Arlington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15038556</person_id>
				<author_profile_id><![CDATA[81100651311]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sharma]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chakravarthy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Arlington]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Aery. Infosift: Adapting graph mining techniques for document classification. Master's thesis, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280791</ref_obj_id>
				<ref_obj_pid>280765</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[G. Boone. Concept features in re:agent, an intelligent email agent. <i>Proc. Agents</i>, pages 141-148, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>637942</ref_obj_id>
				<ref_obj_pid>637913</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Clark and T. Niblett. The cn2 induction algorithm. <i>Machine Learning</i>, pages 261-283, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[W. W. Cohen. Learning rules that classify e-mail. <i>Proceedings of AAAI-1996 Spring Symposium on Machine Learning in Information Access</i>, pages 124-143, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>630532</ref_obj_id>
				<ref_obj_pid>630311</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. J. Cook and L. B. Holder. Graph based data mining. <i>IEEE Intelligent Systems</i>, 15(2):32-41, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[E. Crawford, J. Kay, and E. McCreath. Automatic induction of rules for e-mail classification. <i>Proceedings of the Sixth Australasian Document Computing Symposium, Coffs Harbour, Australia</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Heflman and C. Isbell. Ishmail: Immediate identification of important information, at&t labs. 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658027</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Kuramochi and G. Karypis. Frequent subgraph discovery. <i>IEEE International Conference on Data Mining</i>, pages 313- 320, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. D. M. Rennie. ifile:an application of machine learning to email filtering. <i>Proceedings of KDD-2000 Text Mining Workshop, Boston Aug</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Payne and P. Edwards. Interface agents that learn: An investigation of learning issues in a mail agent interface. <i>Applied Artificial Intelligence</i>, pages 1-32, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>534247</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Rissanen. Stochastic complexity in statistical enquiry. <i>World Publishing Company</i>, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>939307</ref_obj_id>
				<ref_obj_pid>938979</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A. Schenker, M. Last, H. Bunke, and A. Kandel. Classification of web documents using a graph model. <i>Seventh International Conference on Document Analysis and Recognition</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[R. B. Segal and J. O. Kephart. Swiftfile: An intelligent assistant for organizing e-mail. <i>Proceedings of AAAI 2000 Spring Symposium on Adaptive User Interfaces</i>, pages 107- 112, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>238530</ref_obj_id>
				<ref_obj_pid>238386</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S. Whittaker and C. Sidner. Email overload: exploring personal information management of email. <i>Conference Proceedings on Human Factors in Computing Systems</i>, pages 276-283, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844811</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[X. Yan and J. Han. gspan:graph-based substructure pattern mining. <i>Proceedings of the IEEE International Conference on Data Mining</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106478</article_id>
		<sort_key>26</sort_key>
		<display_label></display_label>
		<pages>26-33</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[An Empirical Bayes Approach to Detect Anomalies in Dynamic Multidimensional Arrays]]></title>
		<page_from>26</page_from>
		<page_to>33</page_to>
		<doi_number>10.1109/ICDM.2005.22</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106478</url>
		<abstract>
			<par><![CDATA[We consider the problem of detecting anomalies in data that arise as multidimensional arrays with each dimension corresponding to the levels of a categorical variable. In typical data mining applications, the number of cells in such arrays are usually large. Our primary focus is detecting anomalies by comparing information at the current time to historical data. Naive approaches advocated in the process control literature do not work well in this scenario due to the multiple testing problem - performing multiple statistical tests on the same data produce excessive number of false positives. We use an Empirical Bayes method which works by fitting a two component gaussian mixture to deviations at current time. The approach is scalable to problems that involve monitoring massive number of cells and fast enough to be potentially useful in many streaming scenarios. We show the superiority of the method relative to a naive "per component error rate" procedure through simulation. A novel feature of our technique is the ability to suppress deviations that are merely the consequence of sharp changes in the marginal distributions. This research was motivated by the need to extract critical application information and business intelligence from the daily logs that accompany large-scale spoken dialog systems deployed by AT&T. We illustrate our method on one such system.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Speech recognition and synthesis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Signal processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010583.10010588.10003247</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Signal processing systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010183</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Speech recognition</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15045450</person_id>
				<author_profile_id><![CDATA[81100632698]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Deepak]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Agarwal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AT&T Labs-Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>543615</ref_obj_id>
				<ref_obj_pid>543613</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Babcock, S. Babu, M. Datar, R. Motwani, and J. Widom. Models and issues in data stream systems. In <i>PODS</i>, Madison, Wisconsin, USA, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>574978</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[G. E. Box. <i>Time series analysis: forecasting and control</i>. Holden-Day, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B.P. Carlin and T.A. Louis. <i>Bayes and Empirical Bayes methods for data analysis 2nd Ed.</i> Chapman and Hall/CRC Press, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D.B. Duncan. A bayesian approach to multiple comparisons. <i>Technometrics</i>, 7:171-222, 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1316707</ref_obj_id>
				<ref_obj_pid>1316689</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Kifer, S. Ben-David, and J. Gehrke. Detecting change in data streams. In <i>Proc. of the 30th VLDB conference</i>, pages 180-191. Toronto, Canada, August 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Douglas, D. Agarwal, T. Alonso, R. Bell, M. Rahim, D. F. Swayne, and C. Volinsky. Mining Customer Care Dialogs for "Daily News". In <i>INTERSPEECH-2004</i>, Jeju, Korea, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W. DuMouchel. A bayesian model and graphical elicitation procedure for multiple comparisons. In <i>J.M. Degroot, M.H. Lindley, D.V. Smith, A.F.M.(Eds.), Bayesian Statistics 3</i>. Oxford University Press. Oxford, England, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. Genovese and L. Wasserman. Bayesian and frequentist multiple testing. In <i>Bayesian Statistics 7 - Proc. of the 7th Valencia International Meeting</i>, pages 145-162, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[P. Good. <i>Permutation tests - a practical guide to resampling methods for testing hypotheses</i>. Springer-Verlag, 2nd edition, New York, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J.P. Shaffer. A semi-bayesian study of duncan's bayesian multiple comparison procedure. <i>Journal of statistical planning and inference</i>, 82:197-213, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R. Gopalan and D.A. Berry. Bayesian multiple comparisons using dirichlet process priors. <i>Journal of the American Statistical Association</i>, 93:1130-1139, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Scott and J. Berger. "an exploration of aspects of bayesian multiple testing". Technical report, Institute of Statistics and Decision Science, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507517</ref_obj_id>
				<ref_obj_pid>507515</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[V. Ganti, J.E. Gehrke, and R. Ramakrishnan. Mining data streams under block evolution. <i>Sigkdd explorations</i>, 3:1-10, january 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312184</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[W. DuMouchel, C. Volinsky, T. Johnson, C. Cortes, and D. Pregibon. Squashing flat files flatter. In <i>Proc. of the 5th ACM SIGKDD conference</i>, pages 6-15. San Diego, California, USA, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Y. Benjamini and Y. Hochberg. Controlling the false discovery rate: A practical and powerful approach to multiple testing. <i>Journal of the royal statistical society, series B</i>, 57:289- 300, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847379</ref_obj_id>
				<ref_obj_pid>846219</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[B.-K. Yi, N. Sidiropoulos, T. Johnson, H.V. Jagadish, C. Faloutsos, and A. Biliris. Online data mining for coevolving time sequences. In <i>Proc. of the 16th International Conference on Data Engineering</i>, pages 13-22. San Diego, California, USA, March 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287401</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Y. Zhu and D. Shasha. Statstream: Statistical monitoring of thousands of data streams in real time. In <i>Proc. of the 28th VLDB conference</i>, pages 358-369. HongKong, China, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106479</article_id>
		<sort_key>34</sort_key>
		<display_label></display_label>
		<pages>34-41</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Classifier Fusion Using Shared Sampling Distribution for Boosting]]></title>
		<page_from>34</page_from>
		<page_to>41</page_to>
		<doi_number>10.1109/ICDM.2005.40</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106479</url>
		<abstract>
			<par><![CDATA[We present a new framework for classifier fusion that uses a shared sampling distribution for obtaining a weighted classifier ensemble. The weight update process is self regularizing as subsequent classifiers trained on the disjoint views rectify the bias introduced by any classifier in preceding iterations. We provide theoretical guarantees that our approach indeed provides results which are better than the case when boosting is performed separately on different views. The results are shown to outperform other classifier fusion strategies on a well known texture image database.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39053406</person_id>
				<author_profile_id><![CDATA[81309498517]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Costin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barbu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36031583</person_id>
				<author_profile_id><![CDATA[81317494991]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Raja]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Iqbal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043598</person_id>
				<author_profile_id><![CDATA[81100023197]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging predictors. <i>Machine Learning Journal</i>, 24:123-140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Arching classifiers. <i>Annals of Statistics</i>, 26:801-849, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261549</ref_obj_id>
				<ref_obj_pid>261540</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. <i>Journal of Computer and Systems Science</i>, 55:119-139, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. Schapire. A short introduction to boosting. <i>Journal of Japanese Society for Artificial Intelligence</i>, 5(14):771-780, September 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. C. M. J. G.R.G. Lanckriet, M.H. Deng and W. Noble. Kernel-based data fusion and its application to protein function prediction in yeast. <i>Proceedings of the Pacific Symposium on Biocomputing</i>, 9:300-311, January 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>257622</ref_obj_id>
				<ref_obj_pid>257615</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Hashem. Optimal linear combination of neural networks. <i>Neural Networks</i>, 19:599-614, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>279007</ref_obj_id>
				<ref_obj_pid>279005</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. D. J. Kittler, M. Hatef and J. Matas. On combining classifiers. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 20:226-239, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1042409</ref_obj_id>
				<ref_obj_pid>1042202</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Kim and B. Oommen. On using prototype reduction schemes and classifier fusion strategies to optimize kernel based nonlinear subspace methods. <i>IEEE Transactions Pattern Analysis and Machine Intelligence</i>, 27:455-460, February 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Kittler. Combining classifiers: A theoretical framework. <i>Pattern Analysis and Applications</i>, 1:18-27, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673576</ref_obj_id>
				<ref_obj_pid>645889</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Kittler. A framework for classifier fusion: Is still needed? <i>Lecture Notes in Computer Science</i>, 1876:45-56, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>505512</ref_obj_id>
				<ref_obj_pid>505501</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[L. Kuncheva. A theoretical study on six classifier fusion strategies. <i>IEEE Transactions Pattern Analysis and Machine Intelligence</i>, 24(2):281-286, February 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[L. Kuncheva, J. Bezdek, and R. Duin. Decision templates for multiple classifier fusion: An experimental comparison. <i>Pattern Recognition</i>, 34:299-314, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. K. L. Xu and C. Suen. Methods of combining multiple experts for the recognition of unconstrained handwritten numerals. <i>IEEE Transactions on Systems, Man, and Cybernetics</i>, 19:418-435, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C. S. R. D. L.I. Kuncheva, C. J. Whitaker. Is independence good for combining classifiers? <i>Proceedings of the 15th International Conference on Pattern Recognition</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>500445</ref_obj_id>
				<ref_obj_pid>500435</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[N. Rao. On fusers that perform better than best sensor. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 23(8):904-909, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657129</ref_obj_id>
				<ref_obj_pid>645526</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[P. B. R. E. Schapire, Y. Freund and W. Lee. Boosting the margin: A new explanation for the effectiveness of voting methods. <i>Proceedings of the Fourteenth International Conference on Machine learning</i>, pages 322-330, October 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>337870</ref_obj_id>
				<ref_obj_pid>337859</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[R. Schapire and Y. Singer. Improved boosting algorithms using confidence rated predictions. <i>Machine Learning</i>, 3(37):297-336, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[VisTex. Color image database. http://vismod.media.mit.edu/vismod/imagery/VisionTexture.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1031238</ref_obj_id>
				<ref_obj_pid>1031171</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Y. Wu and E. Chang. Distance-function design and fusion for sequence data. <i>Proceedings of the Thirteenth ACM Conference on Information and Knowledge Management</i>, pages 324-333, November 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106329</article_id>
		<sort_key>42</sort_key>
		<display_label></display_label>
		<pages>42-49</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Improving Automatic Query Classification via Semi-Supervised Learning]]></title>
		<page_from>42</page_from>
		<page_to>49</page_to>
		<doi_number>10.1109/ICDM.2005.80</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106329</url>
		<abstract>
			<par><![CDATA[Accurate topical classification of user queries allows for increased effectiveness and efficiency in general-purpose web search systems. Such classification becomes critical if the system is to return results not just from a general web collection but from topic-specific back-end databases as well. Maintaining sufficient classification recall is very difficult as web queries are typically short, yielding few features per query. This feature sparseness coupled with the high query volumes typical for a large-scale search service makes manual and supervised learning approaches alone insufficient. We use an application of computational linguistics to develop an approach for mining the vast amount of unlabeled data in web query logs to improve automatic topical web query classification. We show that our approach in combination with manual matching and supervised learning allows us to classify a substantially larger proportion of queries than any single technique. We examine the performance of each approach on a real web query stream and show that our combined method accurately classifies 46% of queries, outperforming the recall of best single approach by nearly 20%, with a 7% improvement in overall effectiveness.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Text processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15043333</person_id>
				<author_profile_id><![CDATA[81100429268]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Beitzel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Information Retrieval Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042991</person_id>
				<author_profile_id><![CDATA[81100640303]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Information Retrieval Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043654</person_id>
				<author_profile_id><![CDATA[81100268938]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ophir]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Frieder]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Information Retrieval Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043967</person_id>
				<author_profile_id><![CDATA[81100350273]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Lewis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[America Online, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041532</person_id>
				<author_profile_id><![CDATA[81100512534]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Abdur]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chowdhury]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[America Online, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041849</person_id>
				<author_profile_id><![CDATA[81100397655]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Aleksander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kolcz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[America Online, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1076138</ref_obj_id>
				<ref_obj_pid>1076034</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. M. Beitzel, E. C. Jensen, D. D. Lewis, A. Chowdhury, A. Kolcz, O. Frieder, and D. Grossman, "Automatic Web Query Classification Using Labeled and Unlabeled Training Data," presented at SIGIR-2005, Salvador, Brazil, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1009048</ref_obj_id>
				<ref_obj_pid>1008992</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. Beitzel, E. Jensen, A. Chowdhury, D. Grossman, and O. Frieder, "Hourly Analysis of a Very Large Topically Categorized Web Query Log," presented at ACM-SIGIR, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. Sullivan, "Searches Per Day," vol. 2003: Search Engine Watch, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>342498</ref_obj_id>
				<ref_obj_pid>342495</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[B. Jansen, A. Spink, and T. Saracevic, "Real life, Real Users, and Real Needs: A Study and Analysis of User Queries on the Web.," <i>Information Processing & Management</i>, vol. 36, pp. 207-227, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956925</ref_obj_id>
				<ref_obj_pid>956863</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[L. Gravano, V. Hatzivassiloglou, and R. Lichtenstein, "Categorizing Web Queries According to Geographical Locality," presented at ACM CIKM, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>860449</ref_obj_id>
				<ref_obj_pid>860435</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[I.-H. Kang and G. Kim, "Query Type Classification for Web Document Retrieval," presented at ACM SIGIR, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361220</ref_obj_id>
				<ref_obj_pid>361219</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[G. Salton, C. S. Yang, and A. Wong, "A Vector-Space Model for Automatic Indexing," <i>Communications of the ACM</i>, vol. 18, pp. 613-620, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. Beeferman and A. Berger, "Agglomerative Clustering of a Search Engine Query Log," presented at ACM-SIGMOD, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>503108</ref_obj_id>
				<ref_obj_pid>503104</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J.-R. Wen, J.-Y. Nie, and H.-J. Zhang, "Query Clustering Using User Logs," <i>ACM Transactions on Information Systems</i>, vol. 20, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>384083</ref_obj_id>
				<ref_obj_pid>383952</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J.-R. Wen, J.-Y. Nie, and H.-J. Zhang, "Query Clustering Using Content Words and User Feedback," presented at ACM SIGIR, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>371974</ref_obj_id>
				<ref_obj_pid>371920</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J.-R. Wen, J.-Y. Nie, and H.-J. Zhang, "Clustering User Queries of a Search Engine," presented at WWW 2001, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[W. Krauth and M. Mezard, "Learning Algorithms with Optimal Stability in Neural Networks," <i>Journal of Physics A</i>, vol. 20, pp. pp. 745-752, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[L. L. Kupper and K. B. Hafner, "How Appropriate are Popular Sample Size Formulas?" <i>The American Statistician</i>, vol. 43, pp. pp. 101-105, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311445</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C. D. Manning and H. Schutze, <i>Foundations of Statitical Natural Language Processing</i>: MIT Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1105707</ref_obj_id>
				<ref_obj_pid>1105703</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[D. McCarthy and J. Carroll, "Disambiguating Nouns, Verbs, and Adjectives using Automatically Acquired Selectional Preferences," <i>Computational Linguistics</i>, vol. 29, pp. pp. 639-654, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[P. Resnik, "Selection and Information: A Class-Based Approach to Lexical Relationships," University of Pennsylvania, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>129837</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[T. M. Cover and J. A. Thomas, <i>Elements of Information Theory</i>: Wiley, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Light and W. Greiff, "Statistical Models for the Induction and Use of Selectional Preferences," <i>Cognitive Science</i>, vol. 87, pp. 1-13, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>541177</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[T. M. Mitchell, <i>Machine Learning</i>. New York: McGraw-Hill, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>215366</ref_obj_id>
				<ref_obj_pid>215206</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[D. D. Lewis, "Evaluating and Optimizing Autonomous Text Classification Systems," presented at SIGIR 1995, Seatlle, WA, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>539927</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[C. J. v. Rijsbergen, <i>Information Retrieval</i>, 2nd ed. London: Butterworths, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[J. M. Tague, "The Pragmatics of Information Retrieval Experimentation," in <i>Information Retrieval Experiment</i>, K. S. Jones, Ed. London: Butterworths, 1981, pp. pp. 59-102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106330</article_id>
		<sort_key>50</sort_key>
		<display_label></display_label>
		<pages>50-57</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[ViVo]]></title>
		<subtitle><![CDATA[Visual Vocabulary Construction for Mining Biomedical Images]]></subtitle>
		<page_from>50</page_from>
		<page_to>57</page_to>
		<doi_number>10.1109/ICDM.2005.151</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106330</url>
		<abstract>
			<par><![CDATA[Given a large collection of medical images of several conditions and treatments, how can we succinctly describe the characteristics of each setting? For example, given a large collection of retinal images from several different experimental conditions (normal, detached, reattached, etc.), how can data mining help biologists focus on important regions in the images or on the differences between different experimental conditions? If the images were text documents, we could find the main terms and concepts for each condition by existing IR methods (e.g., tf/idf and LSI). We propose something analogous, but for the much more challenging case of an image collection: We propose to automatically develop a visual vocabulary by breaking images into n  n tiles and deriving key tiles ("ViVos") for each image and condition. We experiment with numerous domain-independent ways of extracting features from tiles (color histograms, textures, etc.), and several ways of choosing characteristic tiles (PCA, ICA). We perform experiments on two disparate biomedical datasets. The quantitative measure of success is classification accuracy: Our "ViVos" achieve high classification accuracy (up to 83% for a nine-class problem on feline retinal images). More importantly, qualitatively, our "ViVos" do an excellent job as "visual vocabulary terms": they have biological meaning, as corroborated by domain experts; they help spot characteristic regions of images, exactly like text vocabulary terms do for documents; and they highlight the differences between pairs of images.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Computer vision</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Health</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010449</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health informatics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010446</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Consumer health</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010247</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Image segmentation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010248</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Video segmentation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041197</person_id>
				<author_profile_id><![CDATA[81100029661]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Arnab]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bhattacharya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Santa Barbara]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041749</person_id>
				<author_profile_id><![CDATA[81100168698]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vebjorn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ljosa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Santa Barbara]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041445</person_id>
				<author_profile_id><![CDATA[81100485214]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jia-Yu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763093</person_id>
				<author_profile_id><![CDATA[81309486281]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Verardo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Santa Barbara]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040437</person_id>
				<author_profile_id><![CDATA[81309483835]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Hyungjeong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chonnam National University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15030495</person_id>
				<author_profile_id><![CDATA[81100373169]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Christos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Faloutsos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15028087</person_id>
				<author_profile_id><![CDATA[81408600836]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Ambuj]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Singh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Santa Barbara]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. V. Boland, M. K. Markey, and R. F. Murphy. Automated recognition of patterns characteristic of subcellular structures in fluorescence microscopy images. <i>Cytometry</i>, 3(33):366-375, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593463</ref_obj_id>
				<ref_obj_pid>593419</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. J. C. Burges. A tutorial on support vector machines for pattern recognition. <i>Data Mining and Knowledge Discovery</i>, 2(2):121-167, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, and R. Harshman. Indexing by latent semantic analysis. <i>J. Am. Soc. Inf. Sci. Technol.</i>, 41(6):391-407, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>950141</ref_obj_id>
				<ref_obj_pid>950135</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[B. A. Draper, K. Baek, M. S. Bartlett, and J. R. Beveridge. Recognizing faces with PCA and ICA. <i>Comp. Vis. and Image Understanding</i>, (91):115-137, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649254</ref_obj_id>
				<ref_obj_pid>645318</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Duygulu, K. Barnard, N. Freitas, and D. A. Forsyth. Object recognition as machine translation: learning a lexicon for a fixed image vocabulary. In <i>Proc. ECCV</i>, volume 4, pages 97-112, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. K. Fisher, G. P. Lewis, K. A. Linberg, and M. R. Verardo. Cellular remodeling in mammalian retina: Results from studies of experimental retinal detachment. <i>Progress in Retinal and Eye Research</i>, 24:395-431, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Y. Hu and R. F. Murphy. Automated interpretation of subcellular patterns from immunofluorescence microscopy. <i>Journal of Immunological Methods</i>, 290:93-105, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Hyvarinen, J. Karhunen, and E. Oja. <i>Independent Component Analysis</i>. John Wiley and Sons, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Jeon and R. Manmatha. Using maximum entropy for automatic image annotation. In <i>Proc. CIVR</i>, pages 24-32, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[I. T. Jolliffe. <i>Principal Component Analysis</i>. Springer, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. J. Klockars and G. Sax. <i>Multiple Comparisons</i>. Number 07-061 in Sage Univ. Paper series on Quantitative Applications in the Social Sciences. Sage Publications, Inc., 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[G. Lewis, K. Talaga, K. Linberg, R. Avery, and S. Fisher. The efficacy of delayed oxygen therapy in the treatment of experimental retinal detachment. <i>Am. J. Ophthalmol.</i>, 137(6):1085-1095, June 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[G. P. Lewis, C. S. Sethi, K. A. Linberg, D. G. Charteris, and S. K. Fisher. Experimental retinal detachment: A new perspective. <i>Mol. Neurobiol.</i>, 28(2):159-175, Oct. 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>714148</ref_obj_id>
				<ref_obj_pid>647060</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J.-H. Lim. Categorizing visual contents by matching visual "keywords". In <i>Proc. VISUAL</i>, pages 367-374, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>306624</ref_obj_id>
				<ref_obj_pid>306607</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[W.-Y. Ma and B. S. Manjunath. A texture thesaurus for browsing large aerial photographs. <i>Journal of the American Society for Information Science</i>, 49(7):633-648, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[B. Manjunath, P. Salembier, and T. Sikora. <i>Introduction to MPEG-7</i>. Wiley, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2319833</ref_obj_id>
				<ref_obj_pid>2318980</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[A. Mojsilovic, J. Kovaevic, J. Hu, R. J. Safranek, and S. K. Ganapathy. Matching and retrieval based on the vocabulary and grammar of color patterns. <i>IEEE Trans. Image Proc.</i>, 9(1):38-54, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[R. F. Murphy. Automated interpretation of protein subcellular location patterns: Implications for early cancer detection and assessment. <i>Annals N.Y. Acad. Sci.</i>, 1020:124-131, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1011136</ref_obj_id>
				<ref_obj_pid>1011128</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[R. F. Murphy, M. Velliste, and G. Porreca. Robust numerical features for description and classification of subcellular location patterns in fluorescence microscope images. <i>Journal of VLSI Signal Processing</i>, 35:311-321, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>939174</ref_obj_id>
				<ref_obj_pid>938978</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[C. P. Papageorgiou, M. Oren, and T. Poggio. A general framework for object detection. In <i>Proceedings of the Sixth International Conference on Computer Vision (ICCV'98)</i>, volume 2, pages 555-562, January 4-7 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>946751</ref_obj_id>
				<ref_obj_pid>946247</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. Sivic and A. Zisserman. Video Google: A text retrieval approach to object matching in videos. In <i>Proc. ICCV</i>, volume 2, pages 1470-1477, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1326894</ref_obj_id>
				<ref_obj_pid>1326887</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. A. Turk and A. P. Pentland. Eigenfaces for recognition. <i>Journal of Cognitive Neuroscience</i>, 3(1):71-96, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106331</article_id>
		<sort_key>58</sort_key>
		<display_label></display_label>
		<pages>58-65</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Adaptive Product Normalization]]></title>
		<subtitle><![CDATA[Using Online Learning for Record Linkage in Comparison Shopping]]></subtitle>
		<page_from>58</page_from>
		<page_to>65</page_to>
		<doi_number>10.1109/ICDM.2005.18</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106331</url>
		<abstract>
			<par><![CDATA[The problem of record linkage focuses on determining whether two object descriptions refer to the same underlying entity. Addressing this problem effectively has many practical applications, e.g., elimination of duplicate records in databases and citation matching for scholarly articles. In this paper, we consider a new domain where the record linkage problem is manifested: Internet comparison shopping. We address the resulting linkage setting that requires learning a similarity function between record pairs from streaming data. The learned similarity function is subsequently used in clustering to determine which records are co-referent and should be linked. We present an online machine learning method for addressing this problem, where a composite similarity function based on a linear combination of basis functions is learned incrementally. We illustrate the efficacy of this approach on several real-world datasets from an Internet comparison shopping site, and show that our method is able to effectively learn various distance functions for product data with differing characteristics. We also provide experimental results that show the importance of considering multiple performance measures in record linkage evaluation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.2.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003212</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database administration</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044708</person_id>
				<author_profile_id><![CDATA[81100053643]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mikhail]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bilenko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045163</person_id>
				<author_profile_id><![CDATA[81100645746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sugato]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Basu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044345</person_id>
				<author_profile_id><![CDATA[81100110334]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mehran]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sahami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Google Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>553876</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Baeza-Yates and B. Ribeiro-Neto. <i>Modern Information Retrieval</i>. ACM Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Baxter, P. Christen, and T. Churches. A comparison of fast blocking methods for record linkage. In <i>Proc. of the KDD-2003 Workshop on Data Cleaning, Record Linkage, and Object Consolidation</i>, pp. 25-27, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1008697</ref_obj_id>
				<ref_obj_pid>1008694</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[I. Bhattacharya and L. Getoor. Iterative record linkage for cleaning and integration. In <i>Proc. of the SIGMOD-2004 Workshop on Research Issues on Data Mining and Knowledge Discovery (DMKD-04)</i>, pp. 11-18, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956759</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Bilenko and R. J. Mooney. Adaptive duplicate detection using learnable string similarity measures. In <i>Proc. of ACM SIGKDD 2003</i>, pp. 39-48, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Bilenko and R. J. Mooney. On evaluation and training-set construction for duplicate detection. In <i>Proc. of the SIGKDD 2003 Workshop on Data Cleaning, Record Linkage, and Object Consolidation</i>, pp. 7-12, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>872796</ref_obj_id>
				<ref_obj_pid>872757</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Chaudhuri, K. Ganjam, V. Ganti, and R. Motwani. Robust and efficient fuzzy match for online data cleaning. In <i>Proc. of ACM SIGMOD 2003</i>, pp. 313-324, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347141</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W. W. Cohen, H. Kautz, and D. McAllester. Hardening soft information sources. In <i>Proc. of ACM SIGKDD 2000</i>, pp. 255-259, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775116</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[W. W. Cohen and J. Richman. Learning to match and cluster large high-dimensional data sets for data integration. In <i>Proc. of ACM SIGKDD 2002</i>, pp. 475-480, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1118694</ref_obj_id>
				<ref_obj_pid>1118693</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Collins. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In <i>Proc. of EMNLP-2002</i>, pp. 1-8, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[K. Crammer, J. Keshet, and Y. Singer. Kernel design using boosting. In <i>NIPS 15</i>, pp. 537-544, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[N. Cristianini, A. Elisseeff, J. Shawe-Taylor, and J. Kandola. On kernel target alignment. In <i>NIPS 14</i>, pp. 367-373, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>267666</ref_obj_id>
				<ref_obj_pid>267658</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. B. Doorenbos, O. Etzioni, and D. S. Weld. A scalable comparison-shopping agent for the World-Wide Web. In <i>Proc. of Agents-1997</i>, pp. 39-48, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[I. P. Fellegi and A. B. Sunter. A theory for record linkage. <i>J. of the American Statistical Association</i>, 64(328):1183- 1210, Dec. 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>337869</ref_obj_id>
				<ref_obj_pid>337859</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. E. Schapire. Large margin classification using the perceptron algorithm. <i>Machine Learning</i>, 37:277- 296, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>262228</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[D. Gusfield. <i>Algorithms on Strings, Trees and Sequences</i>. Cambridge University Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223807</ref_obj_id>
				<ref_obj_pid>223784</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. A. Hern&#225;ndez and S. J. Stolfo. The merge/purge problem for large databases. In <i>Proc. of ACM SIGMOD-1995</i>, pp. 127-138, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331504</ref_obj_id>
				<ref_obj_pid>331499</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: A review. <i>ACM Computing Surveys</i>, 31(3):264-323, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Jaro. Advances in record-linkage methodology as applied to matching the 1985 census of Tampa, Florida. <i>J. of the American Statistical Association</i>, 84:414-420, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1005334</ref_obj_id>
				<ref_obj_pid>1005332</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[G. R. G. Lanckriet, N. Cristianini, P. L. Bartlett, L. El Ghaoui, and M. I. Jordan. Learning the kernel matrix with semidefinite programming. <i>J. of Machine Learning Research</i>, 5:27-72, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>301255</ref_obj_id>
				<ref_obj_pid>301136</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. Lawrence, K. Bollacker, and C. L. Giles. Autonomous citation matching. In <i>Proc. of Agents-1999</i>, pp. 392-393, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[X. Li, P. Morie, and D. Roth. Robust reading: Identification and tracing of ambiguous names. In <i>Proc. of NAACL-2004</i>, pp. 17-24, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311445</ref_obj_id>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[C. D. Manning and H. Sch&#252;tze. <i>Foundations of Statistical Natural Language Processing</i>. MIT Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347123</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[A. McCallum, K. Nigam, and L. Ungar. Efficient clustering of high-dimensional data sets with application to reference matching. In <i>Proc. of ACM SIGKDD-2000</i>, pp. 169-178, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[A. McCallum and B. Wellner. Conditional models of identity uncertainty with application to noun coreference. In <i>NIPS 17</i>, pp. 905-912, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[A. E. Monge and C. P. Elkan. An efficient domain-independent algorithm for detecting approximately duplicate database records. In <i>Proc. of SIGMOD 1997 Workshop on Research Issues on Data Mining and Knowledge Discovery</i>, pp. 23-29, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>210524</ref_obj_id>
				<ref_obj_pid>210516</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[C. F. Olson. Parallel algorithms for hierarchical clustering. <i>Parallel Computing</i>, 21:1313-1325, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2101268</ref_obj_id>
				<ref_obj_pid>2101235</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Parag and P. Domingos. Object Identification with Attribute-Mediated Dependences. In <i>Proc. of PKDD-2005</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[H. Pasula, B. Marthi, B. Milch, S. Russell, and I. Shpitser. Identity uncertainty and citation matching. In <i>NIPS 15</i>, pp. 1401-1408, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775087</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[S. Sarawagi and A. Bhamidipaty. Interactive deduplication using active learning. In <i>Proc. ACM SIGKDD-2002</i>, pp. 269-278, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015376</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[S. Shalev-Shwartz, Y. Singer, and A. Y. Ng. Online and batch learning of pseudo-metrics. In <i>Proc. of ICML-2004</i>, pp. 743-750, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[A. Strehl, J. Ghosh, and R. J. Mooney. Impact of similarity measures on web-page clustering. In <i>AAAI-2000 Workshop on Artificial Intelligence for Web Search</i>, pp. 58-64, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775099</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[S. Tejada, C. A. Knoblock, and S. Minton. Learning domain-independent string transformation weights for high accuracy object identification. In <i>Proc. of ACM SIGKDD- 2002</i>, pp. 350-359, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775455</ref_obj_id>
				<ref_obj_pid>775452</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[V. S. Verykios, G. V. Moustakides, and M. G. Elfeky. A Bayesian decision model for cost optimal record matching. <i>The VLDB Journal</i>, 12(1):28-40, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[W. E. Winkler. Using the EM algorithm for weight computation in the Fellegi-Sunter model of record linkage. <i>American Statistical Association, Proc. of the Section on Survey Research Methods</i>, pp. 667-671, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[W. E. Winkler. The state of record linkage and current research problems. Technical report, Statistical Research Division, U.S. Census Bureau, Washington, DC, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106332</article_id>
		<sort_key>66</sort_key>
		<display_label></display_label>
		<pages>66-73</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Using Information-Theoretic Measures to Assess Association Rule Interestingness]]></title>
		<page_from>66</page_from>
		<page_to>73</page_to>
		<doi_number>10.1109/ICDM.2005.149</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106332</url>
		<abstract>
			<par><![CDATA[Assessing rules with interestingness measures is the cornerstone of successful applications of association rule discovery. However, there exists no information-theoretic measure which is adapted to the semantics of association rules. In this article, we present the Directed Information Ratio (DIR), a new rule interestingness measure which is based on information theory. DIR is specially designed for association rules, and in particular it differentiates two opposite rules a &#8594; b and a &#8594; \mathop b\limits^ - . Moreover, to our knowledge, DIR is the only rule interestingness measure which rejects both independence and (what we call) equilibrium, i.e. it discards both the rules whose antecedent and consequent are negatively correlated, and the rules which have more counter-examples than examples. Experimental studies show that DIR is a very filtering measure, which is useful for association rule post-processing.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.1.1</cat_node>
				<descriptor>Information theory</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>E.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003712.10003713</concept_id>
				<concept_desc>CCS->Mathematics of computing->Information theory->Coding theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003712</concept_id>
				<concept_desc>CCS->Mathematics of computing->Information theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10002979.10002985</concept_id>
				<concept_desc>CCS->Security and privacy->Cryptography->Mathematical foundations of cryptography</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003712</concept_id>
				<concept_desc>CCS->Mathematics of computing->Information theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15043793</person_id>
				<author_profile_id><![CDATA[81309503666]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Julien]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Blanchard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Polytechnic School of Nantes University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042744</person_id>
				<author_profile_id><![CDATA[81100011886]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fabrice]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Guillet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Polytechnic School of Nantes University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763132</person_id>
				<author_profile_id><![CDATA[81309494061]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Regis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gras]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Polytechnic School of Nantes University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043059</person_id>
				<author_profile_id><![CDATA[81100224767]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Henri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Briand]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Polytechnic School of Nantes University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>257975</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I. Verkamo. Fast discovery of association rules. pages 307- 328. AAAI, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312219</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. J. Bayardo and R. Agrawal. Mining the most interesting rules. In <i>Proceedings of ACM KDD'1999</i>, pages 145-154. ACM Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[N. M. Blachman. The amount of information that <i>y</i> gives about <i>x</i>. <i>IEEE Transcations on Information Theory</i>, IT- 14(1):27-31, 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Blanchard, F. Guillet, H. Briand, and R. Gras. Assessing rule interestingness with a probabilistic measure of deviation from equilibrium. In <i>Proceedings of the 11th international symposium on Applied Stochastic Models and Data Analysis ASMDA-2005</i>, pages 191-200, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Blanchard, F. Guillet, R. Gras, and H. Briand. Mesurer la qualit&#233; des r&#232;gles et de leurs contrapos&#233;es avec le taux informationnel TIC. <i>Revue des Nouvelles Technologies de l'Information</i>, E-2:287-298, 2004. Actes EGC2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Blanchard, P. Kuntz, F. Guillet, and R. Gras. Implication intensity: from the basic statistical definition to the entropic version. In <i>Statistical Data Mining and Knowledge Discovery</i>, pages 473-485. Chapman & Hall, 2003. Chapter 28.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253327</ref_obj_id>
				<ref_obj_pid>253262</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, and C. Silverstein. Beyond market baskets: generalizing association rules to correlations. <i>SIGMOD Record</i>, 26(2):265-276, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253325</ref_obj_id>
				<ref_obj_pid>253262</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, J. D. Ullman, and S. Tsur. Dynamic itemset counting and implication rules for market basket data. <i>SIGMOD Record</i>, 26(2):255-264, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>637942</ref_obj_id>
				<ref_obj_pid>637913</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[P. Clark and T. Niblett. The CN2 induction algorithm. <i>Machine Learning</i>, 3(4):261-283, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>6677</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Holland, K. Holyoak, R. Nisbett, and P. Thagard. <i>Induction: Processes of inference, learning and discovery</i>. MIT Press, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[X.-H. Huynh, F. Guillet, and H. Briand. ARQAT: An exploratory analysis tool for interestingness measures. In <i>Proceedings of the 11th international symposium on Applied Stochastic Models and Data Analysis ASMDA-2005</i>, pages 334-344, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>670137</ref_obj_id>
				<ref_obj_pid>645805</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Jaroszewicz and D. A. Simovici. A general measure of rule interestingness. In <i>Proceedings of PKDD'2001</i>, pages 253-265. Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[I. Lerman. Foundations in the likelihood linkage analysis classification method. <i>Applied Stochastic Models and Data Analysis</i>, 7:69-76, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>630575</ref_obj_id>
				<ref_obj_pid>630314</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[B. Liu, W. Hsu, S. Chen, and Y. Ma. Analyzing the subjective interestingness of association rules. <i>IEEE Intelligent Systems</i>, 15(5):47-55, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. Loevinger. A systematic approach to the construction and evaluation of tests of ability. <i>Psychological Monographs</i>, 61(4), 1947.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>340016</ref_obj_id>
				<ref_obj_pid>340009</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[B. Padmanabhan and A. Tuzhilin. Unexpectedness as a measure of interestingness in knowledge discovery. <i>Decision Support Systems</i>, 27(3):303-318, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[G. Piatetsky-Shapiro. Discovery, analysis, and presentation of strong rules. In <i>Knowledge Discovery in Databases</i>, pages 229-248. AAAI/MIT Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. Quinlan, editor. <i>C4.5: Programs for Machine Learning</i>. Morgan Kaufmann, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[M. Sebag and M. Schoenauer. Generation of rules with certainty and confidence factors from incomplete and incoherent learning bases. In <i>Proceedings of EKAW88</i>, pages 28.1-28.20, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[C. Shannon and W. Weaver. <i>The mathematical theory of communication</i>. University of Illinois Press, 1949.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627518</ref_obj_id>
				<ref_obj_pid>627287</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[P. Smyth and R. M. Goodman. An information theoretic approach to rule induction from databases. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 4(4):301-316, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>985332</ref_obj_id>
				<ref_obj_pid>985329</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[P.-N. Tan, V. Kumar, and J. Srivastava. Selecting the right objective measure for association analysis. <i>Information Systems</i>, 29(4):293-313, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[H. Theil. On the estimation of relationships involving qualitative variables. <i>American Journal of Sociology</i>, 76:103- 154, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[B. Vaillant, P. Lenca, and S. Lallich. A clustering of interestingness measures. In <i>Proceedings of the 7th International Conference on Discovery Science</i>, pages 290-297, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1017508</ref_obj_id>
				<ref_obj_pid>1017500</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Mining non-redundant association rules. <i>Data Mining and Knowledge Discovery</i>, 9(3):223-248, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106333</article_id>
		<sort_key>74</sort_key>
		<display_label></display_label>
		<pages>74-81</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Shortest-Path Kernels on Graphs]]></title>
		<page_from>74</page_from>
		<page_to>81</page_to>
		<doi_number>10.1109/ICDM.2005.132</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106333</url>
		<abstract>
			<par><![CDATA[Data mining algorithms are facing the challenge to deal with an increasing number of complex objects. For graph data, a whole toolbox of data mining algorithms becomes available by defining a kernel function on instances of graphs. Graph kernels based on walks, subtrees and cycles in graphs have been proposed so far. As a general problem, these kernels are either computationally expensive or limited in their expressiveness. We try to overcome this problem by defining expressive graph kernels which are based on paths. As the computation of all paths and longest paths in a graph is NP-hard, we propose graph kernels based on shortest paths. These kernels are computable in polynomial time, retain expressivity and are still positive definite. In experiments on classification of graph models of proteins, our shortest-path kernels show significantly higher classificationaccuracy than walk-based kernels.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Structural</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P750611</person_id>
				<author_profile_id><![CDATA[81100155678]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Karsten]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Borgwardt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ludwig-Maximilians-University Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15034628</person_id>
				<author_profile_id><![CDATA[81100512920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kriegel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ludwig-Maximilians-University Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Ben-Hur, D. Horn, H. Siegelmann, and V. Vapnik. A support vector method for hierarchical clustering. In T. K. Leen, T. G. Dietterich, and V. Tresp, editors, <i>Advances in Neural Information Processing Systems 13</i>, pages 367-373. MIT Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H. Berman, J. Westbrook, Z. Feng, G. Gilliland, T. Bhat, H. Weissig, I. Shindyalov, and P. Bourne. The protein data bank. <i>Nucleic Acids Research</i>, 28:235-242, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1093315</ref_obj_id>
				<ref_obj_pid>1093304</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K. M. Borgwardt, C. S. Ong, S. Schoenauer, S. Vishwanathan, A. Smola, and H.-P. Kriegel. Protein function prediction via graph kernel. <i>Bioinformatics</i>, 2005. in press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[E. W. Dijkstra. A note on two problems in connection with graphs. <i>Numerische Mathematics</i>, 1:269-271, 1959.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Drucker, C. J. C. Burges, L. Kaufman, A. Smola, and V. Vapnik. Support vector regression machines. In M. C. Mozer, M. I. Jordan, and T. Petsche, editors, <i>Advances in Neural Information Processing Systems 9</i>, pages 155-161, Cambridge, MA, 1997. MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>368168</ref_obj_id>
				<ref_obj_pid>367766</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Floyd. Algorithm 97, shortest path. <i>Comm. ACM</i>, 5:345, 1962.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>28874</ref_obj_id>
				<ref_obj_pid>28869</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. L. Fredman and R. E. Tarjan. Fibonacci heaps and their uses in improved network optimization algorithms. <i>JACM</i>, 34(3):596-615, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. G&#228;rtner. Exponential and geometric kernels for graphs. In <i>NIPS*02 workshop on unreal data</i>, volume Principles of modeling nonvectorial data, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. G&#228;rtner, P. Flach, and S. Wrobel. On graph kernels: Hardness results and efficient alternatives. In B. Sch&#246;lkopf and M. Warmuth, editors, <i>Sixteenth Annual Conference on Computational Learning Theory and Seventh Kernel Workshop, COLT</i>. Springer, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. Haussler. Convolutional kernels on discrete structures. Technical Report UCSC-CRL-99-10, Computer Science Department, UC Santa Cruz, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014072</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[T. Horvath, T. G&#228;rtner, and S. Wrobel. Cyclic pattern kernels for predictive graph mining. In <i>Proceedings of the International Conference on Knowledge Discovery and Data Mining</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. Jungnickel. <i>Graphen, Netzwerke and Algorithmen</i>. BIWiss.- Verlag, Mannheim, Germany, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[H. Kashima, K. Tsuda, and A. Inokuchi. Marginalized kernels between labeled graphs. In <i>Proceedings of the 20th International Conference on Machine Learning (ICML)</i>, Washington, DC, United States, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655996</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. S. Kondor and J. Lafferty. Diffusion kernels on graphs and other discrete structures. In <i>Proceedings of the ICML</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[E. Lawler. A procedure for computing the k best solutions to discrete optimization problems and its application to the shortest path problem. <i>Management Science</i>, 18:401-405, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015446</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[P. Maha, N. Ueda, T. Akutsu, J.-L. Perret, and J.-P. Vert. Extensions of marginalized graph kernels. In <i>Proceedings of the Twenty-First International Conference on Machine Learning</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. Ramon and T. G&#228;rtner. Expressivity versus efficiency of graph kernels. Technical report, First International Workshop on Mining Graphs, Trees and Sequences (held with ECML/PKDD'03), 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[B. Sch&#246;lkopf and A. J. Smola. <i>Learning with Kernels</i>. MIT Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299113</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[B. Sch&#246;lkopf, A. J. Smola, and K.-R. M&#252;ller. Kernel principal component analysis. In B. Sch&#246;lkopf, C. J. C. Burges, and A. J. Smola, editors, <i>Advances in Kernel Methods -- Support Vector Learning</i>, pages 327-352. MIT Press, Cambridge, MA, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[I. Schomburg, A. Chang, C. Ebeling, M. Gremse, C. Heldt, G. Huhn, and D. Schomburg. Brenda, the enzyme database: updates and major new developments. <i>Nucleic Acids Res</i>, 32 Database issue:D431-D433, Jan 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik. <i>Statistical Learning Theory</i>. Wiley, New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>321107</ref_obj_id>
				<ref_obj_pid>321105</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[S. Warshall. A theorem on boolean matrices. <i>J. ACM</i>, 9:11- 12, 1962.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[J. Y. Yen. Finding the k shortest loopless paths in a network. <i>Management Sciences</i>, 17:712-716, 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106334</article_id>
		<sort_key>82</sort_key>
		<display_label></display_label>
		<pages>82-89</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Mining Frequent Spatio-Temporal Sequential Patterns]]></title>
		<page_from>82</page_from>
		<page_to>89</page_to>
		<doi_number>10.1109/ICDM.2005.95</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106334</url>
		<abstract>
			<par><![CDATA[Many applications track the movement of mobile objects, which can be represented as sequences of timestamped locations. Given such a spatio-temporal series, we study the problem of discovering sequential patterns, which are routes frequently followed by the object. Sequential pattern mining algorithms for transaction data are not directly applicable for this setting. The challenges to address are (i) the fuzziness of locations in patterns, and (ii) the identification of non-explicit pattern instances. In this paper, we define pattern elements as spatial regions around frequent line segments. Our method first transforms the original sequence into a list of sequence segments, and detects frequent regions in a heuristic way. Then, we propose algorithms to find patterns by employing a newly proposed substring tree structure and improving Apriori technique. A performance evaluation demonstrates the effectiveness and efficiency of our approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>E.1</cat_node>
				<descriptor>Trees</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152.10003161.10003163.10003415</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems->Record storage systems->Directory structures->B-trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003634</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041767</person_id>
				<author_profile_id><![CDATA[81545405856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Huiping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P209328</person_id>
				<author_profile_id><![CDATA[81100130062]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nikos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mamoulis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P60960</person_id>
				<author_profile_id><![CDATA[81100460281]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Cheung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Mining sequential patterns. In <i>Proc. of Intl. Conf. on Data Engineering</i>, pages 3-14, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[G. Das, K. I. Lin, H. Mannila, G. Renganathan, and P. Smyth. Rule discovery from time series. In <i>Proc. of Intl. Conf. on Knowledge Discovery and Data Mining</i>, pages 16-22, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. H. Douglas and T. K. Peucker. Algorithms for the reduction of the number of points required to represent a digitized line or its caricature. In <i>The Canadian Cartographer, Vol.10, No.2</i>, pages 112-122, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844747</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Wang, Y. Lu, and P. Tzvetkov. Mining top-k frequent closed patterns without minimum support. In <i>Proc. of Intl. Conf. on Data Mining</i>, pages 211-218, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Hershberger and J. Snoeyink. Speeding up the douglaspeucker line-simplification algorithm. In <i>Proc. of the 5th Intl. Symposium on Spatial Data Handling(SDH)</i>, pages 134-143, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657889</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, S. Chu, D. Hart, and M. Pazzani. An online algorithm for segmenting time series. In <i>Proc. of Intl. Conf. on Data Mining</i>, pages 289-296, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775128</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, S. Lonardi, and B. Chiu. Finding surprising patterns in a time series database in linear time and space. In <i>Proc. of ACM Knowledge Discovery and Data Mining</i>, pages 550-556, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882096</ref_obj_id>
				<ref_obj_pid>882082</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Lin, E. Keogh, and W. Truppel. Clustering of streaming time series is meaningless. In <i>Proc. of the SIGMOD workshop in Data Mining and Knowledge Discovery</i>, pages 56- 65, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014080</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[N. Mamoulis, H. Cao, G. Kollios, M. Hadjieleftheriou, Y. Tao, and D. Cheung. Mining, indexing, and querying historical spatiotemporal data. In <i>Proc. of Intl. Conf. on Knowledge Discovery and Data Mining</i>, pages 236-245, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593449</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[H. Mannila, H. Toivonen, and A. I. Verkamo. Discovery of frequent episodes in event sequences. In <i>Data Mining and Knowledge Discovery, Vol. 1</i>, pages 259-287, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>719225</ref_obj_id>
				<ref_obj_pid>647227</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[I. Tsoukatos and D. Gunopulos. Efficient mining of spatiotemporal patterns. In <i>Proc. of Intl. Symp. on Spatial and Temporal Databases</i>, pages 425-442, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[E. R. White. Assessment of line-generalization algorithms using characteristic points. <i>The American Cartographer</i>, 12(1):17-27, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564738</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Yang, W. Wang, P. S. Yu, and J. Han. Mining long sequential patterns in a noisy environment. In <i>Proc. of SIGMOD conf.</i>, pages 406-417, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106335</article_id>
		<sort_key>90</sort_key>
		<display_label></display_label>
		<pages>90-97</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Modeling Multiple Time Series for Anomaly Detection]]></title>
		<page_from>90</page_from>
		<page_to>97</page_to>
		<doi_number>10.1109/ICDM.2005.101</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106335</url>
		<abstract>
			<par><![CDATA[Our goal is to generate comprehensible and accurate models from multiple time series for anomaly detection. The models need to produce anomaly scores in an online manner for real-life monitoring tasks. We introduce three algorithms that work in a constructed feature space and evaluate them with a real data set from the NASA shuttle program. Our offline and online evaluations indicate that our algorithms can be more accurate than two existing algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39031096</person_id>
				<author_profile_id><![CDATA[81408600551]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Chan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Florida Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040013</person_id>
				<author_profile_id><![CDATA[81100230827]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Mahoney]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Florida Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[W. Cohen. Fast effective rule induction. In <i>Proc. 12th Intl. Conf. Machine Learning</i>, pages 115-123, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. Ferrell and S. Santuro. Nasa shuttle valve data. http://www.cs.fit.edu/~pkc/nasa/data/, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650233</ref_obj_id>
				<ref_obj_pid>645340</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Hadjieleftheriou, G. Kollios, V. Tsotras, and D. Gunopulos. Efficient indexing of spatiotemporal objects. In <i>Proc. EDBT</i>, pages 251-268, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014077</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, S. Lonardi, and C. Ratanamahatana. Towards parameter-free data mining. In <i>Proc. ACM SIGKDD</i>, pages 206-215, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1437604</ref_obj_id>
				<ref_obj_pid>1435713</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Povinelli, M. Johnson, A. Lindgren, and J. Ye. Time series classification using gaussian mixture models of reconstructed phase spaces. <i>IEEE Trans. Knowledge and Data Engineering</i>, 16(6):779-783, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[F. Provost and T. Fawcett. Analysis and visualization of classifier performance: Comparison under imprecise class and cost distributions. In <i>Proc. 3rd Intl. Conf. Knowledge Discovery and Data Mining</i>, pages 43-48, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1105629</ref_obj_id>
				<ref_obj_pid>1105622</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Salvador and P. Chan. Learning states and rules for detecting anomalies in time series. <i>Applied Intelligence</i>, 2005. to appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956777</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Vlachos, M. Hadjieleftheriou, D. Gunopulos, and E. Keogh. Indexing multi-dimensional time-series with support for multiple distance measures. In <i>Proc. ACM SIGKDD</i>, pages 216-225, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106336</article_id>
		<sort_key>98</sort_key>
		<display_label></display_label>
		<pages>98-105</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Summarization &#8212; Compressing Data into an Informative Representation]]></title>
		<page_from>98</page_from>
		<page_to>105</page_to>
		<doi_number>10.1109/ICDM.2005.137</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106336</url>
		<abstract>
			<par><![CDATA[In this paper, we formulate the problem of summarization of a dataset of transactions with categorical attributes as an optimization problem involving two objective functions - compaction gain and information loss. We propose metrics to characterize the output of any summarization algorithm. We investigate two approaches to address this problem. The first approach is an adaptation of clustering and the second approach makes use of frequent itemsets from the association analysis domain. We illustrate one application of summarization in the field of network data where we show how our technique can be effectively used to summarize network traffic into a compact but meaningful representation. Specifically, we evaluate our proposed algorithms on the 1998 DARPA Off-line Intrusion Detection Evaluation data and network data generated by SKAION Corp for the ARDA information assurance program.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>E.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>H.1.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>H.5.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003712</concept_id>
				<concept_desc>CCS->Mathematics of computing->Information theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120</concept_id>
				<concept_desc>CCS->Human-centered computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10002979.10002985</concept_id>
				<concept_desc>CCS->Security and privacy->Cryptography->Mathematical foundations of cryptography</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010346.10010347</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation theory->Systems theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003712.10003713</concept_id>
				<concept_desc>CCS->Mathematics of computing->Information theory->Coding theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003712</concept_id>
				<concept_desc>CCS->Mathematics of computing->Information theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763168</person_id>
				<author_profile_id><![CDATA[81309510517]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Varun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chandola]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041061</person_id>
				<author_profile_id><![CDATA[81452613746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vipin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[SKAION Corporation. SKAION Intrusion Detection System Evaluation Data.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014057</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[F. Afrati, A. Gionis, and H. Mannila. Approximating a collection of frequent sets. In <i>KDD '04</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imieliski, and A. Swami. Mining association rules between sets of items in large databases. In <i>SIGMOD '93</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>604268</ref_obj_id>
				<ref_obj_pid>604264</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Barbara, J. Couto, S. Jajodia, and N. Wu. ADAM: A testbed for exploring the use of data mining in intrusion detection. <i>SIGMOD Rec.</i>, 30(4):15-24, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335388</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander. Lof: Identifying density-based local outliers. In <i>SIGMOD '00</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>670313</ref_obj_id>
				<ref_obj_pid>645806</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Calders and B. Goethals. Mining all non-derivable frequent itemsets. In <i>PKDD '02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[V. Chandola and V. Kumar. Summarization - compressing data into an informative representation. Technical Report TR 05-024, Dept. of Computer Science, University of Minnesota, Minneapolis, MN, USA, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[L. Ert&#246;z, E. Eilertson, A. Lazarevic, P.-N. Tan, V. Kumar, J. Srivastava, and P. Dokas. MINDS - Minnesota Intrusion Detection System. In <i>Data Mining - Next Generation Challenges and Future Directions</i>. MIT Press, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>355013</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Han and M. Kamber. <i>Data Mining: Concepts and Techniques</i>. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844747</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Wang, Y. Lu, and P. Tzvetkov. Mining top-k frequent closed patterns without minimum support. In <i>ICDM '02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014073</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Hu and B. Liu. Mining and summarizing customer reviews. In <i>KDD '04</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A. K. Jain and R. C. Dubes. <i>Algorithms for Clustering Data</i>. Prentice-Hall, Inc., 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[G. Karypis. Cluto 2.1.1 software for clustering high-dimensional datasets.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. P. Lippmann et al. Evaluating intrusion detection systems - the 1998 DARPA off-line intrusion detection evaluation. In <i>DISCEX '00</i>, volume 2, pages 12-26, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347128</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[B. Liu, M. Hu, and W. Hsu. Multi-level organization and summarization of the discovered rules. In <i>KDD '00</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775102</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. V. Mahoney and P. K. Chan. Learning non-stationary models of normal network traffic for detecting novel attacks. In <i>KDD '02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>554275</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[I. Mani. <i>Advances in Automatic Text Summarization</i>. MIT Press, Cambridge, MA, USA, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656256</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets for association rules. In <i>ICDT '99</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844709</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. Pei, G. Dong, W. Zou, and J. Han. On computing condensed frequent pattern bases. In <i>ICDM '02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>604267</ref_obj_id>
				<ref_obj_pid>604264</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. J. Stolfo, W. Lee, P. K. Chan, W. Fan, and E. Eskin. Data mining-based intrusion detectors: An overview of the columbia ids project. <i>SIGMOD Rec.</i>, 30(4):5-14, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1095618</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[P.-N. Tan, M. Steinbach, and V. Kumar. <i>Introduction to Data Mining</i>, chapter 8. Addison-Wesley, April 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106337</article_id>
		<sort_key>106</sort_key>
		<display_label></display_label>
		<pages>106-113</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Labeling Unclustered Categorical Data into Clusters Based on the Important Attribute Values]]></title>
		<page_from>106</page_from>
		<page_to>113</page_to>
		<doi_number>10.1109/ICDM.2005.85</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106337</url>
		<abstract>
			<par><![CDATA[Sampling has been recognized as an important technique to improve the efficiency of clustering. However, with sampling applied, those points which are not sampled will not have their labels. Although there is a straightforward approach in the numerical domain, the problem of how to allocate those unlabeled data points into proper clusters remains as a challenging issue in the categorical domain. In this paper, a mechanism named MAximal Resemblance Data Labeling (abbreviated as MARDL) is proposed to allocate each unlabeled data point into the corresponding appropriate cluster based on the novel categorical clustering representative, namely, Node Importance Representative(abbreviated as NIR), which represents clusters by the importance of attribute values. MARDL has two advantages: (1) MARDL exhibits high execution efficiency; (2) after each unlabeled data is allocated into the proper cluster, MARDL preserves clustering characteristics, i.e., high intra-cluster similarity and low inter-cluster similarity. MARDL is empirically validated via real and synthetic data sets, and is shown to be not only more efficient than prior methods but also attaining results of better quality.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[data mining, categorical clustering, data labeling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763038</person_id>
				<author_profile_id><![CDATA[81392608407]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hung-Leng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Taiwan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042201</person_id>
				<author_profile_id><![CDATA[81100637068]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kun-Ta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chuang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Taiwan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040135</person_id>
				<author_profile_id><![CDATA[81450594725]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ming-Syan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Taiwan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>553876</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Baeza-Yates and B. Riberiro-Neto. <i>Modern Information Retrieval</i>. Addison-Wesley, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. Berkhin. Survey of clustering data mining techniques. Technical report, Accrue Software, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. S. Bradley, U. M. Fayyad, and C. Reina. Scaling clustering algorithms to large databases. In <i>Knowledge Discovery and Data Mining</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the em algorithm. <i>Journal of the Royal Statistical Society</i>, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312201</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[V. Ganti, J. Gehrke, and R. Ramakrishnan. CACTUS-Clustering Categorical Data Using Summaries. <i>In Proc. of ACM SIGKDD</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276312</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Guha, R. Rastogi, and K. Shim. CURE: An Efficient Clustering Algorithm for Large Databases. <i>In Proc. of the ACM SIGMOD Conf.</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847264</ref_obj_id>
				<ref_obj_pid>846218</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Guha, R. Rastogi, and K. Shim. ROCK: A Robust Clustering Algorithm for Categorical Attributes. <i>In Proc. of the 15th ICDE</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Hettich, C. L. Blake, and C. J. Merz. UCI repository of machine learning databases. http://www.ics.uci.edu/~mlearn/mlrepository.html, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593469</ref_obj_id>
				<ref_obj_pid>593420</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Z. Huang. Extensions to the k-means algorithm for clustering large data sets with categorical values. <i>Data Min. Knowl. Discov.</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. Jain and R. Dubes. <i>Algorithms for Clustering Data</i>. Prentiche Hall, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331504</ref_obj_id>
				<ref_obj_pid>331499</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: a review. <i>ACM Computing Surveys</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. S. Johnson M. R. Garey and H. S. Witsenhausen. The complexity of the generalized lloyd-max problem. <i>IEEE Trans. Inf. Theory</i>, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>365499</ref_obj_id>
				<ref_obj_pid>365411</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[N. Mishra, D. Oblinger, and L. Pitt. Sublinear time approximate clustering. In <i>In Proc. of the ACM-SIAM symposium on Discrete algorithms</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628263</ref_obj_id>
				<ref_obj_pid>627342</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. T. Ng and J. Han. CLARANS: A Method for Clustering Objects for Spatial Data Mining. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>560733</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[R. Ramakrishnan and J. Gehrke. <i>Database Management Systems</i>. McGraw-Hill, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[C.E. Shannon. A mathematical theory of communication. <i>Bell System Techical Journal</i>, 1948.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106338</article_id>
		<sort_key>114</sort_key>
		<display_label></display_label>
		<pages>114-121</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Making Subsequence Time Series Clustering Meaningful]]></title>
		<page_from>114</page_from>
		<page_to>121</page_to>
		<doi_number>10.1109/ICDM.2005.91</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106338</url>
		<abstract>
			<par><![CDATA[Recently, the startling claim was made that sequential time series clustering is meaningless. This has important consequences for a significant amount of work in the literature, since such a claim invalidates this work's contribution. In this paper, we show that sequential time series clustering is not meaningless, and that the problem highlighted in these works stem from their use of the Euclidean distance metric as the distance measure in the subsequence vector space. As a solution, we consider quite a general class of time series, and propose a regime based on two types of similarity that can exist between subsequence vectors, which give rise naturally to an alternative distance measure to Euclidean distance in the subsequence vector space. We show that, using this alternative distance measure, sequential time series clustering can indeed be meaningful. We repeat a key experiment in the work on which the "meaningless" claim was based, and show that our method leads to a successful clustering outcome.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39053981</person_id>
				<author_profile_id><![CDATA[81309483528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jason]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Australian National University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>773176</ref_obj_id>
				<ref_obj_pid>773153</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Babcock, M. Datar, R. Motwani, and L. O'Callaghan. Maintaining variance and k-medians over data stream windows. In <i>Proceedings of the 22nd Symposium on Principles of Database Systems (PODS)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. Berkhin. Survey of clustering data mining techniques. Technical report, Accrue Software, San Jose, CA, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952156</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, J. Lin, and W. Truppel. Clustering of time series subsequences is meaningless: Implications for previous and future research. In <i>Proceedings of the International Conference of Data Mining</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1053692</ref_obj_id>
				<ref_obj_pid>1053555</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[X. Feng and H. Huang. A fuzzy-set-based reconstructed phase space method for identification of temporal patterns in complex time series. <i>Transactions on Knowledge and Data Engineering</i>, 17(5):601-612, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[F. Takens. Detecting strange attractors in turbulence. In <i>Lecture Notes in Math.</i>, volume 898. Springer, New York, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>289372</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[H. Kantz and T. Schreiber. <i>Nonlinear Time Series Analysis</i>. Cambridge Univ. Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628245</ref_obj_id>
				<ref_obj_pid>627341</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J.F. Roddick and M. Spiliopoulou. A survey of temporal knowledge discovery paradigms and methods. <i>Transactions on Data Engineering</i>, 14(4):750-767, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>796588</ref_obj_id>
				<ref_obj_pid>795666</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Guha, N. Mishra, R. Motwani, and L. O'Callaghan. Clustering data streams. In <i>Proceedings of the Symposium on Foundations of Computer Science</i>, pages 359-366, Redondo Beach, CA, USA, Nov 12-14 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312268</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. Oates. Identifying distinctive subsequences in multivariate time series by clustering. In <i>Proceedings of the International Conference on Knowledge Discovery and Data Mining</i>, pages 322-326, San Diego, CA, USA, Aug 15-18 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106339</article_id>
		<sort_key>122</sort_key>
		<display_label></display_label>
		<pages>122-129</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Kernel-Density-Based Clustering of Time Series Subsequences Using a Continuous Random-Walk Noise Model]]></title>
		<page_from>122</page_from>
		<page_to>129</page_to>
		<doi_number>10.1109/ICDM.2005.84</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106339</url>
		<abstract>
			<par><![CDATA[Noise levels in time series subsequence data are typically very high, and properties of the noise differ from those of white noise. The proposed algorithm incorporates a continuous random-walk noise model into kernel-density-based clustering. Evaluation is done by testing to what extent the resulting clusters are predictive of the process that generated the time series. It is shown that the new algorithm not only outperforms partitioning techniques that lead to trivial and unsatisfactory results under the given quality measure, but also improves upon other density-based algorithms. The results suggest that the noise elimination properties of kernel-density-based clustering algorithms can be of significant value for the use of clustering in preprocessing of data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040673</person_id>
				<author_profile_id><![CDATA[81309485232]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Anne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Denton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[North Dakota State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>361007</ref_obj_id>
				<ref_obj_pid>361002</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. L. Bentley. Multidimensional binary search trees used for associative searching. <i>Communications of the ACM</i>, 18(9), 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>257961</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Berndt and J. Clifford. <i>Advances in knowledge discovery and data mining</i>, chapter Finding patterns in time series: a dynamic programming approach, pages 229-248. AAAI Press, Menlo Park, CA, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628711</ref_obj_id>
				<ref_obj_pid>628321</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Y. Cheng. Mean shift, mode seeking, and clustering. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 17(8):790-799, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>513076</ref_obj_id>
				<ref_obj_pid>513073</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Comaniciu and P. Meer. Mean shift: a robust approach toward feature space analysis. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 24(5):603-619, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Das, K.-I. Lin, H. Mannila, G. Renganathan, and P. Smyth. Rule discovery from time series. In <i>Proceedings of the IEEE Int. Conf. on Data Mining</i>, Rio de Janeiro, Brazil, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Denton. Density-based clustering of time series subsequences. In <i>In Proceedings of The Third Workshop on Mining Temporal and Sequential Data (TDM 04) in conjunction with The Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, Seattle, WA, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347189</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Gavrilov, D. Anguelov, P. Indyk, and R. Motwani. Mining the stock market (extended abstract): which measure is best? In <i>Sixth ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining</i>, pages 487-496, Boston, MA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. L. Goldberger, L. A. N. Amaral, L. Glass, J. M. Hausdorff, P. C. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E. Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. <i>Circulation</i>, 101(23):e215- e220, 2000 (June 13).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>726176</ref_obj_id>
				<ref_obj_pid>647484</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Goldin and P. Kanellakis. On similarity queries for timeseries data: Constraint specification and implementation. In <i>1st Int'l Conf. on the Principles and Practice of Constraint Programming, LNCS 976</i>, pages 137-153. Springer, Sep. 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. Hinneburg and D. Keim. A general approach to clustering in large databases with noise. <i>Knowl. Inf. Syst.</i>, 5(4):387- 415, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Ihler. Kernel density estimation toolbox for matlab (r13), accessed 04/2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[E. Keogh and T. Folias. The ucr time series data mining archive, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952156</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, J. Lin, and W. Truppel. Clustering of time series subsequences is meaningless: implications for previous and future research. In <i>Proceedings of the IEEE Int. Conf. on Data Mining</i>, pages 115-122, Melbourne, FL, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>270627</ref_obj_id>
				<ref_obj_pid>270613</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Kohavi and G. John. Wrappers for feature subset selection. <i>Artificial Intelligence</i>, 1-2:273-324, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844710</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[P. Patel, E. Keogh, J. Lin, and S. Lonardi. Mining motifs in massive time series databases. In <i>Proceedings of the IEEE Int. Conf. on Data Mining</i>, Maebashi City, Japan, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. Priestley. <i>Non-linear and non-stationary time series analysis</i>. Academic Press, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>878994</ref_obj_id>
				<ref_obj_pid>876875</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[M. Vlachos, D. Gunopoulos, and G. Kollios. Discovering similar multidimensional trajectories. In <i>Proceedings 18th International Conference on Data Engineering (ICDE'02)</i>, San Jose, CA, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106340</article_id>
		<sort_key>130</sort_key>
		<display_label></display_label>
		<pages>130-137</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Usage-Based PageRank for Web Personalization]]></title>
		<page_from>130</page_from>
		<page_to>137</page_to>
		<doi_number>10.1109/ICDM.2005.148</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106340</url>
		<abstract>
			<par><![CDATA[Recommendation algorithms aim at proposing "next" pages to a user based on her current visit and the past users' navigational patterns. In the vast majority of related algorithms, only the usage data are used to produce recommendations, whereas the structural properties of the Web graph are ignored. We claim that taking also into account the web structure and using link analysis algorithms ameliorates the quality of recommendations. In this paper we present UPR, a novel personalization algorithm which combines usage data and link analysis techniques for ranking and recommending web pages to the end user. Using the web site's structure and its usage data we produce personalized navigational graph synopses (prNG) to be used for applying UPR and produce personalized recommendations. Experimental results show that the accuracy of the recommendations is superior to pure usage-based approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Structural</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>User profiles and alert services</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.4</cat_node>
				<descriptor>Navigation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003260.10003261.10003271</concept_id>
				<concept_desc>CCS->Information systems->World Wide Web->Web searching and information discovery->Personalization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010510.10010515</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document preparation->Multi / mixed media creation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003331.10003271</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Users and interactive retrieval->Personalization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10003254</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Hypertext / hypermedia</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15039580</person_id>
				<author_profile_id><![CDATA[81100185742]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Magdalini]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Eirinaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Athens University of Economics and Business]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP38025076</person_id>
				<author_profile_id><![CDATA[81100414295]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michalis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vazirgiannis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Athens University of Economics and Business]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M.S. Aktas, M.A. Nacar, F. Menczer, <i>Personalizing PageRank Based on Domain Profiles</i>, in Proc. of WEBKDD 2004 Workshop, August 2004, Seattle, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1026320</ref_obj_id>
				<ref_obj_pid>1025132</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Baraglia, F. Silvestri, <i>An Online Recommender System for Large Web Sites</i>, in Proc. of ACM/IEEE WI'04 Conference, China, September 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>744399</ref_obj_id>
				<ref_obj_pid>648036</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Borges, M. Levene, <i>Data Mining of User Navigation Patterns</i>, in Revised Papers from the International Workshop on Web Usage Analysis and User Profiling, LNCS Vol. 1836, pp.92-111, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>297827</ref_obj_id>
				<ref_obj_pid>297805</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Brin, L. Page, <i>The anatomy of a large-scale hypertextual Web search engine</i>, Computer Networks, 30(1-7): 107-117, 1998, Proc. of WWW7 Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>744397</ref_obj_id>
				<ref_obj_pid>648036</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A.G. Buchner, M. Baumgarten, S.S. Anand, M.D. Mulvenna, J.G. Hughes, <i>Navigation pattern discovery from Internet data</i>, in Proc. of WEBKDD'99 Workshop, August 1999, San Diego, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347119</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[I. Cadez, S. Gaffney, P. Smyth, <i>A general probabilistic framework for clustering individuals and objects</i>, in Proc. of ACM KDD2000 Conference, Boston, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347151</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[I. Cadez, D. Heckerman, C. Meek, P. Smyth, S. White, <i>Visualization of Navigation Patterns on a Web Site Using Model Based Clustering</i>, in Proc. of ACM KDD2000 Conference, Boston MA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Deshpande, G. Karypis, <i>Selective Markov Models for Predicting Web-Page Accesses</i>, in Proc. of the 1st SIAM International Conference on Data Mining, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Eirinaki, <i>Web Mining: A Roadmap</i>, Technical Report, DB-NET 2004, available at http://www.db-net.aueb.gr]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>643478</ref_obj_id>
				<ref_obj_pid>643477</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Eirinaki, M. Vazirgiannis, <i>Web Mining for Web Personalization</i>, in ACM TOIT, 3(1), February 2003, pp.1-29.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956765</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Eirinaki, M. Vazirgiannis, I. Varlamis, <i>SEWeP: Using Site Semantics and a Taxonomy to Enhance the Web Personalization Process</i>, in Proc. of ACM KDD2003 Conference, August 2003, Washington DC.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1031477</ref_obj_id>
				<ref_obj_pid>1031453</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. El-Sayed, C. Ruiz, E.A. Rundensteiner, <i>FS-Miner: Efficient and Incremental Mining of Frequent Sequence Patterns in Web Logs</i>, in Proc. of WIDM '04, November 2004, Washington DC.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>511513</ref_obj_id>
				<ref_obj_pid>511446</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[T. Haveliwala, <i>Topic-Sensitive PageRank</i>, in Proc. of WWW2002 Conference, Hawaii USA, May 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[M. Kendall, J.D. Gibbons, <i>Rank Correlation Methods, Oxford University Press</i>, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. Levene, G. Loizou, <i>Computing the Entropy of User Navigation in the Web</i>, in Intl. Journal of Information Technology and Decision Making, 2:459-476, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952173</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[E. Manavoglou, D. Pavlov, C.L. Giles, <i>Probabilistic User Behaviour Models</i>, in Proc. of ICDM 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951443</ref_obj_id>
				<ref_obj_pid>951440</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[F. Masseglia, P. Poncelet, M. Teisseire, <i>Using Data Mining Techniques on Web Access Logs to Dynamically Improve Hypertext Structure</i>, in ACM Sig Web Letters, Vol. 8, N. 3, pp. 13-19, October 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211390</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[R. Motwani and P. Raghavan. <i>Randomized Algorithms</i>, Cambridge University Press, United Kingdom, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[msnbc.com Web Log Data, available from <i>UCI KDD Archive</i>, http://kdd.ics.uci.edu/databases/msnbc/msnbc.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>350361</ref_obj_id>
				<ref_obj_pid>350342</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[M. Perkowitz, O. Etzioni, <i>Towards Adaptive Web Sites: Conceptual Framework and Case Study</i>, in Artificial Intelligence 118{1-2} (2000), pp. 245-275.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287410</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[N. Polyzotis, M. Garofalakis, <i>Structure and Value Synopses for XML Data Graphs</i>, in Proc. of the 28th VLDB Conference, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007599</ref_obj_id>
				<ref_obj_pid>1007568</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[N. Polyzotis, M. Garofalakis, Y. Ioannidis, <i>Approximate XML Query Answers</i>, in Proc. of SIGMOD 2004, Paris, France, June 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[M. Richardson, P. Domingos, <i>The Intelligent Surfer: Probabilistic Combination of Link and Content Information in PageRank</i>, in Neural Information Processing Systems, 14, pp.1441-1448, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>346322</ref_obj_id>
				<ref_obj_pid>346241</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[R.R. Sarukkai, <i>Link Prediction and Path Analysis Using Markov Chains</i>, in Computer Networks, 33(1-6): 337-386, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[R. Sen, M. Hansen, <i>Predicting a Web user's next access based on log data</i>, in Journal of Computational Graphics and Statistics, 12(1):143-155, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[M. Spiliopoulou, L.C. Faulstich, and K. Wilkler, <i>A data miner analyzing the navigational behaviour of Web users</i>, in Proc. of the Workshop on Machine Learning in User Modelling, Greece, July 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1053125</ref_obj_id>
				<ref_obj_pid>1053072</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Q. Zhao, S.S. Bhowmick, <i>Mining History of Changes to Web Access Patterns</i>, in Proc. of PKDD 2004, Italy, September 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106341</article_id>
		<sort_key>138</sort_key>
		<display_label></display_label>
		<pages>138-145</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[WARP]]></title>
		<subtitle><![CDATA[Time Warping for Periodicity Detection]]></subtitle>
		<page_from>138</page_from>
		<page_to>145</page_to>
		<doi_number>10.1109/ICDM.2005.152</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106341</url>
		<abstract>
			<par><![CDATA[Periodicity mining is used for predicting trends in time series data. Periodicity detection is an essential process in periodicity mining to discover potential periodicity rates. Existing periodicity detection algorithms do not take into account the presence of noise, which is inevitable in almost every real-world time series data. In this paper, we tackle the problem of periodicity detection in the presence of noise. We propose a new periodicity detection algorithm that deals efficiently with all types of noise. Based on time warping, the proposed algorithm warps (extends or shrinks) the time axis at various locations to optimally remove the noise. Experimental results show that the proposed algorithm out-performs the existing periodicity detection algorithms in terms of noise resiliency.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P482024</person_id>
				<author_profile_id><![CDATA[81100215064]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mohamed]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Elfeky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Google Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P296054</person_id>
				<author_profile_id><![CDATA[81100086855]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Walid]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Aref]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040118</person_id>
				<author_profile_id><![CDATA[81100125597]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ahmed]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Elmagarmid]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>673155</ref_obj_id>
				<ref_obj_pid>645921</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, K. Lin, H. Sawhney, and K. Shim. Fast similarity search in the presence of noise, scaling, and translation in time series databases. In <i>VLDB</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Brendt and J. Clifford. Using dynamic time warping to find patterns in time series. In <i>AAAI Workshop on Knowledge Discovery in Databases</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Chu, E. Keogh, D. Hart, and M. Pazzani. Iterative deepening dynamic time warping for time series. In <i>SDM</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199269</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Crochemore and W. Rytter. <i>Text Algorithms</i>. Oxford University Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Daw, C. Finney, and E. Tracy. A review of symbolic analysis of experimental data. <i>Review of Scientific Instruments</i>, 74(2):915-930, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Elfeky, W. Aref, and A. Elmagarmid. Using convolution to mine obscure periodic patterns in one pass. In <i>EDBT</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1070763</ref_obj_id>
				<ref_obj_pid>1070612</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Elfeky, W. Aref, and A. Elmagarmid. Periodicity detection in time series databases. <i>IEEE TKDE</i>, 17(7), July 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671699</ref_obj_id>
				<ref_obj_pid>645926</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P. Indyk, N. Koudas, and S. Muthukrishnan. Identifying representative trends in massive time series data sets using sketches. In <i>VLDB</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287405</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[E. Keogh. Exact indexing of dynamic time warping. In <i>VLDB</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, S. Chu, D. Hart, and M. Pazzani. Segmenting time series: A survey and novel approach. In M. Last, A. Kandel, and H. Bunke, editors, <i>Data Mining in Time Series Databases</i>. World Scientific Publishing, June 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347153</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[E. Keogh and M. Pazzani. Scaling up dynamic time warping for datamining applications. In <i>KDD</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>756489</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Kim, S. Park, and W. Chu. An index-based approach for similarity search supporting time warping in large sequence databases. In <i>ICDE</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656369</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. Ma and J. Hellerstein. Mining partially periodic event patterns with unknown periods. In <i>ICDE</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1315500</ref_obj_id>
				<ref_obj_pid>1315451</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S. Papadimitriou, A. Brockwell, and C. Faloutsos. Adaptive, hands-off stream mining. In <i>VLDB</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[A. Weigend and N. Gershenfeld. <i>Time Series Prediction: Forecasting the Future and Understanding the Past</i>. Addison-Wesley, Reading, Massachusetts, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106342</article_id>
		<sort_key>146</sort_key>
		<display_label></display_label>
		<pages>146-153</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Bifold Constraint-Based Mining by Simultaneous Monotone and Anti-Monotone Checking]]></title>
		<page_from>146</page_from>
		<page_to>153</page_to>
		<doi_number>10.1109/ICDM.2005.35</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106342</url>
		<abstract>
			<par><![CDATA[Mining for frequent itemsets can generate an overwhelming number of patterns, often exceeding the size of the original transactional database. One way to deal with this issue is to set filters and interestingness measures. Others advocate the use of constraints to apply to the patterns, either on the form of the patterns or on descriptors of the items in the patterns. However, typically the filtering of patterns based on these constraints is done as a post-processing phase. Filtering the patterns post-mining adds a significant overhead, still suffers from the sheer size of the pattern set and loses the opportunity to exploit those constraints. In this paper we propose an approach that allows the efficientmining of frequent itemsets patterns, while pushing simultaneously both monotone and anti-monotone constraints during and at different strategic stages of the mining process. Our implementation shows a significant improvement when considering the constraints early and a better performance over Dualminer which also considers both types of constraints.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P482063</person_id>
				<author_profile_id><![CDATA[81100461137]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mohammad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[El-Hajj]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Alberta Edmonton]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P512311</person_id>
				<author_profile_id><![CDATA[81100104421]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Osmar]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Zaiane]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Alberta Edmonton]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP26002617</person_id>
				<author_profile_id><![CDATA[81309509149]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nalos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Alberta Edmonton]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases. In <i>Proc. 1993 ACM-SIGMOD Int. Conf. Management of Data</i>, pages 207-216, Washington, D.C., May 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. 1994 Int. Conf. Very Large Data Bases</i>, pages 487-499, Santiago, Chile, September 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[I. Almaden. Quest synthetic data generation code. http://www.almaden.ibm.com/software/quest/Resources/index.shtml.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952132</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[F. Bonchi, F. Giannotti, A. Mazzanti, and D. Pedreschi. Examiner: Optimized level-wise frequent pattern mining with monotone constraints. In <i>IEEE ICDM</i>, Melbourne, Florida, November 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[F. Bonchi and B. Goethals. Fp-bonsai: the art of growing and pruning small fp-trees. In <i>Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD'04)</i>, pages 155-160, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033434</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[F. Bonchi and C. Lucchese. On closed constrained frequent pattern mining. In <i>IEEE International Conference on Data Mining (ICDM'04)</i>, Brighton, UK, November 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775054</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Bucila, J. Gehrke, D. Kifer, and W. White. Dualminer: A dual-pruning algorithm for itemsets with constraints. In <i>Eight ACM SIGKDD International Conf. on Knowledge Discovery and Data Mining</i>, pages 42-51, Edmonton, Alberta, August 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656386</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. Burdick, M. Calimlim, and J. Gehrke. Mafia: A maximal frequent itemset algorithm for transactional databases. In <i>ICDE</i>, pages 443-452, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Chaudhuri. Data mining and database systems: Where is the intersection? <i>Bulletin of the Technical Committee on Data Engineering</i>, 21, March 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. El-Hajj and O. R. Za&#239;ane. Non recursive generation of frequent k-itemsets from frequent pattern tree representations. In <i>Proc. of 5th International Conference on Data Warehousing and Knowledge Discovery (DaWak'2003)</i>, September 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Frequent itemset mining implementations repository. http://fimi.cs.helsinki.fi/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>ACM-SIGMOD</i>, Dallas, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304196</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[L. Lakshmanan, R. Ng, J. Han, and A. Pang. Optimization of constrained frequent set queries with 2-variable constraints. In <i>ACM SIGMOD Conference on Management of Data</i>, pages 157-168, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347166</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Pie and J. Han. Can we push more constraints into frequent pattern mining? In <i>ACM SIGKDD Conference</i>, pages 350-354, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656372</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. Pie, J. Han, and L. Lakshmanan. Mining frequent itemsets with convertible constraints. In <i>IEEE ICDE Conference</i>, pages 433-442, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[R. M. Ting, J. Bailey, and K. Ramamohanarao. Paradualminer: An efficient parallel implementation of the dualminer algorithm. In <i>Eight Pacific-Asia Conference, PAKDD 2004</i>, pages 96-105, Sydney, Australia, May 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081964</ref_obj_id>
				<ref_obj_pid>1081870</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[O. R. Za&#239;ane and M. El-Hajj. Pattern Lattice Traversal by Selective Jumps. In <i>In Proc. 2005 Int'l Conf. on Data Mining and Knowledge Discovery (ACM SIGKDD), Chicago, IL, USA.</i>, pages 729-735, August 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106343</article_id>
		<sort_key>154</sort_key>
		<display_label></display_label>
		<pages>154-161</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Effective Estimation of Posterior Probabilities]]></title>
		<subtitle><![CDATA[Explaining the Accuracy of Randomized Decision Tree Approaches]]></subtitle>
		<page_from>154</page_from>
		<page_to>161</page_to>
		<doi_number>10.1109/ICDM.2005.54</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106343</url>
		<abstract>
			<par><![CDATA[There has been increasing number of independently proposed randomization methods in different stages of decision tree construction to build multiple trees. Randomized decision tree methods have been reported to be significantly more accurate than widely-accepted single decision trees, although the training procedure of some methods incorporates a surprisingly random factor and therefore opposes the generally accepted idea of employing gain functions to choose optimum features at each node and compute a single tree that fits the data. One important question that is not well understood yet is the reason behind the high accuracy. We provide an insight based on posterior probability estimations. We first establish the relationship between effective posterior probability estimation and effective loss reduction. We argue that randomized decision tree methods effectively approximate the true probability distribution using the decision tree hypothesis space. We conduct experiments using both synthetic and real-world datasets under both 0-1 and cost-sensitive loss functions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Random number generation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.3</cat_node>
				<descriptor>Uncertainty, "fuzzy," and probabilistic reasoning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Structural</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003687</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Random number generation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010191</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Vagueness and fuzzy logic</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010190</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Probabilistic reasoning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040399</person_id>
				<author_profile_id><![CDATA[81367591181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T.J.Watson Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045182</person_id>
				<author_profile_id><![CDATA[81100303743]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greengrass]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[US Department of Defense]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044102</person_id>
				<author_profile_id><![CDATA[81317489205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Joe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McCloskey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[US Department of Defense]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T.J.Watson Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763072</person_id>
				<author_profile_id><![CDATA[81329488579]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Drummey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[US Department of Defense]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>263042</ref_obj_id>
				<ref_obj_pid>263023</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Yali Amit and Donald Geman. Shape quantization and recognition with randomized trees. <i>Neural Computation</i>, 9(7):1545-1588, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>599607</ref_obj_id>
				<ref_obj_pid>599591</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Eric Bauer and Ron Kohavi. An empirical comparison of voting classification algorithms: Bagging, boosting, and variants. <i>Machine Learning</i>, 36(1-2):105-139, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148062</ref_obj_id>
				<ref_obj_pid>148061</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[E. Bienenstock, S. Geman, and R. Dorsat. Neural networks and the bias/variance dilemma. <i>Neural Computation</i>, 4:1-58, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Leo Breiman. Bagging predictors. <i>Machine Learning</i>, 24(2):123- 140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>352654</ref_obj_id>
				<ref_obj_pid>352644</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Leo Breiman. Randomizing outputs to increase predictiong accuracy. <i>Machine Learning</i>, 40(3):229-242, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>570182</ref_obj_id>
				<ref_obj_pid>570181</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Leo Breiman. Random forests. <i>Machine Learning</i>, 45(1):5-32, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Wray Lindsay Buntine. <i>A Theory of Learning Classification Rules</i>. PhD thesis, School of Computing Science, University of Technology, Syndney, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Chipman, E. George, and R. McCulloch. Bayesian CART model search. <i>J of American Statistics</i>, 93(98):935-960, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>350131</ref_obj_id>
				<ref_obj_pid>350128</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Thomas Dietterich. An experimental comparison of three methods for constructing ensembles of decision trees: bagging, boosting, and randomization. <i>Machine Learning</i>, 40(2):139-157, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1597204</ref_obj_id>
				<ref_obj_pid>1597148</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Wei Fan. On the optimality of probability estimation by random decision trees. In <i>Proceedings of Nineteeth National Conference on Artificial Intelligence (AAAI 2004)</i>, pages 336-341, San Jose, CA, July 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952144</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wei Fan, Haixun Wang, Philip S. Yu, and Sheng Ma. Is random model better? on its accuracy and efficiency. In <i>Proceedings of Third IEEE International Conference on Data Mining (ICDM-2003)</i>, Melbourne, FL, Nov 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Jennifer Hoeting, David Madigan, Adrian Raftery, and Chris Volinsky. Bayesian model averaging: A tutorial. <i>Statistical Science</i>, 14:4:382-401, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2140913</ref_obj_id>
				<ref_obj_pid>2140831</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Fei Tony Liu, Kai Ming Ting, and Wei Fan. Maximizing tree diversity by building complete random decision trees. In <i>Proceedings of Nineth Pacific Asian Knowledge Discovery and Data Mining Conference (PAKDD'05)</i>, May 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>541177</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Tom M. Mitchell. <i>Machine Learning</i>. McGraw Hill, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>779926</ref_obj_id>
				<ref_obj_pid>779909</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Foster Provost and Pedro Domingso. Tree induction for probability-based ranking. <i>Machine Learning</i>, pages 199-215, September, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775151</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Bianca Zadronzy and Charles Elkan. Transforming classifier scores into accurate multiclass probability estimates. In <i>Proceedings of Eighth International Conference on Knowledge Discovery and Data Mining (KDD-2002)</i>, Edmonton, Alberta, Canada, August 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106344</article_id>
		<sort_key>162</sort_key>
		<display_label></display_label>
		<pages>162-169</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[A Thorough Experimental Study of Datasets for Frequent Itemsets]]></title>
		<page_from>162</page_from>
		<page_to>169</page_to>
		<doi_number>10.1109/ICDM.2005.15</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106344</url>
		<abstract>
			<par><![CDATA[The discovery of frequent patterns is a famous problem in data mining. While plenty of algorithms have been proposed during the last decade, only a few contributions have tried to understand the influence of datasets on the algorithms behavior. Being able to explain why certain algorithms are likely to perform very well or very poorly on some datasets is still an open question. In this setting, we describe a thorough experimental study of datasets with respect to frequent itemsets. We study the distribution of frequent itemsets with respect to itemsets size together with the distribution of three concise representations: frequent closed, frequent free and frequent essential itemsets. For each of them, we also study the distribution of their positive and negative borders whenever possible. From this analysis, we exhibit a new characterization of datasets and some invariants allowing to better predict the behavior of well known algorithms. The main perspective of this work is to devise adaptive algorithms with respect to dataset characteristics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763022</person_id>
				<author_profile_id><![CDATA[81309513502]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Frederic]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Flouvat]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Laboratoire LIMOS, UMR CNRS and Universit&#233; Clermont-Ferrand II]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044387</person_id>
				<author_profile_id><![CDATA[81100187373]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fabien]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[De Marchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Laboratoire LIRIS, UMR CNRS and Universit&#233; Lyon I]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP27005568</person_id>
				<author_profile_id><![CDATA[81100324952]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jean-Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Petit]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Laboratoire LIRIS, UMR CNRS and INSA Lyon]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Synthetic data generation code for associations and sequential patterns. Intelligent information systems, IBM almaden research center. http://www.almaden.ibm.com/software/quest/resources/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In P. Buneman and S. Jajodia, editors, <i>SIGMOD conference, Washington</i>, pages 207-216. ACM Press, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In J. B. Bocca, M. Jarke, and C. Zaniolo, editors, <i>VLDB conference, Santiago de Chile, Chile</i>, pages 487-499. Morgan Kaufmann, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>381017</ref_obj_id>
				<ref_obj_pid>380995</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Y. Bastide, R. Taouil, N. Pasquier, G. Stumme, and L. Lakhal. Mining frequent patterns with counting inference. In <i>SIGKDD Explorations 2(2)</i>, pages 66-75, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. J. Bayardo, B. Goethals, and M. J. Zaki, editors. <i>FIMI '04, Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations</i>, volume 126 of <i>CEUR Workshop Proceedings</i>. CEUR-WS.org, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1636</ref_obj_id>
				<ref_obj_pid>1634</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Beeri and M. Vardi. A proof procedure for data dependencies. <i>Journal of the ACM</i>, 31(4):718-741, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Borgelt. Efficient implementations of Apriori and Eclat. In <i>FIMI '03, Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations</i>, November 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>608013</ref_obj_id>
				<ref_obj_pid>608006</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J.-F. Boulicaut, A. Bykowski, and C. Rigotti. Free-sets: A condensed representation of boolean data for the approximation of frequency queries. <i>Data Mining and Knowledge Discovery</i>, 7(1):5-22, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Burdick, M. Calimlim, J. Flannick, J. Gehrke, and T. Yiu. MAFIA: A performance study of mining maximal frequent itemsets. In <i>FIMI '03, Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656386</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. Burdick, M. Calimlim, and J. Gehrke. MAFIA: A maximal frequent itemset algorithm for transactional databases. In <i>ICDE conference, Heidelberg, Germany</i>, pages 443-452. IEEE CS, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375604</ref_obj_id>
				<ref_obj_pid>375551</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Bykowski and C. Rigotti. A condensed representation to find frequent patterns. In <i>PODS'01, Santa Barbara, California, USA</i>. ACM, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. Calders and B. Goethals. Minimal <i>k</i>-free representations of frequent sets. In <i>PKDD</i>, pages 71-82, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2130258</ref_obj_id>
				<ref_obj_pid>2130202</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. Casali, R. Cicchetti, and L. Lakhal. Essential patterns: A perfect cover of frequent patterns. In <i>DaWaK conference, Copenhagen, Denmark</i>, Lecture Notes in Computer Science, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[M. Casanova, R. Fagin, and C. Papadimitriou. Inclusion dependencies and their interaction with functional dependencies. <i>Journal of Computer and System Sciences</i>, 24(1):29- 59, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952179</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[F. De Marchi and J.-M. Petit. Zigzag: a new algorithm for discovering large inclusion dependencies in relational databases. In <i>ICDM conference, Melbourne, USA</i>, pages 27-34. IEEE Computer Society, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[F. Flouvat. Experimental study of frequent itemsets datasets. Technical report, LIMOS, France, http://www.isima.fr/flouvat/papers/rr05- ExpStudyDatasets.pdf, june 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[F. Flouvat, F. De Marchi, and J.-M. Petit. ABS: Adaptive borders search of frequent itemsets. In <i>FIMI '04, Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[B. Goethals. Frequent itemset mining implementations repository, http://fimi.cs.helsinki.fi/, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[B. Goethals and M. J. Zaki, editors. <i>FIMI '03, Proceedings of the ICDM 2003 Workshop on Frequent Itemset Mining Implementations, 19 December 2003, Melbourne, Florida, USA</i>, volume 90 of <i>CEUR Workshop Proceedings</i>. CEURWS.org, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658047</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[K. Gouda and M. J. Zaki. Efficiently mining maximal frequent itemsets. In N. Cercone, T. Y. Lin, and X. Wu, editors, <i>ICDM conference, San Jose, USA</i>, pages 163-170. IEEE Computer Society, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[G. Grahne and J. Zhu. Efficiently using prefix-trees in mining frequent itemsets. In <i>FIMI'03, Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations</i>, November 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>SIGMOD Conference</i>, pages 1-12, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[M. Kantola, H. Mannila, K. J. Rih, and H. Siirtola. Discovering functional and inclusion dependencies in relational databases. <i>International Journal of Intelligent Systems</i>, 7:591-607, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[A. Koeller and E. A. Rundensteiner. Discovery of high-dimentional inclusion dependencies (poster). In <i>Poster session of ICDE conference</i>. IEEE Computer Society, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>693818</ref_obj_id>
				<ref_obj_pid>646420</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[M. Kryszkiewicz and M. Gajek. Concise representation of frequent patterns based on generalized disjunction-free generators. In <i>PAKDD'02, Taipei, Taiwan</i>, volume 2336 of <i>Lecture Notes in Computer Science</i>, pages 159-171. Springer, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[G. Liu, H. Lu, J. X. Yu, W. Wei, and X. Xiao. AFOPT: An efficient implementation of pattern growth approach. In <i>FIMI '03, Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>773181</ref_obj_id>
				<ref_obj_pid>773153</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[W. A. Maniatty, G. Ramesh, and M. J. Zaki. Feasible itemset distributions in data mining: Theory and application. In <i>SIGMOD conference, San Diego, USA</i>, pages 284-295. ACM, June 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and K. J. R&#228;ih&auml. <i>The Design of Relational Databases</i>. Addison-Wesley, second edition, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and H. Toivonen. Multiple uses of frequent sets and condensed representations (extended abstract). In <i>KDD conference, Portland, USA</i>, pages 189-194. AAAI Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593448</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and H. Toivonen. Levelwise Search and Borders of Theories in Knowledge Discovery. <i>Data Mining and Knowledge Discovery</i>, 1(1):241-258, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[S. Orlando, C. Lucchese, P. Palmerini, R. Perego, and F. Silvestri. kDCI: a multi-strategy algorithm for mining frequent sets. In <i>FIMI '03, Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations</i>, November 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>968009</ref_obj_id>
				<ref_obj_pid>967900</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[P. Palmerini, S. Orlando, and R. Perego. Statistical properties of transactional databases. In <i>ACM symposium on Applied computing</i>, pages 515-519, New York, USA, 2004. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>310660</ref_obj_id>
				<ref_obj_pid>310657</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Efficient mining of association rules using closed item set lattices. <i>Information Systems</i>, 24(1):25-46, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and R. Mao. Closet: An efficient algorithm for mining frequent closed itemsets. In <i>SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery</i>, pages 21-30, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[T. Uno, T. Asai, Y. Uchida, and H. Arimura. LCM: An efficient algorithm for enumerating frequent closed item sets. In <i>FIMI '03, Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations</i>, November 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[T. Uno, M. Kiyomi, and H. Arimura. LCM ver. 2: Efficient mining algorithms for frequent/closed/maximal itemsets. In <i>FIMI '04, Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1054148</ref_obj_id>
				<ref_obj_pid>1053724</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[O. R. Za&#239;ane, M. El-Hajj, Y. Li, and S. Luk. Scrutinizing frequent pattern discovery performance. In <i>ICDE</i>, pages 1109- 1110, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki and C.-J. Hsiao. Charm: An efficient algorithm for closed itemset mining. In <i>SIAM International Conference on Data Mining</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106345</article_id>
		<sort_key>170</sort_key>
		<display_label></display_label>
		<pages>170-177</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[AMIOT]]></title>
		<subtitle><![CDATA[Induced Ordered Tree Mining in Tree-Structured Databases]]></subtitle>
		<page_from>170</page_from>
		<page_to>177</page_to>
		<doi_number>10.1109/ICDM.2005.20</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106345</url>
		<abstract>
			<par><![CDATA[Frequent subtree mining has become increasingly important in recent years. In this paper, we present AMIOT algorithm to discover all frequent ordered subtrees in a tree-structured database. In order to avoid the generation of infrequent candidate trees, we propose the techniques such as right-and-left tree join and serial tree extension. Proposed methods enumerate only the candidate trees with high probability of being frequent without any duplications. The experiments on synthetic dataset and XML database show that AMIOT reduces redundant candidate trees and outperforms FREQT algorithm by up to five times in execution time.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Trees</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003634</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763151</person_id>
				<author_profile_id><![CDATA[81414611778]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shohei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hido]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kyoto University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042727</person_id>
				<author_profile_id><![CDATA[81100121679]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hiroyuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Nanzan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proceedings of the 20th International Conference on Very Large Data Bases (VLDB'94)</i>, pages 487- 499, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Apache. Xindice. http://xml.apache.org/xindice, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Asai, K. Abe, S. Kawasoe, H. Arimura, H. Sakamoto, and S. Arikawa. Efficient substructure discovery from large semi-structured data. In <i>Proceedings of the 2nd SIAM International Conference on Data Mining (SDM'02)</i>, pages 158- 174, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Asai and H. Arimura. Algorithms for mining semistructured data. <i>IEICE Journal</i>, J87-D1(2):79-96, 2004. (in Japanese).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276313</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. J. Bayardo Jr. Efficiently mining long patterns from databases. In <i>Proceedings of the International Conference on Management of data (ACM SIGMOD'98)</i>, pages 85-93, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007091</ref_obj_id>
				<ref_obj_pid>998688</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Chi, Y. Yang, and R. R. Muntz. Hybridtreeminer: An efficient algorithm for mining frequent rooted trees and free trees using canonical form. In <i>Proceedings of the 16th International Conference on Scientific and Statistical Database Management (SSDBM'04)</i>, pages 11-20, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>Proceedings of the 2000 International Conference on Management of Data (ACM SIGMOD'00) </i>, pages 1-12, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Hido and H. Kawano. Proposal of efficient enumeration method for frequent ordered subtree discovery. <i>DBSJ Letters</i>, 4(1):161-164, 2005. (in Japanese).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[IBM alphaWorks. ToXgene - the ToX XML Data Generator. http://www.alphaworks.ibm.com/tech/toxgene, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669817</ref_obj_id>
				<ref_obj_pid>645804</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. Inokuchi, T. Washio, and H. Motoda. An apriori-based algorithm for mining frequent substructures from graph data. In <i>Proceedings of the 4th European Conference on Principles of Data Mining and Knowledge Discovery (PKDD'00)</i>, pages 13-23, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Inokuchi, T. Washio, and H. Motoda. Applying the apriori-based graph mining method to mutagenesis data analysis. <i>Computer Aided Chemistry</i>, 2:87-92, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. Kudo and Y. Matsumoto. A boosting algorithm for classification of semi-structured text. In <i>Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP'04)</i>, pages 301-308, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. Nijssen. Frequent structure mining: Efficiency issues. In <i>the 2nd International Workshop on Mining Graphs, Trees and Sequences (MGTS'04)</i>, 2004. http://hms.liacs.nl/mgts2004/mgts-intro.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. R. Punin, M. S. Krishnamoorthy, and M. J. Zaki. Web usage mining: Languages and algorithms. Technical Report 03-1, Rensselaer Polytechnic Institute, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[C. Wang, M. Hong, J. Pei, H. Zhou, W. Wang, and B. Shi. Efficient pattern-growth methods for frequent tree pattern mining. In <i>Proceedings of the 8th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining (PAKDD'04)</i>, pages 441-451, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775058</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Efficiently mining frequent trees in a forest. In <i>Proceedings of the 8th International Conference on Knowledge Discovery and Data Mining (ACM SIGKDD'02)</i>, pages 71-80, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106346</article_id>
		<sort_key>178</sort_key>
		<display_label></display_label>
		<pages>178-185</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Hierarchy-Regularized Latent Semantic Indexing]]></title>
		<page_from>178</page_from>
		<page_to>185</page_to>
		<doi_number>10.1109/ICDM.2005.76</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106346</url>
		<abstract>
			<par><![CDATA[Organizing textual documents into a hierarchical taxonomy is a common practice in knowledge management. Beside textual features, the hierarchical structure of directories reflect additional and important knowledge annotated by experts. It is generally desired to incorporate this information into text mining processes. In this paper, we propose hierarchy-regularized latent semantic indexing, which encodes the hierarchy into a similarity graph of documents and then formulates an optimization problem mapping each document into a low dimensional vector space. The new feature space preserves the intrinsic structure of the original taxonomy and thus provides a meaningful basis for various learning tasks like visualization and classification. Our approach employs the information about class proximity and class specificity, and can naturally cope with multi-labeled documents. Our empirical studies show very encouraging results on two real-world data sets, the new Reuters (RCV1) benchmark and the Swissprot protein database.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Representations (procedural and rule-based)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010314</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Rule learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044144</person_id>
				<author_profile_id><![CDATA[81388600745]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040995</person_id>
				<author_profile_id><![CDATA[81100471660]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Siemens Corporate Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044469</person_id>
				<author_profile_id><![CDATA[81339526780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Matthias]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schubert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044810</person_id>
				<author_profile_id><![CDATA[81100473562]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Shipeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045510</person_id>
				<author_profile_id><![CDATA[81100337356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Volker]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tresp]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Siemens Corporate Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15034628</person_id>
				<author_profile_id><![CDATA[81100512920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kriegel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[H. Blockeel, M. Bruynooghe, S. Dzeroski, J. Ramon, and J. Struyf. Hierarchical mult-classification. In <i>MRDM Workshop on Multirelational data mining at SIGKDD'02, Edmonton, Canada</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. Boeckmann, A. Bairoch, R. Apweiler, M.-C. Blatter, A. Estreicher, E. Gasteiger, M. Martin, K. Michoud, C. O'Donovan, I. Phan, S. Pilbout, and M. Schneider. "The SWISS-PROT Protein Knowledgebase and its Supplement TrEMBL in 2003". <i>Nucleic Acid Research</i>, 31:365-370, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1031186</ref_obj_id>
				<ref_obj_pid>1031171</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Cai and T. Hofmann. Hierarchical document categorization with support vector machines. In <i>Proc. 13th Conf. on Information and Knowledge Management (CIKM'04), Washington D.C., USA</i>, pages 78-87, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[N. Cesa-Bianchi, C. Gentile, A. Tironi, and L. Zaniboni. Incremental algorithms for hierarchical classification. In <i>Proc. 8th ann. Conf. on Neural Information Processing Systems, Vancouver, BC, Canada</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. G. O. Consortium. "Gene Ontology: Tool for the Unification of Biology". <i>Nature Genetics</i>, 25:25-29, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. C. Deerwester, S. T. Dumais, T. K. Landauer, G. W. Furnas, and R. A. Harshman. Indexing by latent semantic analysis. <i>Journal of the American Society of Information Science</i>, 41(6):391-407, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015374</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[O. Dekel, J. Keshnet, and Y. Singer. Large margin hierarchical classification. In <i>Proc. 21th International Conf. on Machine Learning (ICML'04), Banff, Canada</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345593</ref_obj_id>
				<ref_obj_pid>345508</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Dumais and H. Chen. "Hierarchical Classification of Web Content". In <i>Proc. 23rd Int. Conf. on Research and Development in Information Retrieval (SIGIR'00)</i>, pages 256-263, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. R. Hardoon, S. Szedmak, and J. Shawe-Taylor. Canonical correlation analysis; an overview with application to learning methods. Technical Report CSD-TR-03-02, Royal Holloway University of London, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[H. Hotelling. Relations between two sets of variables. <i>Biometrika</i>, 28:321-377, 1936.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649721</ref_obj_id>
				<ref_obj_pid>645326</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. Text categorization with support vector machine: learning with many relevant features. In <i>Proceeding of (ECML)-98, 10th European Conference on Machine Learning</i>, pages 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>324140</ref_obj_id>
				<ref_obj_pid>324133</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. M. Kleinberg. Authoritative sources in a hyperlinked environment. <i>J. ACM</i>, 46(5):604-632, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657130</ref_obj_id>
				<ref_obj_pid>645526</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[D. Koller and M. Sahami. Hierarchically classifying documents using very few words. In <i>Proc. 14th Int. Conf. on Machine Learning (ICML'97), Nashville, TN</i>, pages 170-178, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657461</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. McCallum, R. Rosenfeld, T. Mitchell, and A. Ng. "Improving Text Classification by Shrinkage in a Hierarchy of Classes". In <i>Proc. 15th Int. Conf. on Machine Learning (ICML'98), Madison, WI</i>, pages 359-367, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. Rousu, C. Saunder, S. Szedmak, and J. Shawe-Taylor. On maximum margin hierarchical mulitlabel classification. In <i>Proc. of Workshop on Learning with Structured Outputs at NIPS 2004, Whistler, Canada</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299113</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[B. Sch&#246;lkopf, A. Smola, and K.-R. M&#252;ller. Kernel principal component analysis. In <i>Advances in Kernel Methods - Support Vector Learning</i>, pages 327-352, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>794502</ref_obj_id>
				<ref_obj_pid>794189</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. Shi and J. Malik. Normalized cuts and image segmentation. In <i>IEEE Conf. Computer Vision and Pattern Recognition (CVPR)</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[H. Wold. Partial least squares. <i>Encyclopedia of the Statistical Sciences</i>, pages 581-591, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312647</ref_obj_id>
				<ref_obj_pid>312624</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Y. Yang and X. Liu. A re-examination of text categorization methods. In <i>The 22th Annual International SIGIR Conference (SIGIR'99)</i>, pages 42-49, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657137</ref_obj_id>
				<ref_obj_pid>645526</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Y. Yang and J. O. Pedersen. A comparative study on feature selection in text categorization. In D. H. Fisher, editor, <i>Proc. 14th International Conference on Machine Learning (ICML'97)</i>, pages 412-420, Nashville, US, 1997. Morgan Kaufmann Publishers, San Francisco, US.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>860471</ref_obj_id>
				<ref_obj_pid>860435</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. Zhang and Y. Yang. Robustness of regularized linear classifcation methods in text categorization. In <i>The 26th Annual International SIGIR Conference (SIGIR'99)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>594015</ref_obj_id>
				<ref_obj_pid>593962</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[T. Zhang and F. J. Oles. Text categorization based on regularized linear classification methods. <i>Information Retrieval</i>, (4):5-31, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106347</article_id>
		<sort_key>186</sort_key>
		<display_label></display_label>
		<pages>186-193</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Extracting Frequent Subsequences from a Single Long Data Sequence]]></title>
		<subtitle><![CDATA[A Novel Anti-Monotonic Measure and a Simple On-Line Algorithm]]></subtitle>
		<page_from>186</page_from>
		<page_to>193</page_to>
		<doi_number>10.1109/ICDM.2005.60</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106347</url>
		<abstract>
			<par><![CDATA[In this paper, we study frequent-subsequence extraction from a single very-long data-sequence. First we propose a novel frequency measure, called the total frequency, for counting multiple occurrences of a sequential pattern in a single data sequence. The total frequency is anti-monotonic, and makes it possible to count up pattern occurrences without duplication. Moreover the total frequency has a good property for implementation based on the dynamic programming strategy. Second we give a simple on-line algorithm for a specialized subsequence extraction problem, i.e., a problem with the infinite window-length. This specialized problem is considered to be a relaxation of the general-case problem, thus this fast on-line algorithm is important from the view of practical applications.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Dynamic programming</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>F.1.2</cat_node>
				<descriptor>Online computation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10003809.10011254.10011258</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Algorithm design techniques->Dynamic programming</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003759</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Interactive computation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010047.10010048</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Online algorithms->Online learning algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010079</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Online learning theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15041214</person_id>
				<author_profile_id><![CDATA[81100225209]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Koji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Iwanuma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Yamanashi]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763140</person_id>
				<author_profile_id><![CDATA[81309511515]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ryuichi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ishihara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Yamanashi]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763180</person_id>
				<author_profile_id><![CDATA[81309483880]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Yamanashi]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044374</person_id>
				<author_profile_id><![CDATA[81100376444]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hidetomo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nabeshima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Yamanashi]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant: Mining Sequential Patterns, <i>Proc. 1995 Int. Conf. on Data Engineering (ICDE'95)</i>, pp. 3-14 (1995).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant: Mining sequential patterns: Generalizations and performance improvements. In <i>Proc. 1996 Int. Conf. on Data Engineering (ICDE'96)</i>. pp. 3-17, (1996).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>586959</ref_obj_id>
				<ref_obj_pid>586845</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Datar, A. Gionis, P. Indyk and R. Motwani: Maintaining stream statistics over sliding windows, <i>SIAM J. Comut.</i>, Vol.31, pp. 167-182, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1072313</ref_obj_id>
				<ref_obj_pid>1072228</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[F. Fukumoto and Y. Suzuki: Detecting Shifts in News Stories for Paragraph Extraction. <i>Proc. the 19th Inter. Conf. on Computational Linguistics (COLING'02)</i>, pp. 280-286 (2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[K-Y. Huang and C-H. Chang: Asynchronous Periodic Patterns Mining in Temporal Databases. <i>Proc. IASTED Inter. Conf. on Databases and Applications</i>, pp. 43-48 (2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>762473</ref_obj_id>
				<ref_obj_pid>762471</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R.M. Karp, S. Shenker and C.H. Papadimitriou: A Simple Algorithm for finding frequent elements in streams and bags, <i>ACM Trans. Database Syst.</i>, Vol.28, pp. 51- 55, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Nakamura, K. Iwanuma and H. Nabeshima: Detecting Two Sorts of Correspondences between HTML Documents for Extracting Temporal Differences. <i>Proc. the 3rd IASTED Inter. Conf. on Artif. Intel. and Applications</i>, pp. 611-616 (2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287400</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[G.S. Manku and R. Motwani: Approximate Frequency Counts over Data Streams, <i>Proc. of KDD-95</i>, pp. 356- 357, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and H. Toivonen: <i>Knowledge Discovery in Databases: The Search for Frequent Patterns</i>, URL://www.cs.helsinki.fi/u/htoivone/teaching/timuS02/b.ps]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656379</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, U. Dayal and M-C. Hsu: PrefixSpan: Mining Sequential Patterns Efficiently by Prefix-Projected Pattern Growth. <i>Proc. Int. 2001 Conf. on Data Engineering (ICDE'01)</i>, pp. 215-224 (2001).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347150</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Yang, W. Wang and P. S. Yu: Mining Asynchronous Periodic Patterns in Time Series Data. <i>Proc. 6th ACM SIGKDD</i>, pp. 275-279 (2000).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288643</ref_obj_id>
				<ref_obj_pid>288627</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki: Efficient Enumeration of Frequent Sequences. <i>Proc. the 7th Inter. Conf. on Information and Knowledge Management (CIKM'98), pp. 68-75 (1998)</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106348</article_id>
		<sort_key>194</sort_key>
		<display_label></display_label>
		<pages>194-201</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[Mining Minimal Distinguishing Subsequence Patterns with Gap Constraints]]></title>
		<page_from>194</page_from>
		<page_to>201</page_to>
		<doi_number>10.1109/ICDM.2005.96</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106348</url>
		<abstract>
			<par><![CDATA[Discovering contrasts between collections of data is an important task in data mining. In this paper, we introduce a new type of contrast pattern, called a Minimal Distinguishing Subsequence (MDS). An MDS is a minimal subsequence that occurs frequently in one class of sequences and infrequently in sequences of another class. It is a natural way of representing strong and succinct contrast information between two sequential datasets and can be useful in applications such as protein comparison, document comparison and building sequential classification models. Mining MDS patterns is a challenging task and is significantly different from mining contrasts between relational/transactional data. One particularly important type of constraint that can be integrated into the mining process is the maximum gap constraint. We present an efficient algorithm called ConSGapMiner, to mine all MDSs according to a maximum gap constraint. It employs highly efficient bitset and boolean operations, for powerful gap based pruning within a prefix growth framework. A performance evaluation with both sparse and dense datasets, demonstrates the scalability of ConSGapMiner and shows its ability to mine patterns from high dimensional datasets at low supports.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Structural</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763177</person_id>
				<author_profile_id><![CDATA[81309507755]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiaonan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ji]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Melbourne]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043993</person_id>
				<author_profile_id><![CDATA[81100616144]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bailey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Melbourne]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43123573</person_id>
				<author_profile_id><![CDATA[81451593259]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Guozhu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Wright State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>775109</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Ayres, J. Flannick, J. Gehrke, and T. Yiu. Sequential pattern mining using a bitmap representation. In <i>KDD</i>, pages 429-435, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593515</ref_obj_id>
				<ref_obj_pid>593430</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. D. Bay and M. J. Pazzani. Detecting group differences: Mining contrast sets. <i>Data Mining and Knowledge Discovery</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gemma Casas-Garriga. Discovering unbounded episodes in sequential data. In <i>PKDD</i>, pages 83-94, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>789249</ref_obj_id>
				<ref_obj_pid>789081</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sarah Chan, Ben Kao, Chi Lap Yip, and Michael Tang. Mining emerging substrings. In <i>DASFAA</i>, pages 119-, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312191</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Dong and J. Li. Efficient mining of emerging patterns: Discovering trends and differences. In <i>KDD</i>, pages 43-52, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>763067</ref_obj_id>
				<ref_obj_pid>763058</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Hirao, H. Hoshino, A. Shinohara, M. Takeda, and S. Arikawa. A practical algorithm to find the best subsequence patterns. <i>Theor. Comput. Sci.</i>, 292(2):465-479, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>630534</ref_obj_id>
				<ref_obj_pid>630311</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[N. Lesh, M. Zaki, and M. Ogihara. Scalable feature mining for sequential data. <i>IEEE Intelligent Systems</i>, 15(2):48-56, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545309</ref_obj_id>
				<ref_obj_pid>545308</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Li, G. Dong, and K. Ramamohanarao. Making use of the most expressive jumping emerging patterns for classification. <i>Knowl. Inf. Syst.</i>, 3(2):131-145, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1053102</ref_obj_id>
				<ref_obj_pid>1053072</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Nicolas M&#233;ger and Christophe Rigotti. Constraint-based mining of episode rules and optimal window sizes. In <i>PKDD</i>, pages 313-324, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[G. Narasimhan, C. Bu, Y. Gao, X. Wang, N. Xu, and K. Mathee. Mining protein sequences for motifs. <i>Journal of Computational Biology</i>, 9(5):707-720, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1025077</ref_obj_id>
				<ref_obj_pid>1024872</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, B. Mortazavi-Asl, H. Wang, J. Pinto, Q. Chen, U. Dayal, and M. Hsu. Mining sequential patterns by pattern-growth: The prefixspan approach. <i>IEEE TKDE</i>, 16(10), 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956800</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. She, F. Chen, K. Wang, M. Ester, J. L. Gardy, and F. Brinkman. Frequent-subsequence-based prediction of outer membrane proteins. In <i>KDD</i>, pages 436-445, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>978142</ref_obj_id>
				<ref_obj_pid>977401</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Jianyong Wang and Jiawei Han. Bide: Efficient mining of frequent closed sequences. In <i>ICDE</i>, pages 79-90, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956781</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[G. I. Webb, S. Butler, and D. Newlands. On detecting differences between groups. In <i>Proceedings of KDD</i>, pages 256- 265, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[X. Yan, J. Han, and R. Afshar. Clospan: Mining closed sequential patterns in large databases. In <i>SDM</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>354849</ref_obj_id>
				<ref_obj_pid>354756</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. Zaki. Sequence mining in categorical domains: Incorporating constraints. In <i>CIKM</i>, pages 422-429, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>370671</ref_obj_id>
				<ref_obj_pid>370660</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[M. Zaki. Spade: An efficient algorithm for mining frequent sequences. <i>Machine Learning</i>, 42(1/2):31-60, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106349</article_id>
		<sort_key>202</sort_key>
		<display_label></display_label>
		<pages>202-209</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Learning Instance Greedily Cloning Naive Bayes for Ranking]]></title>
		<page_from>202</page_from>
		<page_to>209</page_to>
		<doi_number>10.1109/ICDM.2005.87</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106349</url>
		<abstract>
			<par><![CDATA[Naive Bayes (simply NB) [12] has been widely used in machine learning and data mining as a simple and effective classification algorithm. Since its conditional independence assumption is rarely true, researchers have made a substantial amount of effort to improve naive Bayes. The related research work can be broadly divided into two approaches: eager learning and lazy learning, depending on when the major computation occurs. Different from eager approach, the key idea for extending naive Bayes from the lazy approach is to learn a naive Bayes for each testing example. In recent years, some lazy extensions of naive Bayes have been proposed. For example, SNNB [18], LWNB [7], and LBR [19]. All are aiming at improving the classification accuracy of naive Bayes. In many real-world machine learning and data mining applications, however, an accurate ranking is more desirable than an accurate classification. Responding to this fact, we present a lazy learning algorithm called instance greedily cloning naive Bayes (simply IGCNB) in this paper. Our motivation is to improve naive Bayes' ranking performance measured by AUC [4, 14]. We experimentally tested our algorithm, using the whole 36 UCI datasets recommended by Weka [1], and compared it to C4.4 [16], NB [12], SNNB [18] and LWNB [7]. The experimental results show that our algorithm outperforms all the other algorithms used to compare significantly in yielding accurate ranking.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39053324</person_id>
				<author_profile_id><![CDATA[81339507504]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Liangxiao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[China University of Geosciences]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043492</person_id>
				<author_profile_id><![CDATA[81100120645]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Harry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of New Brunswick]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[http://prdownloads.sourceforge.net/weka/datasets-uci.jar.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>273530</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Aha. Lazy learning. Norwell, MA: Kluwer Academic Publishers, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. N. Bennett. Assessing the calibration of naive bayes' posterior estimates. Technical Report CMU-CS-00-155, Carnegie Mellon University, School of Computer Science, Pittsburgh, PA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1746434</ref_obj_id>
				<ref_obj_pid>1746432</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. P. Bradley. The use of the area under the ROC curve in the evaluation of machine learning algorithms. <i>Pattern Recognition</i>, 30:1145-1159, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. M. Chickering. Learning bayesian networks is np-complete. In D. Fisher and H. Lenz, editors, <i>Learning from Data: Artificial Intelligence and Statistics V</i>, pages 121- 130. Springer-Verlag, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274160</ref_obj_id>
				<ref_obj_pid>274158</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. M. Domingos, P. Beyond independence: Conditions for the optimality of the simple bayesian classifier. <i>Machine Learning</i>, 29:103-130, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2100614</ref_obj_id>
				<ref_obj_pid>2100584</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[H. M. P. B. Frank, E. Locally weighted naive bayes. In <i>Proceedings of the Conference on Uncertainty in Artificial Intelligence</i>, pages 249-256. Morgan Kaufmann, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274161</ref_obj_id>
				<ref_obj_pid>274158</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[N. Friedman, D. Geiger, and M. Goldszmidt. Bayesian network classifiers. <i>Machine Learning</i>, 29:131-163, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>513543</ref_obj_id>
				<ref_obj_pid>513540</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. J. Hand and R. J. Till. A simple generalisation of the area under the ROC curve for multiple class classification problems. <i>Machine Learning</i>, 45:171-186, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2147171</ref_obj_id>
				<ref_obj_pid>2147137</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Z. H. S. J. Jiang, L. Instance cloning local naive bayes. In <i>Proceedings of the Eighteenth Canadian Conference on Artificial Intelligence</i>, pages 280-291. Springer, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R. Kohavi. Scaling up the accuracy of naive-bayes classifiers: A decision-tree hybrid. In <i>Proceedings of the Second International Conference on Knowledge Discovery and Data Mining</i>, pages 202-207. AAAI Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[P. Langley, W. Iba, and K. Thomas. An analysis of bayesian classifiers. In <i>Proceedings of the Tenth National Conference of Artificial Intelligence</i>, pages 223-228. AAAI Press, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[P. Langley and S. Sage. Induction of selective bayesian classifiers. In <i>Proceedings of Uncertainty in Artificial Intelligence</i>, pages 400-406. Morgan Kaufmann, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[F. Provost and T. Fawcett. Analysis and visualization of classifier performance: comparison under imprecise class and cost distribution. In <i>Proceedings of the Third International Conference on Knowledge Discovery and Data Mining</i>, pages 43-48. AAAI Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657469</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[F. Provost, T. Fawcett, and R. Kohavi. The case against accuracy estimation for comparing induction algorithms. In <i>Proceedings of the Fifteenth International Conference on Machine Learning</i>, pages 445-453. Morgan Kaufmann, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>779926</ref_obj_id>
				<ref_obj_pid>779909</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[F. J. Provost and P. Domingos. Tree induction for probability-based ranking. <i>Machine Learning</i>, 52:199-215, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323651</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[I. H. Witten and E. Frank. <i>Data Mining-Practical Machine Learning Tools and Techniques with Java Implementation</i>. Morgan Kaufmann, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>693808</ref_obj_id>
				<ref_obj_pid>646420</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[H. W. L. Z. L. M. Xie, Z. SNNB: A selective neighborhood based naive bayes for lazy learning. In <i>Proceedings of the Sixth Pacific-Asia Conference on KDD</i>, pages 104-114. Springer, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360550</ref_obj_id>
				<ref_obj_pid>360540</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[W. G. I. Zheng, Z. Lazy learning of bayesian rules. <i>Machine Learning</i>, 41:53-84, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106350</article_id>
		<sort_key>210</sort_key>
		<display_label></display_label>
		<pages>210-217</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[An Algorithm for In-Core Frequent Itemset Mining on Streaming Data]]></title>
		<page_from>210</page_from>
		<page_to>217</page_to>
		<doi_number>10.1109/ICDM.2005.21</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106350</url>
		<abstract>
			<par><![CDATA[Frequent itemset mining is a core data mining operation and has been extensively studied over the last decade. This paper takes a new approach for this problem and makes two major contributions. First, we present a one pass algorithm for frequent itemset mining, which has deterministic bounds on the accuracy, and does not require any out-of-core summary structure. Second, because our one pass algorithm does not produce any false negatives, it can be easily extended to a two pass accurate algorithm. Our two pass algorithm is very memory efficient, and allows mining of datasets with large number of distinct items and/or very low support levels. Our detailed experimental evaluation on synthetic and real datasets shows the following. First, our one pass algorithm is very accurate in practice. Second, our algorithm requires significantly lower memory than Manku and Motwani's one pass algorithm and the multi-pass Apriori algorithm. Our two pass algorithm outperforms Apriori and FP-tree when the number of distinct items is large and/or support levels are very low. In other cases, it is quite competitive, with possible exception of cases where the average length of frequent itemsets is quite high.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P347521</person_id>
				<author_profile_id><![CDATA[81100054574]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ruoming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Kent State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P93478</person_id>
				<author_profile_id><![CDATA[81100288827]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gagan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Agrawal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>257975</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, H. Mannila, R. Srikant, H. Toivonent, and A. Inkeri verkamo, Fast discovery of assocation rules. In U. Fayyad and et al, editors. <i>Advances in Knowledge Discovery and Data Mining</i>, pages 307-328. AAAI Press, Menlo Park, CA. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. 1994 Int. conf. very Large DataBases (VLDB'94)</i>, pages 487-499, Santiago, Chile, September 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>543615</ref_obj_id>
				<ref_obj_pid>543613</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B. Babcock, S. Babu, M. Datar, R. Motwani, and J. Widom. Models and Issues in Data Stream Systems. In <i>Proceedings of the 2002 ACM Symposium on Principles of Database Systems (PODS 2002) (Invited Paper)</i>. ACM Press, June 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Christan Borgelt. Apriori implementation. http://fuzzy.cs.Uni-Magdeburg.de/borgelt/Software. Version 4.08.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033437</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Yun Chi, Haixun Wang. Philip Yu, and Richard Muntz. Moment: Maintaining Closed Frequent Itemsets over a Stream Sliding Window. In <i>Internationl Conference on Data Mining (ICDM)</i>, November 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956766</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Mohammad El-Haji and Osmar R. Zaiane. lnverted Matrix: Efficient Discovery of Frequent Items in Large Datasets in the Context of Interactive Mining. In <i>Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining</i>. ACM Press, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Giannella. Jiawei Han, Jian Pei, Xifeng Yan, and P. S. Yu. Mining Frequent Patterns in Data Streams at Multiple Time Granularities. In <i>Proceedings of the NSF Workshop on Next Generation Data Mining</i>, November 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bart Goethals. Fp-tree implementation. http://www.cs.helsinki.fi/u/goethals/software/index.html. Version Last Updated April 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Bart Goethals and Mohammed J. Zaki. Workshop Report on Workshop on Frequent Itemset Mining Implementations (FIMI). 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628064</ref_obj_id>
				<ref_obj_pid>627328</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E-H. Han, G. Karypis, and V. Kumar, Scalable parallel datamining for association rules. <i>IEEE Transactions on Data and Knowledge Engineering</i>, 12(3), May/June 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Nan, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>Proceedings of the ACM SIGMOD Conference on Management of Data</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304195</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[C. Hidber. Online Association Rule Mining. In <i>Proceedings of ACM SIGMOD Conference on Management of Data</i>, pages 145-156. ACM Press. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Ruoming Jin and Gagan Agrawal, An algorithm for in-core frequent itemset mining on streaming data. Technical Report OSU-CISRC-2/04-TR14, Ohio State University, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Richard M. Karp. Christos H. Papadimitrious, and Scott Shanker. A Simple Algorithm for Finding Frequent Elements in Streams and Bags. Available from http://www.cs.berkeIey.edu/christos/iceberg.ps, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287400</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[G. S. Manku and R. Motwani. Approximate Frequency Counts Over Data Streams. In <i>Proceedings of Conference on Very Large DataBases (VLDB)</i>, pages 346 -357, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223813</ref_obj_id>
				<ref_obj_pid>223784</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J. S. Park, M. Chen, and P. S. Yu. An effecitive hash based algorithm for mining association rules. In <i>ACM SIGMOD Intl. Conf. Management of Data</i>, May 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673300</ref_obj_id>
				<ref_obj_pid>645921</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[A. Savasere, E. Omiecinski, and S. Navathe. An efficient algorithm for mining association rulcs in large database. In <i>21th VLDD Conf.</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673325</ref_obj_id>
				<ref_obj_pid>645922</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[H. Toivonen. Sampling large databases for association rules. In <i>Proc. of the 22nd VLDM Cnnference.</i>, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1316709</ref_obj_id>
				<ref_obj_pid>1316689</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Jeffrey Xu Yu, Zhihong Chong, Hongjun Lu, and Aoying Zhou. False positive or false negative: Mining frequent itemsets from high speed transactional data streams. In <i>Proceedings of the 28th International Conference on Very Large Data Bases (VLDB)</i>, Toronto, Canada, Aug 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki, S. Parthasarathy, M Ogihara, and W. Li. New algorithms for fast discovery of association rules. In <i>3rd Intl. Conf. on Knowlegbe Discovery, and Data Mining.</i>, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614183</ref_obj_id>
				<ref_obj_pid>614067</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Mohammed J. Zaki. Parallel and distributed association mining: A survey. <i>IEEE Concurrency</i>, 7(4):14-25, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502572</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Z. Zheng, R. Kohavi, and L. Mason. Real World Performance of Association Rule Algorithms. In <i>Proceedings of the ACM SIGKDD Conference on Knowledge. Discovery and Data Mining</i>, pages 401-406. ACM Press, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106351</article_id>
		<sort_key>218</sort_key>
		<display_label></display_label>
		<pages>218-225</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[Stability of Feature Selection Algorithms]]></title>
		<page_from>218</page_from>
		<page_to>225</page_to>
		<doi_number>10.1109/ICDM.2005.135</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106351</url>
		<abstract>
			<par><![CDATA[With the proliferation of extremely high-dimensional data, feature selection algorithms have become indispensable components of the learning process. Strangely, despite extensive work on the stability of learning algorithms, the stability of feature selection algorithms has been relatively neglected. This study is an attempt to fill that gap by quantifying the sensitivity of feature selection algorithms to variations in the training set. We assess the stability of feature selection algorithms based on the stability of the feature preferences that they express in the form of weights-scores, ranks, or a selected feature subset. We examine a number of measures to quantify the stability of feature preferences and propose an empirical way to estimate them. We perform a series of experiments with several feature selection algorithms on a set of proteomics datasets. The experiments allow us to explore the merits of each stability measure and create stability profiles of the feature selection algorithms. Finally we show how stability profiles can support the choice of a feature selection algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15043671</person_id>
				<author_profile_id><![CDATA[81100543229]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexandros]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kalousis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Geneva]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043344</person_id>
				<author_profile_id><![CDATA[81100092623]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Julien]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Prados]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Geneva]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043976</person_id>
				<author_profile_id><![CDATA[81100590549]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Melanie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hilario]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Geneva]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>657784</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[P. Domingos. A unified bias-variance decomposition and its applications. In P. Langley, editor, <i>Proceedings of the Seventeenth International Conference on Machine Learning</i>, pages 231-238. Morgan Kaufmann, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Duda, P. Hart, and D. Stork. <i>Pattern Classification and Scene Analysis</i>. John Willey and Sons, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[U. Fayyad and K. Irani. Multi-interval discretization of continuous attributes as preprocessing for classification learning. In R. Bajcsy, editor, <i>Proceedings of the 13th International Joint Conference on Artificial Intelligence</i>, pages 1022-1027. Morgan Kaufmann, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148062</ref_obj_id>
				<ref_obj_pid>148061</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Geman, E. Bienenstock, and R. Doursat. Neural networks and the bias/variance dilemma. <i>Neural Computation</i>, 4:1- 58, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>599671</ref_obj_id>
				<ref_obj_pid>599613</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[I. Guyon, J. Weston, S. Barnhill, and V. Vapnik. Gene selection for cancer classification using support vector machines. <i>Machine Learning</i>, 46(1-3):389-422, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2101293</ref_obj_id>
				<ref_obj_pid>2101235</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Kalousis, J. Prados, E. Rexhepaj, and M. Hilario. Feature extraction from mass spectra for classification. 2005. Submitted to 6th European Conference on Principles and Practice of Knowledge Discovery in Databases.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Petricoin, A. Ardekani, B. Hitt, P. Levine, V. Fusaro, S. Steinberg, G. Mills, C. Simone, D. Fishman, E. Kohn, and L. Liotta. Use of proteomic patterns in serum to identify ovarian cancer. <i>The Lancet</i>, 395:572-577, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[E. Petricoin, D. Ornstein, C. Paweletz, A. Ardekani, P. Hackett, B. Hitt, A. Velassco, C. Trucco, L. Wiegand, K. Wood, C. Simone, P. Levine, W. Marston Linehan, M. Emmert-Buck, S. Steinberg, E. Kohn, and L. Liotta. Serum proteomic patterns for detection of prostate cancer. <i>Journal of the NCI</i>, 94(20), 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Prados, A. Kalousis, J.-C. Sanchez, L. Allard, O. Carrette, and M. Hilario. Mining mass spectra for diagnosis and biomarker discovery of cerebral accidents. <i>Proteomics</i>, 4(8):2320-2332, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>940876</ref_obj_id>
				<ref_obj_pid>940854</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Robnik-Sikonja and I. Kononenko. Theoretical and empirical analysis of relief and relief. <i>Machine Learning</i>, 53(1-2):23-69, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218544</ref_obj_id>
				<ref_obj_pid>218541</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[P. Turney. Technical note: Bias and the quantification of stability. <i>Machine Learning</i>, 20:23-33, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323651</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[I. Witten and E. Frank. <i>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations</i>. Morgan Kaufmann, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106352</article_id>
		<sort_key>226</sort_key>
		<display_label></display_label>
		<pages>226-233</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[HOT SAX]]></title>
		<subtitle><![CDATA[Efficiently Finding the Most Unusual Time Series Subsequence]]></subtitle>
		<page_from>226</page_from>
		<page_to>233</page_to>
		<doi_number>10.1109/ICDM.2005.79</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106352</url>
		<abstract>
			<par><![CDATA[In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. As we will show, discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82 different datasets from diverse domains.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Time Series Data Mining, Anomaly Detection, Clustering]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041897</person_id>
				<author_profile_id><![CDATA[81100209161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eamonn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Keogh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Riverside]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45028030</person_id>
				<author_profile_id><![CDATA[81100222615]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jessica]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Riverside]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P10576</person_id>
				<author_profile_id><![CDATA[81451592510]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ada]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>314321</ref_obj_id>
				<ref_obj_pid>314161</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bentley. J. L. & Sedgewick. R. (1997). Fast algorithms for sorting and searching strings. In Proceedings of the 8th Annual ACM-SIAM Symposium on Discrete Algorithms. pp. 360-369.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956808</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chiu, B., Keogh, E. & Lonardi, S. (2003). Probabilistic Discovery of Time Series Motifs. In the 9th SIGKDD Conference on Knowledge Discovery and Data Mining. pp 493-498.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>80156</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Coerman, T. H., Leiserson, C. E. &. Rivest R. L. (1990) Introduction to Algorithms, McGraw-Hill Company.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Keogh. E. (2005). www.cs.ucr.edu/~eamonn/discords/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775062</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Keogh, E. & Kasetty, S. (2002). On the need for time series data mining benchmarks: A survey and empirical demonstration. In Proc. of SIGKDD. pp 102-111.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014077</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Keogh, E., Lonardi, S. & Ratanamahatana, C. (2004). Towards Parameter-Free Data Mining. In proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp 206-215.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>764218</ref_obj_id>
				<ref_obj_pid>764212</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Knorr, E., Ng, R. &. Tucakov V. (2000). Distance-Based Outliers: Algorithms and Applications. VLDB J. 8(3-4): 237-253.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kumar, N., Lolla N., Keogh, E., Lonardi, S., Ratanamahatana, C., & Li, W. (2005). Time-series Bitmaps: A Practical Visualization Tool for working with Large Time Series Databases. SIAM Data Mining Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>942111</ref_obj_id>
				<ref_obj_pid>942109</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lanctot, J. K., Li, M., Ma. B., Wang, S., &. Zhang, L (2003). Distinguishing string selection problems, Information and Computation 185: pp 41-55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>882086</ref_obj_id>
				<ref_obj_pid>882082</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lin, J., Keogh, E., Lonardi, S., & Chiu, B. (2003). A Symbolic Representation of Time Series, with Implications for Streaming Algorithms. In proceedings of the 8th ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014104</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lin, J., Keogh, E., Lonardi, S., Lankford, J. P. & Nystrom, D. M. (2004). Visually Mining and Monitoring Massive Time Series. In proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp 460-469.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>689570</ref_obj_id>
				<ref_obj_pid>646343</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Sadakane, K., (2000) Compressed text databases with efficient query algorithms based on the compressed suffix array, Proceedings of ISAAC'00, LNCS, pp 410-421.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Tanaka, Y. & Uehara, K. (2004). Motif Discovery Algorithm from Motion Data. In proceedings of the 18th Annual Conference of the Japanese Society for Artificial Intelligence (JSAI).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106353</article_id>
		<sort_key>234</sort_key>
		<display_label></display_label>
		<pages>234-241</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Orthogonal Neighborhood Preserving Projections]]></title>
		<page_from>234</page_from>
		<page_to>241</page_to>
		<doi_number>10.1109/ICDM.2005.113</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106353</url>
		<abstract>
			<par><![CDATA[Orthogonal Neighborhood Preserving Projections (ONPP) is a linear dimensionality reduction technique which attempts to preserve both the intrinsic neighborhood geometry of the data samples and the global geometry. The proposed technique constructs a weighted data graph where the weights are constructed in a data-driven fashion, similarly to Locally Linear Embedding (LLE). A major difference with the standard LLE where the mapping between the input and the reduced spaces is implicit, is that ONPP employs an explicit linear mapping between the two. As a result, and in contrast with LLE, handling new data samples becomes straightforward, as this amounts to a simple linear transformation. ONPP shares some of the properties of Locality Preserving Projections (LPP). Both ONPP and LPP rely on a k-nearest neighbor graph in order to capture the data topology. However, our algorithm inherits the characteristics of LLE in preserving the structure of local neighborhoods, while LPP aims at preserving only locality without specifically aiming at preserving the geometric structure. This feature makes ONPP an effective method for data visualization. We provide ample experimental evidence to demonstrate the advantageous characteristics of ONPP, using well known synthetic test cases as well as real life data from computational biology and computer vision.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Geometric</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15042496</person_id>
				<author_profile_id><![CDATA[81100641674]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[E.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kokiopoulou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041433</person_id>
				<author_profile_id><![CDATA[81410591841]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Y.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Saad]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. A. Alizadeh, M. B. Eisen, R. E. Davis, C. Ma, I. S. Lossos, A. Rosenwald, J. C. Boldrick, H. Sabet, T. Tran, X. Yu, J. I. Powell, L. Yang, G. E. Marti, T. Moore, J. H. Jr, L. Lu, D. B. Lewis, R. Tibshirani, G. Sherlock, W. C. Chan, T. C. Greiner, D. D. Weisenburger, J. O. Armitage, R. Warnke, R. Levy, W. Wilson, M. R. Grever, J. C. Byrd, D. Botstein, P. O. Brown, and L. M. Staudt. Distinct types of diffuse large b-cell lymphoma identified by gene expression profiling. <i>Nature</i>, 403:503-511, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[U. Alon, N. Barkai, D. Notterman, K. Gish, S. Ybarra, D. Mack, and A. Levine. Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays. <i>Proceedings of the National Academy of Science</i>, 96:6745-6750, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>795528</ref_obj_id>
				<ref_obj_pid>795523</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. <i>Neural Comput.</i>, 15(6):1373-1396, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Y. Bengio, J-F Paiement, P. Vincent, O. Delalleau, N. Le Roux, and M. Ouimet. Out-of-Sample Extensions for LLE, Isomap, MDS, Eigenmaps, and Spectral Clustering. In Sebastian Thrun, Lawrence Saul, and Bernhard Sch&#246;lkopf, editors, <i>Advances in Neural Information Processing Systems 16</i>. MIT Press, Cambridge, MA, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Dudoit, J. Fridlyand, and T. Speed. Comparison of discrimination methods for the classification of tumors using gene expression data. <i>Journal of the American Statistical Association</i>, 97:77-87, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[X. He and P. Niyogi. Locality preserving projections. <i>Advances in Neural Information Processing Systems 16 (NIPS 2003)</i>, 2003. Vancouver, Canada.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A.M. Martinez and R. Benavente. The AR Face Database. Technical report, CVC no. 24, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Roweis and L. Saul. Nonlinear Dimensionality Reduction by Locally Linear Embedding. <i>Science</i>, 290:2323-2326, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Y. Saad. <i>Numerical Methods for Large Eigenvalue Problems</i>. Halstead Press, New York, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>945372</ref_obj_id>
				<ref_obj_pid>945365</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[L. Saul and S. Roweis. Think Globally, Fit Locally: Unsupervised Learning of Nonlinear Manifolds. <i>Journal of Machine Learning Research</i>, 4:119-155, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik. <i>Statistical Learning Theory</i>. Wiley, New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A. Webb. <i>Statistical Pattern Recognition</i>. Wiley, 2nd edition, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1042362</ref_obj_id>
				<ref_obj_pid>1042198</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Ye, T. Li, T. Xiong, and R. Janardan. Using uncorrelated discriminant analysis for tissue classification with gene expression data. <i>IEEE/ACM Transactions on Computational Biology and Bioinformatics</i>, 1(4):181-190, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106354</article_id>
		<sort_key>242</sort_key>
		<display_label></display_label>
		<pages>242-249</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[Higher-Order Web Link Analysis Using Multilinear Algebra]]></title>
		<page_from>242</page_from>
		<page_to>249</page_to>
		<doi_number>10.1109/ICDM.2005.77</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106354</url>
		<abstract>
			<par><![CDATA[Linear algebra is a powerful and proven tool in web search. Techniques, such as the PageRank algorithm of Brin and Page and the HITS algorithm of Kleinberg, score web pages based on the principal eigenvector (or singular vector) of a particular non-negative matrix that captures the hyperlink structure of the web graph. We propose and test a new methodology that uses multilinear algebra to elicit more information from a higher-order representation of the hyperlink graph. We start by labeling the edges in our graph with the anchor text of the hyperlinks so that the associated linear algebra representation is a sparse, three-way tensor. The first two dimensions of the tensor represent the web pages while the third dimension adds the anchor text. We then use the rank-1 factors of a multilinear PARAFAC tensor decomposition, which are akin to singular vectors of the SVD, to automatically identify topics in the collection along with the associated authoritative web pages.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>World Wide Web (WWW)</descriptor>
				<type>P</type>
			</other_category>
			<other_category>
				<cat_node>G.1.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010148.10010149.10010158</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms->Linear algebra algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003719</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on matrices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15026510</person_id>
				<author_profile_id><![CDATA[81100225962]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tamara]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Kolda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sandia National Laboratories]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040439</person_id>
				<author_profile_id><![CDATA[81100165342]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Brett]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Bader]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sandia National Laboratories]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763061</person_id>
				<author_profile_id><![CDATA[81339508777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Joseph]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Kenny]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sandia National Laboratories]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>2154670</ref_obj_id>
				<ref_obj_pid>2154644</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Acar, S. A. &#199;amtepe, M. S. Krishnamoorthy, and B. Yener. Modeling and multiway analysis of chatroom tensors. In <i>Proc. ISI 2005</i>, volume 3495 of <i>LNCS</i>, pp. 256-268, Jan. 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1186794</ref_obj_id>
				<ref_obj_pid>1186785</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. W. Bader and T. G. Kolda. MATLAB tensor classes for fast algorithm prototyping. Tech. Rep. SAND2004-5187, Sandia Natl. Labs, Oct. 2004. Submitted to <i>ACM Trans. Math. Soft.</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>222514</ref_obj_id>
				<ref_obj_pid>222504</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. W. Berry, S. T. Dumais, and G. W. O'Brien. Using linear algebra for intelligent information retrieval. <i>SIAM Rev.</i>, 37(4):573-595, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>290972</ref_obj_id>
				<ref_obj_pid>290941</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[K. Bharat and M. R. Henzinger. Improved algorithms for topic distillation in a hyperlinked environment. In <i>Proc. SIGIR '98</i>, pp. 104-111. ACM, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1035557</ref_obj_id>
				<ref_obj_pid>1035533</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[V. D. Blondel, A. Gajardo, M. Heymans, P. Senellart, and P. V. Dooren. A measure of similarity between graph vertices: Applications to synonym extraction and web searching. <i>SIAM Rev.</i>, 46(4):647-666, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>297827</ref_obj_id>
				<ref_obj_pid>297810</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Brin and L. Page. The anatomy of a large-scale hypertextual Web search engine. <i>Comput. Networks ISDN</i>, 30(1- 7):107-117, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. D. Carroll and J. J. Chang. Analysis of individual differences in multidimensional scaling via an N-way generalization of 'Eckart-Young' decomposition. <i>Psychometrika</i>, 35:283-319, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>297821</ref_obj_id>
				<ref_obj_pid>297805</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Chakrabarti, B. Dom, P. Raghavan, S. Rajagopalan, D. Gibson, and J. Kleinberg. Automatic resource compilation by analyzing hyperlink structure and associated text. In <i>Proc. WWW7</i>, pp. 65-74. Elsevier, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>621302</ref_obj_id>
				<ref_obj_pid>619043</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Chakrabarti, B. E. Dom, S. R. Kumar, P. Raghavan, S. Rajagopalan, A. Tomkins, D. Gibson, and J. Kleinberg. Mining the Web's link structure. <i>Computer</i>, 32(8):60-67, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657957</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. Cohn and H. Chang. Learning to probabilistically identify authoritative documents. In <i>Proc. ICML '00</i>, pp. 167- 174. Morgan Kaufmann Publishers Inc., 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[D. Cohn and T. Hofmann. The missing link - a probabilistic model of document content and hypertext connectivity. <i>Advances in Neural Information Processing Systems</i>, 13:460- 436, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[B. D. Davison, A. Gerasoulis, K. Kleisouris, Y. Lu, H.-J. Seo, W. Wang, and B. Wu. DiscoWeb: applying link analysis to web search. Poster at WWW8, May 1999. Available from http://www.cse.lehigh.edu/-brian/ pubs/1999/www8/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>511512</ref_obj_id>
				<ref_obj_pid>511446</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M. Diligenti, M. Gori, and M. Maggini. Web page scoring systems for horizontal and vertical search. In <i>Proc. WWW '02</i>, pp. 508-516. ACM, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564440</ref_obj_id>
				<ref_obj_pid>564376</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C. Ding, X. He, P. Husbands, H. Zha, and H. D. Simon. PageRank, HITS and a unified framework for link analysis. In <i>Proc. SIGIR '02</i>, pp. 353-354. ACM, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1059473</ref_obj_id>
				<ref_obj_pid>1059467</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[C. H. Q. Ding. A probabilistic model for latent semantic indexing. <i>J. Am. Soc. Inf. Sci. Tec.</i>, 56(6):597-608, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[S. T. Dumais. Latent semantic analysis. <i>Annu. Rev. Inform. Sci.</i>, 38:189-230, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>57214</ref_obj_id>
				<ref_obj_pid>57167</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[S. T. Dumais, G. W. Furnas, T. K. Landauer, S. Deerwester, and R. Harshman. Using latent semantic analysis to improve access to textual information. In <i>Proc. CHI '88</i>, pp. 281- 285. ACM, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>860550</ref_obj_id>
				<ref_obj_pid>860435</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[N. Eiron and K. S. McCurley. Analysis of anchor text for web search. In <i>Proc. SIGIR '03</i>, pp. 459-460. ACM, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944950</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[L. Getoor, N. Friedman, D. Koller, and B. Taskar. Learning probabilistic models of link structure. <i>J. Mach. Learn. Res.</i>, 3:679-707, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033488</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[D. Gleich and L. Zhukov. SVD based term suggestion and ranking system. In <i>Proc. ICDM 2004</i>, pp. 391-394, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[G. H. Golub and C. F. Van Loan. <i>Matrix Computations</i>. Johns Hopkins Univ. Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[R. A. Harshman. Foundations of the PARAFAC procedure: models and conditions for an "explanatory" multimodal factor analysis. <i>UCLA working papers in phonetics</i>, 16:1- 84, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>511513</ref_obj_id>
				<ref_obj_pid>511446</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[T. H. Haveliwala. Topic-sensitive PageRank. In <i>Proc. WWW '02</i>, pp. 517-526. ACM, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>324140</ref_obj_id>
				<ref_obj_pid>324133</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[J. M. Kleinberg. Authoritative sources in a hyperlinked environment. <i>J. ACM</i>, 46(5):604-632, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>587830</ref_obj_id>
				<ref_obj_pid>587708</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[T. G. Kolda. Orthogonal tensor decompositions. <i>SIAM J. Matrix Anal. A.</i>, 23(1):243-255, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[A. N. Langville and C. D. Meyer. Deeper inside PageRank. <i>J. Internet Mathematics</i>, 1(3):335-380, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383041</ref_obj_id>
				<ref_obj_pid>382979</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[R. Lempel and S. Moran. SALSA: the stochastic approach for link-structure analysis. <i>ACM Trans. Inf. Syst.</i>, 19(2):131- 160, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>511514</ref_obj_id>
				<ref_obj_pid>511446</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[L. Li, Y. Shang, and W. Zhang. Improvement of HITS-based algorithms on web documents. In <i>Proc. WWW '02</i>, pp. 527- 535. ACM, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>980999</ref_obj_id>
				<ref_obj_pid>980972</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[A. McGovern, L. Friedland, M. Hay, B. Gallagher, A. Fast, J. Neville, and D. Jensen. Exploiting relational structure to understand publication patterns in high-energy physics. <i>ACM SIGKDD Explor. Newsl.</i>, 5(2):165-172, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642215</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[A. Y. Ng, A. X. Zheng, and M. I. Jordan. Link analysis, eigenvectors and stability. In <i>Int. Joint Conf. on Artificial Intelligence (IJCAI)</i>, pp. 903-910, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>384003</ref_obj_id>
				<ref_obj_pid>383952</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[A. Y. Ng, A. X. Zheng, and M. I. Jordan. Stable algorithms for link analysis. In <i>Proc. SIGIR '01</i>, pp. 258-266. ACM, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank citation ranking: bringing order to the Web. Tech. Rep. 1999-66, Stanford Digital Library Technologies Project, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>346421</ref_obj_id>
				<ref_obj_pid>346241</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[D. Rafiei and A. O. Mendelzon. What is this page known for? Computing Web page reputations. <i>Comput. Networks</i>, 33(1-6):823-835, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[M. Richardson and P. Domingos. The intelligent surfer: probabilistic combination of link and content information in PageRank. In <i>Advances in Neural Information Processing Systems 14</i>, pp. 1441-1448. MIT Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[D. Skillicorn. Social network analysis via matrix decompositions: al Qaeda. Available from http://www.cs. queensu.ca/home/skill/alqaeda.pdf, Aug. 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[A. Smilde, R. Bro, and P. Geladi. <i>Multi-way analysis: applications in the chemical sciences</i>. Wiley, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1060803</ref_obj_id>
				<ref_obj_pid>1060745</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[J.-T. Sun, H.-J. Zeng, H. Liu, Y. Lu, and Z. Chen. CubeSVD: a novel approach to personalized Web search. In <i>Proc. WWW '05</i>, pp. 382-390, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[L. R. Tucker. Some mathematical notes on three-mode factor analysis. <i>Psychometrika</i>, 31:279-311, 1966.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649173</ref_obj_id>
				<ref_obj_pid>645315</ref_obj_pid>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[M. A. O. Vasilescu and D. Terzopoulos. Multilinear analysis of image ensembles: TensorFaces. In <i>Proc. ECCV'02</i>, volume 2350 of <i>Lecture Notes in Computer Science</i>, pp. 447- 460. Springer-Verlag, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>587760</ref_obj_id>
				<ref_obj_pid>587704</ref_obj_pid>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[T. Zhang and G. H. Golubuhou. Rank-one approximation to high order tensors. <i>SIAM J. Matrix Anal. A.</i>, 23(2):534-550, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106355</article_id>
		<sort_key>250</sort_key>
		<display_label></display_label>
		<pages>250-257</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[A Generic Framework for Efficient Subspace Clustering of High-Dimensional Data]]></title>
		<page_from>250</page_from>
		<page_to>257</page_to>
		<doi_number>10.1109/ICDM.2005.5</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106355</url>
		<abstract>
			<par><![CDATA[Subspace clustering has been investigated extensively since traditional clustering algorithms often fail to detect meaningful clusters in high-dimensional data spaces. Many recently proposed subspace clustering methods suffer from two severe problems: First, the algorithms typically scale exponentially with the data dimensionality and/or the subspace dimensionality of the clusters. Second, for performance reasons, many algorithms use a global density threshold for clustering, which is quite questionable since clusters in subspaces of significantly different dimensionality will most likely exhibt significantly varying densities. In this paper, we propose a generic framework to overcome these limitations. Our framework is based on an efficient filter-refinement architecture that scales at most quadratic w.r.t. the data dimensionality and the dimensionality of the subspace clusters. It can be applied to any clustering notions including notions that are based on a local density threshold. A broad experimental evaluation on synthetic and real-world data empirically shows that our method achieves a significant gain of runtime and quality in comparison to state-of-the-art subspace clustering algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Structural</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15034628</person_id>
				<author_profile_id><![CDATA[81100512920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kriegel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040369</person_id>
				<author_profile_id><![CDATA[81332509808]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kroger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45026364</person_id>
				<author_profile_id><![CDATA[81343503720]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Matthias]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Renz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763147</person_id>
				<author_profile_id><![CDATA[81309512349]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Sebastian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wurst]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>304188</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal and C. Procopiuc. "Fast Algorithms for Projected Clustering". In <i>Proc. ACM SIGMOD</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276314</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, J. Gehrke, D. Gunopulos, and P. Raghavan. "Automatic Subspace Clustering of High Dimensional Data for Data Mining Applications". In <i>Proc. ACM SIGMOD</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033430</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Baumgartner, K. Kailing, H.-P. Kriegel, P. Kr&#246;ger, and C. Plant. "Subspace Selection for Clustering High-Dimensional Data". In <i>Proc. ICDM</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033433</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. B&#246;hm, K. Kailing, H.-P. Kriegel, and P. Kr&#246;ger. "Density Connected Clustering with Local Subspace Preferences". In <i>Proc. ICDM</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312199</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C.-H. Cheng, A.-C. Fu, and Y. Zhang. "Entropy-Based Subspace Clustering for Mining Numerical Data". In <i>Proc. ACM SIGKDD</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844731</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Dash, K. Choi, P. Scheuermann, and H. Liu. "Feature Selection for Clustering - A Filter Solution". In <i>Proc. ICDM</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[L. Ert&#246;z, M. Steinbach, and V. Kumar. "Finding Clusters of Different Sizes, Shapes, and Densities in Noisy, High Dimensional Data". In <i>Proc. SIAM Data Mining</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. "A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise". In <i>Proc. KDD</i>, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. R. Golub et al. "Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring". <i>Science</i>, 286:531-537, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Han and M. Kamber. <i>Data Mining: Concepts and Techniques</i>. Academic Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[K. Kailing, H.-P. Kriegel, and P. Kr&#246;ger. "Density-Connected Subspace Clustering for High-Dimensional Data". In <i>Proc. SIAM Data Mining</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[H. Nagesh, S. Goil, and A. Choudhary. "Adaptive Grids for Clustering Massive Data Sets". In <i>Proc. SIAM Data Mining</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007731</ref_obj_id>
				<ref_obj_pid>1007730</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[L. Parsons, E. Haque, and H. Liu. Subspace clustering for high dimensional data: A review. <i>SIGKDD Explorations</i>, 6(1):90-105, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564739</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C. M. Procopiuc, M. Jones, P. K. Agarwal, and M. T. M. "A Monte Carlo Algorithm for Fast Projective Clustering". In <i>Proc. ACM SIGMOD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[P. Spellman et al. "Comprehensive Identification of Cell Cycle-Regulated Genes of the Yeast Saccharomyces Cerevisiae by Microarray Hybridization.". <i>Molecular Biolology of the Cell</i>, 9:3273-3297, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>878990</ref_obj_id>
				<ref_obj_pid>876875</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J. Yang, W. Wang, H. Wang, and P. S. Yu. "Delta-Clusters: Capturing Subspace Correlation in a Large Data Set". In <i>Proc. ICDE</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106356</article_id>
		<sort_key>258</sort_key>
		<display_label></display_label>
		<pages>258-265</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[Effective and Efficient Distributed Model-Based Clustering]]></title>
		<page_from>258</page_from>
		<page_to>265</page_to>
		<doi_number>10.1109/ICDM.2005.53</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106356</url>
		<abstract>
			<par><![CDATA[In many companies data is distributed among several sites, i.e. each site generates its own data and manages its own data repository. Analyzing and mining these distributed sources requires distributed data mining techniques to find global patterns representing the complete information. The transmission of the entire local data set is often unacceptable because of performance considerations, privacy and security aspects, and bandwidth constraints. Traditional data mining algorithms, demanding access to complete data, are not appropriate for distributed applications. Thus, there is a need for distributed data mining algorithms in order to analyze and discover new knowledge in distributed environments. One of the most important data mining tasks is clustering which aims at detecting groups of similar data objects. In this paper, we propose a distributed model-based clustering algorithm that uses EM for detecting local models in terms of mixtures of Gaussian distributions. We propose an efficient and effective algorithm for deriving and merging these local Gaussian distributions to generate a meaningful global model. In a broad experimental evaluation we show that our framework is scalable in a highly distributed environment.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>Distributed systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003365.10003368</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Search engine architectures and scalability->Distributed retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152.10003517.10003519</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems->Storage architectures->Distributed storage</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003365.10003369</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Search engine architectures and scalability->Peer-to-peer retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15034628</person_id>
				<author_profile_id><![CDATA[81100512920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kriegel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041198</person_id>
				<author_profile_id><![CDATA[81332509808]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kroger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762966</person_id>
				<author_profile_id><![CDATA[81309509002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Alexey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pryakhin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044356</person_id>
				<author_profile_id><![CDATA[81339526780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Matthias]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schubert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. P. Dempster, N. M. Laird, and D. B. Rubin. "Maximum Likelihood from Incomplete Data via the EM Algorithm". <i>Journal of the Royal Statistical Society, Series B</i>, 39(1):1- 31, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>744385</ref_obj_id>
				<ref_obj_pid>648035</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon and D. S. Modha. "A Data-Clustering Algorithm On Distributed Memory Multiprocessors". In <i>Proc. KDD-WS on High Performance Data Mining</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. "A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise". In <i>Proc. Int. Conf. on Knowledge Discovery and Data Mining (KDD)</i>, pages 291-316, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[U. Fayyad, C. Reina, and P. Bradley. "Initialization of Iterative Refinement Clustering Algorithms". In <i>Proc. Int. Conf. on Knowledge Discovery in Databases (KDD)</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>381010</ref_obj_id>
				<ref_obj_pid>380995</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Forman and B. Zhang. "Distributed Data Clustering can be Efficient and Exact". <i>SIGKDD Explorations</i>, 2, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>607609</ref_obj_id>
				<ref_obj_pid>607585</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Halkidi, Y. Batistakis, and M. Vazirgiannis. "On Clustering Validation Techniques". <i>Journal of Intelligent Information Systems</i>, 2/3(17):107-145, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Han and M. Kamber. <i>Data Mining: Concepts and Techniques</i>. Academic Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1053095</ref_obj_id>
				<ref_obj_pid>1053072</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[E. Januzaj, H.-P. Kriegel, and M. Pfeifle. "Scalable Density-Based Distributed Clustering". In <i>Proc. Europ. Conf. PKDD</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>761140</ref_obj_id>
				<ref_obj_pid>648035</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[E. Johnson and H. Kargupta. "Hierarchical Clustering from Distributed, Heterogeneous Data". In M. Zaki and C. Ho, editors, <i>Large-Scale Parallel KDD Systems</i>, volume 1759 of <i>Lecture Notes in Computer Science (LNCS)</i>. Springer Verlag, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[B.-H. Park and H. Kargupta. "Distributed Data Mining: Algorithms, Systems, and Applications". In N. Ye, editor, <i>The Handbook of Data Mining</i>. Lawrence Erlbaum Associates Publishers, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Sayal and P. Scheuermann. "A Distributed Algorithm for Web-Based Access Patterns". In <i>Proc. KDD-WS on Distributed and Parallel Knowledge Discovery</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593485</ref_obj_id>
				<ref_obj_pid>593424</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[X. Xu, J. J&#228;ger, and H.-P. Kriegel. "A Fast Parallel Clustering Algorithm for Large Spatial Databases". <i>Data Mining and Knowledge Discovery, an International Journal</i>, 3(3):263-290, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106357</article_id>
		<sort_key>266</sort_key>
		<display_label></display_label>
		<pages>266-273</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[Finding Maximal Frequent Itemsets over Online Data Streams Adaptively]]></title>
		<page_from>266</page_from>
		<page_to>273</page_to>
		<doi_number>10.1109/ICDM.2005.68</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106357</url>
		<abstract>
			<par><![CDATA[Due to the characteristics of a data stream, it is very important to confine the memory usage of a data mining process regardless of the amount of information generated in the data stream. For this purpose, this paper proposes a CP-tree (Compressed-prefix tree)that can be effectively used in finding either frequent or maximal frequent itemsets over an online data stream. Unlike a prefix tree, a node of a CP-tree can maintain the information of several itemsets together. Based on this characteristic, the size of a CP-tree can be flexibly controlled by merging or splitting nodes. In this paper, a mining method employing a CP-tree is proposed and an adaptive memory utilization scheme is also presented in order to maximize the mining accuracy of the proposed method for confined memory space at all times. Finally, the performance of the proposed method is analyzed by a series of experiments to identify its various characteristics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>E.1</cat_node>
				<descriptor>Trees</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>E.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003634</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011024.10011028</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language features->Data types and structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152.10003161.10003163.10003415</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems->Record storage systems->Directory structures->B-trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763003</person_id>
				<author_profile_id><![CDATA[81309505832]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daesu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Yonsei University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45028157</person_id>
				<author_profile_id><![CDATA[81100384662]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wonsuk]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Yonsei University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>347114</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R.C. Agarwal, C.C. Aggarwal, and V.V.V. Prasad. Depth First Generation of Long Patterns. In <i>Proc. of the 6th ACM SIGKDD</i>, pp. 108-118, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In <i>Proc. of the 20th VLDB</i>, pp. 487- 499, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253325</ref_obj_id>
				<ref_obj_pid>253260</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, J.D. Ullman, and S. Tsur. Dynamic Itemset Counting and Implication Rules for Market Basket Data. In <i>Proc. of the ACM SIGMOD</i>, pp. 255-264, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956807</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J.H. Chang and W.S. Lee. Finding recent frequent itemsets adaptively over online data streams. In <i>Proc. of the 9th ACM SIGKDD</i>, pp. 487-492, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Dong, J. Han, L.V.S. Lakshmanan, J. Pei, H. Wang, and P.S. Yu. Online Mining of Changes from Data Streams: Research Problems and Preliminary Results. In <i>Proc. of the Workshop on Management and Processing of Data Streams</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Garofalakis, J. Gehrke, and R. Rastogi. Querying and Mining Data Streams: You Only Get One Look. In <i>tutorial notes of the 28th VLDB</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>879026</ref_obj_id>
				<ref_obj_pid>876875</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Guha and N. Koudas. Approximating a Data Stream for Querying and Estimation: Algorithms and Performance Evaluation. In <i>Proc. of the 18th ICDE</i>, pp. 567- 576, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>679118</ref_obj_id>
				<ref_obj_pid>646108</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Hafez, J. Deogun, and V. V. Raghavan. The Item-Set Tree: A data Structure for Data Mining. In <i>Proc. of the 1st International Conference on Datawarehousing and Knowledge Discovery</i>, pages 183-192, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502529</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[G. Hulten, L. Spencer, and P. Domingos. Mining Time-Changing Data Streams. In <i>Proc. of the 7th ACM SIGKDD</i>, pp. 97-106, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502556</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. Lambert and J.C. Pinheiro. Mining a Stream of Transactions for Customer Patterns. In <i>Proc. of the 7th ACM SIGKDD</i>, pp. 305-310, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287400</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G.S. Manku and R. Motwani. Approximate Frequency Counts over Data Streams. In <i>Proc. of the 28th VLDB</i>, pp. 346-357, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106358</article_id>
		<sort_key>274</sort_key>
		<display_label></display_label>
		<pages>274-281</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[CanTree]]></title>
		<subtitle><![CDATA[A Tree Structure for Efficient Incremental Mining of Frequent Patterns]]></subtitle>
		<page_from>274</page_from>
		<page_to>281</page_to>
		<doi_number>10.1109/ICDM.2005.38</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106358</url>
		<abstract>
			<par><![CDATA[Since its introduction, frequent-pattern mining has been the subject of numerous studies, including incremental updating. Many existing incremental mining algorithms are Apriori-based, which are not easily adoptable to FP-tree based frequent-pattern mining. In this paper, we propose a novel tree structure, called CanTree (Canonical-order Tree), that captures the content of the transaction database and orders tree nodes according to some canonical order. By exploiting its nice properties, the CanTree can be easily maintained when database transactions are inserted, deleted, and/or modified. For example, the CanTree does not require adjustment, merging, and/or splitting of tree nodes during maintenance. No rescan of the entire updated database or reconstruction of a new tree is needed for incremental updating. Experimental results show the effectiveness of our CanTree.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>E.1</cat_node>
				<descriptor>Trees</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>E.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003634</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152.10003161.10003162</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems->Record storage systems->Record storage alternatives</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152.10003161.10003163.10003415</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems->Record storage systems->Directory structures->B-trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP45024865</person_id>
				<author_profile_id><![CDATA[81339512271]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Carson]]></first_name>
				<middle_name><![CDATA[Kai-Sang]]></middle_name>
				<last_name><![CDATA[Leung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Manitoba]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763124</person_id>
				<author_profile_id><![CDATA[81309513374]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Quamrul]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Khan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Manitoba]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763162</person_id>
				<author_profile_id><![CDATA[81309497196]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tariqul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hoque]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Manitoba]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases. In <i>Proc. SIGMOD 1993</i>, pp. 207-216.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. VLDB 1994</i>, pp. 487-499.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312252</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[N.F. Ayan, A.U. Tansel, and E. Arkun. An efficient algorithm to update large itemsets with early pruning. In <i>Proc. SIGKDD 1999</i>, pp. 287-291.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276313</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R.J. Bayardo. Efficiently mining long patterns from databases. In <i>Proc. SIGMOD 1998</i>, pp. 85-93.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033434</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[F. Bonchi and C. Lucchese. On closed constrained frequent pattern mining. In <i>Proc. ICDM 2004</i>, pp. 35-42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253327</ref_obj_id>
				<ref_obj_pid>253260</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, and C. Silverstein. Beyond market baskets: generalizing association rules to correlations. In <i>Proc. SIGMOD 1997</i>, pp. 265-276.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775054</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Bucila, J. Gehrke, D. Kifer, and W.M. White. DualMiner: a dual-pruning algorithm for itemsets with constraints. In <i>Proc. SIGKDD 2002</i>, pp. 42-51.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655582</ref_obj_id>
				<ref_obj_pid>645481</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D.W. Cheung, J. Han, V.T. Ng, and C.Y. Wong. Maintenance of discovered association rules in large databases: an incremental updating technique. In <i>Proc. ICDE 1996</i>, pp. 106-114.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>703155</ref_obj_id>
				<ref_obj_pid>646711</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D.W. Cheung, S. D. Lee, and B. Kao. A general incremental technique for maintaining discovered association rules. In <i>Proc. DASFAA 1997</i>, pp. 185-194.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[W. Cheung and O.R. Za&#239;ane. Incremental mining of frequent patterns without candidate generation or support constraint. In <i>Proc. IDEAS 2003</i>, pp. 111-116.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233313</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[T. Fukuda, Y. Morimoto, S. Morishita, and T. Tokuyama. Data mining using two-dimensional optimized association rules: scheme, algorithms, and visualization. In <i>Proc. SIGMOD 1996</i>, pp. 13-23.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014070</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[K. Gade, J. Wang, and G. Karypis. Efficient closed pattern mining in the presence of tough block constraints. In <i>Proc. SIGKDD 2004</i>, pp. 138-147.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>Proc. SIGMOD 2000</i>, pp. 1-12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>954525</ref_obj_id>
				<ref_obj_pid>954514</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, Y. Yin, and R. Mao. Mining frequent patterns without candidate generation: a frequent-pattern tree approach. <i>Data Mining and Knowledge Discovery</i>, &#60;b&#62;8&#60;/b&#62;(1), pp. 53-87, Jan. 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304195</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[C. Hidber. Online association rule mining. In <i>Proc. SIGMOD 1999</i>, pp. 145-156.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844784</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[H. Huang, X. Wu, and R. Relue. Association analysis with one scan of databases. In <i>Proc. ICDM 2002</i>, pp. 629-632.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J.-L. Koh and S.-F. Shieh. An efficient approach for maintaining association rules based on adjusting FP-tree structures. In <i>Proc. DASFAA 2004</i>, pp. 417-424.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>958944</ref_obj_id>
				<ref_obj_pid>958942</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[L.V.S. Lakshmanan, C.K.-S. Leung, and R.T. Ng. Efficient dynamic mining of constrained frequent sets. <i>ACM TODS</i>, &#60;b&#62;28&#60;/b&#62;(4), pp. 337-389, Dec. 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1021502</ref_obj_id>
				<ref_obj_pid>1018432</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[C.K.-S. Leung. Interactive constrained frequent-pattern mining system. In <i>Proc. IDEAS 2004</i>, pp. 49-58.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>568581</ref_obj_id>
				<ref_obj_pid>568574</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[C.K.-S. Leung, L.V.S. Lakshmanan, and R.T. Ng. Exploiting succinct constraints using FP-trees. <i>SIGKDD Explorations</i>, &#60;b&#62;4&#60;/b&#62;(1), pp. 40- 49, June 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>879000</ref_obj_id>
				<ref_obj_pid>876875</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[C.K.-S. Leung, R.T. Ng, and H. Mannila. OSSM: a segmentation approach to optimize frequency counting. In <i>Proc. ICDE 2002</i>, pp. 583-592.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276307</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[R.T. Ng, L.V.S. Lakshmanan, J. Han, and A. Pang. Exploratory mining and pruning optimizations of constrained associations Rules. In <i>Proc. SIGMOD 1998</i>, pp. 13-24.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[K.-L. Ong, W.K. Ng, and E.-P. Lim. FSSM: fast construction of the optimized segment support map. In <i>Proc. DaWaK 2003</i>, pp. 257- 266.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627876</ref_obj_id>
				<ref_obj_pid>627312</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[J.S. Park, M.-S. Chen, and P.S. Yu. Using a hash-based method with transaction trimming for mining association rules. <i>IEEE TKDE</i>, &#60;b&#62;9&#60;/b&#62;(5), pp. 813-825, Sept./Oct. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656372</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and L.V.S. Lakshmanan. Mining frequent itemsets with convertible constraints. In <i>Proc. ICDE 2001</i>, pp. 433-442.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and R. Mao. CLOSET: an efficient algorithm for mining frequent closed itemsets. In <i>Proc. DMKD 2000</i>, pp. 21-30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276335</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[S. Sarawagi, S. Thomas, and R. Agrawal. Integrating association rule mining with relational database systems: alternatives and implications. In <i>Proc. SIGMOD 1998</i>, pp. 343-354.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276306</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[D. Tsur, J.D. Ullman, S. Abiteboul, C. Clifton, R. Motwani, S. Nestorov, and A. Rosenthal. Query flocks: a generalization of association-rule mining. In <i>Proc. SIGMOD 1998</i>, pp. 1-12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[M.J. Zaki and C.-J. Hsiao. CHARM: an efficient algorithm for closed itemset mining. In <i>Proc. SDM 2002</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106359</article_id>
		<sort_key>282</sort_key>
		<display_label></display_label>
		<pages>282-289</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[Combining Multiple Clusterings by Soft Correspondence]]></title>
		<page_from>282</page_from>
		<page_to>289</page_to>
		<doi_number>10.1109/ICDM.2005.45</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106359</url>
		<abstract>
			<par><![CDATA[Combining multiple clusterings arises in various important data mining scenarios. However, finding a consensus clustering from multiple clusterings is a challenging task because there is no explicit correspondence between the classes from different clusterings. We present a new framework based on soft correspondence to directly address the correspondence problem in combining multiple clusterings. Under this framework, we propose a novel algorithm that iteratively computes the consensus clustering and correspondence matrices using multiplicative updating rules. This algorithm provides a final consensus clustering as well as correspondence matrices that gives intuitive interpretation of the relations between the consensus clustering and each clustering from clustering ensembles. Extensive experimental evaluations also demonstrate the effectiveness and potential of this framework as well as the algorithm for discovering a consensus clustering from multiple clusterings.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15043822</person_id>
				<author_profile_id><![CDATA[81375607652]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Long]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State University of New York at Binghamton]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045489</person_id>
				<author_profile_id><![CDATA[81451593853]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zhongfei]]></first_name>
				<middle_name><![CDATA[(Mark)]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State University of New York at Binghamton]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[N. M. L. A. P. Dempster and D. B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. <i>Journal of the Royal Statistical Society</i>, 39(8):1-38, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A.K. Jain and R.C. Dubes. <i>Algorithms for Clustering Data</i>. Prentice-Hall, Englewood Cliffs, NJ, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033458</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. H. C. L. Alexander P. Topchy and A. K. Jain. Analysis of consensus partition in cluster ensemble. In ICDM'04, pages 1101-1111. 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D.D. Lee and H.S. Seung. Learning the parts of objects by non-negative matrix factorization. <i>Nature</i>, 401:788-791, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>686050</ref_obj_id>
				<ref_obj_pid>646258</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E. Dimitriadou, A. Weingessel, and K. Hornik. Voting-merging: An ensemble method for clustering. In <i>ICANN '01</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015414</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[X. Z. Fern and C. E. Brodley. Solving cluster ensemble problems by bipartite graph partitioning. In <i>ICML'04</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>766679</ref_obj_id>
				<ref_obj_pid>766664</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B. Fischer and J. M. Buhmann. Path-based clustering for grouping of smooth curves and texture segmentation. <i>IEEE Trans. Pattern Anal. Mach. Intell.</i>, 25(4):513-518, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. L. Fred and A. K. Jain. Data clustering using evidence accumulation. In <i>ICPR '02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>743949</ref_obj_id>
				<ref_obj_pid>648055</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. L. N. Fred. Finding consistent clusters in data partitions. In <i>Multiple Classifier Systems</i>, pages 309-318, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>266273</ref_obj_id>
				<ref_obj_pid>266021</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[G. Karypis, R. Aggarwal, V. Kumar, and S. Shekhar. Multilevel hypergraph partitioning: application in vlsi domain. In <i>DAC '97</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>305248</ref_obj_id>
				<ref_obj_pid>305219</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G. Karypis and V. Kumar. A fast and high quality multilevel scheme for partitioning irregular graphs. <i>SIAM J. Sci. Comput.</i>, 20(1):359-392, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. D. Lee and H. S. Seung. Algorithms for non-negative matrix factorization. In <i>NIPS</i>, pages 556-562, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[N. C. S. P. Kellam, X. Lin and A. Tucker. Comparing, contrasting and combining clusters in viral gene expression data. In <i>Proceedings of 6th Workshop on Intelligence Data Analysis in Medicine an Pharmocology</i>, pages 56-62, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S. Dudoit and J. Fridlyand. Bagging to improve the accuracy of a clustering procedure. <i>Bioinformatics</i>, 19(9):1090-1099, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>777110</ref_obj_id>
				<ref_obj_pid>777092</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[A. Strehl and J. Ghosh. Cluster ensembles - a knowledge reuse framework for combining partitionings. In <i>AAAI 2002</i>. AAAI/MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952159</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. Topchy, A. K. Jain, and W. Punch. Combining multiple weak clusterings. In <i>Proceedings of the Third IEEE International Conference on Data Mining</i>, page 331, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[A. Topchy, A. K. Jain, and W. Punch. A mixture model for clustering ensembles. In <i>proc. AIAM Data mining</i>, page 379, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106360</article_id>
		<sort_key>290</sort_key>
		<display_label></display_label>
		<pages>290-297</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[A New Algorithm for Finding Minimal Sample Uniques for Use in Statistical Disclosure Assessment]]></title>
		<page_from>290</page_from>
		<page_to>297</page_to>
		<doi_number>10.1109/ICDM.2005.10</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106360</url>
		<abstract>
			<par><![CDATA[We present SUDA2, a recursive algorithm for finding Minimal Sample Uniques (MSUs). SUDA2 uses a novel method for representing the search space forMSUs and new observations about the properties ofMSUs to prune and traverse this space. Experimental comparisons with previous work demonstrate that SUDA2 is not only several orders of magnitude faster but is also capable of identifying the boundaries of the search space, enabling datasets of larger numbers of columns than before to be addressed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Sorting and searching</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10003809.10011254.10011258</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Algorithm design techniques->Dynamic programming</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010213</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Control methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010031.10010033</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Data structures design and analysis->Sorting and searching</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041856</person_id>
				<author_profile_id><![CDATA[81100571239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Manning]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Manchester]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763000</person_id>
				<author_profile_id><![CDATA[81100157452]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Haglin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Minnesota State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases. In <i>Proceedings of the 1993 International Conference on Management of Data (SIGMOD 93)</i>, pages 207-216, May 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Arning, R. Agrawal, and P. Raghavan. A linear method for deviation detection in large databases. In <i>Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, Portland, Or.</i>, pages 164-169. AAAI Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Brankovic, M. Miller, and J. Siran. Towards a practical auditing method for the prevention of statistical database compromise. In <i>Proceedings of the Australasian Database Conference</i>, pages 177-184, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656386</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Burdick, M. Calimlim, and J. Gehrke. Mafia: A maximal frequent itemset algorithm for transactional databases. In <i>Proceedings ICDE 2001</i>, pages 443-452, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. J. Elliot. A new approach to the measurement of statistical disclosure risk. <i>International Journal of Risk Management</i>, 2(4), 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>774548</ref_obj_id>
				<ref_obj_pid>774544</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. J. Elliot, A. M. Manning, and R. W. Ford. A computational algorithm for handling the special uniques problem. <i>International Journal of Uncertainty, Fuzziness and Knowledge Based Systems</i>, 10(5):493-509, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>679107</ref_obj_id>
				<ref_obj_pid>646108</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[V. Estivill-Castro and L. Brankovic. Data swapping: Balancing privacy against precision in mining for logic rules. In <i>Proceedings of the First International Conference on Data Warehousing and Knowledge Discovery DaWak'99 (as a DEXA-Conference along with the 10th International Conference on Data and Expert Systems Applications) Florence, Italy</i>, pages 389-398, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. E. Fienberg and U. E. Makov. Confidentiality uniqueness and disclosure limitation for categorical data. <i>Journal of Official Statistics</i>, 4(4), 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[G. Merz and P. Murphy. Uci repository of machine learning databases. <i>Technical Report, University of California, Department of Information and Computer Science</i>: http://www.ics.uci.edu/mlearn/MLRepository.html, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[L. F. S. Labour force survey, available at: http//www.esds.ac.uk/government/lfs/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. A. R. S. The samples of anonymised records, available at: http//www.ccsr.ac.uk/sars/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[C. J. Skinner and D. J. Holmes. Estimating the reidentification risk per record. <i>Journal of Official Statistics</i>, 14(4):361-372, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. Takemura. Minimum unsafe and maximum safe sets of variables for disclosure risk assessment of individual records in a microdata set. <i>Journal of the Japan Statistical Society</i>, 32(1):107-117, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106361</article_id>
		<sort_key>298</sort_key>
		<display_label></display_label>
		<pages>298-305</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>44</seq_no>
		<title><![CDATA[Alternate Representation of Distance Matrices for Characterization of Protein Structure]]></title>
		<page_from>298</page_from>
		<page_to>305</page_to>
		<doi_number>10.1109/ICDM.2005.19</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106361</url>
		<abstract>
			<par><![CDATA[The most suitable method for the automated classification of protein structures remains an open problem in computational biology. In order to classify a protein structure with any accuracy, an effective representation must be chosen. Here we present two methods of representing protein structure. One involves representing the distances between the C&#225; atoms of a protein as a two-dimensional matrix and creating a model of the resulting surface with Zernike polynomials. The second uses a wavelet-based approach. We convert the distances between a protein's C&#945; atoms into a one-dimensional signal which is then decomposed using a discrete wavelet transformation. Using the Zernike co-efficients and the approximation coefficients of the wavelet decomposition as feature vectors, we test the effectiveness of our representation with two different classifiers on a dataset of more than 600 proteins taken from the 27 most-populated SCOP folds. We find that the wavelet decomposition greatly outperforms the Zernike model.With the wavelet representation, we achieve an accuracy of approximately 56%, roughly 12% higher than results reported on a similar, but less-challenging dataset. In addition, we can couple our structure-based feature vectors with several sequence-based properties to increase accuracy another 5-7%. Finally, we use a multi-stage classification strategy on the combined features to increase performance to 78%, an improvement in accuracy of more than 15-20% and 34% over the highest reported sequence-based and structure-based classification results, respectively.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040139</person_id>
				<author_profile_id><![CDATA[81309482038]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Keith]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Marsolo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043467</person_id>
				<author_profile_id><![CDATA[81100375834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Srinivasan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Parthasarathy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>998838</ref_obj_id>
				<ref_obj_pid>998667</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Z. Aung and K-L Tan. Automatic protein strutcture classification through structural fingerprinting. In <i>BIBE'04</i>. IEEE, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Chinnasamy, W. K. Sung, and A. Mittal. Protein structure and fold prediction using tree-augmented naive bayesian classifier. In <i>PSB'04</i>, Stanford, CA, 2004. World Scientific Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>130655</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[I. Daubechies. <i>Ten Lectures on Wavelets</i>. Soc. Indust. Appl. Math., Philadelphia, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. H. Q. Ding and I. Dubchak. Multi-class protein fold recognition using support vector machines and neural networks. <i>Bioinformatics</i>, 17(4):349-358, April 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[I. Dubchak, I. Muchnik, S. Holbrook, and S-H Kim. Prediction of protein folding class using global description of amino acid sequence. <i>PNAS</i>, 92:8700-8704, September 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R.E. Schapire. Experiments with a new boosting algorithm. In <i>ICML</i>, pages 148-146, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>757999</ref_obj_id>
				<ref_obj_pid>645631</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Gerstein and M. Levitt. Using iterative dynamic programming to obtain accurate pair-wise and multiple alignments of protein structures. In <i>Proc. Fourth Int. Conf. on Intell. Sys. for Mol. Biol</i>, pages 59-67, Menlo Park, CA, 1997. AAAI Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[L. Holm and C. Sander. Protein structure comparision by alignment of distance matrices. <i>J. Mol. Biol</i>, 233:123-138, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Huan, W. Wang, A. Washington, J. Prins, and A. Tropsha. Accurate classification of protein structure families using coherent subgraph analysis. In <i>PSB'04</i>, Stanford, CA, 2004. World Scientific Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[DR Iskander, M.J. Collins, and B. Davis. Optimal modeling of corneal surfaces with zernike polynomials. <i>IEEE TBME</i>, 48(1):87-95, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Andrew F. Laine. Wavelets in temporal and spatial processing of biomedical images. <i>Annu. Rev. Biomed. Eng.</i>, 02:511-550, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Mallat. <i>A Wavelet Tour of Signal Processing</i>. Academic, New York, 2nd edition, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1104670</ref_obj_id>
				<ref_obj_pid>1104657</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[K. Marsolo, S. Parthasarathy, and C. Ding. A multilevel approach to scop fold recognition. In <i>BIBE'05</i>. IEEE, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. G. Murzin, S. E. Brenner, T. Hubbard, and C. Chothia. Scop: a structural classification of proteins database for the investigation of sequences and structures. <i>J. Mol. Biol</i>, 247:536-540, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[C. A. Orengo, A. D. Michie, S. Jones, D. T. Jones, M. B. Swindells, and J. M. Thornton. Cath: A hierarchic classification of protein domain structures. <i>Structure</i>, 5(8):1093-1108, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J.R. Quinlan. <i>C4.5 : programs for machine learning</i>. Morgan Kaufmann Publishers, San Mateo, Calif., 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[O. R&#248;gen and B. Fain. Automatic classification of protein structure by using gauss integrals. <i>PNAS</i>, pages 119-124, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>640110</ref_obj_id>
				<ref_obj_pid>640075</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[F. Schwarzer and I. Lotan. Approximation of protein structure for fast similarity measure. In <i>RECOMB'03</i>. ACM, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. Schwiegerling, J. E. Greinvenkamp, and J. M. Miller. Representation of videokeratoscopic height data with zernike polynomials. <i>J. Opt. Soc. Am. A</i>, 12(10):2105- 2113, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. Y. M. Shi, P. N. Suganthan, and K. Deb. Multi-class protein fold recognition using multi-objective evolutionary algorithms. In <i>CIBCB</i>. IEEE, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[I. N. Shindyalov and P.E. Bourne. Modern protein structure alignment by incremental combinatorial extension (ce) of the optimal path. <i>Protein Eng.</i>, 11(9):739-747, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[A. C. Tan, D. Gilbert, and Y. Deville. Multi-class protein fold classification using a new ensemble machine learning approach. <i>Genome Informatics</i>, 14:206-217, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[M.D. Twa, S. Parthasarathy, T.W. Raasch, and M. Bullimore. Automated classification of keratoconus: A case study in analyzing clinical data. In <i>SIAM'03</i>, San Francisco, CA, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106362</article_id>
		<sort_key>306</sort_key>
		<display_label></display_label>
		<pages>306-313</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>45</seq_no>
		<title><![CDATA[Training Support Vector Machines Using Gilbert's Algorithm]]></title>
		<page_from>306</page_from>
		<page_to>313</page_to>
		<doi_number>10.1109/ICDM.2005.145</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106362</url>
		<abstract>
			<par><![CDATA[Support Vector Machines are classifiers designed around the computation of an optimal separating hyperplane. This hyperplane is typically obtained by solving a constrained quadratic programming problem, but may also be located by solving a nearest point problem. Gilbert's Algorithm can be used to solve this nearest point problem but is unreasonably slow. In this paper we present a modified version of Gilbert's Algorithm for the fast computation of the Support Vector Machine hyperplane. We then compare our algorithm with the Nearest Point Algorithm and with Sequential Minimal Optimization.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Support Vector Machines, Gilbert's Algorithm, Nearest Point Algorithm, Sequential Minimal Optimization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP43122680</person_id>
				<author_profile_id><![CDATA[81542831356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shawn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Martin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sandia National Laboratories]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Marcelo Barros de Almeida. SMOBR - a SMO program for SVMs. http://www.litc.cpdee.ufmg.br/~barros/svm/smobr, 2000. Computational Intelligence and Technology Laboratory.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[K. Bennett and E. J. Bredensteiner. Geometry in learning. In C. Gorini, editor, <i>Geometry at Work</i>, pages 132-145. Mathematical Association of America, Washington, D.C., 2000. Also at K. Bennett's Rensselaer Polytechnic Institute home page http://www.rpi.edu/~bennek.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>380999</ref_obj_id>
				<ref_obj_pid>380995</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K. P. Bennett and C. Campbell. Support vector machines: Hype or hallelujah? <i>SIGKDD Explorations</i>, 2(2):1-13, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[K. P. Bennett and O. L. Mangasarian. Robust linear programming discrimination of two linearly inseparable sets. <i>Optimization Methods and Software</i>, 1:23-34, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C.L. Blake and C.J. Merz. UCI repository of machine learning databases. http://www.ics.uci.edu/~mlearn/MLRepository.html, 1998. University of California, Irvine, Dept. of Information and Computer Sciences.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>130401</ref_obj_id>
				<ref_obj_pid>130385</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[B. E. Boser, I. M. Guyon, and V. N. Vapnik. A training algorithm for optimal margin classifiers. In D. Haussler, editor, <i>5th Annual ACM Workshop on COLT</i>, pages 144- 152, Pittsburgh, PA, 1992. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593463</ref_obj_id>
				<ref_obj_pid>593419</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. J. C. Burges. A Tutorial on Support Vector Machines for Pattern Recognition. <i>Knowledge Discovery and Data Mining</i>, 2(2), 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218929</ref_obj_id>
				<ref_obj_pid>218919</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. Cortes and V. Vapnik. Support vector networks. <i>Machine Learning</i>, 20:273-297, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T.-T. Frie&#223;, N. Cristianini, and C. Campbell. The kernel adatron algorithm: A fast and simple learning procedure for support vector machines. In N. Christianini and J. Shawe-Taylor, editors, <i>An Introduction to Support Vector Machines (and other kernel-based learning methods)</i>. Cambridge University Press, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. T. Frie&#223; and R. F. Harrison. Support vector neural networks: The kernel adatron with bias and soft margin. Technical Report AC&SE RR 725, University of Sheffield, England, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[E. G. Gilbert. An iterative procedure for computing the minimum of a quadratic form on a convex set. <i>SIAM Journal of Control</i>, 4(1), 1966.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299104</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. Making large-scale SVM learning practical. In B. Sch&#246;lkopf, C. J. C. Burges, and A. J. Smola, editors, <i>Advances in Kernel Methods -- Support Vector Learning</i>, pages 169-184, Cambridge, MA, 1999. MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Mark Kantrowitz. CMU artificial intelligence repository. http://www.cs.cmu.edu/afs/cs/project/airepository/ai/areas/neural/bench/0.html, 1993. Carnegie Mellon University School of Computer Science.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S. S. Keerthi. Sathiya Keerthi's home page. http://guppy.mpe.nus.edu.sg/~mpessk/npa.shtml, 1999. Dept. of Mechanical and Production Engineering, The National University of Singapore.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326533</ref_obj_id>
				<ref_obj_pid>2325771</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. S. Keerthi, S. K. Shevade, C. Bhattacharyya, and K. R. K. Murthy. A fast iterative nearest point algorithm for support vector machine classifier design. <i>IEEE-NN</i>, 11(1):124, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326467</ref_obj_id>
				<ref_obj_pid>2325769</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[O. L. Mangasarian and D. R. Musicant. Successive overrelaxation for support vector machines. <i>IEEE Transactions on Neural Networks</i>, 10:1032-1037, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[E. Osuna, R. Freund, and F. Girosi. An improved training algorithm for support vector machines. In J. Principe, L. Gile, N. Morgan, and E. Wilson, editors, <i>Neural Networks for Signal Processing VII -- Proceedings of the 1997 IEEE Workshop</i>, pages 276-285, New York, 1997. IEEE.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. Platt. John Platt's home page. http://www.research.microsoft.com/~jplatt/smo.html, 1998. Microsoft Research.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299105</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. Platt. Fast training of support vector machines using sequential minimal optimization. In B. Sch&#246;lkopf, C. J. C. Burges, and A. J. Smola, editors, <i>Advances in Kernel Methods -- Support Vector Learning</i>, pages 185-208, Cambridge, MA, 1999. MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[N. K. Sancheti and S. S. Keerthi. Computation of certain measures of proximity between convex polytopes: A complexity viewpoint. In <i>Proc. of IEEE International Conference on Robotics and Automation</i>, Nice, France, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1098680</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik. <i>Estimation of Dependences Based on Empirical Data {in Russian}</i>. Nauka, Moscow, 1979. (English translation: Springer Verlag, New York, 1982).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik. <i>Statistical Learning Theory</i>. Wiley Interscience, New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106363</article_id>
		<sort_key>314</sort_key>
		<display_label></display_label>
		<pages>314-321</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>46</seq_no>
		<title><![CDATA[A Heterogeneous Field Matching Method for Record Linkage]]></title>
		<page_from>314</page_from>
		<page_to>321</page_to>
		<doi_number>10.1109/ICDM.2005.7</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106363</url>
		<abstract>
			<par><![CDATA[Record linkage is the process of determining that two records refer to the same entity. A key subprocess is evaluating how well the individual fields, or attributes, of the records match each other. One approach to matching fields is to use hand-written domain-specific rules. This "expert systems" approach may result in good performance for specific applications, but it is not scalable. This paper describes a new machine learning approach that creates expert-like rules for field matching. In our approach, the relationship between two field values is described by a set of heterogeneous transformations. Previous machine learning methods used simple models to evaluate the distance between two fields. However, our approach enables more sophisticated relationships to be modeled, which better capture the complex domain specific, common-sense phenomena that humans use to judge similarity. We compare our approach to methods that rely on simpler homogeneous models in several domains. By modeling more complex relationships we produce more accurate results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P763154</person_id>
				<author_profile_id><![CDATA[81332515902]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Minton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fetch Technologies]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762998</person_id>
				<author_profile_id><![CDATA[81309500630]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Claude]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nanjo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fetch Technologies]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042537</person_id>
				<author_profile_id><![CDATA[81100628789]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Craig]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Knoblock]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042222</person_id>
				<author_profile_id><![CDATA[81343500805]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Michalowski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43122686</person_id>
				<author_profile_id><![CDATA[81342504521]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Michelson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>956759</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Bilenko and R. J. Mooney. Adaptive duplicate detection using learnable string similarity measures. In <i>Proceedings of ACM SIGKDD-03</i>, pages 39-48, Washington DC, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. Christen, T. Churches, and J. X. Zhu. Probabilistic name and address cleaning and standardization. In <i>Proceedings of the Australasian Data Mining Workshop</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W. Cohen, P. Ravikumar, and S. Feinberg. A comparison of string metrics for matching names and records. In <i>KDD- 2003 Workshop on Data Cleaning and Object Consolidation</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775116</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[W. W. Cohen and J. Richman. Learning to match and cluster large high-dimensional data sets for data integration. In <i>Proceedings of ACM SIGKDD-02</i>, pages 475-480, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223807</ref_obj_id>
				<ref_obj_pid>223784</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. A. Hernandez and S. J. Stolfo. The merge/purge problem for large databases. In <i>Proceedings of the ACM SIGMOD Conference</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622340</ref_obj_id>
				<ref_obj_pid>1622270</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Huang and S. J. Russell. Object identification in a bayesian context. In <i>IJCAI-97</i>, pages 1276-1283, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299104</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. Making large-scale support vector machine learning practical. In <i>Advances in Kernel Methods: Support Vector Machines</i>. MIT Press, Cambridge, MA, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. McCallum and B. Wellner. Conditional models of identity uncertainty with application to noun coreference. In <i>Neural Information Processing Systems (NIPS)</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. E. Monge and C. Elkan. The field matching problem: Algorithms and applications. In <i>Proceedings of ACM SIGKDD-96</i>, pages 267-270, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1036898</ref_obj_id>
				<ref_obj_pid>1036843</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. Ravikumar and W. W. Cohen. A hierarchical graphical model for record linkage. In <i>UAI 2004</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775087</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Sarawagi and A. Bhamidipaty. Interactive deduplication using active learning. In <i>Proceedings of ACM SIGKDD-02</i>, Edmonton, Alberta, Canada, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775099</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Tejada, C. A. Knoblock, and S. Minton. Learning domain-independent string transformation weights for high accuracy object identification. In <i>Proceedings of ACM SIGKDD-02</i>, Edmonton, Alberta, Canada, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106364</article_id>
		<sort_key>322</sort_key>
		<display_label></display_label>
		<pages>322-329</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>47</seq_no>
		<title><![CDATA[Leveraging Relational Autocorrelation with Latent Group Models]]></title>
		<page_from>322</page_from>
		<page_to>329</page_to>
		<doi_number>10.1109/ICDM.2005.89</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106364</url>
		<abstract>
			<par><![CDATA[The presence of autocorrelation provides a strong motivation for using relational learning and inference techniques. Autocorrelation is a statistical dependence between the values of the same variable on related entities and is a nearly ubiquitous characteristic of relational data sets. Recent research has explored the use of collective inference techniques to exploit this phenomenon. These techniques achieve significant performance gains by modeling observed correlations among class labels of related instances, but the models fail to capture a frequent cause of autocorrelation &#8212; the presence of underlying groups thatinfluence the attributes on a set of entities. We propose a latent group model (LGM) for relational data, which discovers and exploits the hidden structures responsible for the observed autocorrelation among class labels. Modeling the latent group structure improves model performance, increases inference efficiency, and enhances our understanding of the datasets. We evaluate performance on three relational classification tasks and show that LGM outperforms models that ignore latent group structure, particularly when there is little information with which to seed inference.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041241</person_id>
				<author_profile_id><![CDATA[81100563777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jennifer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Neville]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts at Amherst]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041652</person_id>
				<author_profile_id><![CDATA[81100640362]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts at Amherst]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>944937</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Blei, A. Ng, and M. Jordan. Latent Dirichlet allocation. <i>Journal of Machine Learning Research</i>, 3:993-1022, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276332</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. Chakrabarti, B. Dom, and P. Indyk. Enhanced hypertext categorization using hyperlinks. In <i>ACM SIGMOD 1998</i>, pages 307-318, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>295725</ref_obj_id>
				<ref_obj_pid>295240</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam, and S. Slattery. Learning to extract symbolic knowledge from the World Wide Web. In <i>AAAI- 1998</i>, pages 509-516, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Getoor, N. Friedman, D. Koller, and A. Pfeffer. Learning probabilistic relational models. In <i>Relational Data Mining</i>, pages 307-335. Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Hoff, A. Raftery, and M. Handcock. Latent space approaches to social network analysis. <i>Journal of the American Statistical Association</i>, 97:1090-1098, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655828</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Jensen and J. Neville. Linkage and autocorrelation cause feature selection bias in relational learning. In <i>ICML-2002</i>, pages 259-266, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014125</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Jensen, J. Neville, and B. Gallagher. Why collective inference improves relational classification. In <i>ACM SIGKDD 2004</i>, pages 593-598, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. Kemp, T. Griffiths, and J. Tenenbaum. Discovering latent classes in relational data. Technical Report AI Memo 2004- 019, Massachusetts Institute of Technology, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>315045</ref_obj_id>
				<ref_obj_pid>314613</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Kleinberg. Authoritative sources in a hyperlinked environment. In <i>the 9th ACM SIAM Symposium on Discrete Algorithms</i>, pages 25-27, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>777215</ref_obj_id>
				<ref_obj_pid>777092</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Kubica, A. Moore, J. Schneider, and Y. Yang. Stochastic link and group detection. In <i>AAAI-2002</i>, pages 798-806, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Q. Lu and L. Getoor. Link-based classification. In <i>ICML- 2003</i>, pages 496-503, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Macskassy and F. Provost. Classification in networked data: A toolkit and a univariate case study. Technical Report CeDER-04-08, Stern School of Business, NYU, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1624313</ref_obj_id>
				<ref_obj_pid>1624312</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. McCallum, K. Nigam, J. Rennie, and K. Seymore. A machine learning approach to building domain-specific search engines. In <i>IJCAI-1999</i>, pages 662-667, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[B. Milch, B. Marthi, D. Sontag, S. Russell, D. Ong, and A. Kolobov. Approximate inference for infinite contingent bayesian networks. In <i>AISTATS-2005</i>, pages 238-245, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033451</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. Neville and D. Jensen. Dependency networks for relational data. In <i>ICDM-2004</i>, pages 170-177, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956830</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J. Neville, D. Jensen, L. Friedland, and M. Hay. Learning relational probability trees. In <i>ACM SIGKDD 2003</i>, pages 625-630, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952090</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. Neville, D. Jensen, and B. Gallagher. Simple estimators for relational bayesian classifers. In <i>ICDM-2003</i>, pages 609-612, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[K. Nowicki and T. Snijders. Estimation and prediction for stochastic blockstructures. <i>Journal of the American Statistical Association</i>, 96:1077-1087, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014137</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[A. Popescul and L. Ungar. Cluster-based concept invention for statistical relational learning. In <i>ACM SIGKDD 2004</i>, pages 665-670, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>351611</ref_obj_id>
				<ref_obj_pid>351581</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J. Shi and J. Malik. Normalized cuts and image segmentation. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 22(8):888-905, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658281</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[S. Slattery and T. Mitchell. Discovering test set regularities in relational domains. In <i>ICML-2000</i>, pages 895-902, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[I. Stahl. Predicate invention in inductive logic programming. In <i>Advances in Inductive Logic Programming</i>, pages 34-47. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2073934</ref_obj_id>
				<ref_obj_pid>2073876</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[B. Taskar, P. Abbeel, and D. Koller. Discriminative probabilistic models for relational data. In <i>UAI-2002</i>, pages 485- 492, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642210</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[B. Taskar, E. Segal, and D. Koller. Probabilistic classification and clustering in relational data. In <i>IJCAI-2001</i>, pages 870-878, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[A. Wolfe and D. Jensen. Playing multiple roles: Discovering overlapping roles in social networks. In <i>the Workshop on Statistical Relational Learning, ICML-2004</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106365</article_id>
		<sort_key>330</sort_key>
		<display_label></display_label>
		<pages>330-337</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>48</seq_no>
		<title><![CDATA[Balancing Exploration and Exploitation]]></title>
		<subtitle><![CDATA[A New Algorithm for Active Machine Learning]]></subtitle>
		<page_from>330</page_from>
		<page_to>337</page_to>
		<doi_number>10.1109/ICDM.2005.33</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106365</url>
		<abstract>
			<par><![CDATA[Active machine learning algorithms are used when large numbers of unlabeled examples are available and getting labels for them is costly (e.g. requiring consulting a human expert). Many conventional active learning algorithms focus on refining the decision boundary, at the expense of exploring new regions that the current hypothesis misclassifies.We propose a new active learning algorithm that balances such exploration with refining of the decision boundary by dynamically adjusting the probability to explore at each step. Our experimental results demonstrate improved performance on data sets that require extensive exploration while remaining competitive on data sets that do not. Our algorithm also shows significant tolerance of noise.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763164</person_id>
				<author_profile_id><![CDATA[81536765256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Osugi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Nebraska]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763010</person_id>
				<author_profile_id><![CDATA[81309494319]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Deng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Nebraska]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040419</person_id>
				<author_profile_id><![CDATA[81452610402]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scott]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Nebraska]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1005342</ref_obj_id>
				<ref_obj_pid>1005332</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Y. Baram, R. El-Yaniv, and K. Luz. Online choice of active learning algorithms. <i>Journal of Machine Learning Research</i>, 5(Mar):255-291, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Blake, E. Keogh, and C. J. Merz. UCI repository of machine learning databases, 2005. http://www.ics.uci.edu/~mlearn/MLRepository.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007539</ref_obj_id>
				<ref_obj_pid>1007512</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. F. Bowring, J. M. Rehg, and M. J. Harrold. Active learning for automatic classification of software behavior. In <i>Proceedings of the International Symposium on Software Testing and Analysis</i>, pages 195-205, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[K. Brinker. Incorporating diversity in active learning with support vector machines. In <i>Proc. of the 20th International Conference on Machine Learning</i>, pages 59-66, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657959</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Campbell, N. Cristianini, and A. Smola. Query learning with large margin classifiers. In <i>Proceedings of the 17th Intl. Conf. on Machine Learning</i>, pages 111-118, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>263123</ref_obj_id>
				<ref_obj_pid>263100</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Freund, H. S. Seung, E. Shamir, and N. Tishby. Selective sampling using the query by committee algorithm. <i>Machine Learning</i>, 28:133-168, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Hakkani-T&#252;r, G. Riccardi, and A. Gorin. Active learning for automatic speech recognition. In <i>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</i>, volume 4, pages 3904-3907, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. Hakkani-T&#252;r, G. T&#252;r, M. Rahim, and G. Riccardi. Unsupervised and active learning in automatic speech recognition for call classification. In <i>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</i>, pages 429-432, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347110</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[V. S. Iyengar, C. Apte, and T. Zhang. Active learning using adaptive resampling. In <i>Proceedings of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 91-98, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. Kalai and S. Vempala. Efficient algorithms for online decision problems. In <i>Proceedings of the 16th Annual Conference on Learning Theory</i>, pages 26-40, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>965018</ref_obj_id>
				<ref_obj_pid>965001</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Lindenbaum, S. Markovitch, and D. Rusakov. Selective sampling for nearest neighbor classifiers. <i>Machine Learning</i>, 54:125-152, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1088692</ref_obj_id>
				<ref_obj_pid>1046920</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. Luo, K. Kramer, D. B. Goldgof, L. O. Hall, S. Samson, A. Remsen, and T. Hopkins. Active learning to recognize multiple types of plankton. <i>Journal of Machine Learning Research</i>, 6(Apr):589-613, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>968856</ref_obj_id>
				<ref_obj_pid>968725</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[P. Mitra, C. A. Murthy, and S. K. Pal. A probabilistic active support vector learning algorithm. <i>IEEE Trans. on Pattern Analysis and Machine Intelligence</i>, 26(3):413-418, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015349</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[H. T. Nguyen and A. Smeulders. Active learning using preclustering. In <i>Proceedings of the 21st International Conference on Machine Learning</i>, pages 623-630, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1066689</ref_obj_id>
				<ref_obj_pid>1066677</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[G. Pandey, H. Gupta, and P. Mitra. Stochastic scheduling of active support vector learning algorithms. In <i>Proc. of the ACM Symp. on Applied Computing</i>, pages 38-42, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1018360</ref_obj_id>
				<ref_obj_pid>1018034</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J.-M. Park. Convergence and application of online active sampling using orthogonal pillar vectors. <i>IEEE Trans. on Patt. Anal. and Mach. Intell.</i>, 26(9):1197-1207, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655646</ref_obj_id>
				<ref_obj_pid>645530</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[N. Roy and A. McCallum. Toward optimal active learning through sampling estimation of error reduction. In <i>Proceedings of the 18th International Conference on Machine Learning</i>, pages 441-448, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657802</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[G. Schohn and D. Cohn. Less is more: Active learning with support vector machines. In <i>Proceedings of the 17th Intl. Conf. on Machine Learning</i>, pages 839-846, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>130417</ref_obj_id>
				<ref_obj_pid>130385</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[H. S. Seung, M. Opper, and H. Sompolinsky. Query by committee. In <i>Proc. 5th Annu. Workshop on Comput. Learning Theory</i>, pages 287-294. ACM Press, New York, NY, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944793</ref_obj_id>
				<ref_obj_pid>944790</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. Tong and D. Koller. Support vector machine active learning with applications to text classification. <i>Journal of Machine Learning Research</i>, 2(Nov):45-66, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106366</article_id>
		<sort_key>338</sort_key>
		<display_label></display_label>
		<pages>338-345</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>49</seq_no>
		<title><![CDATA[Finding Representative Set from Massive Data]]></title>
		<page_from>338</page_from>
		<page_to>345</page_to>
		<doi_number>10.1109/ICDM.2005.69</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106366</url>
		<abstract>
			<par><![CDATA[In the information age, data is pervasive. In some applications, data explosion is a significant phenomenon. The massive data volume poses challenges to both human users and computers. In this project, we propose a new model for identifying representative set from a large database. A representative set is a special subset of the original dataset, which has three main characteristics: It is significantly smaller in size compared to the original dataset. It captures the most information from the original dataset compared to other subsets of the same size. It has low redundancy among the representatives it contains. We use information-theoretic measures such as mutual information and relative entropy to measure the representativeness of the representative set. We first design a greedy algorithm and then present a heuristic algorithm that delivers much better performance. We run experiments on two real datasets and evaluate the effectiveness of our representative set in terms of coverage and accuracy. The experiments show that our representative set attains expected characteristics and captures information more efficiently.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.1.1</cat_node>
				<descriptor>Information theory</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003712</concept_id>
				<concept_desc>CCS->Mathematics of computing->Information theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040908</person_id>
				<author_profile_id><![CDATA[81100484594]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Feng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044834</person_id>
				<author_profile_id><![CDATA[81452601906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P524170</person_id>
				<author_profile_id><![CDATA[81100486586]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[K.  H.]]></middle_name>
				<last_name><![CDATA[Tung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP55042339</person_id>
				<author_profile_id><![CDATA[81350589969]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jiong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Case Western Reserve University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[P. Andritsos, P. Tsaparas, R. J. Miller, and K. C. Sevcik. Limbo: Scalable clustering of categorical data. <i>Hellenic Database Symposium</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014062</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. Basu, M. Bilenko, and R. J. Mooney. A probabilistic framework for semi-supervised clustering. <i>KDD'04 Proceedings</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>129837</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. M. Cover and J. A. Thomas. <i>Elements of Information Theory</i>. Wiley, New York, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944973</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon, S. Mallela, and R. Kumar. A divisive information-theoretic feature clustering algorithm for text classification. <i>Jounal of Machine Learning Research</i>, (3):1265-1287, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. Hastie, R. Tibshirani, and J. Friedman. <i>The Elements of Statistical Learning</i>. Springer-Verlag, New York, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014078</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Kumar, U. Mahadevan, and D. Sivakumar. A graphtheoretic approach to extract storylines from search results. <i>KDD'04 Proceedings</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[F. Pan, W. Wang, A. K. H. Tung, and J. Yang. Finding representative set from massive data. <i>Technical Report: TR05- 014</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>796585</ref_obj_id>
				<ref_obj_pid>795666</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. V. R. Kannan and A. Veta. On clusterings: good, bad, and spectral. In <i>IEEE Annual Symposium on Foundations of Computer Science</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. S. Hochbaum and A. Pathria. Analysis of the greedy approach in problems of maximum k-coverage. <i>Naval Research Quarterly</i>, (45):615-627, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345578</ref_obj_id>
				<ref_obj_pid>345508</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[N. Slonim and N. Tishby. Document clustering using word clusters via the information bottleneck method. <i>ACM SIGIR 2000</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033460</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Wang and G. Karypis. Summary: Efficiently summarizing transactions for clustering. <i>ICDM'04 Proceedings</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106367</article_id>
		<sort_key>346</sort_key>
		<display_label></display_label>
		<pages>346-353</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>50</seq_no>
		<title><![CDATA[Parameter-Free Spatial Data Mining Using MDL]]></title>
		<page_from>346</page_from>
		<page_to>353</page_to>
		<doi_number>10.1109/ICDM.2005.117</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106367</url>
		<abstract>
			<par><![CDATA[Consider spatial data consisting of a set of binary features taking values over a collection of spatial extents (grid cells). We propose a method that simultaneously finds spatial correlation and feature co-occurrence patterns, without any parameters. In particular, we employ the Minimum Description Length (MDL) principle coupled with a natural way of compressing regions. This defines what "good" means: a feature co-occurrence pattern is good, if it helps us better compress the set of locations for these features. Conversely, a spatial correlation is good, if it helps us better compress the set of features in the corresponding region. Our approach is scalable for large datasets (both number of locations and of features). We evaluate our method on both real and synthetic datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Structural</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15038030</person_id>
				<author_profile_id><![CDATA[81100631405]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Spiros]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Papadimitriou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39051588</person_id>
				<author_profile_id><![CDATA[81100631289]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Aristides]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gionis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Helsinki]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P314388</person_id>
				<author_profile_id><![CDATA[81100152625]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Panayiotis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsaparas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Helsinki]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763134</person_id>
				<author_profile_id><![CDATA[81309498878]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Risto]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Vaisanen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Helsinki]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P108656</person_id>
				<author_profile_id><![CDATA[81100086722]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Heikki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mannila]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Helsinki]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15030495</person_id>
				<author_profile_id><![CDATA[81100373169]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Christos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Faloutsos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In <i>VLDB</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. Andritsos, P. Tsaparas, R. Miller, and K. Sevcik. LIMBO: Scalable clustering for categorical data. In <i>EDBT</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014062</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Basu, M. Bilenko, and R. J. Mooney. A probabilistic framework for semi-supervised clustering. In <i>KDD</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014064</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Chakrabarti, S. Papadimitriou, D. Modha, and C. Faloutsos. Fully automatic cross-associations. In <i>KDD</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>129837</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. M. Cover and J. A. Thomas. <i>Elements of Information Theory</i>. Wiley-Interscience, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956764</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon, S. Mallela, and D. S. Modha. Information-theoretic co-clustering. In <i>KDD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>370699</ref_obj_id>
				<ref_obj_pid>370660</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon and D. S. Modha. Concept decompositions for large sparse text data using clustering. <i>Mach. Learning</i>, 42, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P. Gr&#252;nwald. A tutorial introduction to the minimum description length principle. In <i>Advances in Minimum Description Length: Theory and Applications</i>. MIT Press, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276312</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Guha, R. Rastogi, and K. Shim. CURE: an efficient clustering algorithm for large databases. In <i>SIGMOD</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[G. Hamerly and C. Elkan. Learning the <i>k</i> in <i>k</i>-means. In <i>NIPS</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>355013</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Han and M. Kamber. <i>Data Mining: Concepts and Techniques</i>. Morgan Kaufmann, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>954525</ref_obj_id>
				<ref_obj_pid>954514</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, Y. Yin, and R. Mao. Mining frequent patterns without candidate generation: A frequent-pattern tree approach. <i>Data Min. Knowl. Discov.</i>, 8(1):53-87, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[T. Hastie, R. Tibshirani, and J. Friedman. <i>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</i>. Springer, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. Hinneburg and D. A. Keim. An efficient approach to clustering in large multimedia databases with noise. In <i>KDD</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952630</ref_obj_id>
				<ref_obj_pid>952532</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Y. Huang, H. Xiong, S. Shekhar, and J. Pei. Mining confident co-location rules without a support threshold. In <i>SAC</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>621303</ref_obj_id>
				<ref_obj_pid>619043</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[G. Karypis, E.-H. Han, and V. Kumar. Chameleon: Hierarchical clustering using dynamic modeling. <i>IEEE Computer</i>, 32(8), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>509086</ref_obj_id>
				<ref_obj_pid>509058</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[G. Karypis and V. Kumar. Multilevel algorithms for multiconstraint graph partitioning. In <i>SC98</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014077</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, S. Lonardi, and C. A. Ratanamahatana. Towards parameter-free data mining. In <i>KDD</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>585268</ref_obj_id>
				<ref_obj_pid>585265</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. Kleinberg and E. Tardos. Approximation algorithms for classification problems with pairwise relationships: Metric labeling and Markov random fields. <i>JACM</i>, 49(5):616-639, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[A. Leino, H. Mannila, and R. L. Pitk&#228;nen. Rule discovery and probabilistic modeling for onomastic data. In <i>PKDD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[N. Mishra, D. Ron, and R. Swaminathan. On finding large conjunctive clusters. In <i>COLT</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral clustering: Analysis and an algorithm. In <i>NIPS</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657808</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[D. Pelleg and A. Moore. X-means: Extending K-means with efficient estimation of the number of clusters. In <i>ICML</i>, pages 727-734, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[R. B. Potts. Some generalized order-disorder transformations. <i>Proc. Camb. Phil. Soc.</i>, 48:106, 1952.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>885478</ref_obj_id>
				<ref_obj_pid>882513</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[P. K. Reddy and M. Kitsuregawa. An approach to relate the web communities through bipartite graphs. In <i>WISE</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1664217</ref_obj_id>
				<ref_obj_pid>1664211</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[J. Rissanen and G. G. Langdon Jr. Arithmetic coding. <i>IBM J. Res. Dev.</i>, 23:149-162, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033518</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[M. Salmenkivi. Evaluating attraction in spatial point patterns with an application in the field of cultural history. In <i>ICDM</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[D. J. Vaisey and A. Gersho. Variable block-size image coding. In <i>ICASSP</i>, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1896365</ref_obj_id>
				<ref_obj_pid>1896300</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[R. Zabih and V. Kolmogorov. Spatially coherent clustering with graph cuts. In <i>CVPR</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672960</ref_obj_id>
				<ref_obj_pid>645905</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[B. Zhang, M. Hsu, and U. Dayal. K-harmonic means--a spatial clustering algorithm with boosting. In <i>TSDM</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233324</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[T. Zhang, R. Ramakrishnan, and M. Livny. BIRCH: An efficient data clustering method for very large databases. In <i>SIGMOD</i>, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014095</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[X. Zhang, N. Mamoulis, D. W. Cheung, and Y. Shou. Fast mining of spatial collocations. In <i>KDD</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106368</article_id>
		<sort_key>354</sort_key>
		<display_label></display_label>
		<pages>354-361</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>51</seq_no>
		<title><![CDATA[Discovering Frequent Arrangements of Temporal Intervals]]></title>
		<page_from>354</page_from>
		<page_to>361</page_to>
		<doi_number>10.1109/ICDM.2005.50</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106368</url>
		<abstract>
			<par><![CDATA[In this paper we study a new problem in temporal pattern mining: discovering frequent arrangements of temporal intervals. We assume that the database consists of sequences of events, where an event occurs during a time-interval. The goal is to mine arrangements of event intervals that appear frequently in the database. There are many applications where these type of patterns can be useful, including data network, scientific, and financial applications. Efficient methods to find frequent arrangements of temporal intervals using both breadth first and depth first search techniques are described. The performance of the proposed algorithms is evaluated and compared with other approaches on real datasets (American Sign Language streams and network data) and large synthetic datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>E.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011024.10011028</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language features->Data types and structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763118</person_id>
				<author_profile_id><![CDATA[81309502280]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Panagiotis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Papapetrou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Boston University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045233</person_id>
				<author_profile_id><![CDATA[81339510233]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kollios]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Boston University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43131667</person_id>
				<author_profile_id><![CDATA[81332525857]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sclaroff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Boston University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40028104</person_id>
				<author_profile_id><![CDATA[81100515024]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dimitrios]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gunopulos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Riverside]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>728185</ref_obj_id>
				<ref_obj_pid>647522</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Abraham and J. F. Roddick. Incremental meta-mining from large temporal data sets. In <i>ER '98: Proceedings of the Workshops on Data Warehousing and Data Mining</i>, pages 41-54, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. of VLDB</i>, pages 487-499, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Mining sequential patterns. In <i>Proc. of IEEE ICDE</i>, pages 3-14, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>898266</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J.F. Allen and G. Ferguson. Actions and events in interval temporal logic. Technical Report 521, The University of Rochester, July 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775109</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Ayres, J. Gehrke, T. Yiu, and J. Flannick. Sequential pattern mining using a bitmap representation. In <i>Proc. of ACM SIGKDD</i>, pages 429-435, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276313</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. J. Bayardo. Efficiently mining long patterns from databases. In <i>Proc. of ACM SIGMOD</i>, pages 85-93, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656386</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Burdick, M. Calimlim, and J. Gehrke. Mafia: A maximal frequent itemset algorithm for transactional databases. In <i>Proc. of IEEE ICDE</i>, pages 443-452, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669495</ref_obj_id>
				<ref_obj_pid>645803</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[X. Chen and I. Petrounias. Mining temporal features in association rules. In <i>Proc. of PKDD</i>, pages 295-300, London, UK, 1999. Springer-Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656379</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Fei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, U. Dayal, and M.-C. Hsu. Prefixspan: Mining sequential patterns efficiently by prefix-projected pattern growth. In <i>Proc. of IEEE ICDE</i>, pages 215-224, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671514</ref_obj_id>
				<ref_obj_pid>645925</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Garofalakis, R. Rastogi, and K. Shim. Spirit: Sequential pattern mining with regular expression constraints. In <i>Proc. of VLDB</i>, pages 223-234, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347167</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, B. Mortazavi-Asl, Q. Chen, U. Dayal, and M.C. Hsu. Freespan: Frequent pattern-projected sequential pattern mining. In <i>Proc. of ACM SIGKDD</i>, pages 355-359, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>Proc. of ACM SIGMOD</i>, pages 1- 12, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1759582</ref_obj_id>
				<ref_obj_pid>1759548</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M. Leleu, Ch. Rigotti, J. Boulicaut, and G. Euvrard. Gospade: Mining sequential patterns over databases with consecutive repetitions. In <i>Proc. of MLDM</i>, pages 293-306, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[H. Mannila, H. Toivonen, and A. Verkamo. Discovering frequent episodes in sequences. In <i>Proc. of ACM SIGKDD</i>, pages 210-215, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[C. Neidle, S. Sclaroff, and V. Athitsos. Signstream: A tool for linguistic and computer vision research on visual-gestural language data. <i>Behavior Research Methods, Instruments and Computers</i>, 33:311-320, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656256</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets for association rules. In <i>Proc. of ICDT</i>, pages 398-416, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and R. Mao. Closet: An efficient algorithm for mining frequent closed itemsets. In <i>Proc. of DMKD</i>, pages 11-20, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>584799</ref_obj_id>
				<ref_obj_pid>584792</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and W. Wang. Constraint-based sequential pattern mining in large databases. In <i>Proc. of CIKM</i>, pages 18-25, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844726</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[M. Seno and G. Karypis. Slpminer: An algorithm for finding frequent sequential patterns using length-decreasing support constraint. In <i>Proc. of IEEE ICDM</i>, pages 418-425, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>719225</ref_obj_id>
				<ref_obj_pid>647227</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[I. Tsoukatos and D. Gunopulos. Efficient mining of spatiotemporal patterns. In <i>Proc. of the SSTD</i>, pages 425-442, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>978142</ref_obj_id>
				<ref_obj_pid>977401</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. Wang and J. Han. Bide: Efficient mining of frequent closed sequences. In <i>Proc. of IEEE ICDE</i>, pages 79-90, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956779</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[J. Wang, J. Han, and J. Pei. Closet+: Scalable and spacesaving closed itemset mining. In <i>Proc. of ACM SIGKDD</i>, pages 236-245, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[X. Yan, J. Han, and R. Afshar. Clospan: Mining closed sequential patterns in large databases. In <i>Proc. of SDM</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>370671</ref_obj_id>
				<ref_obj_pid>370660</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[M. Zaki. Spade: An efficient algorithm for mining frequent sequences. <i>Machine Learning</i>, 40:31-60, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[M. Zaki and C. Hsiao. Charm: An efficient algorithm for closed itemset mining. In <i>Proc. of SIAM</i>, pages 457-473, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106369</article_id>
		<sort_key>362</sort_key>
		<display_label></display_label>
		<pages>362-369</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>52</seq_no>
		<title><![CDATA[Mining Patterns of Change in Remote Sensing Image Databases]]></title>
		<page_from>362</page_from>
		<page_to>369</page_to>
		<doi_number>10.1109/ICDM.2005.98</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106369</url>
		<abstract>
			<par><![CDATA[Remote sensing image databases are the fastest growing archives of spatial information. However, we still have a limited capacity for extracting information from large remote sensing image databases. There are currently very few techniques for image data mining and information extraction in large image data sets, and thus we are failing to exploit our large remote sensing data archives. This paper proposes a methodology to provide guidance for mining remote sensing image databases. The basic idea is to use domain concepts to build generic description of patterns in remote sensing images, and then use structural approaches to identify such patterns in images. We illustrate our proposal with a case study for detecting land use patterns in Amazonia from INPE's remote sensing image database.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Structural</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Signal processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Image databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010382.10010383</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation->Image processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10003247</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Signal processing systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003253</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Multimedia databases</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P763091</person_id>
				<author_profile_id><![CDATA[81309493025]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marcelino]]></first_name>
				<middle_name><![CDATA[Pereira S.]]></middle_name>
				<last_name><![CDATA[Silva]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rio Grande do Norte State University and National Institute for Space Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041644</person_id>
				<author_profile_id><![CDATA[81100352097]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gilberto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Camara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institute for Space Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763133</person_id>
				<author_profile_id><![CDATA[81309485922]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ricardo]]></first_name>
				<middle_name><![CDATA[Cartaxo M.]]></middle_name>
				<last_name><![CDATA[Souza]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institute for Space Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763004</person_id>
				<author_profile_id><![CDATA[81309488132]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dalton]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Valeriano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institute for Space Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763092</person_id>
				<author_profile_id><![CDATA[81388593401]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Maria]]></first_name>
				<middle_name><![CDATA[Isabel S.]]></middle_name>
				<last_name><![CDATA[Escada]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institute for Space Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Datcu, M., et al., Information Mining in Remote Sensing Image Archives - Part A: System Concepts. IEEE Trans. on Geoscience and Remote Sensing, 2003. 41(2923-2936).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357873</ref_obj_id>
				<ref_obj_pid>357871</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Smeulders, A.W.M., et al., Content-Based Image Retrieval at the End of the Early Years. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000. 22(12): p. 1349-1380.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Rui, Y., T.S. Huang, and S.-F. Chang, Image retrieval: current techniques, promising directions and open issues. Journal of Visual Communication and Image Representation, 1999. 10: p. 39-62.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507505</ref_obj_id>
				<ref_obj_pid>507503</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Wang, J.Z., J. Li, and G. Wiederhold, SIMPLIcity: Semantics-sensitive Integrated Matching for Picture LIbraries. IEEE Trans. on Pattern Analysis and Machine Intelligence, 2001. 23(9): p. 947-963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Wang, L., L. Khan, and C. Breen. Object Boundary Detection for Ontology-based Image Classification. in Third International Workshop on Multimedia Data Mining. 2002. Edmonton, Alberta, Canada: ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1016789</ref_obj_id>
				<ref_obj_pid>1005332</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Chen, Y. and J.Z. Wang, Image Categorization by Learning and Reasoning with Regions. Journal of Machine Learning Research, 2004. 5: p. 913-939.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1016913</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Aksoy, S., et al. Interactive Training of Advanced Classifiers for Mining Remote Sensing Image Archives. in ACM International Conference on Knowledge Discovery and Data Mining. 2004. Seattle, WA: ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1650451</ref_obj_id>
				<ref_obj_pid>1650405</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Rushing, J., et al., ADaM: A Data Mining Toolkit for Scientists and Engineers. Computers and Geosciences, In Press, Available online 11 January 2005, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Schr&#246;der, M., et al., Interactive Learning and Probabilistic Retrieval in Remote Sensing Image Archives. IEEE Trans. on Geoscience and Remote Sensing, 2000. 23(9): p. 2288-2298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lambin, E.F., H.J. Geist, and E. Lepers, Dynamics of land-use and land-cover change in Tropical Regions. Annual Review of Environment and Resources, 2003. 28: p. 205- 241.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Chen, Y., J.Z. Wang, and R. Krovetz. CLUE: Cluster-based Retrieval of Images by Unsupervised Learning. in Seventh International Symposium on Signal Processing and its Applications. 2003. Paris: IEEE.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Schober, J.-P., T. Hermes, and O. Herzog. Content-based Image Retrieval by Ontology-based Object Recognition. in KI-2004 Workshop on Applications of Description Logics (ADL-2004). 2004. Ulm, Germany.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Fonseca, F., et al., Using Ontologies for Integrated Geographic Information Systems. Transactions in GIS, 2002. 6(3): p. 231-257.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>681083</ref_obj_id>
				<ref_obj_pid>646128</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C&#226;mara, G., et al., What's In An Image?, in Spatial Information Theory: Foundations of Geographic Information Science. International Conference, COSIT 2001., D. Montello, Editor. 2001, Springer: Santa Barbara, CA. p. 474- 487.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Alves, D., et al., Land use intensification and abandonment in Rond&#244;nia, Brazilian Amaz&#244;nia. International Journal of Remote Sensing, 2003. 24(4): p. 899-903.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Pekkarinen, A., A method for the segmentation of very high spatial resolution images of forested landscapes. International Journal of Remote Sensing, 2002. 23(14): p. 2817-2836.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Meinel, G. and M. Neubert, A comparison of segmentation programs for high resolution remote sensing data. International Archives of Photogrammetry and Remote Sensing, 2004. XXXV(Part B): p. 1097-1105.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Zucker, S.W., Region growing: childhood and adolescence. Computer Graphics and Image Processing, 1976. 15: p. 382-399.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Bins, L., L. Fonseca, and G. Erthal. Satellite Imagery Segmentation: a region growing approach. in VIII Brazilian Symposium on Remote Sensing. 1996. S&#227;o Jos&#233; dos Campos, BR: INPE.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[C&#226;mara, G., et al., SPRING: Integrating Remote Sensing and GIS with Object-Oriented Data Modelling. Computers and Graphics, 1996. 15(6): p. 13-22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Shimabukuro, Y., et al., Using shade fraction image segmentation to evaluate deforestation in Landsat Thematic Mapper images of the Amazon region. International Journal of Remote Sensing, 1998. 19(3): p. 535-541.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Bins, L., et al. Satellite Imagery Segmentation: a Region Growing Approach. in VIII Brazilian Symposium on Remote Sensing. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Quinlan, R., C4.5: Programs for Machine Learning. 1993, San Francisco: Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323651</ref_obj_id>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Witten, I.H. and H. Frank, Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. 1999, San Francisco: Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Quinlan, R., C4.5: Programs for Machine Learning. 1993, San Francisco: Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Turner, M.G., Landscape Ecology: The effect of Pattern on Process. Annual Review of Ecology and Systematics, 1989. 20: p. 171-197.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[McGarigal, K., Landscape pattern metrics, in Encyclopedia of Environmentrics, A.H. El-Shaarawi and W.W. Piegorsch, Editors. 2002, John Wiley & Sons: Sussex, England. p. 1135-1142.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[McGarigal, K. and B. Marks, FRAGSTATS: spatial pattern analysis program for quantifying landscape structure. 1995, USDA Forestry Service Technical Report PNW-351: Washington, DC.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[INPE, National Institute for Space Research: Prodes Project - Brazilian Amazon Forest Monitoring using Satellites. 2005. URL: http://www.obt.inpe.br/prodes/]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106370</article_id>
		<sort_key>370</sort_key>
		<display_label></display_label>
		<pages>370-377</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>53</seq_no>
		<title><![CDATA[Ranking-Based Evaluation of Regression Models]]></title>
		<page_from>370</page_from>
		<page_to>377</page_to>
		<doi_number>10.1109/ICDM.2005.126</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106370</url>
		<abstract>
			<par><![CDATA[We suggest the use of ranking-based evaluation measures for regression models, as a complement to the commonly used residual-based evaluation. We argue that in some cases, such as the case study we present, ranking can be the main underlying goal in building a regression model, and ranking performance is the correct evaluation metric. However, even when ranking is not the contextually correct performance metric, the measures we explore still have significant advantages: They are robust against extreme outliers in the evaluation set; and they are interpretable. The two measures we consider correspond closely to non-parametric correlation coefficients commonly used in data analysis (Spearman's &#961; and Kendall's &#964;); and they both have interesting graphical representations, which, similarly to ROC curves, offer useful "partial" model performance views, in addition to a one-number summary in the area under the curve. We illustrate our methods on a case study of evaluating IT Wallet size estimation models for IBM's customers.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Correlation and regression analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Statistical computing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003698</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Statistical graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003736.10003737</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Functional analysis->Approximation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003636</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Approximation algorithms analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003691</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Regression analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010309.10010313</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Factorization methods->Canonical correlation analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15043856</person_id>
				<author_profile_id><![CDATA[81100549576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Saharon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rosset]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042252</person_id>
				<author_profile_id><![CDATA[81100228392]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Claudia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perlich]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043306</person_id>
				<author_profile_id><![CDATA[81100278691]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bianca]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zadrozny]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Bi and K. P. Bennett. Regression error characteristic curves. In <i>Proceedings of ICML-03</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1746434</ref_obj_id>
				<ref_obj_pid>1746432</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. P. Bradley. The use of the area under the ROC curve in the evaluation of machine learning algorithms. <i>Pattern Recognition</i>, 30(7):1145-1159, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Egan. <i>Signal Detection Theory and ROC Analysis</i>. Academic Press, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Garland. Share of wallet's role in customer profitability. <i>Journal of Financial Services Marketing</i>, 8(3):259-268, March 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[F. R. Hampel, E. M. Ronchetti, P. J. Rousseeuw, and W. A. Stahel. <i>Robust Statistics: The Approach Based on Influence Functions</i>. Wiley & Sons, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Kendall and J. M. Gibbons. <i>Rank Correlation Methods</i>. Edward Arnold, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[N. E. Noether. <i>Elements of Nonparametric Statistics</i>. Wiley and Sons, 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik. <i>The Nature of Statistical Learning Theory</i>. Springer, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106371</article_id>
		<sort_key>378</sort_key>
		<display_label></display_label>
		<pages>378-385</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>54</seq_no>
		<title><![CDATA[Compound Classification Models for Recommender Systems]]></title>
		<page_from>378</page_from>
		<page_to>385</page_to>
		<doi_number>10.1109/ICDM.2005.46</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106371</url>
		<abstract>
			<par><![CDATA[Recommender systems recommend products to customers based on ratings or past customer behavior. Without any information about attributes of the products or customers involved, the problem has been tackled most successfully by a nearest neighbor method called collaborative filtering in the context, while additional efforts invested in building classification models did not pay off and did not increase the quality. Therefore, classification methods have mainly been used in conjunction with product or customer attributes. Starting from a view on the plain recommendation task without attributes as a multi-class classification problem, we investigate two particularities, its autocorrelation structure as well as the absence of re-occurring items (repeat buying). We adapt the standard generic reductions 1-vs-rest and 1-vs-1 of multi-class problems to a set of binary classification problems to these particularities and thereby provide a generic compound classifier for recommender systems. We evaluate a particular specialization thereof using linear support vector machines as member classifiers on MovieLens data and show that it outperforms state-of-the-artmethods, i.e., item-based collaborative filtering.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>User profiles and alert services</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003331.10003271</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Users and interactive retrieval->Personalization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003260.10003261.10003271</concept_id>
				<concept_desc>CCS->Information systems->World Wide Web->Web searching and information discovery->Personalization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP45027725</person_id>
				<author_profile_id><![CDATA[81332525921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lars]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schmidt-Thieme]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Freiburg]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Ansari, S. Essegaier, and R. Kohli. Internet recommendation systems. <i>Journal of Marketing Research</i>, 37:363-375, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245124</ref_obj_id>
				<ref_obj_pid>245108</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Balabanovic and Y. Shoham. Fab - content-based, collaborative recommendation. <i>CACM</i>, 40(3):66-72, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657311</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. Billsus and M. J. Pazzani. Learning collaborative information filters. In <i>ICML '98: Proceedings of the Fifteenth International Conference on Machine Learning</i>, pages 46-54, San Francisco, CA, USA, 1998. Morgan Kaufmann Publishers Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2074100</ref_obj_id>
				<ref_obj_pid>2074094</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In <i>Proc. of the Fourteenth An. Conf. on Uncertainty in AI</i>, pages 43- 52, Madison, WI, USA, July 1998. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>586352</ref_obj_id>
				<ref_obj_pid>586321</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Burke. Hybrid recommender systems: Survey and experiments. <i>User Modeling and User Adapted Interaction</i>, 12/4:331-370, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. K. Condliff, D. D. Lewis, D. Madigan, and C. Posse. Bayesian mixed-effects models for recommender systems. In <i>Proceedings of the ACM SIGIR Workshop on Recommender Systems: Algorithms and Evaluation, 22nd Intl. Conf. on Research and Development in Information Retrieval</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>963776</ref_obj_id>
				<ref_obj_pid>963770</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Deshpande and G. Karypis. Item-based top-n recommendation algorithms. <i>ACM Trans. Inf. Sys.</i>, 22(1):143-177, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R.-E. Fan, P.-H. Chen, and C.-J. Lin. Working set selection using the second order information for training svm. Technical report, Department of Computer Science, National Taiwan University, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>138867</ref_obj_id>
				<ref_obj_pid>138859</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Goldberg, D. Nichols, B. Oki, and D. Terry. Using collaborative filtering to weave an information tapestry. <i>CACM</i>, 35(12):61-70, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>963774</ref_obj_id>
				<ref_obj_pid>963770</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Hofmann. Latent semantic models for collaborative filtering. <i>ACM Trans. Inf. Syst.</i>, 22(1):89-115, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326870</ref_obj_id>
				<ref_obj_pid>2325784</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[C.-W. Hsu and C.-J. Lin. A comparison of methods for multi-class support vector machines. <i>IEEE Transactions on Neural Networks</i>, 13:415-425, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>693504</ref_obj_id>
				<ref_obj_pid>646419</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[V. S. Iyengar and T. Zhang. Empirical study of recommender systems using linear classifiers. In <i>PAKDD '01: Proceedings of the 5th Pacific-Asia Conference on Knowledge Discovery and Data Mining</i>, pages 16-27, London, UK, 2001. Springer-Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655828</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[D. Jensen and J. Neville. Linkage and autocorrelation cause feature selection bias in relational learning. In <i>Proceedings of the 19th International Conference on Machine Learning (ICML)</i>, pages 259-266, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956922</ref_obj_id>
				<ref_obj_pid>956863</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Jin, L. Si, C. Zhai, and J. Callan. Collaborative filtering with decoupled models for preferences and ratings. In <i>CIKM '03: Proceedings of the twelfth international conference on Information and knowledge management</i>, pages 309-316, New York, NY, USA, 2003. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>777124</ref_obj_id>
				<ref_obj_pid>777092</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[P. Melville, R. J. Mooney, and R. Nagarajan. Content-boosted collaborative filtering for improved recommendations. In <i>Eighteenth national conference on Artificial intelligence</i>, pages 187-192, Menlo Park, CA, USA, 2002. American Association for Artificial Intelligence.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192905</ref_obj_id>
				<ref_obj_pid>192844</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl. Grouplens: An open architecture for collaborative filtering of netnews. In <i>Proc. of the Conf. on Comp. Sup. Coop. Work (CSCW'94)</i>, pages 175-186, Chapel Hill NC, 1994. Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[G. Salton. Relevance feedback and the optimization of retrieval effectiveness. In G. Salton, editor, <i>The SMART system -- experiments in automatic document processing</i>, pages 324-336. Prentice-Hall Inc., Englewood Cliffs, NJ, 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223931</ref_obj_id>
				<ref_obj_pid>223904</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[U. Shardanand and P. Maes. Social information filtering: algorithms for automating "word of mouth". In <i>Proc. of the SIGCHI conf. on Human factors in computing systems</i>, pages 210-217. ACM Press/Addison-Wesley Publishing Co., 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122996</ref_obj_id>
				<ref_obj_pid>122974</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[P. D. Stotts and R. Furuta. Dynamic adaptation of hypertext structure. In <i>Hypertext'91 Proc., San Antonio, TX, USA</i>, pages 219-231. ACM, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[C. Ziegler, L. Schmidt-Thieme, and G. Lausen. Exploiting semantic product descriptions for recommender systems. In <i>Proc. 2nd ACM SIGIR Semantic Web and IR WS (SWIR '04), 2004, Sheffield, UK</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106372</article_id>
		<sort_key>386</sort_key>
		<display_label></display_label>
		<pages>386-393</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>55</seq_no>
		<title><![CDATA[Multi-Stage Classification]]></title>
		<page_from>386</page_from>
		<page_to>393</page_to>
		<doi_number>10.1109/ICDM.2005.102</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106372</url>
		<abstract>
			<par><![CDATA[While much research has focused on methods for evaluating and maximizing the accuracy of classifiers either individually or in ensembles, little effort has been devoted to analyzing how classifiers are typically deployed in practice. In many domains, classifiers are used as part of a multi-stage process that increases accuracy at the expense of more data collection and/or more processing resources as the likelihood of a positive class label increases. This paper systematically explores the tradeoffs inherent in constructing these multi-stage classifiers from a series of increasingly accurate and expensive individual classifiers, considering a variety of metrics such as accuracy, cost/benefit ratio, and lift. It suggests architectures appropriate for both independent instances and for highly linked data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.5</cat_node>
				<descriptor>Special architectures</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010520.10010521.10010542.10011714</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Other architectures->Special purpose systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040523</person_id>
				<author_profile_id><![CDATA[81100610621]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ted]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Senator]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DARPA/IPTO]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adibi, J., Chalupsky, H., Grobelnik, M., Milic-Frayling, N., and Mladenic, D. (Eds.) <i>Second International Workshop on Link Analysis and Group Detection (LinkKDD-2004)</i>. (Seattle, WA, USA, August 22, 2004).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>959256</ref_obj_id>
				<ref_obj_pid>959242</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Dzeroski, S., De Raedt, L. Multi-relational data mining: the current frontiers. <i>ACM SIDKDD Explorations Newsletter, 5, 1</i> (July 2003), 1-16.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Friedman, N., Getoor, L., Koller, D., and Pfeffer, A. Learning Probabilistic Relational Models. In <i>Relational Data Mining</i>, S. Dvzeroski and N. Lavrac (Eds.), Springer-Verlag, 307-337, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Getoor, L. and Jensen, D. (Eds.) <i>Learning Statistical Models from Relational Data: Papers from the AAAI 2000 Workshop</i>, AAAI Press, Menlo Park, CA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Goldberg, H.G., and Senator, T.E. Break Detection Systems. In <i>AI Approaches to Fraud Detection and Risk Management: Collected Papers from the 1997 Workshop</i> Technical Report WS-97-07 AAAI Press, Menlo Park, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Goldberg, H., Kirkland, D., Lee, D., Shyr, P., and Thakker, D. The NASD Securities Observation, News Analysis & Regulation System (SONAR). In Proceedings of the Fifteenth Innovative Applications of Artificial Intelligence Conference (IAAI-2003). (Acapulco, MX, August 12-14, 2003.) AAAI Press, Menlo Park, CA, 2003. 11-18.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Jensen, D. and Goldberg, H. <i>Artificial Intelligence and Link Analysis: Papers from the 1998 AAAI Fall Symposium</i>, AAAI Press, Menlo Park, CA, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956794</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Jensen, D., Rattigan, M., and Blau, H. Information Awareness: A Prospective Technical Assessment. In <i>Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-2003)</i>. (Washington, DC, USA, August 24-27, 2003). ACM Press, New York, NY, 2003, 378-387.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Jensen, D. and Neville, J. Data Mining in Social Networks. <i>Papers of the Symposium on Dynamic Social Network Modeling and Analysis</i>. (National Academy of Sciences. November 7-9, 2002). National Academy Press, Washington, DC, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kirkland, J., Senator, T., Hayden, J., Dybala, T., Goldberg, H., and Shyr, P. The NASD Regulation Advanced Detection System (ADS). <i>AI Magazine, 20, 1</i> (Spring 1999), 55-67.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>975251</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kuncheva, Ludmila I. <i>Combining Pattern Classifiers: Methods and Algorithns</i>. John Wiley & Sons, Inc, Hoboken, NJ, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mladenic, D., Grobelnik, M., Milic-Frayling, N., Donoho, S., and Dybala, T. (Eds.) <i>Workshop on Link Analysis for Detecting Complex Behavior (LinkKDD2003)</i> KDD2003, (Washington, DC, USA, August 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Multiple Classifier Systems: First/Second/Third/Fourth/Fifth International Workshop (MCS-2000/2001/2002/2003/2004) Springer-Verlag GmbH, 2000-2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Paulos, J., Do the Math: Rooting Out Terrorists is Tricky Business. <i>Los Angeles Times</i>, January 23, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>971642</ref_obj_id>
				<ref_obj_pid>971617</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Popp, R., Armour, T., Senator, T., and Numrych, K. Countering Terrorism Through Information Technology. <i>Communications of the ACM, 47, 3</i> (March 2004), 36-43.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1098734</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Sebestyen, George S. <i>Decision-Making Processes in Pattern Recognition</i>. The Macmillan Company, New York, NY, 1962.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Scientific American (editorial). Total information overload. <i>Scientific American</i>, March 2003, 12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Senator, T. E., Goldberg, H., Wooton, J., Cottini, A., Khan, A. U., Klinger, C., Llamas, W., Marrone, M., and Wong, R. The FinCEN Artificial Intelligence System: Identifying Potential Money Laundering from Reports of Large Cash Transactions. <i>AI Magazine, 16, 4</i> (Winter 1995), 21-39.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>778333</ref_obj_id>
				<ref_obj_pid>778212</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Senator, T. E., and Goldberg, H. Break Detection Systems. In <i>Handbook of Data Mining and Knowledge Discovery</i>, W. Klosgen and J. Zytkow (eds.), Oxford University Press. 863-873, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>744253</ref_obj_id>
				<ref_obj_pid>648056</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Yang, S., Browne, A., Picton, P. D., Multistage Neural Network Ensembles, In <i>Multiple Classifier Systems: Third International Workshop (MCS 2002) Lecture Notes in Computer Science, 2364</i>. (Cagliari, Italy, June 24-26, 2002). Springer-Verlag, 91-97.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106373</article_id>
		<sort_key>394</sort_key>
		<display_label></display_label>
		<pages>394-401</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>56</seq_no>
		<title><![CDATA[Learning Functional Dependency Networks Based on Genetic Programming]]></title>
		<page_from>394</page_from>
		<page_to>401</page_to>
		<doi_number>10.1109/ICDM.2005.86</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106373</url>
		<abstract>
			<par><![CDATA[Bayesian Network (BN) is a powerful network model, which represents a set of variables in the domain and provides the probabilistic relationships among them. But BN can handle discrete values only; it cannot handle continuous, interval and ordinal ones, which must be converted to discrete values and the order information is lost. Thus, BN tends to have higher network complexity and lower understandability. In this paper, we present a novel dependency network which can handle discrete, continuous, interval and ordinal values through functions; it has lower network complexity and stronger expressive power; it can represent any kind of relationships; and it can incorporate a-priori knowledge though user-defined functions. We also propose a novel Genetic Programming (GP) to learn dependency networks. The novel GP does not use any knowledge-guided nor application-oriented operator, thus it is robust and easy to replicate. The experimental results demonstrate that the novel GP can successfully discover the target novel dependency networks, which have the highest accuracy and the lowest network complexity.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P560518</person_id>
				<author_profile_id><![CDATA[81100453657]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wing-Ho]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shum]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044919</person_id>
				<author_profile_id><![CDATA[81451595717]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kwong-Sak]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044236</person_id>
				<author_profile_id><![CDATA[81451594378]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Man-Leung]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lingnan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Jie Cheng. Belief network powerconstructor. http://www.cs.ualberta.ca/jcheng/bnpc.htm, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[David Maxwell Chickering. The winmine toolkit. Technical Report MSR-TR-2002-103, Microsoft, Redmond, WA, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D.E. Edwards. Hierarchical interaction models. <i>J. Roy. Satist Soc. B</i>, 52:3-20, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581821</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Alex A. Freitas, editor. <i>Data Mining and Knowledge Discovery with Evolutionary Algorithms</i>. Springer, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>719911</ref_obj_id>
				<ref_obj_pid>647234</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. Friedman and I. Nachman. Gaussian procces networks. In <i>Proceedings of the 16th CUAI</i>, pages 211- 219, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G.W. Greewood, G.B. Fogel, and M. Ciobanu. Emphasizing extinction in evolutionary programming. In <i>Proceedings of the 1999 Congress on Evolutionary Computation</i>, pages 666-671, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Hettich, C.L. Blake, and C.J. Merz. Uci repository of machine learning databases, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Chrisman L. A roadmap to research on bayesian networks and other decomposable probabilistic models. Technical report, School of Computer Science, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>279009</ref_obj_id>
				<ref_obj_pid>279005</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Wai Lam. Bayesian network refinement via machine learning approach. In <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, pages 240-251, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Wai Lam and Fahiem Bacchus. Learning bayesian belief networks an approach based on the mdl principle. In <i>Computational Intelligence</i>, pages 269-293, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2073850</ref_obj_id>
				<ref_obj_pid>2073796</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J.W. Myers, K.B. Laskey, and T.S. Levitt. Learning bayesian networks fro incomplete data with stochastic search algorithms. In <i>Proceeding of 15th conference Uncertainty Artificial Intelligence</i>, pages 476- 485, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>853717</ref_obj_id>
				<ref_obj_pid>850951</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[P. Myllymaki, T. Silander, H. Tirri, and P. Uronen. B-course: a web service for bayesian data analysis. In <i>Proceedings of the 13th International Conference on Tools with Artificial Intelligence</i>, pages 247-256, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[R.S. Siegler. Three aspects of cognitive development. In <i>Cognitive Psychology</i>, pages 481-520, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1326748</ref_obj_id>
				<ref_obj_pid>1326744</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Man-Leung Wong and Kwong-Sak Leung. Evolving program induction directed by logic grammars. In <i>Evolutionary Computation</i>, pages 143-180, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2221692</ref_obj_id>
				<ref_obj_pid>2221373</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Man Leung Wong and Kwong Sak Leung. An efficient data mining method for learning bayesian networks using an evolutionary algorithm-based hybrid approach. In <i>IEEE Transactions on Evolutionary Computation</i>, pages 378-404, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106374</article_id>
		<sort_key>402</sort_key>
		<display_label></display_label>
		<pages>402-409</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>57</seq_no>
		<title><![CDATA[Generalizing the Notion of Confidence]]></title>
		<page_from>402</page_from>
		<page_to>409</page_to>
		<doi_number>10.1109/ICDM.2005.72</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106374</url>
		<abstract>
			<par><![CDATA[In this paper, we explore extending association analysis to non-traditional types of patterns and non-binary data by generalizing the notion of confidence. The key idea is to regard confidence as a measure of the extent to which the strength of one association pattern provides information about the strength of another. This approach provides a framework that encompasses the traditional concept of confidence as a special case and can be used as the basis for designing a variety of new confidence measures. Besides discussing such confidence measures, we provide examples that illustrate the potential usefulness of a generalized notion of confidence. In particular, we describe an approach to defining confidence for error tolerant itemsets that preserves the interpretation of confidence as a conditional probability and derive a confidence measure for continuous data that agrees with the standard confidence measure when applied to binary transaction data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>Performance evaluation (efficiency and effectiveness)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003359</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15038346</person_id>
				<author_profile_id><![CDATA[81100645298]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Steinbach]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43136196</person_id>
				<author_profile_id><![CDATA[81452613746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vipin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In <i>SIGMOD 93</i>, pages 207-216, Washington, D.C., May 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>VLDB 94</i>, pages 487-499, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312243</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Y. Aumann and Y. Lindell. A statistical theory for quantitative association rules. In <i>KDD 99</i>, pages 261-270, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Banerjee, S. Merugu, I. S. Dhillon, and J. Ghosh. Clustering with bregman divergences. In <i>SIAM 2004</i>, pages 234- 245, Lake Buena Vista, FL, April 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>679436</ref_obj_id>
				<ref_obj_pid>646110</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Bollmann-Sdorra, A. Hafez, and V. V. Raghavan. A theoretical framework for association mining based on the boolean retrieval model. In <i>DaWaK 2001, Munich, Germany</i>, pages 21-30, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253327</ref_obj_id>
				<ref_obj_pid>253260</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, and C. Silverstein. Beyond market baskets: generalizing association rules to correlations. In <i>SIGMOD 97</i>, pages 265-276, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>264989</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. W. Demmel. <i>Applied Numerical Linear Algebra</i>. SIAM, January 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>599308</ref_obj_id>
				<ref_obj_pid>599233</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Friedman and N. Fisher. Bump-hunting in high-dimensional data. <i>Statistics and Computing</i>, 9(2):123-143, April 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[E.-H. Han, G. Karypis, and V. Kumar. Tr# 97-068: Minapriori: An algorithm for finding association rules in data with continuous attributes. Technical report, Department of Computer Science, University of Minnesota, Minneapolis, MN, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Hastie, R. Tibshirani, and J. Friedman. <i>The Elements of Statistical Learning</i>. Springer Verlag, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Jarosewicz, D. A. Simovici, and I. Rosenberg. An inclusion-exclusion result for boolean polynomials and its applications in data mining. In <i>Proceedings of the Workshop on Discrete Mathematics and Data Mining (DM&DM), SDM02, Arlington, VA</i>. AAAI, April 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276307</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. T. Ng, L. V. S. Lakshmanan, J. Han, and A. Pang. Exploratory mining and pruning optimizations of constrained associations rules. In <i>SIGMOD 98</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1767396</ref_obj_id>
				<ref_obj_pid>1767370</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M. Okoniewski, L. Gancarz, and P. Gawrysiak. Mining multi-dimensional quantitative associations. In <i>INAP 2001, October</i>, volume 2543 of <i>LCNS</i>. Springer, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. Ozgur, P.-N. Tan, and V. Kumar. {rba}: An integrated framework for regression based on association rules. In <i>SIAM 2004</i>, April 22-24 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233311</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[R. Srikant and R. Agrawal. Mining quantitative association rules in large relational tables. In <i>SIGMOD 96</i>, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[R. Srikant, Q. Vu, and R. Agrawal. Mining association rules with item constraints. In <i>KDD 97</i>, pages 67-73, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014141</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[M. Steinbach, P.-N. Tan, H. Xiong, and V. Kumar. Generalizing the notion of support. In <i>KDD '04</i>, pages 689-694, New York, NY, USA, 2004. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775053</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[P.-N. Tan, V. Kumar, and J. Srivastava. Selecting the right interestingness measure for association patterns. In <i>KDD 2002</i>, pages 32-41, New York, NY, 2002. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1095618</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[P.-N. Tan, M. Steinbach, and V. Kumar. <i>Introduction to Data Mining</i>. Pearson Addison-Wesley, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502569</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[G. I. Webb. Discovering associations with numeric variables. In <i>KDD 01</i>, pages 383-388, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502539</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[C. Yang, U. M. Fayyad, and P. S. Bradley. Efficient discovery of error-tolerant frequent itemsets in high dimensions. In <i>KDD 2001</i>, pages 194-203, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki and M. Ogihara. Theoretical foundations of association rules. In <i>DMKD 98</i>, pages 7:1-7:8, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106375</article_id>
		<sort_key>410</sort_key>
		<display_label></display_label>
		<pages>410-417</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>58</seq_no>
		<title><![CDATA[SVM Feature Selection for Classification of SPECT Images of Alzheimer's Disease Using Spatial Information]]></title>
		<page_from>410</page_from>
		<page_to>417</page_to>
		<doi_number>10.1109/ICDM.2005.141</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106375</url>
		<abstract>
			<par><![CDATA[Alzheimer's disease is the most frequent type of dementia for elderly patients. Due to aging populations the occurrence of this disease will increase in the next years. Early diagnosis is crucial to be able to develop more powerful treatments. Brain perfusion changes can be a marker for Alzheimer's disease. In this article we study the use of SPECT perfusion imaging for the diagnosis of Alzheimer's disease differentiating between images from healthy subjects and images from Alzheimer's disease patients. Our classification approach is based on a linear programming formulation similar to the 1-norm support vector machines. In contrastwith other linear hyperplane-based methods that perform simultaneous feature selection and classification, our proposed formulation incorporates proximity information about the features and generates a classifier that does not just select the most relevant voxels but the most relevant "areas" for classification resulting in more robust classifiersthat are better suitable for interpretation. This approach is compared with the classical Fisher linear discriminant (FLD) classifier as well as with statistical parametric mapping (SPM). We tested our method on data from four European institutions. Our method achieved sensitivity of 84.4% at 90.9% specificity, this is considerable better the human experts. Our method also outperformed the FLD and SPM techniques. We conclude that our approach has the potential to be a useful help for clinicians.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Health</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>Performance evaluation (efficiency and effectiveness)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010446</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Consumer health</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010449</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health informatics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044504</person_id>
				<author_profile_id><![CDATA[81100074397]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jonathan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stoeckel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Siemens Medical Solutions USA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044124</person_id>
				<author_profile_id><![CDATA[81100207722]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Glenn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Siemens Medical Solutions USA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[G. McKhann, D. Drachman, M. Folstein, R. Katzman, D. Price, and E.M. Stadlan. Mental and clinical diagnosis of Alzheimer's disease: report of the NINCDS-ADRDA Work Group under the auspices of the Department of Health and Human Services Task Force on Alzheimer's Disease. <i>Neurology</i>, 34(7):939-944, July 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M.F. Folstein, S.E. Folstein, and P.R. McHugh. "Mini-Mental State": a practical method for grading the cognitive state of patients for the clinician. <i>Journal of Psychiatric Research</i>, 12(3):189-198, November 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K.M. Gosche, J.A. Mortimer, C.D. Smith, W.R. Markesbery, and D.A. Snowdon. Hippocampal volume as an index of Alzheimer neuropathology: findings from the Nun Study. <i>Neurology</i>, 58(10):1476-1482, May 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[I. Goethals, C. van de Wiele, D. Slosman, and R. Dierckx. Brain SPET perfusion in early Alzheimer's disease: where to look? <i>European Journal of Nuclear Medicine</i>, 29(8):975-978, August 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[W.A. Van Gool, G.J. Walstra, S. Teunisse, F.M. Van der Zant, H.C. Weinstein, and E.A. Van Royen. Diagnosing Alzheimer's disease in elderly, mildly demented patients: the impact of routine single photon emission computed tomography. <i>Journal of Neurology</i>, 242(6):401-405, June 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Kogure, H. Matsuda, T. Ohnishi, T. Asada, M. Uno, T. Kunihiro, S. Nakano, and M. Takasaki. Longitudinal evaluation of early Alzheimer's disease using brain perfusion SPECT. <i>Journal of Nuclear Medicine</i>, 41(7):1155-1162, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[H. Braak and E. Braak. Diagnostic criteria for neuropathologic assessment of Alzheimer's disease. <i>Neurobiology and Aging</i>, 18(4):S85-S88, July 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M.R. Dawson, A. Dobbs, H.R. Hooper, A.J. McEwan, J. Triscott, and J. Cooney. Artificial neural networks that use single-photon emission tomography to identify patients with probable Alzheimer's disease. <i>European Journal of Nuclear Medicine</i>, 21(12):1303- 1311, December 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Hamilton, D. O'Mahony, J. Coffey, J. Murphy, N. O'Hare, P. Freyne, B. Walsh, and D. Coakley. Classification of mild Alzheimer's disease by artificial neural network analysis of SPET data. <i>Nuclear Medicine Communications</i>, 18(9):805-810, September 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R.S.J. Frackowiak, K.J. Friston, C.D. Frith, and R. Dolan. <i>Human Brain Function</i>. Academic Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Ashburner, K. Friston, A. Holmes, and J.-B. Poline. Statistical Parametric Mapping, SPM'99. The Welcome Department of Cognitive Neurology. Institute of Neurology, University College London, 1999. Freely available at http://www.fil.ion.ucl.ac.uk/spm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>711010</ref_obj_id>
				<ref_obj_pid>646924</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Stoeckel, Malandain G., O. Migneco, P.M. Koulibaly, Robert P., N. Ayache, and J. Darcourt. Classification of SPECT images of normal subjects versus images of Alzheimer's disease patients. In W.J. Niessen and M.A. Viergever, editors, <i>4th Int. Conf. on Medical Image Computing and Computer-Assisted Intervention (MICCAI'01)</i>, volume 2208 of <i>LNCS</i>, pages 666-674, Utrecht, The Netherlands, October 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>709612</ref_obj_id>
				<ref_obj_pid>646921</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. Roche, G. Malandain, X. Pennec, and N. Ayache. The Correlation Ratio as a New Similarity Metric for Multimodal Image Registration. In W. M. Wells, A. C. F. Colchester, and S. Delp, editors, <i>Medical Image Computing and Computer-Assisted Intervention (MICCAI'98)</i>, volume 1496 of <i>Lecture Notes in Computer Science</i>, pages 1115-1124, Boston, USA, October 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215684</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. <i>Numerical Recipes. The Art of Scientific Computing</i>. Cambridge University Press, 2nd edition, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. Prima, S. Ourselin, and N. Ayache. Computation of the mid-sagittal plane in 3D brain images. <i>IEEE Transaction on Medical Imaging</i>, 21(2):122- 138, February 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[V. N. Vapnik. <i>The Nature of Statistical Learning Theory</i>. Springer, New York, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657467</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[P. S. Bradley and O. L. Mangasarian. Feature selection via concave minimization and support vector machines. In J. Shavlik, editor, <i>Machine Learning Proceedings of the Fifteenth International Conference(ICML '98)</i>, pages 82-90, San Francisco, California, 1998. Morgan Kaufmann. ftp://ftp.cs.wisc.edu/math-prog/tech-reports/98-03.ps.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[O. L. Mangasarian. Arbitrary-norm separating plane. <i>Operations Research Letters</i>, 24:15-23, 1999. ftp://ftp.cs.wisc.edu/math-prog/tech-reports/97- 07r.ps.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[T. Evgeniou, M. Pontil, and T. Poggio. Regularization networks and support vector machines. <i>Advances in Computational Mathematics</i>, 13:1-50, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>557403</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[A. Smola, P. L. Bartlett, B. Sch&#246;lkopf, and J. Schuurmann (editors). <i>Advances in Large Margin Classifiers</i>. MIT Press, Cambridge, MA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[D. Soonawala, T. Amin, K.P. Ebmeier, J.D. Steele, N.J. Dougall, J. Best, O. Migneco, F. Nobili, and K. Scheidhauer. Statistical parametric mapping of (99m)Tc-HMPAO-SPECT images for the diagnosis of Alzheimer's disease: normalizing to cerebellar tracer uptake. <i>Neuroimage</i>, 17(3):1193-1202, November 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Sebastian Mika, Gunnar R&#228;tsch, and Klaus-Robert M&#252;ller. A mathematical programming approach to the kernel fisher algorithm. In <i>NIPS</i>, pages 591-597, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[ILOG CPLEX Division, 889 Alder Avenue, Incline Village, Nevada. <i>CPLEX Optimizer</i>, 2004. http://www.cplex.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106376</article_id>
		<sort_key>418</sort_key>
		<display_label></display_label>
		<pages>418-425</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>59</seq_no>
		<title><![CDATA[Neighborhood Formation and Anomaly Detection in Bipartite Graphs]]></title>
		<page_from>418</page_from>
		<page_to>425</page_to>
		<doi_number>10.1109/ICDM.2005.103</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106376</url>
		<abstract>
			<par><![CDATA[Many real applications can be modeled using bipartite graphs, such as users vs. files in a P2P system, traders vs. stocks in a financial trading system, conferences vs. authors in a scientific publication network, and so on. We introduce two operations on bipartite graphs: 1) identifying similar nodes (Neighborhood formation), and 2) finding abnormal nodes (Anomaly detection). And we propose algorithms to compute the neighborhood for each node using random walk with restarts and graph partitioning; we also propose algorithms to identify abnormal nodes, using neighborhood information. We evaluate the quality of neighborhoods based on semantics of the datasets, and we also measure the performance of the anomaly detection algorithm with manually injected anomalies. Both effectiveness and efficiency of the methods are confirmed by experiments on several real datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40027371</person_id>
				<author_profile_id><![CDATA[81455605573]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jimeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP30033842</person_id>
				<author_profile_id><![CDATA[81310483642]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Huiming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Qu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pittsburgh]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042393</person_id>
				<author_profile_id><![CDATA[81100424530]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Deepayan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chakrabarti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Yahoo! Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15030495</person_id>
				<author_profile_id><![CDATA[81100373169]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Christos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Faloutsos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>375668</ref_obj_id>
				<ref_obj_pid>375663</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Aggarwal and P. Yu. Outlier detection for high-dimensional data. In <i>SIGMOD</i>, pages 37-46, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>297827</ref_obj_id>
				<ref_obj_pid>297810</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual Web search engine. <i>Computer Networks and ISDN Systems</i>, 30(1-7):107-117, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1053085</ref_obj_id>
				<ref_obj_pid>1053072</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Deepayan Chakrabarti. Autopart: Parameter-free graph partitioning and outlier detection. In <i>PKDD</i>, pages 112-124, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014064</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Deepayan Chakrabarti, Spiros Papadimitriou, Dharmendra S. Modha, and Christos Faloutsos. Fully automatic cross-associations. In <i>KDD</i>, pages 79-88. ACM Press, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956764</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon, S. Mallela, and D. S. Modha. Information-theoretic co-clustering. In <i>KDD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gary William Flake, Steve Lawrence, and C. Lee Giles. Efficient identification of Web communities. In <i>KDD</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Girvan and M. E. J. Newman. Community structure in social and biological networks. In <i>Proc. Natl. Acad. Sci. USA</i>, volume 99, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>511513</ref_obj_id>
				<ref_obj_pid>511446</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Haveliwala. Topic-sensitive pagerank. In <i>Proceedings of the Eleventh International World Wide Web Conference</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775126</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Glen Jeh and Jennifer Widom. Simrank: a measure of structural-context similarity. In <i>KDD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>796585</ref_obj_id>
				<ref_obj_pid>795666</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. Kannan, S. Vempala, and A. Vetta. On clusterings - good, bad and spectral. In <i>FOCS</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>287111</ref_obj_id>
				<ref_obj_pid>287098</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[George Karypis and Vipin Kumar. Multilevel k-way partitioning scheme for irregular graphs. <i>Journal of Parallel and Distributed Computing</i>, 48(1):96-129, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2384261</ref_obj_id>
				<ref_obj_pid>2384225</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Stefan Klink, Michael Ley, Emma Rabbidge, Patrick Reuther, Bernd Walter, and Alexander Weber. Browsing and visualizing digital bibliographic data. In <i>Vis-Sym </i>, pages 237-242, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956831</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[C. C. Noble and D. J. Cook. Graph-based anomaly detection. In <i>KDD</i>, pages 631-636, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014135</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Jia-Yu Pan, Hyung-Jeong Yang, Pinar Duygulu, and Christos Faloutsos. Automatic multimedia cross-modal correlation discovery. In <i>KDD</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223931</ref_obj_id>
				<ref_obj_pid>223904</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Upendra Shardanand and Pattie Maes. Social information filtering: Algorithms for automating "word of mouth". In <i>Human Factors in Computing Systems</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Gilbert Strang. <i>Introduction to Linear Algebra</i>. Wellesley-Cambridge Press, 3 edition, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106377</article_id>
		<sort_key>426</sort_key>
		<display_label></display_label>
		<pages>426-433</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>60</seq_no>
		<title><![CDATA[A Border-Based Approach for Hiding Sensitive Frequent Itemsets]]></title>
		<page_from>426</page_from>
		<page_to>433</page_to>
		<doi_number>10.1109/ICDM.2005.2</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106377</url>
		<abstract>
			<par><![CDATA[Sharing data among organizations often leads to mutual benefit. Recent technology in data mining has enabled efficientextraction of knowledge from large databases. This, however, increases risks of disclosing the sensitive knowledge when the database is released to other parties. To address this privacy issue, one may sanitize the original database so that the sensitive knowledge is hidden. The challenge is to minimize the side effect on the quality of the sanitized database so that non-sensitive knowledge can still be mined. In this paper, we study such a problem in the context of hiding sensitive frequent itemsets by judiciously modifying the transactions in the database. To preserve the non-sensitive frequent itemsets, we propose a border-based approach to efficiently evaluate the impact of any modification to the database during the hiding process. The quality of database can be well maintained by greedily selecting the modifications with minimal side effect. Experiments results are also reported to show the effectiveness of the proposed approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Security, integrity, and protection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>K.4.4</cat_node>
				<descriptor>Security</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>K.4.4</cat_node>
				<descriptor>Electronic data interchange (EDI)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10003550.10003557</concept_id>
				<concept_desc>CCS->Applied computing->Electronic commerce->Secure online transactions</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10003550.10003553</concept_id>
				<concept_desc>CCS->Applied computing->Electronic commerce->Electronic data interchange</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003022.10003028</concept_id>
				<concept_desc>CCS->Security and privacy->Software and application security->Domain-specific security and privacy architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003018</concept_id>
				<concept_desc>CCS->Security and privacy->Database and storage security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003029</concept_id>
				<concept_desc>CCS->Security and privacy->Human and societal aspects of security and privacy</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011735</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Theory of database privacy and security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041941</person_id>
				<author_profile_id><![CDATA[81392596129]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xingzhi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Queensland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J.  Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. of the 20th VLDB</i>, pages 487-499, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>788219</ref_obj_id>
				<ref_obj_pid>519168</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim, and V. Verykios. Disclosure limitation of sensitive rules. In <i>Proc. of KDEX'99</i>, pages 45-52, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Clifton and D. Marks. Security and privacy implications of data mining. In <i>Workshop on Data Mining and Knowledge Discovery</i>, pages 15-19, Montreal, Canada, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>731877</ref_obj_id>
				<ref_obj_pid>647597</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[E. Dasseni, V. S. Verykios, A. K. Elmagarmid, and E. Bertino. Hiding association rules by using confidence and support. In <i>Proc. of the 4th Information Hiding Worshop</i>, pages 369-383, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593448</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and H. Toivonen. Levelwise search and borders of theories in knowledge discovery. <i>Data Mining and Knowledge Discovery</i>, 1(3):241-258, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>850789</ref_obj_id>
				<ref_obj_pid>850782</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Oliveira and O. Zaiane. Privacy preserving frequent itemset mining. In <i>Proc. ICDM Workshop on Privacy, Security, and Data Mining</i>, pages 43-54, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Oliveira and O. Zaiane. Algorithms for balancing privacy and knowledge discovery in association rule mining. In <i>7th Proc. of the IDEAS</i>, pages 54-63, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952071</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Oliveira and O. Zaiane. Protecting sensitive knowledge by data sanitization. In <i>Proc. of the 3rd ICDM</i>, pages 613- 616, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Oliveira, O. Zaiane, and Y. Saygin. Secure association rule sharing. In <i>Proc. of the 8th PAKDD</i>, pages 74-85, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>604271</ref_obj_id>
				<ref_obj_pid>604264</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Y. Saygin, V. S. Verykios, and C. Clifton. Using unknowns to prevent discovery of association rules. <i>ACM SIGMOD Record</i>, 30:45-54, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Veloso, W. Meira, Jr., M. de Carvalho, B. Possas, S. Parthasarathy, and M. J. Zaki. Mining frequent itemsets in evolving databases. In <i>Proc. of the 2nd SDM</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>974131</ref_obj_id>
				<ref_obj_pid>974121</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[V. S. Verykios, E. Bertino, I. N. Fovino, L. P. Provenza, Y. Saygin, and Y. Theodoridis. State-of-the-art in privacy preserving data mining. <i>ACM SIGMOD Record</i>, 33:50-57, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>972279</ref_obj_id>
				<ref_obj_pid>972214</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[V. S. Verykios, A. K. Elmagarmid, E. Bertino, Y. Saygin, and E. Dasseni. Association rule hiding. <i>TKDE</i>, 16:434- 447, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106378</article_id>
		<sort_key>434</sort_key>
		<display_label></display_label>
		<pages>434-441</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>61</seq_no>
		<title><![CDATA[X-mHMM]]></title>
		<subtitle><![CDATA[An Efficient Algorithm for Training Mixtures of HMMs When the Number of Mixtures Is Unknown]]></subtitle>
		<page_from>434</page_from>
		<page_to>441</page_to>
		<doi_number>10.1109/ICDM.2005.156</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106378</url>
		<abstract>
			<par><![CDATA[In this paper we consider sequence clustering problems and propose an algorithm for the estimation of the number of clusters based on the X-means algorithm. The sequences are modeled using mixtures of Hidden Markov Models. By means of experiments with synthetic data we analyze the proposed algorithm. This algorithm proved to be both computationally efficient and capable of providing accurate estimates of the number of clusters. Some results of experiments with real-world web-log data are also given.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Markov processes</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003651</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Markov networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003700.10003701</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Stochastic processes->Markov processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763187</person_id>
				<author_profile_id><![CDATA[81309495684]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zoltan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Szamonek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hungarian Academy of Sciences and E&#246;tv&#246;s University Budapest]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042136</person_id>
				<author_profile_id><![CDATA[81100538163]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Csaba]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Szepesvari]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hungarian Academy of Sciences]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[L. Baum. An inequality and associated maximization technique in statistical estimation for probabilistic functions of Markov processes. <i>Inequalities</i>, 3:1-8, 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Jain and R. Dubes. <i>Algorithms for Clustering Data</i>. Prentice Hall Advanced Reference Series. Prentice Hall, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B. Juang and L. Rabiner. The segmential k-means training procedure for estimating parameters of hidden Markov models. <i>IEEE Trans. Acoustics, Speech, Signal Processing</i>, 38:1639-1641, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Kaufman and P. Rousseeuw. <i>Finding Groups in Data</i>. John Wiley and Sons, Inc., 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657799</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Li and G. Biswas. A Bayesian approach to temporal data clustering using hidden Markov models. In <i>Proceedings of the Seventeenth International Conference on Machine Learning</i>, pages 543-550, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1746476</ref_obj_id>
				<ref_obj_pid>1746458</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. F. M. Bicego, V. Murino. Similarity-based classification of sequences using Hidden Markov Models. <i>Pattern Recognition</i>, 2004. to appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657808</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Pelleg and A. Moore. X-means: Extending K-means with efficient estimation of the number of clusters. In <i>Proceedings of the Seventeenth International Conference on Machine Learning</i>, pages 727-734, San Francisco, 2000. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[L. R. Rabiner. A tutorial on hidden Markov models and selected applications in speech recognition. In <i>Proceedings of the IEEE</i>, volume 77, pages 257-286, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[P. Smyth. Clustering sequences with hidden Markov models. In M. C. Mozer, M. I. Jordan, and T. Petsche, editors, <i>Advances in Neural Information Processing Systems</i>, volume 9, page 648. The MIT Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. Ypma and T. Heskes. Categorization of web pages and user clustering with mixtures of Hidden Markov Models. In <i>Proceedings of the International Workshop on Web Knowledge Discovery and Data Mining</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>964287</ref_obj_id>
				<ref_obj_pid>945365</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Zhong and J. Ghosh. A unified framework for model-based clustering. <i>Journal of Machine Learning Research</i>, 4:1001-1037, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106380</article_id>
		<sort_key>442</sort_key>
		<display_label></display_label>
		<pages>442-449</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>62</seq_no>
		<title><![CDATA[A Random Walk through Human Associations]]></title>
		<page_from>442</page_from>
		<page_to>449</page_to>
		<doi_number>10.1109/ICDM.2005.12</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106380</url>
		<abstract>
			<par><![CDATA[Letting one's thoughts wander is not simply an arbitrary or rambling process. It can better be described as "associative thinking", where a complex chain of associative thoughts and ideas are linked. It is our contention that this seemingly chaotic process can be modeled by a random walk in a weighted directed graph. Furthermore, is it possible to predict mathematically the "steady state" of such a process, to determine where such wandering is leading. The random walk process uses rules of association, defined by the Local Confidence Gain (LCG) interestingness measure. Extracted concepts are used as nodes of a directed graph. The associative "forces" between any two concepts (measured by LCG) are used to weigh the edges connecting the nodes that create a graph of associations. It is common, yet not trivial, for people to look for data about a subject without knowing its exact nomenclature (for example, finding the name of a disease just by knowing its symptoms). Random walk in association graphs can discover highly informative phrases that can be used for query expansion in a way that better expresses the user's initial search goals. A different usage is to create a user profile representing his current interests. We used a modified version of the Turing Test to show that the random walk process discovers association rules that conform to a human associations generating process. By constructing the user associations we were able to build a profile representing the user's "line of thoughts". The suggested algorithm can be used in any database and can implement the ranking measures of other association rules.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.0</cat_node>
				<descriptor>Cognitive simulation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>User profiles and alert services</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010194</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Cognitive robotics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010216.10010217</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Philosophical/theoretical foundations of artificial intelligence->Cognitive science</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003331.10003271</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Users and interactive retrieval->Personalization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003260.10003261.10003271</concept_id>
				<concept_desc>CCS->Information systems->World Wide Web->Web searching and information discovery->Personalization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15042307</person_id>
				<author_profile_id><![CDATA[81316491070]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Raz]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tamir]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hebrew University of Jerusalem]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>384086</ref_obj_id>
				<ref_obj_pid>383952</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Farahat, T. LoFaro, and J.C. Miller, "Modification of kleinberg's hits algorithm using matrix exponentiation and web log records", <i>Proceedings of the 24th International Conference on Research and Development in Information Retrieval (SIGIR 2001)</i>, New Orleans, USA, September 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A.A. Freitas "On rule interestingness measures". <i>Knowledge-Based Systems</i> 12, 2000, pp. 309-315.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A.M. Turing, "Computing machinery and intelligence", <i>Mind</i>, Vol. 59, No. 236, 1950 pp. 433- 460.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>596952</ref_obj_id>
				<ref_obj_pid>596724</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A.P. Saygin, I. Cicekli, and V. Akman, "Turing Test: 50 Years Later", <i>Minds and Machines</i>. 10(4), 2000, pp. 463-518.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>354155</ref_obj_id>
				<ref_obj_pid>354138</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C.R. MacCluer, "The many proofs and applications of Perrons's theorem" <i>SIAM Rev</i>. 42(3), 2000, pp. 487-498.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gantmacher F.R. "<i>The Theory of Matrices</i>", Volume I, II, Chelsea Publ. Co., New York, 1959.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Google API. http://www.google.com/apis/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Haveliwala T.H., and S.D. Kamvar, "<i>The second eigenvalue of the Google matrix</i>". Stanford University Technical Report, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[IRCache Internet caching project. See http://www.ircache.net/ (current 6.2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>794502</ref_obj_id>
				<ref_obj_pid>794189</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Shi and J. Malik, "Normalized Cuts and Image Segmentation", <i>Proc. Computer Vision and Pattern Recognition</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J.R. Searl, "Minds, Brains and Programs", <i>Behavioral and Brain Science</i> 3(262), 1980, pp. 26- 31.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>315045</ref_obj_id>
				<ref_obj_pid>314613</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[L. Kleinberg J. "Authoritative sources in a hyperlinked environment", <i>Proceedings of the ACM-SIAM Symposium on Discrete Algorithms</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M.D. Wilson, "The MRC Psycholinguistic Database: Machine Readable Dictionary", <i>Behavioral Research Methods, Instruments and Computers</i>, 20(1), 1988, pp. 6-11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[M.R. Henzinger "Algorithmic Challenges in Web Search Engines", <i>Internet Mathematics</i>, Vol. 1, No. 1, 2003, pp. 115-126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Michie D., "Turing's Test and Conscious Thought", in P. Millican and A. Clark, eds. <i>Machines and Thought: The Legacy of Alan Turing</i>, Oxford, UK: Oxford University Press, 1996, pp. 27-51.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[N. Deo, and P. Gupta, "Sampling the Web With Random Walks", <i>Congressus Numerantium</i>, 149 (2001), 32nd Southeastern International Conference on Combinatorics, Graph Theory and Computing, Feb. 26 - Mar. 2, 2001, Baton Rouge, LA. pp. 143- 154.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658655</ref_obj_id>
				<ref_obj_pid>645578</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[N. Deo, and P. Gupta, "Graph-Theoretic Web Algorithms: An Overview", <i>Lecture Notes in Computer Science</i>, (eds. T. B&#246;hme and H. Unger), 2026 (2001), Innovative Internet Computing Systems, June 21-22, 2001, IImenau Technical University, Germany, pp. 91-102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Nelson D.L., C.L. McEvoy, and Schreiber T.A. "<i>The University of South Florida Word Association, Rhyme, and Word Fragment normsNorms</i>", 2002. See http://w3.usf.edu/FreeAssociation/Intro.html (Current 6.2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[P. Tan, V. Kumar, and J. Srivastava, "Selecting the right interestingness measure for association patterns", <i>Technical Report 2002-112</i>, Army High Performance Computing Research Center, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[P.D. Turney, "Answering Subcognitive Turing Test Questions: A reply to French", <i>Submitted to the Journal of Experimental and Theoretical Artificial Intelligence, 2001</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383041</ref_obj_id>
				<ref_obj_pid>382979</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[R. Lempel and S. Morran, "SALSA: The stochastic approach for link-structure analysis", <i>ACM Transactions on Information Systems</i>, 19(2), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1146469</ref_obj_id>
				<ref_obj_pid>1146466</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[R. Tamir, "On Confidence Gain Measure for Association Rules Generation and Scoring", <i>VLDB Journal</i>, forthcoming, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952072</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[R. Tamir, and R. Rapp, "Mining the Web to Discover the Meanings of an Ambiguous Word", <i>Proceedings of the third IEEE international conference on data mining</i>, 19-22 November 2003, Melbourne, Florida, pp. 645.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[R.M. French, "Subcognition and the Limit of the Turing Test", <i>Mind</i>, Vol. 99, No. 393, 1990, pp. 53- 65.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[R.M. Shiffrin, "Modeling Memory and Perception", <i>Cognitive Science</i> 27, 2003, pp. 341-378.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>297827</ref_obj_id>
				<ref_obj_pid>297805</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[S. Brin, and L. Page, "The anatomy of a large-scale hypertextual Web search engine" <i>Proceedings of the 7th International World Wide Web Conference, Brisbane, Australia</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Strang G. <i>Linear Algebra and Its Applications</i>, Third Edition, Harcourt Brace Jovanovich Publishers, San Diego, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[T.J. Palmeri, "An exemplar-based random walk model of perceptual categorization". M. Ramscar, U. Hahn, E. Cambouropolos, & H. Pain (Eds.), <i>Proceedings of the Interdisciplinary Workshop on Similarity and Categorisation</i>, Edinburgh, Scotland: University of Edinburgh (1997), pp. 181-187.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106379</article_id>
		<sort_key>450</sort_key>
		<display_label></display_label>
		<pages>450-457</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>63</seq_no>
		<title><![CDATA[Supervised Tensor Learning]]></title>
		<page_from>450</page_from>
		<page_to>457</page_to>
		<doi_number>10.1109/ICDM.2005.139</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106379</url>
		<abstract>
			<par><![CDATA[This paper aims to take general tensors as inputs for supervised learning. A supervised tensor learning (STL) framework is established for convex optimization based learning techniques such as support vector machines (SVM) and minimax probability machines (MPM). Within the STL framework, many conventional learning machines can be generalized to take n^th-order tensors as inputs. We also study the applications of tensors to learning machine design and feature extraction by linear discriminant analysis (LDA). Our method for tensor based feature extraction is named the tenor rank-one discriminant analysis (TR1DA). These generalized algorithms have several advantages: 1) reduce the curse of dimension problem in machine learning and data mining; 2) avoid the failure to converge; and 3) achieve better separation between the different categories of samples. As an example, we generalize MPM to its STL version, which is named the tensor MPM (TMPM). TMPM learns a series of tensor projections iteratively. It is then evaluated against the original MPM. Our experiments on a binary classification problem show that TMPM significantly outperforms the original MPM.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003716</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003716</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041145</person_id>
				<author_profile_id><![CDATA[81100159571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dacheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of London]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040388</person_id>
				<author_profile_id><![CDATA[81452599228]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xuelong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of London]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040061</person_id>
				<author_profile_id><![CDATA[81350588251]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Weiming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese Academy of Science]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044197</person_id>
				<author_profile_id><![CDATA[81409593039]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Maybank]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of London]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040802</person_id>
				<author_profile_id><![CDATA[81452596585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Xindong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>993483</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge University Press, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik, The Nature of Statistical Learning Theory. Springer-Verlag, New York, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944934</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[G. Lanckriet <i>et al.</i>, "A Robust Minimax Approach to Classification," <i>JMLR</i>, 3, 555-582, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>942768</ref_obj_id>
				<ref_obj_pid>942593</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Li and J. Wang, "Automatic Linguistic Indexing of Pictures by a Statistical Modeling Approach," <i>IEEE Trans. PAMI</i>, 25(9), 1075-1088, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Turk and A. Pentland, "Face recognition using eigenfaces," in <i>Proc. of IEEE CVPR</i>, 586-591, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>297870</ref_obj_id>
				<ref_obj_pid>297843</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[L. Itti <i>et al.</i>, "A Model of Saliency-Based Visual Attention for Rapid Scene Analysis," <i>IEEE Trans. PAMI</i>, 20(11), 1254-1259, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1038235</ref_obj_id>
				<ref_obj_pid>1038062</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Sarkar <i>et al.</i>, "The Human ID Gait Challenge Problem: Data Sets, Performance, and Analysis," <i>IEEE Trans. PAMI</i>, 27(2), 162-177, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>615104</ref_obj_id>
				<ref_obj_pid>614674</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Chang, "The Holy Grail of Content-Based Media Analysis," <i>IEEE Multimedia Magazine</i>, 9(2), 6-10, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. Bellman, Adaptive Control Processes: A Guided Tour. Princeton University Press, 1960.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>128936</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Anthony <i>et al.</i>, Computational Learning Theory. Cambridge Univ. Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>954544</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R. O. Duda <i>et al.</i>, Pattern Classification. 2/e, Wiley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1005334</ref_obj_id>
				<ref_obj_pid>1005332</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[G. Lanckriet <i>et al.</i>, "Learning the Kernel Matrix with Semidefinite Programming," <i>JMLR</i>, 5, 27-72, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. Shashua and A. Levin, "Linear Image Coding for Regression and Classification Using the Tensor-rank Principle," in <i>Proc. of IEEE CVPR</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[L. Lathauwer, Signal Processing based on Multilinear Algebra. PhD Thesis, Universiteit Leuven, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[A. Marshall, and I. Olkin, "Multivariate Chebyshev Inequalities," <i>Annals of Mathematical Statistics</i>, 31(4), 1001-1014, 1960.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. Treisman and G. Gelade, "A Feature-Integration Theory of Attention," <i>Cognitive Psychology</i>, 12(1), 97- 136, 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507505</ref_obj_id>
				<ref_obj_pid>507503</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. Wang <i>et al.</i>, "SIMPLIcity: Semantics-Sensitive Integrated Matching for Picture Libraries," <i>IEEE Trans. PAMI</i>, 23(9), 947-963, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[D. Tao <i>et al.</i>, Tensor Rank One Discriminant Analysis. Tech. Rep., Birkbeck College, University of London, Nov. 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[A. Vailaya <i>et al.</i>, "On Image Classification: City Images vs. Landscapes," <i>Pattern Recognition</i>, 31(12), 1921- 1935, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106381</article_id>
		<sort_key>458</sort_key>
		<display_label></display_label>
		<pages>458-465</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>64</seq_no>
		<title><![CDATA[A Bernoulli Relational Model for Nonlinear Embedding]]></title>
		<page_from>458</page_from>
		<page_to>465</page_to>
		<doi_number>10.1109/ICDM.2005.1</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106381</url>
		<abstract>
			<par><![CDATA[The notion of relations is extremely important in mathematics. In this paper, we use relations to describe the embedding problem and propose a novel stochastic relational model for nonlinear embedding. Given some relation among points in a high-dimensional space, we start from preserving the same relation in a low embedded space and model the relation as probabilistic distributions over these two spaces, respectively. We illustrate that the stochastic neighbor embedding and the Gaussian process latent variable model can be derived from our relational model. Moreover we devise a new stochastic embedding model and refer to it as Bernoulli relational embedding (BRE). BRE's ability in nonlinear dimensionality reduction is illustrated on a set of synthetic data and collections of bitmaps of handwritten digits and face images.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15025894</person_id>
				<author_profile_id><![CDATA[81539583956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044522</person_id>
				<author_profile_id><![CDATA[81452605158]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Xi'an Jiaotong University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045224</person_id>
				<author_profile_id><![CDATA[81100116269]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Zhihua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042738</person_id>
				<author_profile_id><![CDATA[81100048867]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Frederick]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Lochovsky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Belkin and P. Niyogi. Laplacian eigenmaps and spectral techniques for embedding and clustering. In <i>Advances in Neural Information Processing Systems 14</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1630740</ref_obj_id>
				<ref_obj_pid>1630659</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Brand. Nonlinear dimensionality reduction by kernel eigenmaps. In <i>Proceedings, International Joint Conference on Artificial Intelligence(IJCAI-2003)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Brand. A unifying theorem for spectral embedding and clustering. In <i>The 9th International Conference on Artificial Intelligence and Statistics</i>, Key West, Florida, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[F. R. Chung. <i>Spectral Graph Theory</i>. American Mathematical Society, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[O. Dekel and Y. Singer. Multiclass learning by probabilistic embeddings. In <i>Advances in Neural Information Processing Systems 15</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Goldberger, S. Roweis, G. Hinton, and R. Salakhutdinov. Neighbourhood components analysis. In <i>Advances in Neural Information Processing Systems 17</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[G. Hinton and S. Roweis. Stochastic neighbor embedding. In <i>Advances in Neural Information Processing Systems 15</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>555246</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. Kolman, R. C. Busby, and S. C. Ross. <i>Discrete Mathematical Structures</i>. Prentice Hall, N.J., fourth edition, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[N. D. Lawrence. Gaussian process latent variable models for visualisation of high dimensional data. In <i>Advances in Neural Information Processing Systems 16</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. Memisevic and G. Hinton. Multiple relational embedding. In <i>Advances in Neural Information Processing Systems 17</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[I. T. Nabney. <i>NETLAB: Algorithms for Pattern Recognition</i>. Springer, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Roweis, L. K. Saul, and G. Hinton. Global coordination of local linear model. In <i>Advances in Neural Information Processing Systems 14</i>, pages 889-896, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. T. Roweis and L. K. Saul. Nonlinear dimensionality reduction by locally linear embedding. <i>Science</i>, 290(22):2323-2326, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>295960</ref_obj_id>
				<ref_obj_pid>295919</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[B. Sch&#246;lkopf, A. Smola, and K.-R. M&#252;ller. Nonlinear component analysis as a kernel eigenvalue problem. <i>Neural Computation</i>, 10:1299-1319, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. B. Tenenbaum, V. de Silva, and J. C. Langford. A global geometric framework for nonlinear dimensionality reduction. <i>Science</i>, 290(22):2319-2323, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[E. P. Xing, A. Y. Ng, M. I. Jordan, and S. Ressell. Distance metric learning with application to clustering with side information. In <i>Advances in Neural Information Processing Systems 15</i>, volume 15, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106382</article_id>
		<sort_key>466</sort_key>
		<display_label></display_label>
		<pages>466-473</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>65</seq_no>
		<title><![CDATA[Template-Based Privacy Preservation in Classification Problems]]></title>
		<page_from>466</page_from>
		<page_to>473</page_to>
		<doi_number>10.1109/ICDM.2005.142</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106382</url>
		<abstract>
			<par><![CDATA[In this paper, we present a template-based privacy preservation to protect against the threats caused by data mining abilities. The problem has dual goals: preserve the information for a wanted classification analysis and limit the usefulness of unwanted sensitive inferences that may be derived from the data. Sensitive inferences are specified by a set of "privacy templates". Each template specifies the sensitive information to be protected, a set of identifying attributes, and the maximum association between the two. We show that suppressing the domain values is an effective way to eliminate sensitive inferences. For a large data set, finding an optimal suppression is hard, since it requires optimization over all suppressions. We present an approximate but scalable solution. We demonstrate the effectiveness of this approach on real life data sets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Security, integrity, and protection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011735</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Theory of database privacy and security</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003018</concept_id>
				<concept_desc>CCS->Security and privacy->Database and storage security</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15043015</person_id>
				<author_profile_id><![CDATA[81350574174]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044796</person_id>
				<author_profile_id><![CDATA[81327488637]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Benjamin]]></first_name>
				<middle_name><![CDATA[C.  M.]]></middle_name>
				<last_name><![CDATA[Fung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large datasets. In <i>Proc. of the 1993 ACM SIGMOD</i>, pages 207-216, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1054048</ref_obj_id>
				<ref_obj_pid>1053724</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. J. Bayardo and R. Agrawal. Data privacy through optimal k-anonymization. In <i>Proc. of the 21st IEEE ICDE</i>, pages 217-228, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>371092</ref_obj_id>
				<ref_obj_pid>371090</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Clifton. Using sample size to limit exposure to data mining. <i>Journal of Computer Security</i>, 8(4):281-307, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>772867</ref_obj_id>
				<ref_obj_pid>772862</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. Clifton, M. Kantarcioglu, J. Vaidya, X. Lin, and M. Y. Zhu. Tools for privacy preserving data mining. <i>SIGKDD Explorations</i>, 4(2), 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[L. H. Cox. Suppression methodology and statistical disclosure control. <i>Journal of the American Statistics Association, Theory and Method Section</i>, 75:377-385, 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775080</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. In <i>Proc. of the 8th ACM SIGKDD</i>, pages 217-228, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>772864</ref_obj_id>
				<ref_obj_pid>772862</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Farkas and S. Jajodia. The inference problem: A survey. <i>SIGKDD Explorations</i>, 4(2):6-11, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1054047</ref_obj_id>
				<ref_obj_pid>1053724</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. C. M. Fung, K. Wang, and P. S. Yu. Top-down specialization for information and privacy preservation. In <i>Proc. of the 21st IEEE ICDE</i>, pages 205-216, Tokyo, Japan, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Hettich and S. D. Bay. The UCI KDD Archive, 1999. http://kdd.ics.uci.edu.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775089</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[V. S. Iyengar. Transforming data to satisfy privacy constraints. In <i>Proc. of the 8th ACM SIGKDD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014126</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Kantarcioglu, J. Jin, and C. Clifton. When do data mining results violate privacy? In <i>Proc. of the 2004 ACM SIGKDD</i>, pages 599-604, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Kim and W. Winkler. Masking microdata files. In <i>ASA Proc. of the Section on Survey Research Methods</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[W. Kloesgen. Knowledge discovery in databases and data privacy. In <i>IEEE Expert Symposium: Knowledge Discovery in Databases</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. R. Quinlan. <i>C4.5: Programs for Machine Learning</i>. Morgan Kaufmann, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>679937</ref_obj_id>
				<ref_obj_pid>646115</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[L. Sweeney. Datafly: A system for providing anonymity in medical data. In <i>Proc. of the 11th International Conference on Database Security</i>, pages 356-381, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>774553</ref_obj_id>
				<ref_obj_pid>774544</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[L. Sweeney. Achieving k-anonymity privacy protection using generalization and suppression. <i>International Journal on Uncertainty, Fuzziness, and Knowledge-based Systems</i>, 10(5):571-588, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>972279</ref_obj_id>
				<ref_obj_pid>972214</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[V. S. Verykios, A. K. Elmagarmid, E. Bertino, Y. Saygin, and E. Dasseni. Association rule hiding. <i>IEEE TKDE</i>, 16(4):434-447, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033461</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[K. Wang, P. S. Yu, and S. Chakraborty. Bottom-up generalization: a data mining solution to privacy protection. In <i>Proc. of the 4th IEEE ICDM</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>679951</ref_obj_id>
				<ref_obj_pid>646116</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[R. W. Yip and K. N. Levitt. The design and implementation of a data level database inference detection system. In <i>Proc. of the 12th International Working Conference on Database Security XII</i>, pages 253-266, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106383</article_id>
		<sort_key>474</sort_key>
		<display_label></display_label>
		<pages>474-481</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>66</seq_no>
		<title><![CDATA[On Reducing Classifier Granularity in Mining Concept-Drifting Data Streams]]></title>
		<page_from>474</page_from>
		<page_to>481</page_to>
		<doi_number>10.1109/ICDM.2005.108</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106383</url>
		<abstract>
			<par><![CDATA[Many applications use classification models on streaming data to detect actionable alerts. Due to concept drifts in the underlying data, how to maintain a model's up-to-dateness has become one of the most challenging tasks in mining data streams. State of the art approaches, including both the incrementally updated classifiers and the ensemble classifiers, have proved that model update is a very costly process. In this paper, we introduce the concept of model granularity. We show that reducing model granularity will reduce model update cost. Indeed, models of fine granularity enable us to efficiently pinpoint local components in the model that are affected by the concept drift. It also enables us to derive new components that can easily integrate with the model to reflect the current data distribution, thus avoiding expensive updates on a global scale. Experiments on real and synthetic data show that our approach is able to maintain good prediction accuracy at a fraction of model updating cost of state of the art approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>E.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011024.10011028</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language features->Data types and structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041286</person_id>
				<author_profile_id><![CDATA[81451596194]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fudan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040433</person_id>
				<author_profile_id><![CDATA[81455605782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haixun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763176</person_id>
				<author_profile_id><![CDATA[81309490924]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xiaochen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fudan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045421</person_id>
				<author_profile_id><![CDATA[81452601906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fudan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040806</person_id>
				<author_profile_id><![CDATA[81452594599]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Baile]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Fudan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz. UCI repository of machine learning databases. In <i>Univ. of California, Dept. of Information and Computer Science</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956807</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. H. Chang and W. S. Lee. Finding recent frequent itemsets adaptively over online data streams. In <i>SIGKDD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287398</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Y. Chen, G. Dong, J. Han, B. W. Wah, and J. Wang. Multi-dimensional regression analysis of time-series data streams. In <i>VLDB</i>, Hongkong, China, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033437</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Yun Chi, Haixun Wang, Philip S. Yu, and Richard R. Muntz. Moment: Maintaining closed frequent itemsets over a stream sliding window data streams. In <i>ICDM</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347107</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Domingos and G. Hulten. Mining high-speed data streams. In <i>SIGKDD</i>, pages 71-80, Boston, MA, 2000. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304197</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Gehrke, V. Ganti, R. Ramakrishnan, and W. Loh. BOAT- optimistic decision tree construction. In <i>SIGMOD</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671330</ref_obj_id>
				<ref_obj_pid>645924</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Gehrke, R. Ramakrishnan, and V. Ganti. RainForest: A framework for fast decision tree construction of large datasets. In <i>VLDB</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>796588</ref_obj_id>
				<ref_obj_pid>795666</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Guha, N. Milshra, R. Motwani, and L. O'Callaghan. Clustering data streams. In <i>FOCS</i>, pages 359-366, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502529</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[G. Hulten, L. Spencer, and P. Domingos. Mining time-changing data streams. In <i>SIGKDD</i>, pages 97-106, San Francisco, CA, 2001. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657866</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Wenmin Li, Jiawei Han, and Jian Pei. CMAR: Accurate and efficient classification based on multiple class-association rules. In <i>ICDM</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Bing Liu, Wynne Hsu, and Yiming Ma. Integrating classification and association rule mining. In <i>SIGKDD</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287400</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[G. Manku and R. Motwani. Approximate frequency counts over data streams. In <i>VLDB</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673491</ref_obj_id>
				<ref_obj_pid>645922</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[C. Shafer, R. Agrawal, and M. Mehta. Sprint: A scalable parallel classifier for data mining. In <i>VLDB</i>, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502568</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[W. Nick Street and YongSeog Kim. A streaming ensemble algorithm (SEA) for large-scale classification. In <i>SIGKDD</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956778</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Haixun Wang, Wei Fan, Philip S. Yu, and Jiawei Han. Mining concept-drifting data streams using ensemble classifiers. In <i>SIGKDD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Peng Wang, Haixun Wang, Xiaochen Wu, Wei Wang, and Baile Shi. On reducing classifier granularity in mining concept-drifting data streams. Technical report, http://wis.cs.ucla.edu/~ hxwang/publications/wangtech05.pdf, IBM T. J. Watson Research Center, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106384</article_id>
		<sort_key>482</sort_key>
		<display_label></display_label>
		<pages>482-489</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>67</seq_no>
		<title><![CDATA[Approximate Inverse Frequent Itemset Mining]]></title>
		<subtitle><![CDATA[Privacy, Complexity, and Approximation]]></subtitle>
		<page_from>482</page_from>
		<page_to>489</page_to>
		<doi_number>10.1109/ICDM.2005.27</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106384</url>
		<abstract>
			<par><![CDATA[In order to generate synthetic basket datasets for better benchmark testing, it is important to integrate characteristics from real-life databases into the synthetic basket datasets. The characteristics that could be used for this purpose include the frequent itemsets and association rules. The problem of generating synthetic basket datasets from frequent itemsets is generally referred to as inverse frequent itemset mining. In this paper, we show that the problem of approximate inverse frequent itemset mining is NP-complete. Then we propose and analyze an approximate algorithm for approximate inverse frequent itemset mining, and discuss privacy issues related to the synthetic basket dataset. In particular, we propose an approximate algorithm to determine the privacy leakage in a synthetic basket dataset.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[data mining, privacy, complexity, inverse frequent itemset mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Security, integrity, and protection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>Performance evaluation (efficiency and effectiveness)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011735</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Theory of database privacy and security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003636</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Approximation algorithms analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003018</concept_id>
				<concept_desc>CCS->Security and privacy->Database and storage security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003736.10003737</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Functional analysis->Approximation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15043735</person_id>
				<author_profile_id><![CDATA[81100232955]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yongge]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Charlotte]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43122728</person_id>
				<author_profile_id><![CDATA[81375615147]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xintao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Charlotte]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imilienski, and A. Swami. Mining association rules between sets of items in large databases. In <i>Proc. of ACM SIGMOD International Conference on Management of Database</i>, pages 207-216, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[T. Calders. <i>Axiomatization and Deduction Rules for the Frequency of Itemsets</i>. PhD Thesis, Universiteit Antwerpen, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1055580</ref_obj_id>
				<ref_obj_pid>1055558</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Calders. Computational complexity of itemset frequency satisfiability. In: <i>Proc. 23rd ACM PODS 04</i>, pages 143-154, ACM Press, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>83888</ref_obj_id>
				<ref_obj_pid>83884</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Fagin, J. Halpern, and N. Megiddo. A logic for reasoning about probabilities. <i>Information and Computation</i>, &#60;b&#62;87&#60;/b&#62;(1,2):78-128, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>49442</ref_obj_id>
				<ref_obj_pid>49441</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Georgakopoulos, D. Kavvadias, and C. Papadimitriou. Probabilistic satisfiability. <i>J. of Complexity</i>, &#60;b&#62;4&#60;/b&#62;:1-11, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Linear Programming Frequently Asked Questions. http://www-unix.mcs.anl.gov/otc/ Guide/faq/linear-programming-faq. html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Mielik&#228;inen. On inverse frequent set mining. In: <i>Proc. of 2nd Workshop on Privacy Preserving Data Mining (PPDM)</i>, pages 18-23, IEEE Computer Society, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. Potts. Analysis of a linear programming heuristic for scheduling unrelated parallel machines. <i>Discrete Appl. Math</i>. &#60;b&#62;10&#60;/b&#62;:155-164, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>773181</ref_obj_id>
				<ref_obj_pid>773153</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[G. Ramesh, W. Maniatty, and M. Zaki. Feasible itemset distributions in data mining: theory and application. In: <i>Proc. 22nd ACM PODS</i>, pages 284-295, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Y. Wang, X. Wu, and Y. Zheng. Privacy preserving data generation for database application performance testing. In: <i>Proc. 1st Int. Conf. on Trust and Privacy in Digital Business (TrustBus '04, together with DEXA)</i>, LNCS 3184, pages 142-151, 2004, Springer-Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[X. Wu, Y. Wu, Y. Wang, and Y. Li. Privacy aware market basket data set generation: a feasible approach for inverse frequent set mining. In <i>Proc. 5th SIAM International Conference on Data Mining</i>, April 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502572</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Z. Zheng, R. Kohavi, and L. Mason. Real world performance of association rule algorithms. In <i>Proc. of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 401- 406. ACM Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106385</article_id>
		<sort_key>490</sort_key>
		<display_label></display_label>
		<pages>490-497</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>68</seq_no>
		<title><![CDATA[Atomic Wedgie]]></title>
		<subtitle><![CDATA[Efficient Query Filtering for Streaming Times Series]]></subtitle>
		<page_from>490</page_from>
		<page_to>497</page_to>
		<doi_number>10.1109/ICDM.2005.28</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106385</url>
		<abstract>
			<par><![CDATA[In many applications it is desirable to monitor a streaming time series for predefined patterns. In domains as diverse as the monitoring of space telemetry, patient intensive care data, and insect populations, where data streams at a high rate and the number of predefined patterns is large, it may be impossible for the comparison algorithm to keep up. We propose a novel technique that exploits the commonality among the predefined patterns to allow monitoring at higher bandwidths, while maintaining a guarantee of no false dismissals. Our approach is based on the widely used envelope-based lower bounding technique. Extensive experiments demonstrate that our approach achieves tremendous improvements in performance in the offline case, and significant improvements in the fastest possible arrival rate of the data stream that can be processed with guaranteed no false dismissal.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15043051</person_id>
				<author_profile_id><![CDATA[81452594230]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Li]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Riverside]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044060</person_id>
				<author_profile_id><![CDATA[81100209161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eamonn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Keogh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Riverside]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041642</person_id>
				<author_profile_id><![CDATA[81322508252]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Helga]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Van Herle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762961</person_id>
				<author_profile_id><![CDATA[81309492786]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Agenor]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mafra-Neto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ISCA Technologies]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Carson, M. P., Fisher, A. J., & Scorza W. E. (2002). Atrial Fibrillation in Pregnancy Associated With Oral Terbutaline. <i>Obstet. Gynecol</i>, 100(5): pp. 1096-1097, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007374</ref_obj_id>
				<ref_obj_pid>1007352</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cole R., Gottlieb L., & Lewenstein M. (2004). Dictionary Matching and Indexing with Errors and Don't Cares. <i>In Proceedings of the 36th annual ACM Symposium on Theory of Computing</i>, pp. 91-100, Chicago, Illinois, June 13-15, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>958947</ref_obj_id>
				<ref_obj_pid>958942</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Diao, Y., Altinel, M., Franklin, M. J., Zhang, H., & Fischer, P. (2003). Path Sharing and Predicate Evaluation for High-Performance XML Filtering. <i>ACM Transactions on Database Systems</i>, 28(4): pp. 467-516, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564734</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gao L. & Wang X. (2002). Continually Evaluating Similarity-based Pattern Queries on a Streaming Time Series. <i>In Proceedings of the 2002 ACM SIGMOD International Conference on Management of Data</i>, pp. 370-381, Madison, Wisconsin, June 3-6, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Goldberger A., Amaral L., Glass L., Hausdorff J., Ivanov P., Mark R., Mietus J., Moody G., Peng C., & He S. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. <i>Circulation</i> 101(23): pp. 215-220, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[http://www.whitehouse.gov/omb/budget/fy2005/agricult ure.html (US Dept of Agriculture, Office of Budget and Management Website).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775062</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Keogh, E. & Kasetty, S. (2002). On the Need for Time Series Data Mining Benchmarks: A Survey and Empirical Demonstration. <i>In Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pp. 102-111, Edmonton, Alberta, Canada, July 23-26, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Keogh, E. http://www.cs.ucr.edu/~wli/ICDM05/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kuo, J.-C., Wen, C.-H. & Wu, A.-Y. (2003). Implementation of a Programmable 64-2048-point FFT/IFFT Processor for OFDM-Based Communication Systems. <i>In Proceedings of IEEE International Symposium on Circuits and Systems</i>, pp. 121-124, Bangkok, Thailand, May 25-28, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1437595</ref_obj_id>
				<ref_obj_pid>1435713</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Li Q., L&#243;pez I., & Moon B. (2004). Skyline Index for Time Series Data. <i>IEEE Transactions on Knowledge and Data Engineering</i>. 16(6): pp. 669-684, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Moore A. & Miller, R. H. (2002). Automated Identification of Optically Sensed Aphid (Homoptera: Aphidae) Wingbeat Waveforms. <i>Annals of the Entomological Society of America</i>, 95(1): pp. 1-8, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Pheromone Pest Management Moritor Technologies, Inc. http://www.moritor.com/web/]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106386</article_id>
		<sort_key>498</sort_key>
		<display_label></display_label>
		<pages>498-505</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>69</seq_no>
		<title><![CDATA[Discriminatively Trained Markov Model for Sequence Classification]]></title>
		<page_from>498</page_from>
		<page_to>505</page_to>
		<doi_number>10.1109/ICDM.2005.52</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106386</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a discriminative counterpart of the directed Markov Models of order k - 1, or MM(k-1) for sequence classification. MM(k-1) models capture dependencies among neighboring elements of a sequence. The parameters of the classifiers are initialized to based on the maximum likelihood estimates for their generative counterparts. We derive gradient based update equations for the parameters of the sequence classifiers in order to maximize the conditional likelihood function. Results of our experiments with data sets drawn from biological sequence classification (specifically protein function and subcellular localization) and text classification applications show that the discriminatively trained sequence classifiers outperform their generative counterparts, confirming the benefits of discriminative training when the primary objective is classification.Our experiments also show that the discriminatively trained MM(k - 1) sequence classifiers are competitive with the computationally much more expensive Support Vector Machines trained using k-gram representations of sequences.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.6</cat_node>
				<descriptor>Gradient methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Markov processes</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003648.10003700.10003701</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Stochastic processes->Markov processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003716</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003716</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003651</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Markov networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763115</person_id>
				<author_profile_id><![CDATA[81414607210]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Oksana]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yakhnenko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042569</person_id>
				<author_profile_id><![CDATA[81100327674]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Adrian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Silvescu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040931</person_id>
				<author_profile_id><![CDATA[81100409481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Vasant]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Honavar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Andorf, A. Silvescu, D. Dobbs, and V. Honavar. Learning classifiers for assigning protein sequences to gene ontology (GO) functional families. In <i>Proceedings of the Fifth International Conference On Knowledge Based Computer Systems (KBCS)</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. D. Appel, A. Bairoch, and D. F. Hochstrasser. A new generation of information retrieval tools for biologists: the new example of ExPASy www server. <i>Trenchs Biochem. Sci</i>, 19:258-260, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>500801</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Baldi and S. Brunak. <i>Bioinformatics: The Machine Learning Approach</i>. MIT Press, Cambridge, MA, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Bhasin and G. P. S. Raghava. ESLpred: SVM-based method for sub-cellular localization of eukaryotic proteins using dipeptide composition and PSI-BLAST. <i>Nucleic Acids Research</i>, 32, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Bouchard and B. Triggs. The trade-off between generative and discriminative classifiers. In <i>Proceedings to IASC International Symposium on Computational Statistics (CompStat)</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>581061</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[E. Charniak. <i>Statistical Language Learning (Language, Speech, and Communication)</i>. MIT Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B. Y. M. Cheng, J. G. Carbonell, and J. Klein-Seetharaman. Protein classification based on text document classification techniques. <i>Proteins</i>, 1(58):955-70, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>554525</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. G. Cowell, A. P. Dawid, S. L. Lauritzen, and D. J. Spiegelhalter. Probabilistic networks and expert systems. <i>Springer</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288651</ref_obj_id>
				<ref_obj_pid>288627</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Dumais, J. Platt, D. Heckerman, and M. Sahami. Inductive learning algorithms and representations for text categorization. In <i>CIKM '98: Proceedings of the seventh international conference on Information and knowledge management</i>, pages 148-155. ACM Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015339</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. Grossman and P. Domingos. Learning bayesian network classifiers by maximizing conditional likelihood. In <i>Proceedings to the 21st International Conference On Machine Learning (ICML)</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Hua and Z. Sun. Support vector machine approach for protein subcellular localization prediction. <i>Bioinformatics</i>, 17(8):721-8, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[C. Leslie, E. Eskin, J. Weston, and W. Noble. Mismatch string kernels for SVM protein classification. In <i>Advances in Neural Information Processing Systems (NIPS) 15</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2100633</ref_obj_id>
				<ref_obj_pid>2100584</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. McCallum. Efficiently inducing features of conditional random fields. In <i>Proc. of Conference on Uncertainty in Artificial Intelligence (UAI)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. McCallum and K. Nigam. A comparison of event models for naive bayes text classification. In <i>AAAI-98 Workshop on "Learning for Text Categorization</i>", 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[A. Ng and M. Jordan. On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>964610</ref_obj_id>
				<ref_obj_pid>964569</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[F. Peng, D. Shuurmans, and S. Wang. Augmenting naive bayes classifier using statistical n-gram language modeling. <i>Information Retrieval</i>, 7(3- 4):317-345, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>307376</ref_obj_id>
				<ref_obj_pid>307343</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[N. Qian. On the momentum term in gradient descent learning algorithms. <i>Neural Networks</i>, 12:145-151, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[R. Raina, Y. Shen, A. Ng, and A. McCallum. Classification with hybrid generative/discriminative models. In <i>Advances in Neural Information Processing Systems (NIPS) 16</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[A. Reinhardt and T. Hubbard. Using neural networks for prediction of the subcellular location of proteins. <i>Nucleic Acids Research</i>, 26(9):2230- 2236, May 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1067331</ref_obj_id>
				<ref_obj_pid>1067327</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[T. Roos, H. Wettig, P. Gr&#252;nwald, P. Mullym&#228;ki, and H. Tirri. On discriminative bayesian network classifiers and logistic regression. <i>Machine Learning</i>, (59):267-296, June, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[D. Rubinstein and T. Hastie. Discriminative vs informative learning. In <i>Proceedings of Knowledge Discovery and Data Mining (KDD)</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2073934</ref_obj_id>
				<ref_obj_pid>2073876</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[B. Taskar, P. Abbeel, and D. Koller. Discriminative probabilistic models for relational data. In <i>Proc. of Eighteenth Conference On Uncertainty in Artificial Intelligence (UAI02)</i>, Edmonton, Canada, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[V. N. Vapnik. <i>The Nature of Statistical Learning Theory</i>. Springer-Verlag, New York, New York, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1093274</ref_obj_id>
				<ref_obj_pid>1090314</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[C. Yan, D. Dobbs, V. Honavar, and D. Dobbs. A two-stage classifier for identification of proteinprotein interface residues. <i>Bioinfromatics</i>, 20(S1):i371-i378, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Z. Yuan. Prediction of protein subcellular locations using Markov chain models. <i>FEBS Letters</i>, 451(1):23-6, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106387</article_id>
		<sort_key>506</sort_key>
		<display_label></display_label>
		<pages>506-513</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>70</seq_no>
		<title><![CDATA[Integrating Hidden Markov Models and Spectral Analysis for Sensory Time Series Clustering]]></title>
		<page_from>506</page_from>
		<page_to>513</page_to>
		<doi_number>10.1109/ICDM.2005.82</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106387</url>
		<abstract>
			<par><![CDATA[We present a novel approach for clustering sequences of multi-dimensional trajectory data obtained from a sensor network. The sensory time-series data present new challenges to data mining, including uneven sequence lengths, multi-dimensionality and high levels of noise. We adopt a principled approach, by first transforming all the data into an equal-length vector form while keeping as much temporal information as we can, and then applying dimensionality and noise reduction techniques such as spectral clustering to the transformed data. Experimental evaluation on synthetic and real data shows that our proposed approach outperforms standard model-based clustering algorithms for time series data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15031571</person_id>
				<author_profile_id><![CDATA[81100408980]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041607</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1965889</ref_obj_id>
				<ref_obj_pid>1965841</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Alon, S. Sclaroff, G. K. G., and V. Pavlovic. Discovering clusters in motion time-series data. In <i>Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition</i>, pages 375-381, Madison, Wisconsin, USA, June 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347119</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. V. Cadez, S. Gaffney, and P. Smyth. A general probabilistic framework for clustering individuals and objects. In <i>Proceedings of sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 140-149, Boston, MA, USA, August 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1630790</ref_obj_id>
				<ref_obj_pid>1630659</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[G. Czielniak, M. Bennewitz, and W. Burgard. Where is ...? learning and utilizing motion patterns of persons with mobile robots. In <i>Proceedings of International Joint Conference on Artificial Intelligence</i>, pages 909-914, Acapulco, Mexico, Augest 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. B. Eisen, P. T. Spellman, P. O. Brown, and D. Bostein. Cluster analysis and display of genome-wide expession patterns. <i>Proceedings of the National Academy of Sciences of the United States of America</i>, 95(25):14863-14868, December 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312198</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Gaffney and P. Smyth. Trajectory clustering with mixtures of regression models. In <i>Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 63-72, San Diego, CA, USA, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. K. Jain and R. C. Dubes. <i>Algorithms for Clustering Data</i>. Prentice Hall, Englewood Cliffs, NJ, USA, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775062</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Keogh and S. Kasetty. On the need for time series data mining benchmarks: A survey and empirical demonstration. In <i>Proceedings of the eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 102-111, Edmonton, Alberta, Canada, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312186</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. Larsen and C. Aone. Fast and effective text mining using linear-time document clustering. In <i>Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining</i>, pages 16-22, San Diego, CA, USA, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657799</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. Li and G. Biswas. A Bayesian approach to temporal data clustering using hidden Markov models. In <i>Proceedings of the International Conference on Machine Learning</i>, pages 543-550, Stanford, CA, USA, June 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Meila and J. Shi. Learning segmentation by random walks. In T. K. Leen, T. G. Dietterich, and V. Tresp, editors, <i>Advances in Neural Information Processing Systems 13</i>, pages 873-879. MIT Press, Denver, CO, USA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral clustering: Analysis and an algorithm. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, <i>In Advances in Neural Information Processing Systems 14</i>, pages 849-856. MIT Press, Vancouver, British Columbia, Canada, December 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>713886</ref_obj_id>
				<ref_obj_pid>647073</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. Oates, L. Firoiu, and R. P. Cohen. Using dynamic time warping to bootstrap hmm-based clustering of time series. <i>Sequence Learning: Paradigms, Algorithms and Applications</i>, pages 35-52, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>721117</ref_obj_id>
				<ref_obj_pid>647288</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[T. Oates, M. D. Schmill, and P. R. Cohen. A method for clustering the experiences of a mobile robot that accords with human judgements. In <i>Proceedings of the Seventeenth National Conference on Artificial Intelligence</i>, pages 846-851, Austin, Texas, USA, August 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[L. R. Rabiner. A tutorial on hidden Markov models and selected applications in speech recognition. <i>Proceedings of the IEEE</i>, 77(2):257-286, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[P. Smyth. Clustering sequences with hidden Markov models. In M. C. Mozer, M. I. Jordan, and T. Petsche, editors, <i>Advances in Neural Information Processing System 9</i>, pages 648-654. The MIT Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844814</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Y. Xiong and D. Yeung. Mixtures of ARMA models for model-based time series clustering. In <i>Proceedings of the 2002 IEEE International Conference on Data Mining</i>, pages 717-720, Maebashi City, Japan, December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106388</article_id>
		<sort_key>514</sort_key>
		<display_label></display_label>
		<pages>514-521</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>71</seq_no>
		<title><![CDATA[Discriminant Analysis]]></title>
		<subtitle><![CDATA[A Unified Approach]]></subtitle>
		<page_from>514</page_from>
		<page_to>521</page_to>
		<doi_number>10.1109/ICDM.2005.51</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106388</url>
		<abstract>
			<par><![CDATA[Linear discriminant analysis (LDA) as a dimension reduction method is widely used in data mining and machine learning. It however suffers from the small sample size (SSS) problem when data dimensionality is greater than the sample size. Many modified methods have been proposed to address some aspect of this difficulty from a particular viewpoint. A comprehensive framework that provides a complete solution to the SSS problem is still missing. In this paper, we provide a unified approach to LDA, and investigate the SSS problem in the framework of statistical learning theory. In such a unified approach, our analysis results in a deeper understanding of LDA. We demonstrate that LDA (and its nonlinear extension) belongs to the same framework where powerful classifiers such as support vector machines (SVMs) are formulated. In addition, this approach allows us to establish an error bound for LDA. Finally our experiments validate our theoretical analysis results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15042622</person_id>
				<author_profile_id><![CDATA[81100114269]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763114</person_id>
				<author_profile_id><![CDATA[81309499503]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Norbert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Riedel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Bartlett. Further aspects of the theory of multiple regression. In <i>Proceedings of the Cambridge Philosophical Society</i>, number 34, 1938.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261512</ref_obj_id>
				<ref_obj_pid>261506</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[V. Belhumeur, J. Hespanha, and D. Kriegman. Eigenfaces vs. fisherfaces: Recognition using class specific linear projection. <i>IEEE Trans. Pattern Analysis and Machine Intelligence</i>, 19(7):711-720, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Chen, H. M. Liao, M.T.Ko, J. Lin, and G. Yu. A new lda-based face recognition system which can solve the small sample size problem. <i>Pattern Recognition</i>, 33:1713-1726, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[F. Cucker and S. Smale. On the mathematical foundations of learning. <i>Bulletin of the American Mathematical Society</i>, 39(1):1-49, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[F. Cucker and S. Smale. Best choices for regularization parameters in learning theory: On the bias-variance problem. <i>Foundations Comput. Math.</i>, (4):413-428, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. O. Duda and P. E. Hart. <i>Pattern Classification and Scene Analysis</i>. John Wiley-Sons, New York, 1 edition, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Evgeniou, M. Pontil, and T. Poggio. Regularization networks and support vector machines. <i>Advances in Computational Mathematics</i>, 13(1):1-50, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Fisher. The use of multiple measurements in taxonomic problems. <i>Ann. Eugenics</i>, 7:178-188, 1936.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. H. Friedman. Regularized discriminant analysis. <i>Journal of the American Statistical Association</i>, 84(405):165-175, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>92131</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[K. Fukunaga. <i>Introduction to statistical pattern recognition</i>. Academic Press, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502527</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G. Fung and O. L. Mangasarian. Proximal support vector machine classifiers. In F. Provost and R. Srikant, editors, <i>Proceedings KDD-2001: Knowledge Discovery and Data Mining, August 26-29, 2001, San Francisco, CA</i>, pages 77- 86, New York, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>338461</ref_obj_id>
				<ref_obj_pid>338441</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A. Hoerl and R. Kennard. Ridge regression: Biased estimation for nonorthogonal problems. <i>Technometrics</i>, 12(3):55- 67, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>104000</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. K. J. Hertz and R. Palmer. <i>Introduction to the Theory of Neural Computation</i>. Addison Wesley, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1038240</ref_obj_id>
				<ref_obj_pid>1038062</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Yang, A.F. Frangi, J.-Y. Yang, D. Zhang, and Z. Jin. Kpca plus lda: a complete kernel fisher discriminant framework for feature extraction and recognition. <i>IEEE Trans. on Pattern Analysis and Machine Intelligence</i>, 27:230-244, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[K. Liu, Y. Cheng, and J. Yang. A generalized optimal set of discriminant vectors. <i>Pattern Recognition</i>, 25(7):731-739, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2327075</ref_obj_id>
				<ref_obj_pid>2325795</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J. Lu, K. N. Plataniotis, and A. N. Venetsanopoulos. Face recognition using kernel direct discriminant analysis algorithms. <i>IEEE Transactions on Neural Networks</i>, 14(1):117- 126, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[S. Mika. <i>Kernel Fisher Discriminants</i>. PhD thesis, University of Technology, Berlin, October 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[T. Poggio and S. Smale. The mathematics of learning: Dealing with data. <i>Notices of the American Mathematical Society</i>, 50(5):537-544, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. A. K. Suykens, T. V. Gestel, J. D. Brabanter, B. D. Moor, and J. Vandewalle. <i>Least Squares Support Vector Machines</i>. World Scientific Pub. Co., Singapore, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>236271</ref_obj_id>
				<ref_obj_pid>236262</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[D. Swets and J. Weng. Using discriminant eigenfeatures for image retrieval. <i>IEEE Trans. Pattern Analysis and Machine Intelligence</i>, 18(8):831-836, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[A. N. Tikhonov and V. Y. Arsenin. <i>Solutions of Ill-posed problems</i>. John Wiley and Sons, Washington D.C., 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik. <i>Statistical Learning Theory</i>. Wiley, New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[H. Yu and J. Yang. A direct lda algorithm for high-dimension data with application to face recognition. <i>Pattern Recognition</i>, 34:2067-2070, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1020467</ref_obj_id>
				<ref_obj_pid>1018427</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[P. Zhang and J. Peng. Svm vs regularized least squares classification. In <i>Proceedings of IEEE International Conference on Pattern Recognition</i>, volume 1, pages 176-179, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106389</article_id>
		<sort_key>522</sort_key>
		<display_label></display_label>
		<pages>522-529</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>72</seq_no>
		<title><![CDATA[Sharing Classifiers among Ensembles from Related Problem Domains]]></title>
		<page_from>522</page_from>
		<page_to>529</page_to>
		<doi_number>10.1109/ICDM.2005.131</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106389</url>
		<abstract>
			<par><![CDATA[A classification ensemble is a group of classifiers that all solve the same prediction problem in different ways. It is well-known that combining the predictions of classifiers within the same problem domain using techniques like bagging or boosting often improves the performance. This research shows that sharing classifiers among different but closely related problem domains can also be helpful. In addition, a semi-definite programming based ensemble pruning method is implemented in order to optimize the selection of a subset of classifiers for each problem domain. Computational results on a catalog dataset indicate that the ensembles resulting from sharing classifiers among different product categories generally have larger AUCs than those ensembles trained only on their own categories. The pruning algorithm not only prevents the occasional decrease of effectiveness caused by conflicting concepts among the problem domains, but also provides a better understanding of the problem domains and their relationships.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP48026879</person_id>
				<author_profile_id><![CDATA[81100126673]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Iowa]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041891</person_id>
				<author_profile_id><![CDATA[81100237093]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[Nick]]></middle_name>
				<last_name><![CDATA[Street]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Iowa]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45028029</person_id>
				<author_profile_id><![CDATA[81100046110]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Samuel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Burer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Iowa]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>599607</ref_obj_id>
				<ref_obj_pid>599591</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Bauer and R. Kohavi. An empirical comparison of voting classification algorithms: Bagging, boosting, and variants. <i>Machine Learning</i>, 36(1-2):105-139, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging predictors. <i>Machine Learning</i>, 24(2):123-140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Arcing classifiers. <i>Annals of Statistics</i>, 26:801- 849, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>570182</ref_obj_id>
				<ref_obj_pid>570181</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Random forests. <i>Machine Learning</i>, 45(1):5- 32, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Burer and R. Monteiro. A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization. <i>Mathematical Programming (Series B)</i>, 95:329- 357, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>262872</ref_obj_id>
				<ref_obj_pid>262868</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Caruana. Multitask learning. <i>Machine Learning</i>, 28(1):41-75, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015432</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. Caruana, A. Niculescu-Mizil, G. Crew, and A. Ksikes. Ensemble selection from libraries of models. In <i>Proc. of the 21st International Conference on Machine Learning</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>630505</ref_obj_id>
				<ref_obj_pid>630309</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P. K. Chan, W. Fan, A. Prodromidis, and S. J. Stolfo. Distributed data mining in credit card fraud detection. <i>IEEE Intelligent Systems</i>, November/December:67-74, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312283</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[W. Fan, S. J. Stolfo, and J. Zhang. The application of adaboost for distributed, scalable and on-line learning. In <i>Proc. of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 362-366. ACM Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[W. Fan, H. Wang, and P. Yu. Mining extremely skewed trading anomalies. In <i>Proc. of the 9th International Conference on Extending Database Technology</i>, pages 801-810, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. E. Schapire. Experiments with a new boosting algorithm. In <i>International Conference on Machine Learning</i>, pages 148-156, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>227684</ref_obj_id>
				<ref_obj_pid>227683</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. Geomans and D. Williamson. Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. <i>Journal of ACM</i>, 42:1115- 1145, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Q. Han, Y. Ye, and J. Zhang. An improved rounding method and semidefinite programming relaxation for graph partition. <i>Mathematical Programming</i>, pages 509-535, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628429</ref_obj_id>
				<ref_obj_pid>628297</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[L. K. Hansen and P. Salamon. Neural network ensembles. <i>IEEE Trans. Pattern Anal. Mach. Intell.</i>, 12(10):993-1001, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[A. Krogh and J. Vedelsby. Neural network ensembles, cross validation, and active learning. In G. Tesauro, D. Touretzky, and T. Leen, editors, <i>Advances in Neural Information Processing Systems</i>, volume 7, pages 231-238. MIT Press, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502557</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. Lazarevic and Z. Obradovic. The distributed boosting algorithm. In <i>KDD '01: Proc. of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 311-316. ACM Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>757762</ref_obj_id>
				<ref_obj_pid>645526</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[D. Margineantu and T. Dietterich. Pruning adaptive boosting. In <i>14th International Conference on Machine Learning</i>, pages 211-218, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[A. McCallum. Multi-label text classification with a mixture model trained by EM, 1999. AAAI Workshop on Text Learning.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[R. J. Quinlan. <i>C4.5: Programs for Machine Learning</i>. Morgan Kaufman, San Manteo, CA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[A. Sharkey. On combining artificial neural nets. <i>Connection Science</i>, 8:299-313, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502568</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[W. N. Street and Y. Kim. A streaming ensemble algorithm (SEA) for large-scale classification. In <i>Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-01)</i>, pages 377-382, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622445</ref_obj_id>
				<ref_obj_pid>1622434</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[G. Weiss and F. Provost. Learning when training data are costly: The effect of class distribution on tree induction. <i>Journal of Artificial Intelligence Research</i>, 19:315- 354, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Wikipedia. Herfindahl index, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148453</ref_obj_id>
				<ref_obj_pid>148448</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[D. H. Wolpert. Stacked generalization. <i>Neural Networks</i>, 5:241-259, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Y. Zhang, W. N. Street, and S. Burer. Ensemble pruning via semi-definite programming, 2005. Under review.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106390</article_id>
		<sort_key>530</sort_key>
		<display_label></display_label>
		<pages>530-537</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>73</seq_no>
		<title><![CDATA[A Visual Data Mining Framework for Convenient Identification of Useful Knowledge]]></title>
		<page_from>530</page_from>
		<page_to>537</page_to>
		<doi_number>10.1109/ICDM.2005.16</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106390</url>
		<abstract>
			<par><![CDATA[Data mining algorithms usually generate a large number of rules, which may not always be useful to human users. In this project, we propose a novel visual data-mining framework, called Opportunity Map, to identify useful and actionable knowledge quickly and easily from the discovered rules. The framework is inspired by the House of Quality from Quality Function Deployment (QFD) in Quality Engineering. It associates discovered rules, related summarized data and data distributions with the application objective using an interactive matrix. Combined with drill down visualization, integrated visualization of data distribution bars and rules, visualization of trend behaviors, and comparative analysis, the Opportunity Map allows users to analyze rules and data at different levels of detail and quickly identify the actionable knowledge and opportunities. The proposed framework represents a systematic and flexible approach to rule analysis. Applications of the system to large-scale data sets from our industrial partner have yielded promising results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.5</cat_node>
				<descriptor>Interactive systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.4.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003129</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interactive systems and tools</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP48025712</person_id>
				<author_profile_id><![CDATA[81100535537]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kaidi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040113</person_id>
				<author_profile_id><![CDATA[81414615435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040736</person_id>
				<author_profile_id><![CDATA[81100547163]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Tirpak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Motorola Labs]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044166</person_id>
				<author_profile_id><![CDATA[81321500119]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Weimin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xiao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Motorola Labs]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adomavicius G. and Tuzhilin, A. "Discovery of actionable patterns in databases: the action hierarchy approach". KDD-97, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Agrawal R. and Srikant R. "Fast algorithms for mining association rules". VLDB-1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blanchard J, Guillet F, Briand H. "Exploratory Visualization for Association Rule Rummaging". KDD- 03 Workshop on Multimedia Data Mining, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bruzzese D., Davino C. "Visual Post-Analysis of Association Rules" ECML/PKDD VDM Workshop 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Chambers J.M, Cleveland W. S, Kleiner B, and Tukey P.A. Graphical Methods for Data Analysis. Chapman & Hall, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cohen L. Quality Function Deployment. Prentice Hall, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347139</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Han J, Cercone N. "RuleViz: A Model for Visualizing Knowledge Discovery Process". KDD-00, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Han J., Fu, Y., Wang W., Koperski, K. and Zaiane, O. "DMQL: a data mining query language for relational databases". SIGMOD Workshop on DMKD, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347133</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hofmann H, Siebes A., Wilhelm, A. "Visualizing association rules with interactive mosaic plots". KDD- 00, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Jorge A., Pocas J., Azevedo P. "Post-processing environment for browsing large sets of association rules". PKDD-02 VDM Workshop, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614508</ref_obj_id>
				<ref_obj_pid>614285</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Keim D. "Information Visualization and Visual Data Mining". IEEE Trans. Vis. Comput. Graph, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Liu B., Hsu W., and Chen S. "Using general impressions to analyze discovered classification rules". KDD-97, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Liu B., Hsu W, Ma Y. "Integrating Classification and Association Rule Mining". KDD-98, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312274</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Liu B., Hsu W., and Ma Y. "Mining Association Rules with Multiple Minimum Support". KDD-99. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502560</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Liu, B., Hsu, H., Ma, Y. "Identifying Non-Actionable Association Rules". KDD-01, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Ma S., Hellerstein J. "Ordering Categorical Data to Improve Visualization". INFOVIS-99, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Ong K-H, Ong K-L, Ng W-K, Lim E-P. "CrystalClear: Active Visualization of Association Rules". ICDM-02 Workshop on Active Mining (AM-02), 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Padmanabhan B. and Tuzhilin A. "A belief-driven method for discovering unexpected patterns". KDD-98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Piatesky-Shapiro G., and Matheus C. "The interestingness of deviations". KDD-94, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Quinlan J. R. 1992. C4.5: program for machine learning. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627804</ref_obj_id>
				<ref_obj_pid>627307</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Silberschatz A., and Tuzhilin, A. "What makes patterns interesting in knowledge discovery systems." IEEE Trans. on Know. and Data Eng. 8(6), 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Suzuki E., "Autonomous discovery of reliable exception rules". KDD-97, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Terninko J. "Step-by-Step QFD: Customer-Driven Product Design". Saint Lucie Press. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775055</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Tuzhilin A., and Liu, B. "Querying multiple sets of discovered rules". KDD, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>857670</ref_obj_id>
				<ref_obj_pid>857189</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Wong P-C, Whitney P, Thomas J. "Visualizing Association Rules for Text Mining". INFOVIS-99.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Zhao K. Liu B. "Visual Analysis of the Behavior of Discovered Rules". KDD-2001 Workshop on Visual Data Mining.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014108</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Zhao K. Liu, B., Tirpak, T., and Schaller, A. "V-Miner: Using Enhanced Parallel Coordinates to Mine Product Design and Test Data". KDD-2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1099568</ref_obj_id>
				<ref_obj_pid>1099554</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Zhao K., Liu B., Tirpak T., and Xiao W. "Opportunity Map: A Visualization Framework for Fast Identification of Actionable Knowledge". CIKM 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106391</article_id>
		<sort_key>538</sort_key>
		<display_label></display_label>
		<pages>538-545</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>74</seq_no>
		<title><![CDATA[Efficient Text Classification by Weighted Proximal SVM]]></title>
		<page_from>538</page_from>
		<page_to>545</page_to>
		<doi_number>10.1109/ICDM.2005.56</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106391</url>
		<abstract>
			<par><![CDATA[In this paper, we present an algorithm that can classify large-scale text data with high classification quality and fast training speed. Our method is based on a novel extension of the proximal SVM mode [3]. Previous studies on proximal SVM have focused on classification for low dimensional data and did not consider the unbalanced data cases. Such methods will meet difficulties when classifying unbalanced and high dimensional data sets such as text documents. In this work, we extend the original proximal SVM by learning a weight for each training error. We show that the classification algorithm based on this model is capable of handling high dimensional and unbalanced data. In the experiments, we compare our method with the original proximal SVM (as a special case of our algorithm) and the standard SVM (such as SVM light) on the recently published RCV1-v2 dataset. The results show that our proposed method had comparable classification quality with the standard SVM. At the same time, both the time and memory consumption of our method are less than that of the standard SVM.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Text processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Parameter learning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010316</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040481</person_id>
				<author_profile_id><![CDATA[81309484049]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhuang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Beijing Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040151</person_id>
				<author_profile_id><![CDATA[81309512327]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Benyu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040812</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041150</person_id>
				<author_profile_id><![CDATA[81100045080]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Peking University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044221</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044562</person_id>
				<author_profile_id><![CDATA[81309508221]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Ying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Beijing Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>553876</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Baeza-Yates, R. and Ribeiro-Neto, B., <i>Modern Information Retrieval</i>. Addison Wesley, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593463</ref_obj_id>
				<ref_obj_pid>593419</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Burges, C., <i>A Tutorial on Support Vector Machine for Pattern Recognition</i>. Data Mining and Knowledge Discovery, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502527</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Fung, G. and Mangasarian, O. L., <i>proximal Support Vector Machine Classifiers</i>. In Proc. of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2001), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299104</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Joachims, T., <i>Making Large-Scale SVM Learning Practical</i>. Advances in Kernel Methods - Support Vector Learning, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Joachims T., SVM Light: Support Vector Machine. Feb 9th, 2004. http://svmlight.joachims.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Lewis, D. D., <i>Applying support vector machines to the TREC-2001 batch filtering and routing tasks</i>. In The Tenth Text REtrieval Conference (TREC 2001), pages 286-292, Gaithersburg, MD 20899-0001, 2002. National Institute of Standards and Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Lewis, D. D., <i>RCV1-v2/LYRL2004: The LYRL2004 Distribution of the RCV1-v2 Text Categorization Test Collection (12-Apr-2004 Version)</i>. http://www.jmlr.org/papers/volume5/lewis04a/lyrl2004_ rcv1v2_README.htm]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1005345</ref_obj_id>
				<ref_obj_pid>1005332</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lewis, D. D., Yang, Y. Rose, T. and Li, F., <i>RCV1: A New Benchmark Collection for Text Categorization Research</i>. Journal of Machine Learning Research, 5:361-397, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356000</ref_obj_id>
				<ref_obj_pid>355993</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Paige C. C. and Saunders, M. A., <i>Algorithm 583; LSQR: Sparse linear equations and least-squares problems</i>. TOMS 8(2), 195-209, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299105</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Platt, J., <i>Fast Training of Support Vector Machines using Sequential Minimal Optimization</i>. Advances in Kernel Methods - Support Vector Learning, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Vapnik, V. N., <i>Statistical Learning Theory</i>. John Wiley & Sons, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383975</ref_obj_id>
				<ref_obj_pid>383952</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Yang Y., <i>A study on thresholding strategies for text categorization</i>. In the Twenty-Fourth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 01), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Freund, Y. and Schapire, R, <i>Experiments with a New Boosting Algorithm</i>. Machine Learing: Proceedings of the Thirteenth International Conference (ICML 96), 199.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106392</article_id>
		<sort_key>549</sort_key>
		<display_label></display_label>
		<pages>549-552</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>75</seq_no>
		<title><![CDATA[A Rule Evaluation Support Method with Learning Models Based on Objective Rule Evaluation Indexes]]></title>
		<page_from>549</page_from>
		<page_to>552</page_to>
		<doi_number>10.1109/ICDM.2005.13</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106392</url>
		<abstract>
			<par><![CDATA[In this paper, we present a novel rule evaluation support method for post-processing of mined results with rule evaluation models based on objective indexes. Post-processing of mined results is one of the key issues to make a data mining process successfully. However, it is difficult for human experts to evaluate many thousands of rules from a large dataset with noises completely. To reduce the costs of rule evaluation procedures, we have developed the rule evaluation support method with rule evaluation models, which are obtained with objective rule evaluation indexes and evaluations of a human expert for each rule. Since the method is needed more accurate rule evaluation models, we have compared learning algorithms to construct rule evaluation models with the actual meningitis data mining result and actual rule sets from UCI datasets. Then we show the availability of our adaptive rule evaluation support method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.4.2</cat_node>
				<descriptor>Decision support (e.g., MIS)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010481.10010484</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Decision analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15042479</person_id>
				<author_profile_id><![CDATA[81100308224]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hidenao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Abe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Shimane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044836</person_id>
				<author_profile_id><![CDATA[81100219997]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shusaku]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsumoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Shimane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045246</person_id>
				<author_profile_id><![CDATA[81331500723]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Miho]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ohsaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Doshisha University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042717</person_id>
				<author_profile_id><![CDATA[81100449998]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Takahira]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yamaguchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Keio University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>325884</ref_obj_id>
				<ref_obj_pid>325865</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Frank, E., Wang, Y., Inglis, S., Holmes, G., and Witten, I. H.: Using model trees for classification, Machine Learning, Vol.32, No.1 (1998) 63-76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657305</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Frank, E, Witten, I. H., Generating accurate rule sets without global optimization, in Proc. of the Fifteenth International Conference on Machine Learning, (1998) 144-151.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>693003</ref_obj_id>
				<ref_obj_pid>646416</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gray, B., Orlowska, M. E.: CCAIIA: Clustering Categorical Attributes into Interesting Association Rules. Proc. of Pacific-Asia Conf. on Knowledge Discovery and Data Mining PAKDD-1998 (1998) 132-143.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hatazawa, H., Negishi, N., Suyama, A, Tsumoto, S., and Yamaguchi, T.: Knowledge Discovery Support from a Meningoencephalitis Database Using an Automatic Composition Tool for Inductive Applications, in Proc. of KDD Challenge 2000 in conjunction with PAKDD2000 (2000) 28-33.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hettich, S., Blake, C. L., and Merz, C. J.: UCI Repository of machine learning databases {http://www.ics.uci.edu/~mlearn/MLRepository.html}, Irvine, CA: University of California, Department of Information and Computer Science, (1998).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>559454</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hilderman, R. J. and Hamilton, H. J.: Knowledge Discovery and Measure of Interest, Kluwe Academic Publishers (2001).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hinton, G. E.: "Learning distributed representations of concepts", <i>Proceedings of 8th Annual Conference of the Cognitive Science Society</i>, Amherest, MA. Reprinted in R.G.M. Morris (ed.) (1986).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>173574</ref_obj_id>
				<ref_obj_pid>173568</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Holte, R. C.: Very simple classification rules perform well on most commonly used datasets, Machine Learning, Vol. 11 (1993) 63-91.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1053106</ref_obj_id>
				<ref_obj_pid>1053072</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Ohsaki, M., Kitaguchi, S., Kume, S., Yokoi, H., and Yamaguchi, T.: Evaluation of Rule Interestingness Measures with a Clinical Dataset on Hepatitis, in Proc. of ECML/PKDD 2004, LNAI3202 (2004) 362-373.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299105</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Platt, J.: Fast Training of Support Vector Machines using Sequential Minimal Optimization, Advances in Kernel Methods - Support Vector Learning, B. Sch&#246;lkopf, C. Burges, and A. Smola, eds., MIT Press (1999) 185-208.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Quinlan, R.: C4.5: Programs for Machine Learning, Morgan Kaufmann Publishers, (1993).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775053</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Tan, P. N., Kumar V., Srivastava, J.: Selecting the Right Interestingness Measure for Association Patterns. Proc. of Int. Conf. on Knowledge Discovery and Data Mining KDD-2002 (2002) 32-41.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323651</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Witten, I. H and Frank, E.: DataMining: Practical Machine Learning Tools and Techniques with Java Implementations, Morgan Kaufmann, (2000).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>693038</ref_obj_id>
				<ref_obj_pid>646417</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Yao, Y. Y. Zhong, N.: An Analysis of Quantitative Measures Associated with Rules. Proc. of Pacific-Asia Conf. on Knowledge Discovery and Data Mining PAKDD-1999 (1999) 479-488.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>858970</ref_obj_id>
				<ref_obj_pid>1435677</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Zhong, N., Yao, Y. Y., Ohshima, M.: Peculiarity Oriented Multi-Database Mining. IEEE Trans. on Knowledge and Data Engineering, 15, 4, (2003) 952-960.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106393</article_id>
		<sort_key>553</sort_key>
		<display_label></display_label>
		<pages>553-556</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>76</seq_no>
		<title><![CDATA[Mining Chains of Relations]]></title>
		<page_from>553</page_from>
		<page_to>556</page_to>
		<doi_number>10.1109/ICDM.2005.94</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106393</url>
		<abstract>
			<par><![CDATA[Traditional data mining applications consider the problem of mining a single relation between two attributes. For example, in a scientific bibliography database, authors are related to papers, and we may be interested in discovering association rules between authors. However, in real life, we often have multiple attributes related though chains of relations. For example, authors write papers, and papers concern one or more topics. Mining such relational chains poses additional challenges. In this paper we consider the following problem: given a chain of two relationsR&#8321;(A, P) and R&#8322;(P, T) we want to find selectors for the objects in T such that the projected relation between A and P satisfies a specific property. The motivation for our approach is that a given property might not hold on the whole dataset, but it might hold when projecting the data on a selector set. We discuss various algorithms and we examine the conditions under which the apriori technique can be used. We experimentally demonstrate the effectiveness of our methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040197</person_id>
				<author_profile_id><![CDATA[81100264320]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Foto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Afrati]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Technical University of Athens]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042004</person_id>
				<author_profile_id><![CDATA[81100143322]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gautam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Das]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Technical University of Athens]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39051588</person_id>
				<author_profile_id><![CDATA[81100631289]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Aristides]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gionis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Helsinki]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P108656</person_id>
				<author_profile_id><![CDATA[81100086722]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Heikki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mannila]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Helsinki]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36031702</person_id>
				<author_profile_id><![CDATA[81321495651]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Taneli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mielikainen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Helsinki]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P314388</person_id>
				<author_profile_id><![CDATA[81100152625]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Panayiotis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsaparas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Helsinki]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Bayardo, B. Goethals, and M. J. Zaki, editors. <i>Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033479</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Clare, H. E. Williams, and N. Lester. Scalable multirelational association mining. In <i>ICDM</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>742623</ref_obj_id>
				<ref_obj_pid>647997</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Dehaspe and L. D. Raedt. Mining association rules in multiple relations. In <i>ILP</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Dzeroski and N. L. editors. <i>Relational Data Mining</i>. Springer, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1065191</ref_obj_id>
				<ref_obj_pid>1065167</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Fagin, R. Guha, R. Kumar, J. Novak, D. Sivakumar, and A. Tomkins. Multi-structural databases. In <i>PODS</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276652</ref_obj_id>
				<ref_obj_pid>276627</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Gibson, J. Kleinberg, and P. Raghavan. Inferring web communities from link topology. In <i>HYPERTEXT</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658027</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Kuramochi and G. Karypis. Frequent subgraph discovery. In <i>ICDM</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593448</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and H. Toivonen. Levelwise search and borders of theories in knowledge discovery. <i>Data Mining and Knowledge Discovery</i>, 1(3):241-258, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>336564</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Sarawagi and G. Sathe. i&#60;sup&#62;3&#60;/sup&#62;: Intelligent, interactive investigaton of olap data cubes. In <i>SIGMOD</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007607</ref_obj_id>
				<ref_obj_pid>1007568</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[X. Yan, P. S. Yu, and J. Han. Graph indexing: a frequent structure-based approach. In <i>SIGMOD</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>804355</ref_obj_id>
				<ref_obj_pid>800133</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Yannakakis. Node-and edge-deletion NP-complete problems. In <i>STOC</i>, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775058</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Efficiently mining frequent trees in a forest. In <i>KDD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106394</article_id>
		<sort_key>557</sort_key>
		<display_label></display_label>
		<pages>557-560</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>77</seq_no>
		<title><![CDATA[A Preference Model for Structured Supervised Learning Tasks]]></title>
		<page_from>557</page_from>
		<page_to>560</page_to>
		<doi_number>10.1109/ICDM.2005.11</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106394</url>
		<abstract>
			<par><![CDATA[The preference model introduced in this paper gives a natural framework and a principled solution for a broad class of supervised learning problems with structured predictions, such as predicting orders (label and instance ranking), and predicting rates (classification and ordinal regression). We show how all these problems can be cast as linear problems in an augmented space, and we propose an on-line method to efficiently solve them. Experiments on an ordinal regression task confirm the effectiveness of the approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044895</person_id>
				<author_profile_id><![CDATA[81321488916]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fabio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aiolli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; di Padova]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[F. Aiolli. A unifying framework for supervised learning tasks. http://www.di.unipi.it/~aiolli/slpref-long.pdf, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[F. Aiolli and A. Sperduti. Preference learning for multiclass problems. In <i>NIPS</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K. Crammer and Y. Singer. Pranking with ranking. In <i>NIPS</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[O. Dekel, C. Manning, and Y. Singer. Log-linear models for label ranking. In <i>NIPS</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Har-Peled, D. Roth, and D. Zimak. Constraint classification for multiclass classification and ranking. In <i>NIPS</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106395</article_id>
		<sort_key>561</sort_key>
		<display_label></display_label>
		<pages>561-564</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>78</seq_no>
		<title><![CDATA[Blocking Anonymity Threats Raised by Frequent Itemset Mining]]></title>
		<page_from>561</page_from>
		<page_to>564</page_to>
		<doi_number>10.1109/ICDM.2005.37</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106395</url>
		<abstract>
			<par><![CDATA[In this paper we study when the disclosure of datamining results represents, per se, a threat to the anonymity of the individuals recorded in the analyzed database. The novelty of our approach is that we focus on an objective definition of privacy compliance of patterns without any reference to a preconceived knowledge of what is sensitive and what is not, on the basis of the rather intuitive and realistic constraint that the anonymity of individuals should be guaranteed. In particular, the problem addressed here arises from the possibility of inferring from the output of frequent itemset mining (i.e., a set of itemsets with support larger than a threshold &#243;), the existence of patterns with very low support (smaller than an anonymity threshold k)[3]. In the following we develop a simple methodology to block such inference opportunities by introducing distortion on the dangerous patterns.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Security, integrity, and protection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011735</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Theory of database privacy and security</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003018</concept_id>
				<concept_desc>CCS->Security and privacy->Database and storage security</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Management</gt>
			<gt>Security</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP45027964</person_id>
				<author_profile_id><![CDATA[81343488291]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Maurizio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Atzori]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ISTI - CNR and University of Pisa]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43123628</person_id>
				<author_profile_id><![CDATA[81100305585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Francesco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bonchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ISTI - CNR]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043872</person_id>
				<author_profile_id><![CDATA[81100458577]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Fosca]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Giannotti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ISTI - CNR]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043149</person_id>
				<author_profile_id><![CDATA[81100352341]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dino]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pedreschi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pisa]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[http://fimi.cs.helsinki.fi/data/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In <i>Proceedings of the 1993 ACM SIGMOD</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2101244</ref_obj_id>
				<ref_obj_pid>2101235</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Atzori, F. Bonchi, F. Giannotti, and D. Pedreschi. <i>k</i>- anonymous patterns. In <i>Proceedings of the PKDD'05</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>670313</ref_obj_id>
				<ref_obj_pid>645806</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Calders and B. Goethals. Mining all non-derivable frequent itemsets. In <i>Proceedings of the 6th PKDD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656256</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets for association rules. In <i>Proc. ICDT '99</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>774552</ref_obj_id>
				<ref_obj_pid>774544</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[L. Sweeney. <i>k</i>-anonymity: a model for protecting privacy. <i>International Journal on Uncertainty Fuzziness and Knowledge-based Systems</i>, 10(5), 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106396</article_id>
		<sort_key>565</sort_key>
		<display_label></display_label>
		<pages>565-568</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>79</seq_no>
		<title><![CDATA[Adaptive Clustering]]></title>
		<subtitle><![CDATA[Obtaining Better Clusters Using Feedback and Past Experience]]></subtitle>
		<page_from>565</page_from>
		<page_to>568</page_to>
		<doi_number>10.1109/ICDM.2005.17</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106396</url>
		<abstract>
			<par><![CDATA[Adaptive clustering uses external feedback to improve cluster quality; past experience serves to speed up execution time. An adaptive clustering environment is proposed that uses Q-learning to learn the reward values of successive data clusterings. Adaptive clustering supports the reuse of clusterings by memorizing what worked well in the past. It has the capability of exploring multiple paths in parallel when searching for good clusters. In a case study, we apply adaptive clustering to instance-based learning relying on a distance function modification approach. A distance function adaptation scheme that uses external feedback is proposed and compared with other distance function learning approaches. Experimental results indicate that the use of adaptive clustering leads to significant improvements of instance-based learning techniques, such as k-nearest neighbor classifiers. Moreover, as a by-product a new instance-based learning technique is introduced that classifies examples by solely using cluster representatives; this technique shows high promise in our experimental evaluation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P762078</person_id>
				<author_profile_id><![CDATA[81309486040]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Abraham]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bagherjeiran]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Houston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45027627</person_id>
				<author_profile_id><![CDATA[81339498116]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christoph]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Eick]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Houston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762996</person_id>
				<author_profile_id><![CDATA[81343489932]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chun-Sheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Houston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043592</person_id>
				<author_profile_id><![CDATA[81339533935]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ricardo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vilalta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Houston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Bagherjeiran, C. F. Eick, and R. Vilalta. Adaptive clustering: Better representatives with reinforcement learning. Technical Report UH-CS-05-06, University of Houston Computer Science Department, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz. UCI repository of machine learning databases, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C.-S. Chen. Using weight updating heuristics and randomized hill climbing distance function learning. Master's thesis, University of Houston, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Cohn, R. Caruana, and A. McCallum. Semi-supervised clustering with user feedback. Technical Report 2003-1892, Cornell University, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. F. Eick, A. Rouhana, A. Bagherjeiran, and R. Vilalta. Using clustering to learn distance functions for supervised similarity assessment. In <i>Proc. Int'l Conf. on Machine Learning and Data Mining</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. F. Eick and N. Zeidat. Using supervised clustering to enhance classifiers. In <i>Proc. 15th Int'l Symp. on Methodologies for Intelligent Systems</i>, Saratoga Springs, NY, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622748</ref_obj_id>
				<ref_obj_pid>1622737</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[L. P. Kaelbling, M. L. Littman, and A.W. Moore. Reinforcement learning: A survey. <i>J. Artif. Intell. Res.</i>, 4:237-285, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Kohonen, J. Hynninen, J. Kangas, J. Laaksonen, and K. Torkkola. LVQ PAK: The learning vector quantization program package. Technical report, Helsinki University of Technology, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. M. McQueen. Some methods of classification and analysis of multivariate observations. In <i>Proc. 5th Berkeley Symp. on Mathematical Statistics and Probability</i>, pages 281-297, 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>178741</ref_obj_id>
				<ref_obj_pid>178732</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. W. Moore and C. G. Atkeson. Prioritized sweeping-reinforcement learning with less data and less time. <i>Machine Learning</i>, 13:103-130, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>528623</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. L. Puterman. <i>Markov Decision Processes: Discrete Stochastic Dynamic Programming</i>. John Wiley & Sons, New York, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>773294</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Russell and P. Norvig. <i>Artificial Intelligence: A Modern Approach</i>. Prentice Hall, 2nd edition, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>139618</ref_obj_id>
				<ref_obj_pid>139611</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[C. J. Watkins and P. Dayan. Q-learning. <i>Machine Learning</i>, 8:279-292, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[E. P. Xing, A. Y. Ng, M. I. Jordan, and S. Russell. Distance metric learning, with application to clustering with side-information. In <i>Advances in Neural Information Processing Systems 15</i>. MIT Press, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106397</article_id>
		<sort_key>569</sort_key>
		<display_label></display_label>
		<pages>569-572</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>80</seq_no>
		<title><![CDATA[Semi-Supervised Mixture of Kernels via LPBoost Methods]]></title>
		<page_from>569</page_from>
		<page_to>572</page_to>
		<doi_number>10.1109/ICDM.2005.129</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106397</url>
		<abstract>
			<par><![CDATA[We propose an algorithmto construct classification models with a mixture of kernels from labeled and unlabeled data. The derived classifier is a mixture of models, each based on one kernel choice from a library of kernels. The sparse-favoring 1-norm regularization method is employed to restrict the complexity of mixture models and to achieve the sparsity of solutions. By modifying the column generation boosting algorithm LPBoost to a more general linear programming formulation, we are able to efficiently solve mixture-of-kernel problems and automatically select kernel basis functions centered at labeled data as well as unlabeled data. The effectiveness of the proposed approach is proved by experimental results on benchmark datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.6</cat_node>
				<descriptor>Linear programming</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003716.10011138.10010041</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Mathematical optimization->Continuous optimization->Linear programming</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003716.10011138.10010041</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Mathematical optimization->Continuous optimization->Linear programming</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP45027833</person_id>
				<author_profile_id><![CDATA[81100131666]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jinbo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Siemens Medical Solutions]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45027859</person_id>
				<author_profile_id><![CDATA[81100207722]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Glenn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Siemens Medical Solutions]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042145</person_id>
				<author_profile_id><![CDATA[81344490105]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Murat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dundar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Siemens Medical Solutions]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041851</person_id>
				<author_profile_id><![CDATA[81326491982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Bharat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Siemens Medical Solutions]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. S. Bazaraa, H. D. Sherali, and C. M. Shetty. <i>Nonlinear Programming: Theory and Algorithms</i>. John Wiley & Sons, Inc., New York, NY, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775051</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[K. Bennett, M. Momma, and M. Embrechts. MARK: A boosting algorithm for heterogeneous kernel models. In <i>Proceedings of SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 24-31, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014113</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Bi, T. Zhang, and K. P. Bennett. Column-generation boosting methods for mixture of kernels. In <i>Proceedings of SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 521-526, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>599656</ref_obj_id>
				<ref_obj_pid>599613</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Demiriz, K. P. Bennett, and J. Shawe-Taylor. Linear programming boosting via column generation. <i>Machine Learning</i>, 46(1-3):225-254, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1005334</ref_obj_id>
				<ref_obj_pid>1005332</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Lanckriet, N. Cristianini, P. Bartlett, L. Ghaoui, and M. I. Jordan. Learning the kernel matrix with semidefinite programming. <i>Journal of Machine Learning Research</i>, 5:27-72, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. G. Nash and A. Sofer. <i>Linear and Nonlinear Programming</i>. McGraw-Hill, New York, NY, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[V. N. Vapnik. <i>Statistical Learning Theory</i>. John Wiley & Sons, Inc., New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106398</article_id>
		<sort_key>573</sort_key>
		<display_label></display_label>
		<pages>573-576</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>81</seq_no>
		<title><![CDATA[A Levelwise Search Algorithm for Interesting Subspace Clusters]]></title>
		<page_from>573</page_from>
		<page_to>576</page_to>
		<doi_number>10.1109/ICDM.2005.9</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106398</url>
		<abstract>
			<par><![CDATA[We present a levelwise search algorithm for finding subspace clusters in high dimensional data satisfying various properties besides the commonly used minimum density property. A set of such properties are summarized and a user can choose any of these properties. A lattice is built with all the discovered clusters which enables further analysis and discovery of useful knowledge about the clusters and their inter-relationships.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Search process</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.5</cat_node>
				<descriptor>Interactive systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003129</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interactive systems and tools</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003325</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Information retrieval query processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763032</person_id>
				<author_profile_id><![CDATA[81309490493]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Haiyun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cincinnati]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43123546</person_id>
				<author_profile_id><![CDATA[81100498916]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Raj]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bhatnagar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cincinnati]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>276314</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, J. Gehrke, D. Gunopulos, and P. Raghavan. Automatic subspace clustering of high dimensional data for data mining applications. In <i>ACM SIGMOD Conference Proceedings</i>, pages 94-105, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases. In <i>Proceedings of ACM SIGMOD Conference on Management of Data</i>, pages 207-216, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Mining sequential patterns. In <i>Proceedings of 11th International Conference on Data Engineering</i>, pages 3-14, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[U. Alon, N. Barkai, D. A. Notterman, K. Gish, S. Ybarra, D. Mack, and A. J. Levine. Broad patterns of gene expression revealed by clustering of tumor and normal colon tissues probed by oligonucleotide arrays. In <i>Proceedings of National Academy Science</i>, pages 6745-6750, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz. UCI repository of machine learning databases, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312199</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. H. Cheng, A. W.-C. Fu, and Y. Zhang. Entropy-based subspace clustering for mining numerical data. <i>Knowledge Discovery and Data Mining</i>, pages 84-93, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Goil, H. Nagesh, and A. Choudhary. Mafia: efficient and scalable subspace clustering for very large data sets. <i>Technical Report CPDC-TR-9906-010, Northwestern University</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P. Krger, H. P. Kriegel, and K. Kailing. Density-connected subspace clustering for high-dimensional data. In <i>Proceedings of SIAM International Conference on Data Mining</i>, pages 246-257, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. Lindig. Fast concept analysis. In <i>Working with Conceptual Structures - Contributions to ICCS</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642208</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[L. D. Raedt and S. Kramer. The levelwise version space algorithm and its application to molecular fragment finding. In <i>Proceedings of IJCAI</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106399</article_id>
		<sort_key>577</sort_key>
		<display_label></display_label>
		<pages>577-580</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>82</seq_no>
		<title><![CDATA[Segment-Based Injection Attacks against Collaborative Filtering Recommender Systems]]></title>
		<page_from>577</page_from>
		<page_to>580</page_to>
		<doi_number>10.1109/ICDM.2005.127</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106399</url>
		<abstract>
			<par><![CDATA[Significant vulnerabilities have recently been identi- fied in collaborative filtering recommender systems. Researchers have shown that attackers can manipulate a system's recommendations by injecting biased profiles into it. In this paper, we examine attacks that concentrate on a targeted set of users with similar tastes, biasing the system's responses to these users. We show that such attacks are both pragmatically reasonable and also highly effective against both user-based and item-based algorithms. As a result, an attacker can mount such a "segmented" attack with little knowledge of the specific system being targeted and with strong likelihood of success.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>K.6.5</cat_node>
				<descriptor>Invasive software (e.g., viruses, worms, Trojan horses)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Security, integrity, and protection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>User profiles and alert services</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>K.4.4</cat_node>
				<descriptor>Security</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002978.10003029</concept_id>
				<concept_desc>CCS->Security and privacy->Human and societal aspects of security and privacy</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011735</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Theory of database privacy and security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003022.10003028</concept_id>
				<concept_desc>CCS->Security and privacy->Software and application security->Domain-specific security and privacy architectures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10003550.10003557</concept_id>
				<concept_desc>CCS->Applied computing->Electronic commerce->Secure online transactions</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003018</concept_id>
				<concept_desc>CCS->Security and privacy->Database and storage security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003331.10003271</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Users and interactive retrieval->Personalization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003260.10003261.10003271</concept_id>
				<concept_desc>CCS->Information systems->World Wide Web->Web searching and information discovery->Personalization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10002997</concept_id>
				<concept_desc>CCS->Security and privacy->Intrusion/anomaly detection and malware mitigation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003462.10003574</concept_id>
				<concept_desc>CCS->Social and professional topics->Computing / technology policy->Computer crime</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Security</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040822</person_id>
				<author_profile_id><![CDATA[81100241179]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Burke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DePaul University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040260</person_id>
				<author_profile_id><![CDATA[81100172561]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bamshad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mobasher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DePaul University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763139</person_id>
				<author_profile_id><![CDATA[81309484424]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Runa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bhaumik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DePaul University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP38026681</person_id>
				<author_profile_id><![CDATA[81309513243]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Chad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[DePaul University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Burke, B. Mobasher, and R. Bhaumik. Limited knowledge shilling attacks in collaborative filtering systems. In <i>Proceedings of the 3rd IJCAI Workshop in Intelligent Techniques for Personalization</i>, Edinburgh, Scotland, August 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Burke, B. Mobasher, R. Zabicki, and R. Bhaumik. Identifying attack models for secure recommendation. In <i>Beyond Personalization: A Workshop on the Next Generation of Recommender Systems</i>, San Diego, California, January 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312682</ref_obj_id>
				<ref_obj_pid>312624</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Herlocker, J. Konstan, A. Borchers, and J. Riedl. An algorithmic framework for performing collaborative filtering. In <i>Proceedings of the 22nd ACM Conference on Research and Development in Information Retrieval (SIGIR'99)</i>, Berkeley, CA, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>963772</ref_obj_id>
				<ref_obj_pid>963770</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Herlocker, J. Konstan, L. G. Tervin, and J. Riedl. Evaluating collaborative filtering recommender systems. <i>ACM Transactions on Information Systems</i>, 22(1):5-53, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>988726</ref_obj_id>
				<ref_obj_pid>988672</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Lam and J. Reidl. Shilling recommender systems for fun and profit. In <i>Proceedings of the 13th International WWW Conference</i>, New York, May 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1031116</ref_obj_id>
				<ref_obj_pid>1031114</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. O'Mahony, N. Hurley, N. Kushmerick, and G. Silvestre. Collaborative recommendation: A robustness analysis. <i>ACM Transactions on Internet Technology</i>, 4(4):344-377, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>372071</ref_obj_id>
				<ref_obj_pid>371920</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Item-based collaborative filtering recommendation algorithms. In <i>Proceedings of the 10th International World Wide Web Conference</i>, Hong Kong, May 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106400</article_id>
		<sort_key>581</sort_key>
		<display_label></display_label>
		<pages>581-584</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>83</seq_no>
		<title><![CDATA[On Feature Selection through Clustering]]></title>
		<page_from>581</page_from>
		<page_to>584</page_to>
		<doi_number>10.1109/ICDM.2005.106</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106400</url>
		<abstract>
			<par><![CDATA[We study an algorithm for feature selection that clusters attributes using a special metric and then makes use of the dendrogram of the resulting cluster hierarchy to choose the most relevant attributes. The main interest of our technique resides in the improved understanding of the structure of the analyzed data and of the relative importance of the attributes for the selection process.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15042747</person_id>
				<author_profile_id><![CDATA[81539678956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Butterworth]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts at Boston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43122744</person_id>
				<author_profile_id><![CDATA[81100286057]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Gregory]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Piatetsky-Shapiro]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[KDnuggets]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043070</person_id>
				<author_profile_id><![CDATA[81100393892]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dan]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Simovici]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts at Boston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Agresti. <i>An Introduction to Categorical Data Analysis</i>. John Wiley, New York, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Barth&#233;lemy. Remarques sur les propri&#233;t&#233;s metriques des ensembles ordonn&#233;s. <i>Math. Sci. hum.</i>, 61:39-60, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Barth&#233;lemy and B. Leclerc. The median procedure for partitions. In <i>Partitioning Data Sets</i>, pages 3-34, Providence, 1995. American Mathematical Society.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. L. Blake and C. J. Merz. <i>UCI Repository of machine learning databases</i>. University of California, Irvine, Dept. of Information and Computer Sciences, http://www.ics.uci.edu/~mlearn/MLRepository.html, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>270626</ref_obj_id>
				<ref_obj_pid>270613</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Blum and P. Langley. Selection of relevant features and examples in machine learning. <i>Artificial Intelligence</i>, pages 245-271, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Brown, W. Grundy, D. Lin, N. Cristiani, C. W. Sugnet, T. Furey, M. Ares, and D. Haussler. Knowledge-based analysis of microarray gene expression data by using support vector machines. <i>PNAS</i>, 97:262-267, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944968</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Guyon and A. Elisseeff. An introduction to variable and feature selection. <i>J. of Machine Learning Research</i>, pages 1157-1182, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. A. Hall. <i>Correlation-based feature selection for machine learning</i>. PhD thesis, The University of Waikato, Hamilton, New Zealand, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>980977</ref_obj_id>
				<ref_obj_pid>980972</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[B. Hanczar, M. Courtine, A. Benis, C. Hannegar, K. Clement, and J. Zucker. Improving classification of microarray data using prototype-based feature selection. <i>SIGKDD Explorations</i>, pages 23-28, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[L. Kaufman and P. J. Rousseeuw. <i>Finding Groups in Data - An Introduction to Cluster Analysis</i>. Wiley Interscience, New York, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Khan, J. Wei, M. Ringner, L. H. Saal, M. Ladanyi, F. Westerman, F. Berthold, M. Schwab, C. R. Antonescu, C. Peterson, and P. Meltzer. Classification and diagnostic prediction of cancers using gene expression profiling and artificial neural networks. <i>Nature Medicine</i>, 7:673-679, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>270627</ref_obj_id>
				<ref_obj_pid>270613</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. Kohavi and G. John. Wrappers for feature selection. <i>Artificial Intelligence</i>, pages 273-324, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1208727</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Maindonald and J. Brown. <i>Data Analysis and Graphics Using R</i>. Cambridge University Press, Cambridge, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[B. Monjardet. Metrics on parially ordered sets - a survey. <i>Discrete Mathematics</i>, 35:173-184, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033521</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[D. Simovici and N. Singla. Metric incremental clustering of categorical data. In <i>Proceedings of ICDM</i>, pages 523-527, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323651</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[I. H. Witten and E. Frank. <i>Data Mining - Practical Machine Learning Tools and Techniques with Java Implementations</i>. Morgan Kaufmann, San Francisco, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1216722</ref_obj_id>
				<ref_obj_pid>1216715</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[D. Zongker and A. Jain. Algorithms for feature selection: An evaluation. In <i>Proceedings of the International Conference on Pattern Recognition</i>, pages 18-22, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106401</article_id>
		<sort_key>585</sort_key>
		<display_label></display_label>
		<pages>585-588</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>84</seq_no>
		<title><![CDATA[Sequential Pattern Mining in Multiple Streams]]></title>
		<page_from>585</page_from>
		<page_to>588</page_to>
		<doi_number>10.1109/ICDM.2005.130</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106401</url>
		<abstract>
			<par><![CDATA[In this paper, we deal with mining sequential patterns in multiple data streams. Building on a state-of-the-art sequential pattern mining algorithm PrefixSpan for mining transaction databases, we propose MILE, an efficient algorithm to facilitate the mining process. MILE recursively utilizes the knowledge of existing patterns to avoid redundant data scanning, and can therefore effectively speed up the new patterns' discovery process. Another unique feature of MILE is that it can incorporate some prior knowledge of the data distribution in data streams into the mining process to further improve the performance. Extensive empirical results show thatMILE is significantly faster than PrefixSpan. As MILE consumes more memory than PrefixSpan, we also present a solution to balance the memory usage and time efficiency in memory constrained environments.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>Performance evaluation (efficiency and effectiveness)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>E.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011024.10011028</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language features->Data types and structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044063</person_id>
				<author_profile_id><![CDATA[81309505353]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043082</person_id>
				<author_profile_id><![CDATA[81452596585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xindong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043717</person_id>
				<author_profile_id><![CDATA[81452600756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xingquan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[G. Chen, X. Wu, and X. Zhu. Mining sequential patterns across data streams. <i>Computer Science Technical Report CS-05-04, University of Vermont</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[G. Das, K.-I. Lin, H. Mannila, G. Renganathan, and P. Smyth. Rule discovery from time series. In <i>Proceedings of the 4th International Conference of Knowledge Discovery and Data Mining</i>, pages 16-22, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Oates and P. R. Cohen. Searching for structure in multiple streams of data. In <i>Proceedings of the 13th International Conference on Machine Learning</i>, pages 346-354, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1025077</ref_obj_id>
				<ref_obj_pid>1024872</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, B. Mortazavi-Asl, J. Wang, H. Pinto, Q. Chen, U. Dayal, and M.-C. Hsu. Mining sequential patterns by pattern-growth: The prefixspan approach. <i>IEEE Trans. Knowl. Data Eng.</i>, 16(11):1424- 1440, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106402</article_id>
		<sort_key>589</sort_key>
		<display_label></display_label>
		<pages>589-592</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>85</seq_no>
		<title><![CDATA[Privacy Preserving Data Classification with Rotation Perturbation]]></title>
		<page_from>589</page_from>
		<page_to>592</page_to>
		<doi_number>10.1109/ICDM.2005.121</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106402</url>
		<abstract>
			<par><![CDATA[Data perturbation techniques are one of the most popular models for privacy preserving data mining [3, 1]. It is especially convenient for applications where the data owners need to export/publish the privacy-sensitive data. A data perturbation procedure can be simply described as follows. Before the data owner publishes the data, they randomly change the data in certain way to disguise the sensitive information while preserving the particular data property that is critical for building the data models. Several perturbation techniques have been proposed recently, among which the most typical ones are randomization approach [3] and condensation approach [1].]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Security, integrity, and protection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>E.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10002979</concept_id>
				<concept_desc>CCS->Security and privacy->Cryptography</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002971.10003451.10002976</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Data structures->Data layout->Data encryption</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003777</concept_id>
				<concept_desc>CCS->Theory of computation->Computational complexity and cryptography</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003018</concept_id>
				<concept_desc>CCS->Security and privacy->Database and storage security</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011735</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Theory of database privacy and security</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Security</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15042644</person_id>
				<author_profile_id><![CDATA[81100107380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Keke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39047013</person_id>
				<author_profile_id><![CDATA[81350573402]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ling]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal and P. S. Yu. A condensation approach to privacy preserving data mining. <i>Proc. of Intl. Conf. on Extending Database Technology (EDBT)</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375602</ref_obj_id>
				<ref_obj_pid>375551</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Agrawal and C. C. Aggarwal. On the design and quantification of privacy preserving data mining algorithms. <i>Proc. of ACM PODS Conference</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335438</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Privacy-preserving data mining. <i>Proc. of ACM SIGMOD Conference</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[K. Chen and L. Liu. A random rotation perturbation approach to privacy preserving data classification. <i>Technical Report</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>773174</ref_obj_id>
				<ref_obj_pid>773153</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Evfimievski, J. Gehrke, and R. Srikant. Limiting privacy breaches in privacy preserving data mining. <i>Proc. of ACM PODS Conference</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1066163</ref_obj_id>
				<ref_obj_pid>1066157</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Z. Huang, W. Du, and B. Chen. Deriving private information from randomized data. <i>Proc. of ACM SIGMOD Conference</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. Hyvarinen, J. Karhunen, and E. Oja. <i>Independent Component Analysis</i>. Wiley-Interscience, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952160</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Kargupta, S. Datta, Q. Wang, and K. Sivakumar. On the privacy preserving properties of random data perturbation techniques. <i>Proc. of Intl. Conf. on Data Mining (ICDM)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Y. Lindell and B. Pinkas. Privacy preserving data mining. <i>Journal of Cryptology</i>, 15(3), 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106403</article_id>
		<sort_key>593</sort_key>
		<display_label></display_label>
		<pages>593-596</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>86</seq_no>
		<title><![CDATA[A Computational Framework for Taxonomic Research]]></title>
		<subtitle><![CDATA[Diagnosing Body Shape within Fish Species Complexes]]></subtitle>
		<page_from>593</page_from>
		<page_to>596</page_to>
		<doi_number>10.1109/ICDM.2005.3</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106403</url>
		<abstract>
			<par><![CDATA[It is estimated that ninety percent of the world's species have yet to be discovered and described. The main reason for the slow pace of new species description is that the science of taxonomy, as traditionally practiced, can be very laborious. To formally describe a new species, taxonomists have to manually gather and analyze data from large numbers of specimens, often from broad geographic areas, and identify the smallest subset of external body characters that uniquely diagnoses the new species as distinct from all its known relatives. In this paper, we use an automated feature selection and classification approach to address the taxonomic impediment in new species discovery. The experiments on a taxonomic problem involving species of suckers in the genus Carpiodes demonstrate promising results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Representations (procedural and rule-based)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010314</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Rule learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15045252</person_id>
				<author_profile_id><![CDATA[81100127466]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yixin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of New Orleans]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042765</person_id>
				<author_profile_id><![CDATA[81309497519]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Bart]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043086</person_id>
				<author_profile_id><![CDATA[81361599172]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shuqing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043448</person_id>
				<author_profile_id><![CDATA[81309501469]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Huimin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[F. Abramovich, Y. Benjamini, D. L. Donoho, and I. M. Johnstone, "Adapting to Unknown Sparsity by Controlling the False Discovery Rate," <i>Annals of Statistics</i>, 2005, to appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. C. Adams, F. J. Rohlf, and D. E. Slice, "Geometric Morphometrics: Ten Years of Progress Following the 'Revolution'," <i>Ital. J. Zool.</i>, 71:5-16, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944971</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Bi, K. P. Bennett, M. Embrechts, C. Breneman, and M. Song, "Dimensionality Reduction via Sparse Support Vector Machines," <i>Journal of Machine Learning Research</i>, 3:1229-1243, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. L. Pimm and J. H. Lawton, "Ecology-Planning for Biodiversity," <i>Science</i>, 279:2068-2069, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[F. J. Rohlf and F. L. Bookstein, <i>Proceedings of the Michigan Morphometrics Workshop</i>, Special Publ. No. 2, The University of Michigan Museum of Zoology, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. D. Suttkus and H. L. Bart, Jr., "A Preliminary Analysis of the River Carpsucker, Carpiodes Carpio, in the Southern Portion of its Range," <i>In: L. Lozano (ed.) Libro jubilar en honor al Dr. Salvador Contreras Balderas</i>, Universidad Autonoma de Nuevo Leon, Monterrey Mexico, pp. 209-221, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106404</article_id>
		<sort_key>597</sort_key>
		<display_label></display_label>
		<pages>597-600</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>87</seq_no>
		<title><![CDATA[Obtaining Best Parameter Values for Accurate Classification]]></title>
		<page_from>597</page_from>
		<page_to>600</page_to>
		<doi_number>10.1109/ICDM.2005.105</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106404</url>
		<abstract>
			<par><![CDATA[In this paper we examine the effect that the choice of support and confidence thresholds has on the accuracy of classifiers obtained by Classification Association Rule Mining. We show that accuracy can almost always be improved by a suitable choice of threshold values, and we describe a method for finding the best values. We present results that demonstrate this approach can obtain higher accuracy without the need for coverage analysis of the training data. Keywords: Classification, Association Rule Mining.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>Performance evaluation (efficiency and effectiveness)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P86339</person_id>
				<author_profile_id><![CDATA[81100499892]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Frans]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Coenen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Liverpool]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041631</person_id>
				<author_profile_id><![CDATA[81100359326]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Liverpool]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>2140863</ref_obj_id>
				<ref_obj_pid>2140831</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Coenen, F., Leng, P. and Zhang, L. (2005). <i>Threshold Tuning for Improved Classification Association Rule Mining</i> Proc PAKDD 2005: LNCS 3518, Springer, pp. 216-225.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657866</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Li W., Han, J. and Pei, J. (2001). <i>CMAR: Accurate and Efficient Classification Based on Multiple Class-Association Rules</i>. Proc ICDM 2001, pp. 369-376.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Liu, B. Hsu, W. and Ma, Y. (1998). <i>Integrating Classification and Association Rule Mining</i>. Proceedings KDD-98, New York, 27-31 August. AAAI. pp. 80-86.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Yin, X. and Han, J. (2003). <i>CPAR: Classification based on Predictive Association Rules</i>. Proc. SIAM Int. Conf. on Data Mining (SDM'03), San Francisco, CA, pp. 331-335.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106405</article_id>
		<sort_key>601</sort_key>
		<display_label></display_label>
		<pages>601-604</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>88</seq_no>
		<title><![CDATA[Process Diagnosis via Electrical-Wafer-Sorting Maps Classification]]></title>
		<page_from>601</page_from>
		<page_to>604</page_to>
		<doi_number>10.1109/ICDM.2005.123</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106405</url>
		<abstract>
			<par><![CDATA[The commonality analysis is a proven tool for fault detection in semiconductor manufacturing. This methodology extracts subsets of production lots from all the available data. Then, data mining techniques are used only on the selected data. This approach loses part of the available information and does not discriminate among the lots. The new methodology performance the automatic classificationof the electrical wafer test maps in order to identify the classes of failure present in the production lots. Subsequently, the proposed procedure uses the process history of each wafer to create a list of the root cause candidates. This methodology is the core of the software tool ACID which is currently used for process diagnosis at the Agrate site of the ST Microelectronics. A real analysis is presented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided manufacturing (CAM)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010481.10010483</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Computer-aided manufacturing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763020</person_id>
				<author_profile_id><![CDATA[81309501722]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Federico]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Di Palma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pavia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045090</person_id>
				<author_profile_id><![CDATA[81100449635]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Giuseppe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[De Nicolao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Pavia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39053499</person_id>
				<author_profile_id><![CDATA[81339517356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Guido]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miraglia]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ST Microelectronics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763116</person_id>
				<author_profile_id><![CDATA[81309498040]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Oliver]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Donzelli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ST Microelectronics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[G. E. P. Box, W. G. Hunter, and S. J. Huunter. <i>Statistics for Experimenters. An Introduction to Design, Data Analysis and Model Building</i>. Johin Wiley & Sons, New York, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[F. Chen and S. F. Liu. A neural network approach to recognize defect spatial pattern in semiconductor fabrication. <i>IEEE Trans. Semiconduct. Manufact.</i>, 13:366-373, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[F. DiPalma, G. DeNicolao, G. Miraglia, and O. M. Donzelli. Unsupervised algorithms for the automatic classification of ews maps: a comparison. In <i>ISSM International Simposium on Semiconductor Manufactoring</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1103092</ref_obj_id>
				<ref_obj_pid>1103084</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[F. DiPalma, G. DeNicolao, E. Pasquinetti, G. Miraglia, and F. Piccinini. Unsupervised spatial pattern classification of electrical failures in semiconductor manufacturing. <i>Pattern Recognition Letters</i>, 26:1857-1865, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Kong. Tool commonality analysis for yiel enhancement. <i>IEEE/SEMI Advanced Semiconductor Manufacturing Conference</i>, pages 202-205, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Lee, A. Chatterjee, and D. Croley. Advanced yield enhancement: computer-based spatial pattern analysis part 1. <i>IEEE/SEMI Advance Semiconductors Manufacturing conference</i>, pages 409-415, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Malinaric, R. Hoffmeistern, and C. Sun. Case study for root cause analysis of yield problems. <i>IEEE/SEMI Advance Semiconductors Manufacturing conference</i>, pages 8- 13, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106406</article_id>
		<sort_key>605</sort_key>
		<display_label></display_label>
		<pages>605-608</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>89</seq_no>
		<title><![CDATA[An Improved Categorization of Classifier's Sensitivity on Sample Selection Bias]]></title>
		<page_from>605</page_from>
		<page_to>608</page_to>
		<doi_number>10.1109/ICDM.2005.24</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106406</url>
		<abstract>
			<par><![CDATA[A recent paper categorizes classifier learning algorithms according to their sensitivity to a common type of sample selection bias where the chance of an example being selected into the training sample depends on its feature vector x but not (directly) on its class label y. A classifier learner is categorized as "local" if it is insensitive to this type of sample selection bias, otherwise, it is considered "global". In that paper, the true model is not clearly distinguished from the model that the algorithm outputs. In their discussion of Bayesian classifiers, logistic regression and hard-margin SVMs, the true model (or the model that generates the true class label for every example) is implicitly assumed to be contained in the model space of the learner, and the true class probabilities and model estimated class probabilities are assumed to asymptotically converge as the training data set size increases. However, in the discussion of naive Bayes, decision trees and soft-margin SVMs, the model space is assumed not to contain the true model, and these three algorithms are instead argued to be "global learners". We argue that most classifier learners may or may not be affected by sample selection bias; this depends on the dataset as well as the heuristics or inductive bias implied by the learning algorithm and their appropriateness to the particular dataset.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40027830</person_id>
				<author_profile_id><![CDATA[81367591181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043782</person_id>
				<author_profile_id><![CDATA[81100099431]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Davidson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State University of New York at Albany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041542</person_id>
				<author_profile_id><![CDATA[81100278691]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bianca]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zadrozny]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ying So. A tutorial on logistic regression. Technical report, SAS Institute Inc, Cary, NC, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015425</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bianca Zadrozny. Learning and evaluating classifiers under sample selection bias. In <i>Proceedings of the 21th International Conference on Machine Learning</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106407</article_id>
		<sort_key>609</sort_key>
		<display_label></display_label>
		<pages>609-612</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>90</seq_no>
		<title><![CDATA[Fast Frequent String Mining Using Suffix Arrays]]></title>
		<page_from>609</page_from>
		<page_to>612</page_to>
		<doi_number>10.1109/ICDM.2005.62</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106407</url>
		<abstract>
			<par><![CDATA[We present a method to mine strings that are frequent in one database and infrequent in another. The method uses suffix- and lcp-arrays that can be computed extremely fast and space efficiently, and further exhibit a good locality behavior. Experiments with several biologically relevant data sets show that our approach outperforms existing methods in terms of time and space.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>E.1</cat_node>
				<descriptor>Arrays</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Pattern matching</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Sorting and searching</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10003809.10010031.10010033</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Data structures design and analysis->Sorting and searching</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152.10003161</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems->Record storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010031.10010032</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Data structures design and analysis->Pattern matching</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041960</person_id>
				<author_profile_id><![CDATA[81321491592]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Johannes]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fischer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#228;t M&#252;nchen]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041594</person_id>
				<author_profile_id><![CDATA[81549279356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Volker]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Heun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#228;t M&#252;nchen]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042240</person_id>
				<author_profile_id><![CDATA[81100175708]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kramer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TU M&#252;nchen]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>985389</ref_obj_id>
				<ref_obj_pid>985384</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. I. Abouelhoda, S. Kurtz, and E. Ohlebusch. Replacing suffix trees with enhanced suffix arrays. <i>J Discrete Algorithm</i>, 2:53-86, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Bairoch et al. The universal protein resource (UniProt). <i>Nucleic Acids Res.</i>, 33:D154-159, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844746</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. De Raedt, M. J&#228;ger, S. D. Lee, and H. Mannila. A theory of inductive query answering. In <i>Proc. ICDM</i>, pages 123- 130. IEEE Computer Society, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Dementiev, J. K&#228;rkk&#228;inen, J. Mehnert, and P. Sanders. Better external memory suffix array construction. In <i>Proc. Workshop on Algorithms and Experiments</i>, 2005 (in press).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Fischer, V. Heun, and S. Kramer. Fast frequent string mining using suffix arrays. Technical Report TUM-I0515, Fakult&#228;t f&#252;r Informatik, TU M&#252;nchen, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>262228</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Gusfield. <i>Algorithms on Strings, Trees, and Sequences</i>. Cambridge University Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>736222</ref_obj_id>
				<ref_obj_pid>647820</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Kasai, G. Lee, H. Arimura, S. Arikawa, and K. Park. Linear-time longest-common-prefix computation in suffix arrays and its applications. In <i>Proc. CPM</i>, volume 2089 of <i>LNCS</i>, pages 181-192. Springer, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1217858</ref_obj_id>
				<ref_obj_pid>1217856</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. K&#228;rkk&#228;inen, P. Sanders, and S. Burkhardt. Linear work suffix array construction. <i>J ACM</i>, 2005 (in press).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2080872</ref_obj_id>
				<ref_obj_pid>2080863</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. D. Lee and L. De Raedt. An efficient algorithm for mining string databases under constraints. In <i>Proc. KDID 2004</i>, volume 3377 of <i>LNCS</i>, pages 108-129. Springer, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[W. Ludwig et al. Arb: a software environment for sequence data. <i>Nucleic Acids Res.</i>, 32(4):1363-1371, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>159921</ref_obj_id>
				<ref_obj_pid>159918</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[U. Manber and G. Myers. Suffix arrays: A new method for on-line string searches. <i>SIAM J Comput.</i>, 22:935-948, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[G. Manzini. Two space saving tricks for linear time lcp array computation. In <i>Proc. SWAT</i>, volume 3111 of <i>LNCS</i>, pages 372-383. Springer, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014543</ref_obj_id>
				<ref_obj_pid>1014540</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[G. Manzini and P. Ferragina. Engineering a lightweight suffix array construction algorithm. <i>Algorithmica</i>, 40:33-50, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106408</article_id>
		<sort_key>613</sort_key>
		<display_label></display_label>
		<pages>613-616</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>91</seq_no>
		<title><![CDATA[Privacy-Preserving Frequent Pattern Mining across Private Databases]]></title>
		<page_from>613</page_from>
		<page_to>616</page_to>
		<doi_number>10.1109/ICDM.2005.122</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106408</url>
		<abstract>
			<par><![CDATA[Privacy consideration has much significance in the application of data mining. It is very important that the privacy of individual parties will not be exposed when data mining techniques are applied to a large collection of data about the parties. In many scenarios such as data warehousing or data integration, data from the different parties form a many-to-many schema. This paper addresses the problem of privacy-preserving frequent pattern mining in such a schema across two dimension sites. We assume that sites are not trusted and they are semi-honest. Our method is based on the concept of semi-join and does not involve data encryption which is used in most previous work. Experiments are conducted to study the efficiency of the proposed models.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Security, integrity, and protection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Data warehouse and repository</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10003219.10003242</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Information integration->Data warehouses</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003242</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Data warehouses</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003018</concept_id>
				<concept_desc>CCS->Security and privacy->Database and storage security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011735</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Theory of database privacy and security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Management</gt>
			<gt>Security</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15042611</person_id>
				<author_profile_id><![CDATA[81451592510]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ada]]></first_name>
				<middle_name><![CDATA[Wai-Chee]]></middle_name>
				<last_name><![CDATA[Fu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43123507</person_id>
				<author_profile_id><![CDATA[81406592097]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Raymond]]></first_name>
				<middle_name><![CDATA[Chi-Wing]]></middle_name>
				<last_name><![CDATA[Wong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040472</person_id>
				<author_profile_id><![CDATA[81350574174]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[List of device bandwidths. In <i>Wikipedia</i>, http://en.wikipedia.org/wiki/List_of_device_bandwidths.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>872771</ref_obj_id>
				<ref_obj_pid>872757</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, A. Evfimievski, and R. Srikant. Information sharing across private databases. In <i>SIGMOD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>322238</ref_obj_id>
				<ref_obj_pid>322234</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P.A. Bernstein and D. W. Chiu. Using semi-joins to solve relational queries. In <i>Journal of the ACM</i>, pages 25-40, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014120</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[B. Gilburd, A. Schuster, and R. Wolff. k-ttp: A new privacy model for large-scale distributed environments. In <i>SIGKDD</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844718</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E.K.K. Ng, A. Fu, and K. Wang. Association rule mining from stars. In <i>The 2002 IEEE International Conference on Data Mining (ICDM)</i>, pages 322-329, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>293457</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M.T. Ozsu and P. Valduriez. <i>Principles of Distributed Database Systems</i>. Prentice Hall, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775142</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Vaidya and C. Clifton. Privacy preserving association rule mining in vertically partitioned data. In <i>SIGKDD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106409</article_id>
		<sort_key>617</sort_key>
		<display_label></display_label>
		<pages>617-620</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>92</seq_no>
		<title><![CDATA[CoLe]]></title>
		<subtitle><![CDATA[A Cooperative Data Mining Approach and Its Application to Early Diabetes Detection]]></subtitle>
		<page_from>617</page_from>
		<page_to>620</page_to>
		<doi_number>10.1109/ICDM.2005.44</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106409</url>
		<abstract>
			<par><![CDATA[We present CoLe, a cooperative data mining approach for discovering hybrid knowledge. It employs multiple different data mining algorithms, and combines results from them to enhance the mined knowledge. For our medical application area, we analyse several focusing strategies that allowed us to gain medically significant results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Health</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010449</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health informatics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010446</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Consumer health</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15040781</person_id>
				<author_profile_id><![CDATA[81309485868]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041310</person_id>
				<author_profile_id><![CDATA[81100597356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jorg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Denzinger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763135</person_id>
				<author_profile_id><![CDATA[81406598689]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[James]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Aechidna Health Informatics]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Mining sequential patterns. <i>Proc. 11th Intl. Conf. on Data Eng.</i>, IEEE, 1995, pp. 3-14.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657305</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[E. Frank and I. H. Witten. Generating accurate rule sets without global optimization. <i>Proc. 15th Intl. Conf. on Machine Learning</i>, Morgan Kaufmann, 1998, pp. 144-151.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2156023</ref_obj_id>
				<ref_obj_pid>2156013</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Gao, J. Denzinger, and R. C. James. A cooperative multi-agent data mining model and its application to medical data on diabetes. <i>Proc. AIS-ADM</i>, LNAI 3505, 2005, pp. 93-107.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Kargupta, I. Hamzaoglu, and B. Stafford. Scalable, distributed data mining - an agent architecture. <i>Proc. KDD-97</i>, 1997, pp. 211-214.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628148</ref_obj_id>
				<ref_obj_pid>627335</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Liu, H. Lu, and J. Yao. Toward multidatabase mining: Identifying relevant databases. <i>IEEE Trans. Knowledge Data Eng.</i>, 13(4):541-553, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. J. Stolfo, A. L. Prodromidis, S. Tselepis, W. Lee, D. W. Fan, and P. K. Chan. JAM: Java agents for meta-learning over distributed databases. <i>Proc. KDD-97</i>, 1997 pp. 74-81.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106410</article_id>
		<sort_key>621</sort_key>
		<display_label></display_label>
		<pages>621-624</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>93</seq_no>
		<title><![CDATA[Feature Selection for Building Cost-Effective Data Stream Classifiers]]></title>
		<page_from>621</page_from>
		<page_to>624</page_to>
		<doi_number>10.1109/ICDM.2005.63</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106410</url>
		<abstract>
			<par><![CDATA[A stream classifier is a decision model that assigns a class label to a data stream, based on its arriving data. Various features of the stream can be used in the classifier, each of which may have different relevance to the classification task and different cost in obtaining its value. As time passes by, some less costly features may become more relevant, but the time needed for decision may be considered as a cost. A challenge is how to balance the different costs when building a cost-effective classifier. This paper proposes a new feature selection strategy that extends the traditional Relief algorithm in two aspects: (1) estimate the classification cost associated with each feature, and (2) order all the features with a score that combines both cost estimation and classification relevance. A classifier is then built with the selected features using a traditional classification method. Experimental results show that classifiers constructed with this strategy are indeed cost effective.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>E.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011024.10011028</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language features->Data types and structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041086</person_id>
				<author_profile_id><![CDATA[81100132279]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Like]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044225</person_id>
				<author_profile_id><![CDATA[81423593091]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[X.]]></first_name>
				<middle_name><![CDATA[Sean]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1014110</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. On demand classification of data streams. In <i>ACM SIGKDD</i>, pages 503-508, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>508870</ref_obj_id>
				<ref_obj_pid>508791</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Q. Ding, Q. Ding, and W. Perrizo. Decision tree classification of spatial data streams using Peano Count Trees. In <i>ACM SAC</i>, pages 413-417, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K. Kira and L. Rendell. The feature selection problem: traditional methods and a new algorithm. In <i>National Conference on Artificial Intelligence</i>, pages 129-134, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>756485</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Liu, H. Motoda, and L. Yu. Feature selection with selective sampling. In <i>ICML</i>, pages 395-402, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>940876</ref_obj_id>
				<ref_obj_pid>940854</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Robnik and I. Kononenko. Theoretical and empirical analysis of ReliefF and RReliefF. <i>Machine Learning</i>, 52(2):23-69, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502568</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[W. N. Street and Y. Kim. A streaming ensemble algorithm (SEA) for large-scale classification. In <i>ACM SIGKDD</i>, pages 377-382, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622838</ref_obj_id>
				<ref_obj_pid>1622826</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. D. Turney. Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm. <i>Journal of Artificial Intelligence Research</i>, (2):369-409, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106411</article_id>
		<sort_key>625</sort_key>
		<display_label></display_label>
		<pages>625-628</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>94</seq_no>
		<title><![CDATA[A Scalable Collaborative Filtering Framework Based on Co-Clustering]]></title>
		<page_from>625</page_from>
		<page_to>628</page_to>
		<doi_number>10.1109/ICDM.2005.14</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106411</url>
		<abstract>
			<par><![CDATA[Collaborative filtering-based recommender systems have become extremely popular in recent years due to the increase in web-based activities such as e-commerce and online content distribution. Current collaborative filtering (CF) techniques such as correlation and SVD based methods provide good accuracy, but are computationally expensive and can be deployed only in static off-line settings. However, a number of practical scenarios require dynamic real-time collaborative filtering that can allow new users, items and ratings to enter the system at a rapid rate. In this paper, we consider a novel CF approach based on a recently proposed weighted co-clustering algorithm [1] that involves simultaneous clustering of users and items. We design incremental and parallel versions of the co-clustering algorithm and use it to build an efficient real-time CF framework. Empirical evaluation demonstrates that our approach provides an accuracy comparable to that of the correlation and matrix factorization based approaches at a much lower computational cost.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>User profiles and alert services</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003331.10003271</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Users and interactive retrieval->Personalization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003260.10003261.10003271</concept_id>
				<concept_desc>CCS->Information systems->World Wide Web->Web searching and information discovery->Personalization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040461</person_id>
				<author_profile_id><![CDATA[81100355539]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[George]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Texas A & M University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43123668</person_id>
				<author_profile_id><![CDATA[81100331031]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Srujana]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Merugu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1014111</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Banerjee, I. Dhillon, J. Ghosh, S. Merugu, and D. Modha. A generalized maximum entropy approach to bregman co-clustering and matrix approximation. In <i>KDD</i>, pages 509-514, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Brand. Fast online SVD revisions for lightweight recommender systems. In <i>SDM</i>, pages 37-48, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2074100</ref_obj_id>
				<ref_obj_pid>2074094</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. S. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In <i>UAI</i>, pages 43-52, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1106411</ref_obj_id>
				<ref_obj_pid>1106326</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. George and S. Merugu. A scalable collaborative filtering framework based on co-clustering. Technical report, CS Dept., Texas A & M Univ., 2005. url:http://students.cs.tamu.edu/icdm05collab.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>963772</ref_obj_id>
				<ref_obj_pid>963770</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. L. Herlocker, J. A. Konstan, L. G. Terveen, and J. T. Riedl. Evaluating collaborative filtering recommender systems. <i>ACM Trans. Inf. Syst.</i>, 22(1):5-53, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>963774</ref_obj_id>
				<ref_obj_pid>963770</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Hofmann. Latent semantic models for collaborative filtering. <i>ACM Trans. Inf. Sys.</i>, 22(1):89-115, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. D. Lee and H. S. Seung. Algorithms for non-negative matrix factorization. In <i>NIPS</i>, pages 556-562, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192905</ref_obj_id>
				<ref_obj_pid>192844</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P. Resnick, N. Iacovou, M. Suchak, P. Bergstorm, and J. Riedl. GroupLens: An Open Architecture for Collaborative Filtering of Netnews. In <i>Proc. of ACM Conf. on CSCW</i>, pages 175-186, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Application of dimensionality reduction in recommender systems-a case study. In <i>WebKDD Workshop.</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Incremental SVD-based algorithms for highly scaleable recommender systems. In <i>5th Intl. Conf. on CIT</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[N. Srebro and T. Jaakkola. Weighted low rank approximation. In <i>ICML</i>, pages 720-728, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106412</article_id>
		<sort_key>629</sort_key>
		<display_label></display_label>
		<pages>629-632</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>95</seq_no>
		<title><![CDATA[Text Classification with Evolving Label-Sets]]></title>
		<page_from>629</page_from>
		<page_to>632</page_to>
		<doi_number>10.1109/ICDM.2005.143</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106412</url>
		<abstract>
			<par><![CDATA[We introduce the evolving label-set problem encountered in building real-world text classification systems. This problem arises when a text classification system trained on a label-set encounters documents of unseen classes at deployment time. We design a Class-Detector module that monitors unlabeled data, detects new classes, and suggests them to the administrator for inclusion in the label-set. We propose abstractions that group together tokens under human understandable concepts and provide a mechanism of assigning importance to unseen terms. We present generative algorithms leveraging the notion of support of documents in a model for (1) selecting documents of proposed new classes, and (2) automatically triggering detection of new classes. Experiments on three real world taxonomies show that our methods select new class documents with high precision, and trigger emergence of new classes with low false-positive and false-negative rates.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Representations (procedural and rule-based)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Text processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.5</cat_node>
				<descriptor>Interactive systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010314</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Rule learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003129</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interactive systems and tools</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041994</person_id>
				<author_profile_id><![CDATA[81336489465]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shantanu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Godbole]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Indian Institute of Technology - Bombay]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043755</person_id>
				<author_profile_id><![CDATA[81100289098]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ganesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ramakrishnan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM India Research Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43115490</person_id>
				<author_profile_id><![CDATA[81100043079]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Sunita]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sarawagi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Indian Institute of Technology - Bombay]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>354843</ref_obj_id>
				<ref_obj_pid>354756</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Allan, V. Lavrenko, and H. Jin. First story detection in TDT is hard. In <i>Proc. of CIKM 2000</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>290954</ref_obj_id>
				<ref_obj_pid>290941</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Allan, R. Papka, and V. Lavrenko. Online new event detection and tracking. In <i>Proc. of SIGIR '98</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. In <i>Proc. of NIPS14, 2002</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>988738</ref_obj_id>
				<ref_obj_pid>988672</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[E. Gabrilovich, S. Dumais, and E. Horvitz. Newsjunkie: providing personalized newsfeeds via analysis of information novelty. In <i>Proc. of WWW '04</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1053091</ref_obj_id>
				<ref_obj_pid>1053072</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Godbole, A. Harpale, S. Sarawagi, and S. Chakrabarti. Document classification through interactive supervision of document and term labels. In <i>Proc. of ECML/PKDD '04</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Hofmann. Probabilistic latent semantic analysis. In <i>Proc. of UAI'99</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649721</ref_obj_id>
				<ref_obj_pid>645326</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. Text categorization with support vector machines: learning with many relevant features. In <i>Proc. of ECML-98</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657791</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Klinkenberg and T. Joachims. Detecting concept drift with support vector machines. In <i>Proc. of ICML-00</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1005345</ref_obj_id>
				<ref_obj_pid>1005332</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Lewis, Y. Yang, T. Rose, and F. Li. Rcv1: A new benchmark collection for text categorization research. <i>Journal of Machine Learning Research</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[G. Ramakrishnan. <i>Bridging chasms in text mining through Word and Entity Associations</i>. PhD thesis, IIT Bombay, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1102437</ref_obj_id>
				<ref_obj_pid>1102351</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G. Ramakrishnan, K. P. Chitrapura, R. Krishnapuram, and P. Bhattacharya. A model for handling approximate, noisy or incomplete labeling in text classification. In <i>Proc. of ICML 2005</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775150</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Y. Yang, J. Zhang, J. Carbonell, and C. Jin. Topic-conditioned novelty detection. In <i>Proc of SIGKDD '02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106413</article_id>
		<sort_key>633</sort_key>
		<display_label></display_label>
		<pages>633-636</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>96</seq_no>
		<title><![CDATA[CloseMiner]]></title>
		<subtitle><![CDATA[Discovering Frequent Closed Itemsets Using Frequent Closed Tidsets]]></subtitle>
		<page_from>633</page_from>
		<page_to>636</page_to>
		<doi_number>10.1109/ICDM.2005.41</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106413</url>
		<abstract>
			<par><![CDATA[Complete set of itemsets can be grouped into non-overlapping clusters identified by closed tidsets. Each cluster has only one closed itemset and is the superset of all itemsets with the same support. Number of closed itemsets is identical to the number of clusters. Therefore, the problem of discovering closed itemsets can be considered as the problem of clustering the complete set of itemsets by closed tidsets. In this paper, we present CloseMiner, a new algorithm for discovering all frequent closed itemsets by grouping the complete set of itemsets into non-overlapping clusters identified by closed tidsets. An extensive experimental evaluation on a number of real and synthetic databases shows that CloseMiner outperforms Apriori and CHARM.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763112</person_id>
				<author_profile_id><![CDATA[81309513022]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[Gourakishwar]]></middle_name>
				<last_name><![CDATA[Singh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Manipur University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763142</person_id>
				<author_profile_id><![CDATA[81309504134]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[Ranbir]]></middle_name>
				<last_name><![CDATA[Singh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Manipur University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762970</person_id>
				<author_profile_id><![CDATA[81314490836]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Anjana]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Mahanta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Gauhati University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>367141</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J.-M. Adamo. <i>Data mining for association rules and sequential patterns</i>. Springer-Verlag, Berlin Heidalberg New York, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases. <i>Proceeding of the ACM SIGMOD International Conference on Management of Data</i>, pages 207-216, May 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B. A. Davey and Priestley. <i>Introduction to lattices and order</i>. Cambridge University Press, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent pattern without candidate generation. <i>Proceeding of the ACM SIGMOD International Conference on Management of Data</i>, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656256</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets. <i>Proceeding of the 7th International Conference on Database Theory(ICDT'99)</i>, January 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and R. Mao. Closet: An efficient algorithm for mining frequent closed itemsets. <i>Proceeding of the ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery</i>, 2000:21-30, May 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673300</ref_obj_id>
				<ref_obj_pid>645921</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. Savasere, E. Omiecinski, and S. Navathe. An efficient algorithm for mining association rules in large databases. <i>Proceedings of the 21th International Conference on Very Large Data Bases</i>, pages 432-444, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347101</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Zaki. Generating non redundant association rules. <i>Proceeding of the ACM SIGKDD International Conference of Knowledge Discovery and Data Mining</i>, August 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628066</ref_obj_id>
				<ref_obj_pid>627328</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Zaki. Scalable algorithm for association mining. <i>IEEE Transaction on Knowledge and Data Engineering</i>, 12(3):372-390, May-June 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Zaki and K. Gauda. Fast vertical mining using diffsets. <i>Technical Report 01-1, Computer Science Department, Rensselaer Polytechnic Institute</i>, March 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Zaki and C.-J. Hsiao. Charm: An efficient algorithm for closed association rule mining. <i>Technical Report 99-10, Computer Science Department, Rensselaer Polytechnic Institute</i>, October 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106414</article_id>
		<sort_key>637</sort_key>
		<display_label></display_label>
		<pages>637-640</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>97</seq_no>
		<title><![CDATA[A Framework for Semi-Supervised Learning Based on Subjective and Objective Clustering Criteria]]></title>
		<page_from>637</page_from>
		<page_to>640</page_to>
		<doi_number>10.1109/ICDM.2005.4</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106414</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a semi-supervised framework for learning a weighted Euclidean subspace, where the best clustering can be achieved. Our approach capitalizes on user-constraints and the quality of intermediate clustering results in terms of its structural properties. It uses the clustering algorithm and the validity measure as parameters.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Structural</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15043042</person_id>
				<author_profile_id><![CDATA[81100649267]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Halkidi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Riverside and Athens University of Economics and Business]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP48027910</person_id>
				<author_profile_id><![CDATA[81100515024]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gunopulos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Riverside]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042389</person_id>
				<author_profile_id><![CDATA[81343497834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Riverside]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP48026944</person_id>
				<author_profile_id><![CDATA[81100414295]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vazirgiannis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Athens University of Economics and Business]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45027977</person_id>
				<author_profile_id><![CDATA[81100062921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Domeniconi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[George Mason University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>658280</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Anderson, A. Moore, and D. Cohn. A nonparametric approach to noisy and costly optimization. In <i>ICML</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Bar-Hillel, T. Hertz, N. Shental, and D.Weinshall. Learning distance function using equivalence relations. In <i>ICML</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014062</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Basu, M. Bilenko, and R. Mooney. A probabilistic framework for semi-supervised clustering. In <i>KDD</i>, August 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015360</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Bilenko, S. Basu, and R. J. Mooney. Integrating constraints and metric learning in semi-supervised clustering. In <i>ICML</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>279962</ref_obj_id>
				<ref_obj_pid>279943</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. In <i>Conf. on Computational Learning Theory</i>, pages 92-100, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Cohn, R. Caruana, and A. McCallum. Semi-supervised clustering with user feedback. In <i>Technical Report TR2003- 1892</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657864</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Halkidi and M. Vazirgiannis. Clustering validity assessment: Finding the optimal partitioning of a data set. In <i>ICDM</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347724</ref_obj_id>
				<ref_obj_pid>347709</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[K. Nigam, K. McCallum, S. Thrun, and T. Mitchell. Text classification labeled and unlabeled documents using em. <i>Machine Learning</i>, 39:103-134, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. <i>Numerical Recipes in C, The art of Scientific Computing</i>. Cambridge University Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E. Segal, H. Wang, and D. Koller. Discovering molecular pathways from protein interaction and gene expression data. <i>Bioinformatics</i>, 19:264-272, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[B. Stein, S. M. zu Eissen, and F. Wibrock. On cluster validity and the information need of users. In <i>AIA</i>, September 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Theodoridis and K. Koutroubas. <i>Pattern Recognition</i>. Academic Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655669</ref_obj_id>
				<ref_obj_pid>645530</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[K. Wagstaff, C. Cardie, S. Rogers, and S. Schroedl. Constrained k-means clustering with background knowledge. In <i>ICML</i>, pages 577-584, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[E. P. Xing, A. Y. Ng, M. I. Jordan, and S. Russell. Distance metric learning, with application to clustering with side-information. In <i>NIPS</i>, December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106415</article_id>
		<sort_key>641</sort_key>
		<display_label></display_label>
		<pages>641-644</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>98</seq_no>
		<title><![CDATA[Focused Community Discovery]]></title>
		<page_from>641</page_from>
		<page_to>644</page_to>
		<doi_number>10.1109/ICDM.2005.70</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106415</url>
		<abstract>
			<par><![CDATA[We present a new approach to community discovery. Community discovery usually partitions the graph into communities or clusters. Focused community discovery allows the searcher to specify start points of interest, and find the community of those points. Focused search allows for a much more scalable algorithm in which the time depends only on the size of the community, and not on the number of nodes in the graph, and so is scalable to arbitrarily large graphs. Furthermore, our algorithm is robust to imperfect data, such as extra or missing edges in the graph. We show the effectiveness of our algorithm using both synthetic graphs and on the real-life Livejournal friends graph, a publicly-available social network consisting of over two million users and 13 million edges.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040777</person_id>
				<author_profile_id><![CDATA[81339504302]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kirsten]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hildrum]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T.J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T.J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>2150202</ref_obj_id>
				<ref_obj_pid>2150193</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Aiello, C. Kalmanek, P. McDaniel, S. Sen, O. Spatscheck, and J. V. der Merwe. Analysis of communities of interest in data networks. In <i>Proceedings of PAM</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>741620</ref_obj_id>
				<ref_obj_pid>647967</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Cortes, D. Pregibon, and C. Volinsky. Communities of interest. In <i>Proceedings IDA2001</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347121</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[G. Flake, S. Lawrence, and C. L. Giles. Efficient identification of web communities. In <i>Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 150-160, Boston, MA, August 20-23 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. Flake, R. Tarjan, and K. Tsioutsiouliklis. Graph clustering and minimum cut trees. <i>J. of Internet Mathematics</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1060841</ref_obj_id>
				<ref_obj_pid>1060745</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Ino, M. Kudo, and A. Nakamura. Partitioning of web graphs by community topology. In <i>WWW '05: Proceedings of the 14th international conference on World Wide Web</i>, pages 661-669, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106416</article_id>
		<sort_key>645</sort_key>
		<display_label></display_label>
		<pages>645-648</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>99</seq_no>
		<title><![CDATA[Suppressing Data Sets to Prevent Discovery of Association Rules]]></title>
		<page_from>645</page_from>
		<page_to>648</page_to>
		<doi_number>10.1109/ICDM.2005.140</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106416</url>
		<abstract>
			<par><![CDATA[Enterprises have been collecting data for many reasons including better customer relationship management, and high-level decision making. Public safety was another motivation for large-scale data collection efforts initiated by government agencies. However, such widespread data collection efforts coupled with powerful data analysis tools raised concerns about privacy. This is due to the fact that collected data may contain confidential information. One method to ensure privacy is to selectively hide confidential information from the data sets to be disclosed. In this paper, we focus on hiding confidential correlations. We introduce a heuristic to reduce the information loss and propose a blocking method that prevents discovery of confidential correlations while preserving the usefulness of the data set.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>K.4.1</cat_node>
				<descriptor>Privacy</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Security, integrity, and protection</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002978.10003029</concept_id>
				<concept_desc>CCS->Security and privacy->Human and societal aspects of security and privacy</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003462.10003477</concept_id>
				<concept_desc>CCS->Social and professional topics->Computing / technology policy->Privacy policies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003018</concept_id>
				<concept_desc>CCS->Security and privacy->Database and storage security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011735</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Theory of database privacy and security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Security</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P762976</person_id>
				<author_profile_id><![CDATA[81313485090]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ayca]]></first_name>
				<middle_name><![CDATA[Azg&#305;n]]></middle_name>
				<last_name><![CDATA[Hintoglu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sabanc&#305; University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762967</person_id>
				<author_profile_id><![CDATA[81309493484]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ali]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Inan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sabanc&#305; University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763182</person_id>
				<author_profile_id><![CDATA[81100554441]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yucel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sayg&#305;n]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sabanc&#305; University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763099</person_id>
				<author_profile_id><![CDATA[81375594510]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Mehmet]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Keskinoz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sabanc&#305; University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>604271</ref_obj_id>
				<ref_obj_pid>604264</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Saygin, Y., Verykios, V. S., Clifton, C. Using Unknowns to Prevent Discovery of Association Rules. <i>SIGMOD Record</i>, 30(4):45-54, December 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>972279</ref_obj_id>
				<ref_obj_pid>972214</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Verykios, V. S., Elmagarmid, A., Bertino, E., Saygin, Y., Dasseni, E. Association Rule Hiding. <i>IEEE TKDE</i>, 16(4), 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952071</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Oliveira, S. R. M., Zaiane, O. R. Protecting Sensitive Knowledge by Data Sanitization. In <i>Proc. of the 3rd IEEE International Conference on Data Mining</i>, p. 613-616, Nov 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Azgin Hintoglu, A., Inan, A., Saygin, Y., Keskinoz, M. Suppressing Data Sets to Prevent Discovery of Association Rules. http://students.sabanciuniv.edu/ ~aycah/ICDM05.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106417</article_id>
		<sort_key>649</sort_key>
		<display_label></display_label>
		<pages>649-652</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>100</seq_no>
		<title><![CDATA[Triple Jump Acceleration for the EM Algorithm]]></title>
		<page_from>649</page_from>
		<page_to>652</page_to>
		<doi_number>10.1109/ICDM.2005.146</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106417</url>
		<abstract>
			<par><![CDATA[This paper presents the triple jump framework for accelerating the EM algorithm and other bound optimization methods. The idea is to extrapolate the third search point based on the previous two search points found by regular EM. As the convergence rate of regular EM becomes slower, the distance of the triple jump will be longer, and thus provide higher speedup for data sets where EM converges slowly. Experimental results show that the triple jump framework significantly outperforms EM and other acceleration methods of EM for a variety of probabilistic models, especially when the data set is sparse. The results also show that the triple jump framework is particularly effective for Cluster Models.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003716</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003716</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Mathematical optimization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010148.10010149</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15039674</person_id>
				<author_profile_id><![CDATA[81423595791]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Han-Shen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Academia Sinica]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762982</person_id>
				<author_profile_id><![CDATA[81452604795]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bou-Ho]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Academia Sinica and Chang Gung University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041180</person_id>
				<author_profile_id><![CDATA[81350597365]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chun-Nan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hsu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Academia Sinica]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>2074227</ref_obj_id>
				<ref_obj_pid>2074226</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Bauer, D. Koller, and Y. Singer. "Update rules for parameter estimation in Bayesian networks." In <i>Proc. of the 13th Conference on Uncertainty in Artificial Intelligence</i>, pages 3- 13, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. L. Burden and D. Faires. <i>Numerical Analysis</i>. PWS-KENT Pub Co., 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Cheeseman, J. Kelly, M. Self, J. Stutz, W. Taylor, and D. Freeman. "Autoclass: A Bayesian classification system." In <i>Proc. of the 5th International Conference on Machine Learning</i>, pages 54-56, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>145259</ref_obj_id>
				<ref_obj_pid>145254</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. F. Cooper and E. Herskovits. "A Bayesian method for the induction of probabilistic networks from data." <i>Machine Learning</i>, 9:309-347, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Dempster, N. Laird, and D. Rubin. "Maximum likelihood from incomplete data via the EM algorithm." <i>Journal of the Royal statistical Society</i>, B39:1-37, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2073854</ref_obj_id>
				<ref_obj_pid>2073796</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[O. Luis and K. Leslie. "Accelerating EM: An empirical study." In <i>Proc. of the 15th Conference on Uncertainty in Artificial Intelligence</i>, pages 512-521, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. Salakhutdinov and S. Roweis. "Adaptive overrelaxed bound optimization methods." In <i>Proc. of the 20th International Conference on Machine Learning</i>, pages 664-671, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2100646</ref_obj_id>
				<ref_obj_pid>2100584</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Salakhutdinov, S. Roweis, and Z. Ghahramani. "On the convergence of bound optimization algorithms." In <i>Proc. of the 19th Conference on Uncertainty in Artificial Intelligence</i>, pages 509-516, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106418</article_id>
		<sort_key>653</sort_key>
		<display_label></display_label>
		<pages>653-656</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>101</seq_no>
		<title><![CDATA[Partial Ensemble Classifiers Selection for Better Ranking]]></title>
		<page_from>653</page_from>
		<page_to>656</page_to>
		<doi_number>10.1109/ICDM.2005.119</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106418</url>
		<abstract>
			<par><![CDATA[Ranking is an important task in data mining and knowledge discovery. We propose a novel approach called PECS algorithm to improve the overall ranking performance of a given ensemble. We formally analyse the sufficient and necessary condition under whichPECS algorithm can effectively improve ensemble ranking performance. The experiments with real-world data sets show that this new approach achieves significant improvements in ranking over the original Bagging and Adaboost ensembles.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Relevance feedback</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359.10003361</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results->Relevance assessment</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15045381</person_id>
				<author_profile_id><![CDATA[81100084313]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Western Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040951</person_id>
				<author_profile_id><![CDATA[81100159332]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[X.]]></middle_name>
				<last_name><![CDATA[Ling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Western Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz. UCI repository of machine learning databases. http://www.ics.uci.edu/~mlearn/MLRepository.html, 1998. University of California, Irvine, Dept. of Information and Computer Sciences.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1746434</ref_obj_id>
				<ref_obj_pid>1746432</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. P. Bradley. The use of the area under the ROC curve in the evaluation of machine learning algorithms. <i>Pattern Recognition</i>, 30:1145-1159, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging predictors. <i>Machine Learning</i>, 24(2):123-140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Caruana and A. Niculescu-Mizil. An empirical evaluation of supervised learning for ROC area. In <i>The First Workshop on ROC Analysis in AI</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>756505</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An efficient boosting algorithm for combining preferences. In <i>Proceedings of ICML-98, 15th International Conference on Machine Learning</i>, pages 170-178, Madison, US, 1998. Morgan Kaufmann Publishers, San Francisco, US.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. E. Schapire. Experiments with a new boosting algorithm. In <i>Proceedings of the Thirteenth International Conference on Machine Learning</i>, pages 148-156, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>513543</ref_obj_id>
				<ref_obj_pid>513540</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. J. Hand and R. J. Till. A simple generalisation of the area under the ROC curve for multiple class classification problems. <i>Machine Learning</i>, 45:171-186, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[F. Provost and T. Fawcett. Analysis and visualization of classifier performance: comparison under imprecise class and cost distribution. In <i>Proceedings of the Third International Conference on Knowledge Discovery and Data Mining</i>, pages 43-48. AAAI Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>7906</ref_obj_id>
				<ref_obj_pid>7902</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. Stanfill and D. Waltz. Toward memory-based reasoning. <i>Communications of the ACM</i>, 29:1213-1228, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323651</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[I. H. Witten and E. Frank. <i>Data Mining: Practical machine learning tools with Java implementations</i>. Morgan Kaufmann, San Francisco, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106419</article_id>
		<sort_key>657</sort_key>
		<display_label></display_label>
		<pages>657-660</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>102</seq_no>
		<title><![CDATA[Pairwise Symmetry Decomposition Method for Generalized Covariance Analysis]]></title>
		<page_from>657</page_from>
		<page_to>660</page_to>
		<doi_number>10.1109/ICDM.2005.114</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106419</url>
		<abstract>
			<par><![CDATA[We propose a new theoretical framework for generalizing the traditional notion of covariance. First, we discuss the role of pairwise cross-cumulants by introducing a cluster expansion technique for the cumulant generating function. Next, we introduce a novel concept of symmetry decomposition of probability density functions according to the C_4v group. By utilizing the irreducible representations, generalized covariances are explicitly defined, and their utility is demonstrated using an analytically solvable model.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Multivariate statistics</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Statistical computing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003648.10003688</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003698</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Statistical graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010148.10010149.10010158</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms->Linear algebra algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003719</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on matrices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003704</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Multivariate statistics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P719216</person_id>
				<author_profile_id><![CDATA[81100055426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tsuyoshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ide]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Research, Tokyo Research Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Inui, Y. Tanabe, and Y. Onodera. <i>Group Theory and Its Applications in Physics, 2nd ed.</i> Springer-Verlag Telos, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Kondor and T. Jebara. A kernel between sets of vectors. In <i>Proc. the 20th International Conference on Machine Learning</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Kubo. Generalized cumulant expansion method. <i>Journal of the Physical Society of Japan</i>, 17(7):1100- 1120, 1962.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. J. Sakurai. <i>Modern Quantum Mechanics</i>. Addison Wesley, 2nd Ed., 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Stuart and J. K. Ord. <i>Kendall's Advanced Theory of Statistics, Volume 1</i>. Arnold Publishers, 6th ed., London, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106420</article_id>
		<sort_key>661</sort_key>
		<display_label></display_label>
		<pages>661-664</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>103</seq_no>
		<title><![CDATA[FS<sup>3</sup>]]></title>
		<subtitle><![CDATA[A Random Walk Based Free-Form Spatial Scan Statistic for Anomalous Window Detection]]></subtitle>
		<page_from>661</page_from>
		<page_to>664</page_to>
		<doi_number>10.1109/ICDM.2005.71</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106420</url>
		<abstract>
			<par><![CDATA[Often, it is required to identify anomalous windows over a spatial region that reflect unusual rate of occurrence of a specific event of interest. A spatial scan statistic essentially considers a scan window, and identifies anomalous windows by moving the scan window in the region. While spatial scan statistic has been successful, earlier proposals suffer from two limitations: (i) They resrict the scan window to be of a regular shape (e.g., circle, rectangle, cylinder). However, the region of anomaly, in general, is not necessarily of a regular shape. (ii) They take into account autocorrelation among spatial data, but not spatial heterogeneity. As a result, they often result in inaccurate anomalous windows. To address these limitations, we propose a random walk based Free-Form Spatial Scan Statistic (FS). Application of FS on real datasets has shown that it can identify more refined anomalous windows with better likelihood ratio of it being an anomaly, than those identified by earlier spatial scan statistic approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P728004</person_id>
				<author_profile_id><![CDATA[81100287451]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Vandana]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Janeja]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rutgers University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15027940</person_id>
				<author_profile_id><![CDATA[81100274477]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vijayalakshmi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Atluri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rutgers University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>116880</ref_obj_id>
				<ref_obj_pid>116873</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[F. Aurenhammer. Voronoi diagramsa survey of a fundamental geometric data structure. <i>ACM Comput. Surv.</i>, 23(3):345-405, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. N. Barber and B. W. Ninham. <i>Random and Restricted Walks: Theory and Applications (Mathematics and Its Applications)</i>. Gordon & Breach Science Pub, New York, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[V. Barnett and T. Lewis. <i>Outliers in Statistical Data</i>. John Wiley and Sons, 3rd edition, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502552</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Harel and Y. Koren. Clustering spatial data using random walks. In <i>KDD</i>, pages 281-286, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1066790</ref_obj_id>
				<ref_obj_pid>1066677</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[V. Janeja and V. Atluri. <i>LS</i>
&#60;sup&#62;3&#60;/sup&#62;: A linear semantic scan statistic technique for detecting anomalous windows. In <i>ACM Symposium on Applied Computing</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2295334</ref_obj_id>
				<ref_obj_pid>2295317</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. S. Jonathan. Delaunay refinement algorithms for triangular mesh generation. <i>Computational Geometry: Theory and Applications</i>, 22(1-3):21-74, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Kulldorff. A spatial scan statistic. <i>Communications of Statistics-Theory Meth.</i>, 26(6):1481-1496, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Kulldorff, W. F. Athas, E. J. Feurer, B. A. Miller, and C. R. Key. Evaluating cluster alarms: a space-time scan statistic and brain cancer in los alamos, new mexico. <i>American Journal of Public Health</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Naus. The distribution of the size of the maximum cluster of points on the line. <i>Journal of the American Statistical Association 60</i>, pages 532-538, 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. Neill and A. Moore. Detecting significant multidimensional spatial clusters. In <i>Advances in Neural Information Processing Systems 17</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G. P. Patil and C. Tallie. Geographic and network surveillance via scan statistics for critical area detection. <i>Statistical Science</i>, 18(4):457-465, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106421</article_id>
		<sort_key>665</sort_key>
		<display_label></display_label>
		<pages>665-668</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>104</seq_no>
		<title><![CDATA[Mining Ontological Knowledge from Domain-Specific Text Documents]]></title>
		<page_from>665</page_from>
		<page_to>668</page_to>
		<doi_number>10.1109/ICDM.2005.97</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106421</url>
		<abstract>
			<par><![CDATA[Traditional text mining systems employ shallow parsing techniques and focus on concept extraction and taxonomic relation extraction. This paper presents a novel system called CRCTOL for mining rich semantic knowledge in the form of ontology from domain-specific text documents. By using a full text parsing technique and incorporating both statistical and lexico-syntactic methods, the knowledge extracted by our system is more concise and contains a richer semantics compared with alternative systems. We conduct a case study wherein CRCTOL extracts ontological knowledge, specifically key concepts and semantic relations, from a terrorism domain text collection. Quantitative evaluation, by comparing with a state-of-the-art ontology learning system known as Text-To-Onto, has shown that CRCTOL produces much better precision and recall for both concept and relation extraction, especially from sentences with complex structures.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Representations (procedural and rule-based)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Semantic networks</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Language parsing and understanding</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Text processing</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010188</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Semantic networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010314</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Rule learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763178</person_id>
				<author_profile_id><![CDATA[81309503467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Nanyang Technological University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045469</person_id>
				<author_profile_id><![CDATA[81100255697]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ah-Hwee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Nanyang Technological University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Berners-Lee, J. Hendler, and O. Lassila. The semantic web: A new form of web content that is meaningful to computers will unleash a revolution of new possibilities. <i>Scientific America</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>173747</ref_obj_id>
				<ref_obj_pid>173743</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[T. R. Gruber. A translation approach to portable ontology specification. <i>Knowledge Acquisition</i>, 5:199-220, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Kavalec, A. Maedche, and V. Svateck. Discovery of lexical entries for non-taxonomic relations in ontology learning. In <i>SOFSEM2004</i>, pages 249-256, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Maedche and S. Staab. The text-to-onto ontology learning environment. In <i>Software Demonstration at ICCS-2000</i>, pages 14-18, August 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>711420</ref_obj_id>
				<ref_obj_pid>646996</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Missikoff, R. Navigli, and P. Velardi. The usable ontology: An environment for building and assessing a domain ontology. In <i>ISWC 2002</i>, pages 39-53.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1118778</ref_obj_id>
				<ref_obj_pid>1118771</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[H. Nakagawa and T. Mori. Simple but powerful automatic term extraction method. In <i>COMPTERM 02</i>, pages 29-35, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952070</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[K. Rajaraman and A.-H. Tan. Mining semantic networks for knowledge discovery. In <i>Third IEEE ICDM</i>, pages 633-636, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106422</article_id>
		<sort_key>669</sort_key>
		<display_label></display_label>
		<pages>669-672</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>105</seq_no>
		<title><![CDATA[Mining Patterns That Respond to Actions]]></title>
		<page_from>669</page_from>
		<page_to>672</page_to>
		<doi_number>10.1109/ICDM.2005.99</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106422</url>
		<abstract>
			<par><![CDATA[Data mining focuses on patterns that summarize the data. In this paper, we focus on mining patterns that could change the state by responding to opportunities of actions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15043187</person_id>
				<author_profile_id><![CDATA[81100606282]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yuelong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043498</person_id>
				<author_profile_id><![CDATA[81350574174]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042458</person_id>
				<author_profile_id><![CDATA[81100364633]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tuzhilin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042728</person_id>
				<author_profile_id><![CDATA[81451592510]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ada]]></first_name>
				<middle_name><![CDATA[Wai-Chee]]></middle_name>
				<last_name><![CDATA[Fu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[G. Adomavicius and A. Tuzhilin. Discovery of actionable patterns in databases: The action hierarchy approach. In <i>KDD</i>, pages 111-114, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>578852</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Derman. <i>Finite State Markov Decision Process</i>. Academic Press, New York, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Duda and P. Hart. Pattern classification and scence analysis. In <i>Wiley</i>, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Y. Jiang, K. Wang, A. Tuzhilin, and A. Fu. Mining patterns that respond to actions. <i>Technical Report, School of Computing Science, Simon Fraser University</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593470</ref_obj_id>
				<ref_obj_pid>593421</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Kleinberg, C. Papadimitriou, and P. Raghavan. A microeconomic view of data mining. <i>Journal of Knowledge Discovery and Data Mining</i>, 2:311-324, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G. Piatesky-Shapiro and C. J. Matheus. The interestingness of deviations. In <i>AAAI-94 Workshop on KDD</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Quinlan. C4.5: Programs for machine learning. In <i>Morgan Kaufmann</i>, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650209</ref_obj_id>
				<ref_obj_pid>645340</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[K. Wang, S. Zhou, and J. Han. Profit mining: From patterns to actions. In <i>EDBT</i>, pages 70-87, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952108</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Q. Yang and J. Yin. Postprocessing decision trees to extract actionable knowledge. In <i>ICDM</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106423</article_id>
		<sort_key>673</sort_key>
		<display_label></display_label>
		<pages>673-676</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>106</seq_no>
		<title><![CDATA[Supervised Ordering &#8212; An Empirical Survey]]></title>
		<page_from>673</page_from>
		<page_to>676</page_to>
		<doi_number>10.1109/ICDM.2005.138</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106423</url>
		<abstract>
			<par><![CDATA[Ordered lists of objects are widely used as representational forms. Such ordered objects include Web search results or bestseller lists. In spite of their importance, methods of processing orders have received little attention. However, research concerning orders has recently become common; in particular, researchers have developed various methods for the task of Supervised Ordering to acquire functions for object sorting from example orders. Here, we give a unified view of these methods and our new one, and empirically survey their merits and demerits.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Representations (procedural and rule-based)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Relevance feedback</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>A.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003359.10003361</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results->Relevance assessment</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122.10002945</concept_id>
				<concept_desc>CCS->General and reference->Document types->Surveys and overviews</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010314</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Rule learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15040194</person_id>
				<author_profile_id><![CDATA[81100394205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Toshihiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kamishima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institute of Advanced Industrial Science and Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042670</person_id>
				<author_profile_id><![CDATA[81100515544]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hideto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kazawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Nippon Telegraph and Telephone Corporation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040512</person_id>
				<author_profile_id><![CDATA[81100206468]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shotaro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Akaho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institute of Advanced Industrial Science and Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Agresti. <i>Categorical Data Analysis</i>. John Wiley & Sons, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. C. Arnold, N. Balakrishnan, and H. N. Nagaraja. <i>A First Course in Order Statistics</i>. John Wiley & Sons, Inc., 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622867</ref_obj_id>
				<ref_obj_pid>1622859</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W. W. Cohen, R. E. Schapire, and Y. Singer. Learning to order things. <i>Journal of Artificial Intelligence Research</i>, 10:243-270, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. E. Critchlow, M. A. Fligner, and J. S. Verducci. Probability models on rankings. <i>Journal of Mathematical Psychology</i>, 35:294-318, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>964285</ref_obj_id>
				<ref_obj_pid>945365</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An efficient boosting algorithm for combining preferences. <i>Journal of Machine Learning Research</i>, 4:933-969, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Herbrich, T. Graepel, P. Bollmann-Sdorra, and K. Obermayer. Learning preference relations for information retrieval. In <i>ICML-98 Workshop: Text Categorization and Machine Learning</i>, pages 80-84, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775067</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. Optimizing search engines using clickthrough data. In <i>Proc. of The 8th Int'l Conf. on Knowledge Discovery and Data Mining</i>, pages 133-142, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Kamishima. Homepage. http://www.kamishima.net/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844813</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. Kamishima and S. Akaho. Learning from order examples. In <i>Proc. of The 2nd IEEE Int'l Conf. on Data Mining</i>, pages 645-648, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Kamishima, H. Kazawa, and S. Akaho. Estimating attributed central orders -- an empirical comparison. In <i>Proc. of the 15th European Conference on Machine Learning</i>, pages 563-565, 2004. {LNAI 3201}.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1060375</ref_obj_id>
				<ref_obj_pid>1060369</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[H. Kazawa, T. Hirao, and E. Maeda. Order SVM: a kernel method for order learning based on generalized order statistics. <i>Systems and Computers in Japan</i>, 36(1):35-43, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. I. Marden. <i>Analyzing and Modeling Rank Data</i>, volume 64 of <i>Monographs on Statistics and Applied Probability</i>. Chapman & Hall, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106424</article_id>
		<sort_key>677</sort_key>
		<display_label></display_label>
		<pages>677-680</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>107</seq_no>
		<title><![CDATA[Categorization and Keyword Identification of Unlabeled Documents]]></title>
		<page_from>677</page_from>
		<page_to>680</page_to>
		<doi_number>10.1109/ICDM.2005.39</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106424</url>
		<abstract>
			<par><![CDATA[In this paper we first propose a global unsupervised feature selection approach for text, based on frequent itemset mining. As a result, each document is represented as a set of words that co-occur frequently in the given corpus of documents. We then introduce a locally adaptive clustering algorithm, designed to estimate (local) word relevance and, simultaneously, to group the documents. We present experimental results to demonstrate the feasibility of our approach. Furthermore, the analysis of the weights credited to terms provides evidence that the identified keywords can guide the process of label assignment to clusters. We take into consideration both spam email filtering and general classification datasets. Our analysis of the distribution of weights in the two cases provides insights on how the spam problem distinguishes from the general classification case.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Text processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43123533</person_id>
				<author_profile_id><![CDATA[81541192156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[George Mason University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041186</person_id>
				<author_profile_id><![CDATA[81100062921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Carlotta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Domeniconi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[George Mason University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044250</person_id>
				<author_profile_id><![CDATA[81100273432]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barbara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[George Mason University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>304188</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Aggarwal, C. Procopiuc, J. L. Wolf, P. Yu, and J. S. Park. Fast algorithms for projected clustering. In <i>Proceedings of the ACM SIGMOD Conference on Management of Data</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276314</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, J. Gehrke, D. Gunopulos, and P. Raghavan. Automatic subspace clustering of high dimensional data for data mining applications. In <i>Proceedings of the ACM SIGMOD Conference on Management of Data</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. Barbar&#225;, C. Domeniconi, and N. Kang. Classifying documents without labels. In <i>Proceedings of the SIAM International Conference on Data Mining</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671852</ref_obj_id>
				<ref_obj_pid>645926</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[K. Chakrabarti and S. Mehrotra. Local dimensionality reduction: A new approach to indexing high dimensional spaces. In <i>Proceedings of the VLDB Conference</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Domeniconi, D. Papadopoulos, D. Gunopulos, and S. Ma. Subspace clustering of high dimensional data. In <i>Proceedings of the SIAM International Conference on Data Mining</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. T. Dumais, T. Letsche, M. L. Littman, and T. Landauer. Automatic cross-language retrieval using latent semantic indexing. In <i>AAAI Spring Symposium on Cross-Language Text and Speech Retrieval</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375680</ref_obj_id>
				<ref_obj_pid>375663</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, K. Chakrabarti, S. Mehrotra, and M. Pazzani. Locally adaptive dimensionality reduction for indexing large time series databases. In <i>Proceedings of the ACM SIGMOD Conference on Management of Data</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564739</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. Procopiuc, M. Jones, P. Agarwal, and T. Murali. A monte carlo algorithm for fast projective clustering. In <i>Proceedings of the ACM SIGMOD Conference on Management of Data</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288658</ref_obj_id>
				<ref_obj_pid>288627</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Thomasian, V. Castelli, and C. Li. Clustering and singular value decomposition for approximate indexing in high dimensional spaces. In <i>Proceedings of the CIKM Conference</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106425</article_id>
		<sort_key>681</sort_key>
		<display_label></display_label>
		<pages>681-684</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>108</seq_no>
		<title><![CDATA[Gradual Model Generator for Single-Pass Clustering]]></title>
		<page_from>681</page_from>
		<page_to>684</page_to>
		<doi_number>10.1109/ICDM.2005.73</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106425</url>
		<abstract>
			<par><![CDATA[We present an algorithm for generating a mixture model from data set by performing a single pass over the data. The method is applicable when the entire data is not available at the same time in the main memory. We use Gaussian mixture model but the algorithm can be adapted to other types of models, too. We also outline a post processing method, which can iteratively reduce the size of the model obtained by the single-pass algorithm. This will result in a model with fewer components, but with approximately the same representation accuracy than the result of the original model from the single-pass algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041776</person_id>
				<author_profile_id><![CDATA[81100071805]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ismo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Karkkainen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Joensuu]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042158</person_id>
				<author_profile_id><![CDATA[81100165787]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pasi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Franti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Joensuu]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1121869</ref_obj_id>
				<ref_obj_pid>1121858</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Sato, and S. Ishii, "On-line EM Algorithm for the Normalized Gaussian Network", <i>Neural Computation</i>, 12(2) (2000), pp. 407-432.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. Bradley, U. Fayyad, and C. Reina, "Clustering Very Large Databases Using EM Mixture Models", <i>Proc. of the 15th Int. Conf. on Pattern Recognition vol. 2</i>, 2000, pp. 76-80.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593443</ref_obj_id>
				<ref_obj_pid>593415</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Zhang, R. Ramakrishnan, and M. Livny, "BIRCH: A New Data Clustering Algorithm and Its Applications", <i>Data Mining and Knowledge Discovery</i>, 1(2) (1997) 141-182.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>584889</ref_obj_id>
				<ref_obj_pid>584792</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. Ordonez, and E. Omiecinski, "FREM: Fast and Robust EM Clustering for Large Data Sets", <i>Proc. of the 11th int. conf. on Information and Knowledge Management</i>, 2002, pp. 590- 599.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1746564</ref_obj_id>
				<ref_obj_pid>1746528</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Jin, K.-S. Leung, M.-L. Wong, and Z.-B. Xu, "Scalable model-based cluster analysis using clustering features", <i>Pattern Recognition</i>, 38 (5), 2005, pp. 637-649.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Bhattacharyya, "On a Measure of Divergence Between Two Statistical Populations Defined by Their Distributions", <i>Bull. Calcutta Math. Soc.</i>, 35, 1943, pp. 99-110.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>92131</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[K. Fukunaga, <i>Introduction to Statistical Pattern Recognition</i>, Academic Press, Boston, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Dempster, N. Laird, and D. Rubin, "Maximum likelihood from incomplete data via the EM algorithm", <i>Journal of the Royal Statistical Society B</i>, 39, 1977, pp. 1-38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[G. McLachlan, and T. Krishnan, <i>The EM Algorithm and Extensions</i>, John Wiley & Sons, New York, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627955</ref_obj_id>
				<ref_obj_pid>627319</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Ortega, Y. Rui, K. Chakrabati, K. Porkaew, S. Mehrotra, and T.S. Huang, "Supporting Ranked Boolean Similarity Queries in MARS", <i>IEEE Transactions on Knowledge and Data Engineering</i>, 10(6), 1998, pp. 905-925.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Hettich, and S. Bay, The UCI KDD Archive {http://kdd.ics.uci.edu}. Irvine, CA: University of California, Department of Information and Computer Science. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106426</article_id>
		<sort_key>685</sort_key>
		<display_label></display_label>
		<pages>685-688</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>109</seq_no>
		<title><![CDATA[Making Logistic Regression a Core Data Mining Tool with TR-IRLS]]></title>
		<page_from>685</page_from>
		<page_to>688</page_to>
		<doi_number>10.1109/ICDM.2005.90</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106426</url>
		<abstract>
			<par><![CDATA[Binary classification is a core data mining task. For large datasets or real-time applications, desirable classifiersare accurate, fast, and need no parameter tuning. We present a simple implementation of logistic regression that meets these requirements. A combination of regularization, truncated Newton methods, and iteratively re-weighted least squares make it faster and more accurate than modern SVM implementations, and relatively insensitive to parameters. It is robust to linear dependencies and some scaling problems, making most data preprocessing unnecessary.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Correlation and regression analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003691</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Regression analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010309.10010313</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Factorization methods->Canonical correlation analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15041224</person_id>
				<author_profile_id><![CDATA[81339510268]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Komarek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041429</person_id>
				<author_profile_id><![CDATA[81100042782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Moore]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C.-C. Chang and C.-J. Lin. <i>LIBSVM: a library for support vector machines</i>, 2001. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. E. Gentle. <i>Elements of Computational Statistics</i>. Statistics and Computing. Springer Verlag, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Hastie, R. Tibshirani, and J. Friedman. <i>The Elements of Statistical Learning</i>. Springer Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. W. Hosmer and S. Lemeshow. <i>Applied Logistic Regression</i>. Wiley, 2nd edition, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[http://www.sas.com/. SAS. http://www.sas.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. SVM&#60;sup&#62;
<i>light</i>
&#60;/sup&#62;, 2002. svmlight.joachims.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. Komarek. Logistic Regression for Data Mining and High-Dimensional Classification. Technical Report TR-O4-34, Robotics Inst., Carnegie Mellon Univ., Pgh, PA, May 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P. Komarek. Making Logistic Regression A Core Data Mining Tool: A Practical Investigation of Accuracy, Speed, and Simplicity. Technical Report TR-O5-27, Robotics Inst., Carnegie Mellon Univ., Pgh, PA, May 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[P. Komarek. Datasets, 2005. http://komarix.org/ac/ds.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. Komarek and A. Moore. Fast Robust Logistic Regression for Large Sparse Datasets with Binary Outputs. In <i>Artificial Intelligence and Statistics</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Kubica, A. Goldenberg, P. Komarek, A. Moore, and J. Schneider. A Comparison of Statistical and Machine Learning Algorithms on the Task of Link Completion. In <i>KDD Workshop on Link Analysis for Detecting Complex Behavior</i>, page 8, August 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. Liu, A. Moore, and A. Gray. Efficient Exact k-NN and Nonparametric Classification in High Dimensions. In <i>Proc. of Neural Information Processing Systems</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[P. McCullagh and J. A. Nelder. <i>Generalized Linear Models</i>, volume 37 of <i>Monographs on Statistics and Applied Probability</i>. Chapman & Hall, 2 edition, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>539101</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. McIntosh. <i>Fitting Linear Models: An Application of Conjugate Gradient Algorithms</i>, volume 10 of <i>Lecture Notes in Statistics</i>. Springer-Verlag, New York, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[T. P. Minka. Algorithms for maximum-likelihood logistic regression. Technical Report Stats 758, Carnegie Mellon University, October 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. Moore, P. Komarek, and J. Ostlund. Activity Prediction From Links, 2004. http://www.autonlab.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[S. G. Nash and A. Sofer. <i>Linear and Nonlinear Programming</i>. McGraw-Hill, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Orr. Introduction to Radial Basis Function Networks, 1996. http://www.anc.ed.ac.uk/~mjo/rbf.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>865018</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. R. Shewchuk. An Introduction to the Conjugate Gradient Method Without the Agonizing Pain. Technical Report CS- 94-125, Carnegie Mellon University, Pittsburgh, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[T. Zhang and F. J. Oles. <i>Text Categorization Based on Regularized Linear Classification Methods</i>. Kluwer, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. Zhu and T. Hastie. Kernel logistic regression and the import vector machine. <i>Journal of Computational and Graphical Statistics</i>, 14(1):185-205, March 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106427</article_id>
		<sort_key>689</sort_key>
		<display_label></display_label>
		<pages>689-692</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>110</seq_no>
		<title><![CDATA[Hierarchical Density-Based Clustering of Uncertain Data]]></title>
		<page_from>689</page_from>
		<page_to>692</page_to>
		<doi_number>10.1109/ICDM.2005.75</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106427</url>
		<abstract>
			<par><![CDATA[The hierarchical density-based clustering algorithm OPTICS has proven to help the user to get an overview over large data sets. When using OPTICS for analyzing uncertain data which naturally occur in many emerging application areas, e.g. location based services, or sensor databases, the similarity between uncertain objects has to be expressed by one numerical distance value. Based on such single-valued distance functions OPTICS, like other standard data mining algorithms, can work without any changes. In this paper, we propose to express the similarity between two fuzzy objects by distance probability functions which assign a probability value to each possible distance value. Contrary to the traditional approach, we do not extract aggregated values from the fuzzy distance functions but enhance OPTICS so that it can exploit the full information provided by these functions. The resulting algorithm FOPTICS helps the user to get an overview over a large set of fuzzy objects.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15034628</person_id>
				<author_profile_id><![CDATA[81100512920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kriegel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P479270</person_id>
				<author_profile_id><![CDATA[81100553208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pfeifle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>304187</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ankerst M., Breunig M., Kriegel H.-P., Sander J.: <i>OPTICS: Ordering Points To Identify the Clustering Structure</i>. SIGMOD' 99.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106428</article_id>
		<sort_key>693</sort_key>
		<display_label></display_label>
		<pages>693-696</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>111</seq_no>
		<title><![CDATA[Semi-Supervised Clustering with Metric Learning Using Relative Comparisons]]></title>
		<page_from>693</page_from>
		<page_to>696</page_to>
		<doi_number>10.1109/ICDM.2005.128</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106428</url>
		<abstract>
			<par><![CDATA[Semi-supervised clustering algorithms partition a given data set using limited supervision from the user. In this paper, we propose a clustering algorithmthat uses supervision in terms of relative comparisons, viz., is closer to than to . The success of a clustering algorithm also depends on the kind of dissimilarity measure. The proposed clustering algorithm learns the underlying dissimilarity measure while finding compact clusters in the given data set. Through our experimental studies on high-dimensional textual data sets, we demonstrate that the proposed algorithm achieves higher accuracy than the algorithms using pairwise constraints for supervision.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040124</person_id>
				<author_profile_id><![CDATA[81309481970]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nimit]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM India Research Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044162</person_id>
				<author_profile_id><![CDATA[81100149166]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Krishna]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kummamuru]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM India Research Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045057</person_id>
				<author_profile_id><![CDATA[81309496647]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Deepa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Paranjpe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM India Research Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo- 20/www/data/news20.tar.gz.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[http://www.cs.utexas.edu/users/ml/risc/code/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015360</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Bilenko, S. Basu, and R. Mooney. Integrating constraints and metric learning in semi-supervised clustering. In <i>Proceedings of ICML</i>, pages 81-88, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014128</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[K. Kummamuru, R. Krishnapuram, and R. Agrawal. Learning spatially variant dissimilarity (svad) measures. In <i>Proceedings of SIGKDD</i>, pages 611-616, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Schultz and T. Joachims. Learning a distance metric with relative comparisons. <i>Advances in Neural Information Processing Systems</i>, 16, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345578</ref_obj_id>
				<ref_obj_pid>345508</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[N. Slonim and N. Tishby. Document clustering using word clusters via the information bottleneck method. In <i>Proceedings of SIGIR</i>, page 208215, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Xing, A. Ng, M. Jordon, and S. Russell. Distance metric learning, with application to clustering with side-information. <i>Advances in Neural Information Processing Systems</i>, 16:505- 512, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106429</article_id>
		<sort_key>697</sort_key>
		<display_label></display_label>
		<pages>697-700</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>112</seq_no>
		<title><![CDATA[On Learning Asymmetric Dissimilarity Measures]]></title>
		<page_from>697</page_from>
		<page_to>700</page_to>
		<doi_number>10.1109/ICDM.2005.107</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106429</url>
		<abstract>
			<par><![CDATA[Many practical applications require that distance measures to be asymmetric and context-sensitive. We introduce Context-sensitive Learnable Asymmetric Dissimilarity (CLAD) measures, which are defined to be a weighted sum of a fixed number of dissimilarity measures where the associated weights depend on the point from which the dissimilarity is measured. The parameters used in defining the measure capture the global relationships among the features. We provide an algorithm to learn the dissimilarity measure automatically from a set of user specified comparisons in the form "x is closer to y than to z," and study its performance. The experimental results show that the proposed algorithm outperforms other approaches due to the context sensitive nature of the CLAD measures.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>Performance evaluation (efficiency and effectiveness)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040832</person_id>
				<author_profile_id><![CDATA[81100149166]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Krishna]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kummamuru]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM India Research Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040463</person_id>
				<author_profile_id><![CDATA[81100282550]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Raghu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Krishnapuram]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM India Research Lab]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40025714</person_id>
				<author_profile_id><![CDATA[81100289193]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Rakesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Agrawal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Almaden Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[http://www-2.cs.cmu.edu/afs/cs.cmu.edu/project/theo- 20/www/data/news20.tar.gz.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956756</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal. Towards systematic design of distance functions for data mining applications. In <i>Proceedings of SIGKDD</i>, pages 9-18. ACM Press, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015360</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Bilenko, S. Basu, and R. Mooney. Integrating constraints and metric learning in semi-supervised clustering. In <i>Proceedings of ICML</i>, pages 81-88, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Cohn, R. Caruana, and A. McCallum. Semi-supervised clustering with user feedback. <i>Technical Report TR2003- 1892, Cornell University</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>295725</ref_obj_id>
				<ref_obj_pid>295240</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam, and S. Slattery. Learning to extract symbolic knowledge from the world wide web. In <i>Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98)</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>521706</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Haykin. <i>Neural Networks: A Comprehensive Foundation</i>. Prentice Hall, Upper Saddle River, NJ, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299104</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. Making large-scale svm learning practical. In B. Schlkopf, C. Burges, and A. Smola, editors, <i>Advances in Kernel Methods - Support Vector Learning</i>. MIT-Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775067</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. Optimizing search engines using clickthrough data. In <i>Proceedings of SIGKDD</i>, pages 133-142. ACM Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502694</ref_obj_id>
				<ref_obj_pid>502585</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[K. Krishna and R. Krishnapuram. A clustering algorithm for asymmetrically related data with applications to text mining. In <i>Proceedings of CIKM</i>, pages 571-573. ACM, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. Kullback. <i>Information Theory and Statistics</i>. Cloucester, MA: Peter Smith, 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014128</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[K. Kummamuru, R. Krishnapuram, and R. Agrawal. Learning spatially variant dissimilarity (svad) measures. In <i>Proceedings of SIGKDD</i>, pages 611-616, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. Schultz and T. Joachims. Learning a distance metric with relative comparisons. <i>Advances in Neural Information Processing Systems</i>, 16, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345578</ref_obj_id>
				<ref_obj_pid>345508</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[N. Slonim and N. Tishby. Document clustering using word clusters via the information bottleneck method. In <i>Proceedings of SIGIR</i>, pages 208-215, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106430</article_id>
		<sort_key>701</sort_key>
		<display_label></display_label>
		<pages>701-704</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>113</seq_no>
		<title><![CDATA[Partial Elastic Matching of Time Series]]></title>
		<page_from>701</page_from>
		<page_to>704</page_to>
		<doi_number>10.1109/ICDM.2005.118</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106430</url>
		<abstract>
			<par><![CDATA[We consider the problem of elastic matching of time series. We propose an algorithm that determines a subsequence of a target time series that best matches a query series. In the proposed algorithm we map the problem of the best matching subsequence to the problem of a cheapest path in a DAG (directed acyclic graph). The proposed approach allows us to also compute the optimal scale and translation of time series values, which is a nontrivial problem in the case of subsequence matching.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Pattern matching</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010031.10010032</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Data structures design and analysis->Pattern matching</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15043847</person_id>
				<author_profile_id><![CDATA[81100594681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Longin]]></first_name>
				<middle_name><![CDATA[Jan]]></middle_name>
				<last_name><![CDATA[Latecki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Temple University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P290187</person_id>
				<author_profile_id><![CDATA[81100072429]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vasileios]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Megalooikonomou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Temple University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042718</person_id>
				<author_profile_id><![CDATA[81100212494]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Temple University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37030364</person_id>
				<author_profile_id><![CDATA[81322499049]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Rolf]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lakaemper]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Temple University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762987</person_id>
				<author_profile_id><![CDATA[81100182188]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Ratanamahatana]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Riverside]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042069</person_id>
				<author_profile_id><![CDATA[81100209161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[E.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Keogh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California at Riverside]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Aach and G. Church. Aligning gene expression time series with time warping algorithms. <i>Bioinformatics</i>, 17:495-508, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Berndt and J. Clifford. Using dynamic time warping to find patterns in time series. In <i>Proc. AAAI-94 W. on Knowledge Discovery and Databases</i>, pages 229-248, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956808</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B. Chiu, E. Keogh, and S. Lonardi. Probabilistic discovery of time series motifs. In <i>Proc. ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining</i>, Washington, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Chu, E. Keogh, D. Hart, and M. Pazzani. Iterative deepening dynamic time warping for time series. In <i>Proc. SIAM Int. Conf. on Data Mining</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669017</ref_obj_id>
				<ref_obj_pid>645801</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Das, D. Gunopoulos, and H. Mannila. Finding similar timie series. In <i>Proc. 1st PKDD Symposium</i>, pages 88-100, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669998</ref_obj_id>
				<ref_obj_pid>645805</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[F. H&#246;ppner. Discovery of temporal patterns. learning rules about the qualitative behavior of time series. In <i>Proc. European Conf. on Principles and Practice of Knowledge Discovery in Databases</i>, pages 192-203, Freiburg, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014077</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, S. Lonardi, and C. Ratanamahatana. Towards parameter-free data mining. In <i>Proc. ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining</i>, Seattle, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>878994</ref_obj_id>
				<ref_obj_pid>876875</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[G. Kollios, M. Vlachos, and D. Gunopoulos. Discovering similar multidimensional trajectories. In <i>Proc. Int. Conf. on Data Engineering</i>, pages 673-684, San Jose, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2101298</ref_obj_id>
				<ref_obj_pid>2101235</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[L. J. Latecki, V. Megalooikonomou, Q. Wang, R. Lakaemper, C. A. Ratanamahatana, and E. Keogh. Elastic partial matching of time series. In <i>Conf. PKDD</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1054107</ref_obj_id>
				<ref_obj_pid>1053724</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[V. Megalooikonomou, Q. Wang, G. Li, and C. Faloutsos. A multiresolution symbolic representation of time series. In <i>Proc. IEEE Int. Conf. on Data Engineering (ICDE05)</i>, pages 668-679, Tokyo, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847198</ref_obj_id>
				<ref_obj_pid>846218</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[D. Rafiei. On similarity-based queries for time series data. In <i>Proc. Int. Conf. on Data Engineering</i>, pages 410-417, Sydney, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[C. A. Ratanamahatana and E. Keogh. Everything you know about dynamic time warping is wrong. In <i>W. on Mining Temporal and Sequential Data</i>, Seattle, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[H. Sakoe and S. Chiba. Dynamic programming algorithm optimization for spoken word recognition. <i>IEEE Trans. on Acoustics, Speech, and Signal Processing</i>, 26(1): 43-49, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956777</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[M. Vlachos, M. Hadjieleftheriou, D. Gunopoulos, and E. Keogh. Indexing multi-dimensional time-series with support for multiple distance measures. In <i>Proc. of ACM SIGKDD</i>, pages 216-225, Washington, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>653609</ref_obj_id>
				<ref_obj_pid>645483</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[B. Yi, K. Jagadish, and C. Faloutsos. Efficient retrieval of similar time sequences under time warping. In <i>Proc. Int. Conf. on Data Engineering</i>, pages 23-27, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106431</article_id>
		<sort_key>705</sort_key>
		<display_label></display_label>
		<pages>705-708</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>114</seq_no>
		<title><![CDATA[CLUGO]]></title>
		<subtitle><![CDATA[A Clustering Algorithm for Automated Functional Annotations Based on Gene Ontology]]></subtitle>
		<page_from>705</page_from>
		<page_to>708</page_to>
		<doi_number>10.1109/ICDM.2005.42</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106431</url>
		<abstract>
			<par><![CDATA[We address the issue of providing highly informative and comprehensive annotations using information revealed by the structured vocabularies of Gene Ontology (GO). For a target, a set of candidate terms for inferring target properties is collected and form a unique distribution on the GO directed acyclic graph (DAG). We propose a novel ontology-based clustering algorithm &#8212; CLUGO, which considers GO hierarchical characteristics and the clustering of term distributions. By identifying significant groups in the distributions, CLUGO assigns comprehensive and correct annotations for a target. According to the results of experiments with automated sequence functional annotations, CLUGO represents a considerable improvement over our previous work &#8212; GOMIT in terms of recall while maintaining a similar level of precision. We conclude that given a GO candidate term distribution, CLUGO is an efficient ontology-based clustering algorithm for selecting comprehensive and correct annotations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Representations (procedural and rule-based)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010314</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Rule learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044961</person_id>
				<author_profile_id><![CDATA[81309510470]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[In-Yee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Taiwan University and Academia Sinica]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P134479</person_id>
				<author_profile_id><![CDATA[81100317452]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jan-Ming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Academia Sinica]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044717</person_id>
				<author_profile_id><![CDATA[81450594725]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ming-Syan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Taiwan University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Altschul, S.F., Gish, W., Miller, W., Myers, E. W., and Lipman, D.J. "Basic local alignment search tool," <i>J Mol Biol</i>, 215(3), pp. 403-10, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1092883</ref_obj_id>
				<ref_obj_pid>1092875</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Beissbarth T., Speed T.P., "GOstat: find statistically overrepresented Gene Ontologies within a group of genes." <i>Bioinformatics</i>, 20(9), pp. 1464-5, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1093275</ref_obj_id>
				<ref_obj_pid>1090314</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Joslyn C.A., Mniszewski S.M., Fulmer A., Heaton G., "The Gene Ontology Categorizer," <i>Bioinformatics</i>, v. 20:s1, pp. 169-177, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kaufman L., Rousseeuw R., "Finding Groups in Data," Wiley, New York, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Khan S., Situ G., Decker K., Schmidt C.J., "GoFigure: automated Gene Ontology annotation," <i>Bioinformatics</i>, Dec 12;19(18), pp. 2484-5, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Karypis G. et al., "CLUTO: Software package for clustering high-dimensional datasets," http://wwwusers.cs.umn.edu/~karypis/cluto/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>942943</ref_obj_id>
				<ref_obj_pid>942790</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Lee I.Y., Ho J.M., Lin W.C., "An algorithm for generating representative functional annotations based on Gene Ontology," <i>Proc. DEXA Workshops</i>, pp. 10-15, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1104668</ref_obj_id>
				<ref_obj_pid>1104657</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lee I.Y., Ho J.M., Chen M. S., "GOMIT: A Generic and Adaptive Annotation Algorithm Based on Gene Ontology Term Distributions," <i>IEEE fifth Symposium on Bioinformatics and Bioengineering</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1090631</ref_obj_id>
				<ref_obj_pid>1090620</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lee S.G., Hur J.U., Kim Y.S., "A graph-theoretic modeling on GO space for biological interpretation of gene clusters," <i>Bioinformatics</i>, 20(3), pp. 381-8, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Speer N., Spieth C., Zell A., "a memetic clustering algorithm for the functional partition of genes based on the gene ontology," <i>IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[The Gene Ontology Consortium, "Creating the gene ontology resource: design and implementation," <i>Genome Res</i> 11, pp. 1425-1433.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[The <i>Saccharomyces</i> Genome Database: http://www.yeastgenome.org/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[The UniProt/Swiss-Prot Protein Knowledgebase. http://www.ebi.ac.uk/swissprot/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Zeeberg B.R., Feng W., Wang G., Wang M.D., Fojo A.T., Sunshine M., Narasimhan S., Kane D.W., Reinhold W.C., Lababidi S., Bussey K.J., Riss J., Barrett J.C., Weinstein J.N., "GoMiner: a resource for biological interpretation of genomic and proteomic data," <i>Genome Biol</i>. 4(4), pp. R28, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Zhang B., Schmoyer D., Kirov S., Snoddy J., "GOTree Machine (GOTM): a web-based platform for interpreting sets of interesting genes using Gene Ontology hierarchies," <i>BMC Bioinformatics</i>, 5(1), pp. 16, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106432</article_id>
		<sort_key>709</sort_key>
		<display_label></display_label>
		<pages>709-712</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>115</seq_no>
		<title><![CDATA[An Optimal Linear Time Algorithm for Quasi-Monotonic Segmentation]]></title>
		<page_from>709</page_from>
		<page_to>712</page_to>
		<doi_number>10.1109/ICDM.2005.25</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106432</url>
		<abstract>
			<par><![CDATA[Monotonicity is a simple yet significant qualitative characteristic. We consider the problem of segmenting an array in up to K segments. We want segments to be as monotonic as possible and to alternate signs. We propose a quality metric for this problem, present an optimal linear time algorithm based on novel formalism, and compare experimentally its performance to a linear time top-down regression algorithm. We show that our algorithm is faster and more accurate. Applications include pattern recognition and qualitative modeling.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Computations on discrete structures</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Sorting and searching</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.1.2</cat_node>
				<descriptor>Analysis of algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Correlation and regression analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010148.10010149</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010031.10010033</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Data structures design and analysis->Sorting and searching</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010309.10010313</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Factorization methods->Canonical correlation analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003691</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Regression analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15043792</person_id>
				<author_profile_id><![CDATA[81100092997]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lemire]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Quebec at Montreal]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044420</person_id>
				<author_profile_id><![CDATA[81100076748]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Brooks]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Research Council of Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042761</person_id>
				<author_profile_id><![CDATA[81323497985]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yuhong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Research Council of Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. L. Goldberger et al. PhysioBank, PhysioToolkit, and PhysioNet. <i>Circulation</i>, 101(23): 215-220, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642357</ref_obj_id>
				<ref_obj_pid>1642293</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Brooks, Y. Yan, and D. Lemire. Scale-based monotonicity analysis in qualitative modelling with flat segments. In <i>IJCAI'05</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>782121</ref_obj_id>
				<ref_obj_pid>782115</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. Lemire. Wavelet-based relative prefix sum methods for range sum queries in data cubes. In <i>CASCON</i>. IBM, October 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>978140</ref_obj_id>
				<ref_obj_pid>977401</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Palpanas, M. Vlachos, E. Keogh, D. Gunopulos, and W. Truppel. Online amnesic algorithm of streaming time series. In <i>ICDE</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[V. A. Ubhaya. Isotone optimization I. <i>Approx. Theory</i>, 12: 146-159, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106433</article_id>
		<sort_key>713</sort_key>
		<display_label></display_label>
		<pages>713-716</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>116</seq_no>
		<title><![CDATA[Average Number of Frequent (Closed) Patterns in Bernouilli and Markovian Databases]]></title>
		<page_from>713</page_from>
		<page_to>716</page_to>
		<doi_number>10.1109/ICDM.2005.31</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106433</url>
		<abstract>
			<par><![CDATA[In data mining, enumerate the frequent or the closed patterns is often the first difficult task leading to the association rules discovery. The number of these patterns represents a great interest. The lower bound is known to be constant whereas the upper bound is exponential, but both situations correspond to pathological cases. For the first time, we give an average analysis of the number of frequent or closed patterns. Average analysis is often closer to real situations and gives more information about the role of the parameters. In this paper, two probabilistic models are studied: a BERNOULLI and a MARKOVIAN. In both models and for large databases, we prove that the number of frequent patterns, for a fixed frequency threshold , is exponential in the number of items and polynomial in the number of transactions. On the other hand, for a proportional frequency threshold , the number of frequent patterns is polynomial in the number of items and does not involve the number of transactions. Finally, we prove in the BERNOULLI model that the number of closed patterns, for a proportional frequency threshold, is polynomial in the number of items.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.1.2</cat_node>
				<descriptor>Analysis of algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Markov processes</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010148.10010149</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003651</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Markov networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003700.10003701</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Stochastic processes->Markov processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P763021</person_id>
				<author_profile_id><![CDATA[81100058054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Francois]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rioult]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#233; de Caen Basse-Normandie]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045216</person_id>
				<author_profile_id><![CDATA[81365592401]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Arnaud]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Soulet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#233; de Caen Basse-Normandie]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>257975</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, H. Mannila, R. Srikant, H. Toivonen. and A. Verkamo. Fast discovery of association rules. In <i>Advances in Knowledge Discovery and Data Mining</i>, pages 307-328, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>International Conference on Very Large Data Bases (VLDB'94), Santiago de Chile</i>, pages 487-499, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H. Fu and E. Mephu Nguifo. How well go lattice algorithms on currently used machine learning testbeds ? In <i>First international Conference on Formal Concept Analysis</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657870</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[F. Geerts, B. Goethals, and J. Van den Bussche. A tight upper bound on the number of candidate patterns. In <i>ICDM</i>, pages 155-162, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>263684</ref_obj_id>
				<ref_obj_pid>263661</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Gunopulos, H. Mannila, R. Khardon, and H. Toivonen. Data mining, hypergraph transversals, and machine learning. In <i>PODS 1997</i>, pages 209-216, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656097</ref_obj_id>
				<ref_obj_pid>645502</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Gunopulos,. H. Mannila, and S. Saluja. Discovering all most specific sentences by randomized algorithms. In <i>ICDT</i>, pages 215-229, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. O. Kuznetsov and S. A. Obiedkov. Comparing performance of algorithms for generating concept lattices. <i>Journal of Experimental and Theoretical Artificial Intelligence</i>, 14(2-3):189-216, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[L. Lhote, F. Riouit, and A. Soulet. Average number of frequent and closed patterns in random databases. In <i>Conf&#233;rence d'Apprentissage</i>, CAp'05, pages 345-360, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[L. Lhote, F. Rioult, and A. Soulet. Average number of frequent and closed patterns in random databases. In <i>Technical Report, Universit&#233; de Caen</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. W. Purdom, D. V. Gucht, and D. P. Groth. Average-case performance of the apriori algorithm. <i>SIAM Journal on Computing</i>, 33(5): 1223-1260, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233311</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R. Srikant and R. Agrawal. Mining quantitative association rules in large relational tables. In <i>Proceedings of the 1996 ACM SIGMOD international conference on Management of data</i>, pages 1-12. ACM Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673325</ref_obj_id>
				<ref_obj_pid>645922</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[H. Toivonen. Sampling large databases for association rules. In <i>International Conference on Very Large Data Bases</i>, pages 134-145. Morgan Kaufman, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[R. Wille. Concept lattices and conceptual knowledge systems. In <i>Computer mathematic applied</i>, 23(6-9): 493-515, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347101</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Generating non-redundant association rules. In <i>SIGKDD'00, Boston</i>, pages 34-43, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106434</article_id>
		<sort_key>717</sort_key>
		<display_label></display_label>
		<pages>717-720</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>117</seq_no>
		<title><![CDATA[Predicting Software Escalations with Maximum ROI]]></title>
		<page_from>717</page_from>
		<page_to>720</page_to>
		<doi_number>10.1109/ICDM.2005.120</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106434</url>
		<abstract>
			<par><![CDATA[Enterprise software venders often have to release software products before all reported defects are corrected, and a small number of these reported defects will be escalated by customers whose businesses are seriously impacted. Escalated defects must be quickly resolved at a high cost by the software vendors. The total costs can be even greater, including loss of reputation, satisfaction, loyalty, and repeat revenue. In this paper, we develop an Escalation Prediction (EP) system to mine historic defect report data and predict the escalation risk of current defect reports for maximum ROI (Return On Investment). More specifically, we first describe a simple and general framework to convert the maximum ROI problem to cost-sensitive learning. We then apply and compare several best-known cost-sensitive learning approaches for EP. The EP system has produced promising results, and has been deployed in the product group of an enterprise software vendor. Conclusions drawn from this study also provide guidelines for mining imbalanced datasets and cost-sensitive learning.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>D.2.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>D.2.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011123.10011124</concept_id>
				<concept_desc>CCS->General and reference->Cross-computing tools and techniques->Metrics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003490.10003503.10003505</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Management of computing and information systems->Software management->Software maintenance</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011111</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Software post-development issues</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP39030222</person_id>
				<author_profile_id><![CDATA[81100159332]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[X.]]></middle_name>
				<last_name><![CDATA[Ling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Western Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042034</person_id>
				<author_profile_id><![CDATA[81309493236]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shengli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sheng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Western Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041469</person_id>
				<author_profile_id><![CDATA[81100577935]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tilmann]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bruckhaus]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Sun Microsystems, Inc.]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042503</person_id>
				<author_profile_id><![CDATA[81100077635]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Nazim]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Madhavji]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Western Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>560675</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Berry, M.J.A., and Linoff, G. 1997. <i>Data Mining Techniques: For Marketing, Sales, and Customer Support</i>. John Wiley & Sons.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>621640</ref_obj_id>
				<ref_obj_pid>619059</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Beohm, B.W., and Basili, V. 2001. Software Defect Reduction Top 10 List. <i>Computer</i> 34(1): 135-137.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>539425</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Boehm, B.W. 1981. <i>Software Engineering Economics</i>. Prentice-Hall Advances in Computing Science & Technology Series.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Breiman, L. 1996. Bagging Predictors. Machine Learning 24(2): 123-140.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bruckhaus, T., Ling, C.X., Madhavji, N.H., and Sheng, S. 2004. Software Escalation Prediction with Data Mining. <i>Workshop on Predictive Software Models (PSM 2004), A STEP Software Technology & Engineering Practice</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Chulani, S., and Boehm, B.W. 1997. Modeling Software Defect Introduction. <i>California Software Symposium</i>, Nov. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Dai, H. (editor). 2003. <i>Proceedings of The International Workshop on Data Mining for Software Engineering and Knowledge Engineering</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Drummond, C., and Holte, R.C. 2003. C4.5, Class Imbalance, and Cost Sensitivity: Why under-sampling beats over-sampling. <i>Workshop on Learning from Imbalanced Datasets II</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642224</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Elkan, C. 2001. The Foundations of Cost-Sensitive Learning. <i>International Joint Conference of Artificial Intelligence (IJCAI 2001)</i>. 973-978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>257938</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Fayyad, U., Piatetsky-Shapiro, G., Smyth, P., and Uthurusamy, R. (editors). 1996. <i>Advances in Knowledge Discovery and Data Mining</i>, AAAI/MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Freund Y. and Schapire, R.E. 1996. Experiments with a New Boosting Algorithm. <i>Proceeding of International Conference on Machine Learning (ICML)</i>. 148-156.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>726288</ref_obj_id>
				<ref_obj_pid>647462</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Japkowicz. N. 2001. Concept-Learning in the Presence of Between-Class and Within-Class Imbalances, <i>Proceedings of the Fourteenth Conference of the Canadian Society for Computational Studies of Intelligence (AI'2OO1)</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375673</ref_obj_id>
				<ref_obj_pid>375663</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Joshi, M.V., Agarwal, R.C., and Kumar, V. 2001. Mining needles in a haystack: classifying rare classes via two-phase rule induction. <i>In SIGMOD'01 Conference on Management of Data</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Ling, C.X., and Li, C. 1998. Data Mining for Direct Marketing: Specific Problems and Solutions. <i>Proceedings of Fourth International Conference on Knowledge Discovery and Data Mining (KDD-98)</i>, 73-79.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1015369</ref_obj_id>
				<ref_obj_pid>1015330</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Ling, C.x., Yang, Q., Wang, J., and Zhang, S. 2004. Decision trees with minimal costs. <i>Proceedings of international Conference on Machine Learning (ICML)</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Niculescu-Mizil, A., and Caruana, R. 2001. Obtaining Calibrated Probabilities from Boosting. <i>AI Stats</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>637969</ref_obj_id>
				<ref_obj_pid>637962</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Quinlan, J.R. 1986. Induction of decision trees. <i>Machine Learning</i>, 1(1): 81-106.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Quinlan, J.R. 1993. <i>C4. 5: Programs for Machine Learning</i>. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323651</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Witten, I.H., and Frank, E. 2000. <i>Data Mining: Practical machine learning tools with Java implementations</i>. Morgan Kaufmann, San Francisco.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952181</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Zadrozny, B., Langford, J., and Abe, N. 2003. Cost-Sensitive Learning by Cost-Proportionate Example Weighting. <i>Proceedings of International Conference of Data Mining (ICDM)</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106436</article_id>
		<sort_key>721</sort_key>
		<display_label></display_label>
		<pages>721-724</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>118</seq_no>
		<title><![CDATA[Mining Approximate Frequent Itemsets from Noisy Data]]></title>
		<page_from>721</page_from>
		<page_to>724</page_to>
		<doi_number>10.1109/ICDM.2005.93</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106436</url>
		<abstract>
			<par><![CDATA[Frequent itemset mining is a popular and important first step in analyzing data sets across a broad range of applications. The traditional, "exact" approach for finding frequent itemsets requires that every item in the itemset occurs in each supporting transaction. However, real data is typically subject to noise, and in the presence of such noise, traditional itemset mining may fail to detect relevant itemsets, particularly those large itemsets that are more vulnerable to noise. In this paper we propose approximate frequent itemsets (AFI), as a noise-tolerant itemset model. In addition to the usual requirement for sufficiently many supporting transactions, the AFI model places constraints on the fraction of errors permitted in each item column and the fraction of errors permitted in a supporting transaction. Taken together, these constraints winnow out the approximate itemsets that exhibit systematic errors. In the context of a simple noise model, we demonstrate that AFI is better at recovering underlying data patterns, while identifying fewer spurious patterns than either the exact frequent itemset approach or the existing error tolerant itemset approach of Yang et al. [11].]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15041333</person_id>
				<author_profile_id><![CDATA[81405595453]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jinze]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763156</person_id>
				<author_profile_id><![CDATA[81309494996]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Susan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Paulsen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042678</person_id>
				<author_profile_id><![CDATA[81452601906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762969</person_id>
				<author_profile_id><![CDATA[81309482576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nobel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040561</person_id>
				<author_profile_id><![CDATA[81407592542]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Prins]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases In SIGMOD 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>257975</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A Verkamo. Fast discovery of association rules. In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors, Advances in Knowledge Discover and Data Mining, chapter 12, pages 307328. AAAI Pre 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Becquet, S. Blachon, B. Jeudy, J.F. Boulicaut, Gandrillon O. Strong-association-rule mining for large-scale gene-expression data analysis: a case study on humaMining gene expression databases for association rules. n SAGE data. Genome Biol. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. Creighton, S. Hanash. Mining gene expression databases for association rules. Bioinformatics. 2003 Jan;19(1): 79-86.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Liu, S. Paulsen, W. Wang, A. Nobel, J. Prins. "Mining Approximate Frequent Itemset from Noisy Data". Technical Report(TR05-015) of Department of Compuater Science, UNC-Chapel Hill, 2005 Jun.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[H.C. Kum, S. Paulsen, W. Wang, Comparative Study of Sequential Pattern Mining Models, Studies in Computational Intelligence, Volume 6, Aug 2005, Pages 43-70.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Pei, A. K. Tung, and J. Han. Fault-tolerant frequent pattern mining: Problems and challenges. In Workshop on Research Issues in Data Mining and Knowledge Discovery, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014140</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. K. Seppanen, H. Mannila. Dense Itemsets. In SIGKDD 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014086</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Steinbach, P. N. Tan, V. Kumar. Support envelopes: a technique for exploring the structure of association patterns. In SIGKDD 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. J. Unmack. Biogeography of Australian freshwater fishes. Journal of Biogeography. Vol. 28: pages 1053-1089. Blackwell Science Ltd. 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502539</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[C. Yang, U. Fayyad, P. S. Bradley. Efficient discovery of error-tolerant frequent itemsets in high dimensions. In SIGKDD 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106435</article_id>
		<sort_key>725</sort_key>
		<display_label></display_label>
		<pages>725-728</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>119</seq_no>
		<title><![CDATA[Text Representation]]></title>
		<subtitle><![CDATA[From Vector to Tensor]]></subtitle>
		<page_from>725</page_from>
		<page_to>728</page_to>
		<doi_number>10.1109/ICDM.2005.144</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106435</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a text representation model, Tensor Space Model (TSM), which models the text by multilinear algebraic high-order tensor instead of the traditional vector. Supported by techniques of multilinear algebra, TSM offers a potent mathematical framework for analyzing the multifactor structures. TSM is further supported by certain introduced particular operations and presented tools, such as the High-Order Singular Value Decomposition (HOSVD) for dimension reduction and other applications. Experimental results on the 20 Newsgroups dataset show that TSM is constantly better than VSM for text classification.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Representations (procedural and rule-based)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010314</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Rule learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044589</person_id>
				<author_profile_id><![CDATA[81321494547]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tsinghua University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045299</person_id>
				<author_profile_id><![CDATA[81309512327]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Benyu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044936</person_id>
				<author_profile_id><![CDATA[81100045080]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Peking University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043111</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042811</person_id>
				<author_profile_id><![CDATA[81461644631]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Wenyin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[City University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043487</person_id>
				<author_profile_id><![CDATA[81100633623]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Fengshan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tsinghua University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763080</person_id>
				<author_profile_id><![CDATA[81450595233]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Leefeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Academia Sinica]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Aslam, J., Belkin, N., Zhai, C., Callan, J., Hiemstra, D., Hofmann, T., Dumais, S., Harper, D.J., et.al. Challenges in information retrieval and language modeling: report of a workshop held at the center for intelligent information retrieval, University of Massachusetts Amherst, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>553876</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Baeza-Yates, R. and Ribeiro-Neto, B. <i>Modern Information Retrieval</i>. Addison-Wesley, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cavnar, W.B. and Trenkle, J.M., N-Gram-Based Text Categorization. In <i>Proceedings of the SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval</i>, (1994), 161-169.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>940438</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Croft, W.B. and Lafferty, J. <i>Language Modeling for Information Retrieval</i>. Kluwer Academic, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>866292</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gerard, S. and Chris, B. Term Weighting Approaches in Automatic Text Retrieval, Technical Report TR87-881, Department of Computer Science, Cornell University, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Jolliffe, I.T. <i>Principal Component Analysis</i>. Spriger Verlag, New York, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Lang, K., NewsWeeder: Learning to Filter Netnews. In <i>Proceedings of the 12th International Conference on Machine Learning (ICML 1995)</i>, 331-339.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>354398</ref_obj_id>
				<ref_obj_pid>354353</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lathauwer, L.D., Moor, B.D. and Vandewalle, J. A Multilinear Singular Value Decomposition. <i>SIAM Journal on Matrix Analysis and Applications, 21</i>. 1253-1278.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Wrede, R.C. Introduction to Vector and Tensor Analysis. Wiley, 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106437</article_id>
		<sort_key>729</sort_key>
		<display_label></display_label>
		<pages>729-732</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>120</seq_no>
		<title><![CDATA[Parallel Algorithms for Distance-Based and Density-Based Outliers]]></title>
		<page_from>729</page_from>
		<page_to>732</page_to>
		<doi_number>10.1109/ICDM.2005.116</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106437</url>
		<abstract>
			<par><![CDATA[An outlier is an observation that deviates so much from other observations as to arouse suspicion that it was generated by a different mechanism. Outlier detection has many applications, such as data cleaning, fraud detection and network intrusion. The existence of outliers can indicate individuals or groups that exhibit a behavior that is very different from most of the individuals of the dataset. In this paper we design two parallel algorithms, the first one is for finding out distance-based outliers based on nested loops along with randomization and the use of a pruning rule. The second parallel algorithm is for detecting density-based local outliers. In both cases data parallelism is used. We show that both algorithms reach near linear speedup. Our algorithms are tested on four real-world datasets coming from the Machine Learning Database Repository at the UCI.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>G.1.0</cat_node>
				<descriptor>Parallel algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.1.2</cat_node>
				<descriptor>Analysis of algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10003809</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010170</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Parallel algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010148.10010149</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010169.10010170</concept_id>
				<concept_desc>CCS->Computing methodologies->Parallel computing methodologies->Parallel algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763015</person_id>
				<author_profile_id><![CDATA[81309483297]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Elio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lozano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Puerto Rico]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P744768</person_id>
				<author_profile_id><![CDATA[81375594091]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Edgar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Acuna]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Puerto Rico]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>956758</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. Bay and M. Schwabacher. Mining distance-based outliers in near linear time with randomization and a simple pruning rule. <i>Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Mertz. VCI repository of machine learning databases. <i>Irvine. CA: University of California, Department of Information and Computer Science</i>. {http://www.ics.uci.edu/mlearn/MLRepository.html}, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335388</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Breuning, H. Kriegel, R. Ng, and J. Sander. LOF: Identifying density-based local outliers. <i>ACM SlGMOD International Conference on Management of Data</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Hawkins. <i>Identification of Outliers</i>. Chapman and Hall. London, 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1028946</ref_obj_id>
				<ref_obj_pid>1028911</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[V. Hodge and J. Austin. A survey of outlier detection methodologies. <i>Artificial Intelligence Review</i>, 22:85-126, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>607200</ref_obj_id>
				<ref_obj_pid>607046</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[E. Hung and D. Cheung. Parallel Mining of Outliers in Large Database. <i>Distributed and Parallel Databases. Kluver Academic Publishers.</i>, (12):5-26, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671334</ref_obj_id>
				<ref_obj_pid>645924</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Knorr and R. Ng. Algorithms for mining distance-based outliers in large datasets. <i>In Proc. 24th Int. Conf. Very Large Data Bases VLDB</i>, pages 392-403, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>764218</ref_obj_id>
				<ref_obj_pid>764212</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[E. Knorr, R. Ng, and V. Tucakov. Aistance-based outliers: Algorithms and applications. <i>VLDB Journal: Very Large Data Bases</i>, (8(3-4)):237-253, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672827</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. Ng and J. Han. Efficient and effective clustering methods for spatiall data mining. <i>Proc. 20th Int. Conf. on Very Large Databases. Morgan and Kaufmann Publishers, San Francisco</i>. (8(3-4)):44-155, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>248511</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. Pacheco. <i>Parallel Programming with MPl</i>, Morgan Kauffmann Publishers Inc., 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335437</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Ramaswamy, R. Rastogi, and K. Shim. Efficient algorithms for mining outliers from large data sets. <i>In Proceedings of the ACM SIGMOD International Conference on Management of Data</i>, pages 427-438, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. Rocke and D. Woodruff. Computational connections between robust multivariate analysis and clustering. <i>In COMPSTAT 2002 Proc. in Computational Statistics</i>, Wolfgang H}.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Ruoming and G. Agrawal. <i>A Middleware for developing parallel data mining applications</i>. Proc. of the First SIAM Conference on Data Mining. <i>2001</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614184</ref_obj_id>
				<ref_obj_pid>614067</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[D. Skillicorn. <i>Strategies for Parallel Data Mining</i>. IEEE Concurrency, <i>4(7):36-35, 2001</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106438</article_id>
		<sort_key>733</sort_key>
		<display_label></display_label>
		<pages>733-736</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>121</seq_no>
		<title><![CDATA[Bit Reduction Support Vector Machine]]></title>
		<page_from>733</page_from>
		<page_to>736</page_to>
		<doi_number>10.1109/ICDM.2005.36</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106438</url>
		<abstract>
			<par><![CDATA[Support vector machines are very accurate classifiers and have been widely used in many applications. However, the training and to a lesser extent prediction time of support vector machines on very large data sets can be very long. This paper presents a fast compression method to scale up support vector machines to large data sets. A simple bit reduction method is applied to reduce the cardinality of the data by weighting representative examples. We then develop support vector machines which may be trained on weighted data. Experiments indicate that the bit reduction support vector machine produces a significant reduction in the time required for both training and prediction with minimum loss in accuracy. It is also shown to be more accurate than random sampling, when the data is not over-compressed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041237</person_id>
				<author_profile_id><![CDATA[81100416006]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Luo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of South Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040894</person_id>
				<author_profile_id><![CDATA[81407593306]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lawrence]]></first_name>
				<middle_name><![CDATA[O.]]></middle_name>
				<last_name><![CDATA[Hall]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of South Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044292</person_id>
				<author_profile_id><![CDATA[81409597662]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dmitry]]></first_name>
				<middle_name><![CDATA[B.]]></middle_name>
				<last_name><![CDATA[Goldgof]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of South Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044647</person_id>
				<author_profile_id><![CDATA[81321497446]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Remsen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of South Florida]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Boley and D. Cao. Training support vector machines using adaptive clustering. In <i>SIAM International Conference on Data Mining</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1961199</ref_obj_id>
				<ref_obj_pid>1961189</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Chang and C. Lin. LIBSVM: a library for support vector machines (version 2.3), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W. G. Cochran. <i>Sampling Techniques</i>. John Wiley and Sons, Inc., 3 edition, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>580470</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. H. Cormen, C. E. Leiserson, R. L. Rivest. and C. Stein. <i>Introduction to Algorithms</i>. MIT Press, 2 edition. 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[ELENA. ftp://ftp.dice.ucl.ac.be/pub/neuralnets/ elena/database.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2235084</ref_obj_id>
				<ref_obj_pid>2234534</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Eschrich. J. Ke. L. Hall. and D. Goldgof. Fast accurate fuzzy clustering through data reduction. <i>IEEE Transactions on Fuzzy Systems</i>. 11(2):262-270, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Luo. L. Hall. D. Goldgof, and A. Remsen. Bit reduction support vector machines. Technical Report ISL-1-05. Dept. of CSE. University of South Florida, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1021012</ref_obj_id>
				<ref_obj_pid>1018429</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Luo, K. Kramer, D. Goldgof, L. Hall. S. Samson, A. Remsen. and T. Hopkins. Active learning to recognize multiple types of plankton. In <i>17th conference of the International Association for Pattern Recognition</i>, volume 3, pages 478- 481, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2226282</ref_obj_id>
				<ref_obj_pid>2225307</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. Luo. K. Kramer. D. Goldgof. L. Hall, S. Samson, A. Remsen. and T. Hopkins. Recognizing plankton images from the shadow image particle profiling evaluation recorder. <i>IEEE Transactions on System, Man, and Cybernetics-Part B: Cybernetics</i>, 34(4):1753-1762, August 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. J. Merz and P. M. Murphy. UCI repository of machine learning database. http://www.ics.uci.edu/mlearn/MLRepository.html, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>212782</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[D. Michie, D. J. Spiegelhaiter. and C. C. Taylor. Machine learning, neural and statistical classification, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>608017</ref_obj_id>
				<ref_obj_pid>608006</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A. Owen. Data squashing by empirical likelihood. <i>Data Mining and Knowledge Discovery</i>, pages 101-113, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347155</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[D. Pavlov, D. Chudova, and P. Smyth. Towards scalable: support vector machines using squashing. In <i>Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining</i>, pages 295-299, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299105</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Platt. Fast training of support vector machines using sequential minimal optimization. In <i>Advances in Kernel Methods - Support Vector Learning</i>. pages 185-208. The MIT Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>373433</ref_obj_id>
				<ref_obj_pid>373423</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[G. Ratsch. T. Onoda, and K. Muller. Soft margins for adaboost. <i>Machine Learning</i>, 42(3):287-320, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Y. C. L. Shih, J. D. M. Rennie, and D. R. Karger. Text bundling: Statistics based data-reduction. In <i>Proceedings of the Twentieth International Conference on Machine Learning</i>, pages 696-703, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106439</article_id>
		<sort_key>737</sort_key>
		<display_label></display_label>
		<pages>737-740</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>122</seq_no>
		<title><![CDATA[Spatial Clustering of Chimpanzee Locations for Neighborhood Identification]]></title>
		<page_from>737</page_from>
		<page_to>740</page_to>
		<doi_number>10.1109/ICDM.2005.133</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106439</url>
		<abstract>
			<par><![CDATA[Since 1960, the chimpanzees (Pan troglodytes) of Gombe National Park, Tanzania, have been studied by behavioral ecologists, including Jane Goodall. Data have been collected for more than 40 years and are being analyzed by researchers in order to increase our understanding of the social structure of chimpanzees. In this paper, we consider the following question of interest to behavioral ecologists &#8212; "Does clustering exist among female chimpanzees in terms of their spatial locations?" The analysis of this question will help behavioral ecologists to learn about the space use and the social interactions between female chimpanzees. The data collected for this analysis are marked spatial point patterns over the park. Current spatial clustering methods lack the ability to handle such marked point patterns directly. This paper presents a novel application of spatial point pattern analysis and data mining techniques to the ecological problem of clustering female chimpanzees. We found that Ripley's K-function provides a powerful statistical tool for evaluating clustering behavior among spatial point patterns. We then proposed two clustering approaches for marked point patterns using the K-function. Experimental results using the proposed clustering methods provide significant insight into the dynamics of female chimpanzee space use and into the overall social stucture of the species. In addition, the proposed methods can be extended to also include temporal information.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15040720</person_id>
				<author_profile_id><![CDATA[81100631453]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sandeep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mane]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762990</person_id>
				<author_profile_id><![CDATA[81309491596]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Carson]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Murray]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040160</person_id>
				<author_profile_id><![CDATA[81100610476]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shekhar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39025487</person_id>
				<author_profile_id><![CDATA[81100063012]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jaideep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Srivastava]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P762971</person_id>
				<author_profile_id><![CDATA[81309510771]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Anne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pusey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[N. A. Cressie. <i>Statistics for Spatial Data</i>. Wiley: New York, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>578296</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. George and W. Liu. <i>Computer Solution of Large Sparse Positive Definite Systems</i>. Prentice-Hall series in computational mathematics, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Goodall. <i>The Chimpanzees of Gombe: Patterns of Behavior</i>. Harvard University Press, Cambridge, MA, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Han, M. Kamber, and A. K. H. Tung. Spatial clustering methods in data mining: A survey. In H. Miller and J. Han, editors, <i>Geographic Data Mining and Knowledge Discovery</i>. Taylor and Francis, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Mane, C. Murray, S. Shekhar, J. Srivastava, and A. Pusey. Spatial clustering of chimpanzee locations for neighborhood identification. Technical Report 05-031, Dept. of Computer Science, University of Minnesota, Minneapolis, USA, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Williams, A. Pusey, J. Carlis, and B. Farm. Female competition and male territorial behavior influence female chimapnzees ranging patterns. <i>Animal Behavior</i>, 63, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106440</article_id>
		<sort_key>741</sort_key>
		<display_label></display_label>
		<pages>741-744</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>123</seq_no>
		<title><![CDATA[A Graph-Ranking Algorithm for Geo-Referencing Documents]]></title>
		<page_from>741</page_from>
		<page_to>744</page_to>
		<doi_number>10.1109/ICDM.2005.6</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106440</url>
		<abstract>
			<par><![CDATA[This paper presents an application of PageRank for assigning documents with a corresponding geographical scope. We describe the technique in detail, together with its theoretical formulation. Experimental results are promising, comparing favorably with previous proposals.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Relevance feedback</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359.10003361</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results->Relevance assessment</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15039432</person_id>
				<author_profile_id><![CDATA[81300139701]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bruno]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Martins]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidade de Lisboa]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043043</person_id>
				<author_profile_id><![CDATA[81100060665]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mario]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Silva]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidade de Lisboa]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1009040</ref_obj_id>
				<ref_obj_pid>1008992</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Amitay, N. Har'El, R. Sivan, and A. Soffer. Web-a-Where: Geotagging Web content. In <i>Proceedings of SIGIR-04, the 27th conference on research and development in information retrieval</i>, pages 273-280. ACM Press, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1316739</ref_obj_id>
				<ref_obj_pid>1316689</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Balmin, V. Hristidis, and Y. Papakonstantinou. ObjectRank: Authority-based keyword search in databases. In <i>Proceedings of VLDB-04, the 30th Conference on Very Large Data Bases</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[G. Caldarelli, P. D. L. Rios, L. Laura, S. Leonardi, and S. Millozzi. A study of stochastic models for the Web graph. Technical Report 04-03, Dipartimento di Informatica e Sistemistica - Universita' di Roma "La Sapienza", 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Chaves, M. Silva, and B. Martins. A geographic knowledge base for semantic Web applications. In <i>Proceedings of SBBD-05, the 20th Brazilian Symposium on Databases</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. J. Conyon and M. R. Muldoon. Ranking the importance of boards of directors. <i>Management Science</i>, 2004. (to appear).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672013</ref_obj_id>
				<ref_obj_pid>645926</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Ding, L. Gravano, and N. Shivakumar. Computing geographical scopes of Web resources. In <i>Proceedings of VLDB- 00, the 26th conference on Very Large Data Bases</i>, pages 545-556. Morgan Kaufmann Publishers Inc., 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[N. Eiron and K. S. McCurley. Locality, hierarchy, and bidirectionality in the Web. In <i>Proceedings of WAW-03, the 2nd Workshop on Algorithms/Models for the Web Graph</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Haveliwala. Efficient computation of Page Rank. Technical Report 1999-31, Stanford University, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. N. Langville and C. D. Meyer. Deeper inside PageRank. <i>Internet Mathematics</i>, 1 (3), 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[B. Martins and M. Silva. Geographical named entity recognition and disambiguation in Web pages, 2005. (To appear).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R. Mihalcea and P. Tarau. TextRank: Bringing order into texts. In <i>Proceedings of EMNLP-04, the 2004 Conference on Empirical Methods in Natural Language Processing</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank citation ranking: Bringing order to the Web. Technical Report SIDL-WP-1999-0120, Stanford Digital Library, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M. Richardson and P. Domingos. The Intelligent Surfer: Probabilistic Combination of Link and Content Information in PageRank. In <i>Advances in Neural Information Processing Systems</i>, volume 14. MIT Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106441</article_id>
		<sort_key>745</sort_key>
		<display_label></display_label>
		<pages>745-748</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>124</seq_no>
		<title><![CDATA[An Expected Utility Approach to Active Feature-Value Acquisition]]></title>
		<page_from>745</page_from>
		<page_to>748</page_to>
		<doi_number>10.1109/ICDM.2005.23</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106441</url>
		<abstract>
			<par><![CDATA[In many classification tasks training data have missing feature values that can be acquired at a cost. For building accurate predictive models, acquiring all missing values is often prohibitively expensive or unnecessary, while acquiring a random subset of feature values may not be most effective. The goal of active feature-value acquisition is to incrementally select feature values that are most cost-effective for improving the model's accuracy. We present an approach that acquires feature values for inducing a classification model based on an estimation of the expected improvement in model accuracy per unit cost. Experimental results demonstrate that our approach consistently reduces the cost of producing a model of a desired accuracy compared to random feature acquisitions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044988</person_id>
				<author_profile_id><![CDATA[81100590712]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Prem]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Melville]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045337</person_id>
				<author_profile_id><![CDATA[81335496720]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Maytal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Saar-Tsechansky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042855</person_id>
				<author_profile_id><![CDATA[81100596683]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Foster]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Provost]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043183</person_id>
				<author_profile_id><![CDATA[81100539345]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Raymond]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mooney]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. L. Blake and C. J. Merz. UCI repository of machine learning databases. www.ics.uci.edu/~mlearn/MLRepository.html, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>189489</ref_obj_id>
				<ref_obj_pid>189256</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Cohn, L. Atlas, and R. Ladner. Improving generalization with active learning. <i>Machine Learning</i>, 15(2):201- 221,1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[G. John, R. Kohavi, and K. Pfleger. Irrelevant features and the subset selection problem. In <i>Proc. of 11th Intl. Conf. on Machine Learning</i>, pages 121-129, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>21412</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Little and D. Rubin. <i>Statistical Analysis with Missing Data</i>. John Wiley and Sons, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2100630</ref_obj_id>
				<ref_obj_pid>2100584</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Lizotte, O. Madani, and R. Greiner. Budgeted learning of naive-Bayes classifiers. In <i>Proc. of 19th Conf. on Uncertainty in Artificial Intelligence</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033511</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Prem Melville, Maytal Saar-Tsechansky, Foster Provost, and Raymond Mooney. Active feature-value acquisition for classifier induction. In <i>Proc. of 4th IEEE Intl. Conf. on Data Mining (ICDM-04)</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1089828</ref_obj_id>
				<ref_obj_pid>1089827</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Prem Melville, Maytal Saar-Tsechansky, Foster Provost, and Raymond Mooney. Economical active feature-valuf acquisition through expected utility estimation. In <i>Proc of the KDD-05 Workshop on Utility-Based Data Mining</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655646</ref_obj_id>
				<ref_obj_pid>645530</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[N. Roy and A. McCallum. Toward optimal active learning through sampling estimation of error reduction. In <i>Proc. of ICML-2001</i>, pages 441-448, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[P. D. Turney. Types of cost in inductive concept learning. In <i>Proc. of ICML Workshop on Cost-Sensitive Learning</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323651</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[I. H. Witten and E. Frank. <i>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations</i>. Morgan Kaufmann, San Francisco, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844719</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Z. Zheng and B. Padmanabhan. On active learning for data acquisition. In <i>Proc. of Intl. Conf. on Data Mining</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106442</article_id>
		<sort_key>749</sort_key>
		<display_label></display_label>
		<pages>749-752</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>125</seq_no>
		<title><![CDATA[Automatically Mining Result Records from Search Engine Response Pages]]></title>
		<page_from>749</page_from>
		<page_to>752</page_to>
		<doi_number>10.1109/ICDM.2005.30</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106442</url>
		<abstract>
			<par><![CDATA[Usually, Web applications such as deep Web crawlers, metasearch engines, and other Web mining systems need to extract information displayed in the form of result records on response pages returned by search engines in response to submitted queries. Extracting such records is challenging as search engines are heterogeneous in displaying their records. In addition, response pages returned by many search engines include other noisy content such as advertisements, suggestion links, etc., which make the extraction task even more complicated. In this paper, we propose a highly effective and efficient algorithm for automatically mining result records from search engine response pages.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>World Wide Web (WWW)</descriptor>
				<type>P</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003152</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763011</person_id>
				<author_profile_id><![CDATA[81309491928]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dheerendranath]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mundluru]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Louisiana at Lafayette]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763048</person_id>
				<author_profile_id><![CDATA[81309489769]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jayasimha]]></first_name>
				<middle_name><![CDATA[Reddy]]></middle_name>
				<last_name><![CDATA[Katukuri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Louisiana at Lafayette]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763144</person_id>
				<author_profile_id><![CDATA[81309493605]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Saygin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Celebi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Louisiana at Lafayette]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1046457</ref_obj_id>
				<ref_obj_pid>1046456</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Liu and K. Chang. "Editorial: Special Issue on Web Content Mining", SIGKDD Explorations special issue on Web Content Mining, Dec 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[N. Kushmerick, D. Weld, and R. Doorenbos. "Wrapper Induction for Information Extraction", Proc. Int. Joint Conf. Artificial Intelligence, Japan, 1997, pp. 729-735.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>860555</ref_obj_id>
				<ref_obj_pid>860435</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Z. Wu, V. Raghavan, C. Du, K. Sai Charan, W. Meng, H. He, and C. Yu. "SE-LEGO: Creating Metasearch Engine on Demand". Proc. of 26th ACM SIGIR Conference, Demo paper, Canada, July 2003, pp. 464.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>372182</ref_obj_id>
				<ref_obj_pid>371920</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. Chang and S. Lui. "IEPAD: Information Extraction Based on Pattern Discovery", WWW Conf., Hongkong, 2001, pp. 681-688.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956826</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[B. Liu, R. Grossman, Y. Zhai. "Mining Data Records in Web Pages", SIGKDD, USA, August 2003, pp. 601-606.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Z. Wu, D. Mundluru, and V. Raghavan. "Automatically Detecting Boolean Operations Supported by Search Engines, towards Search Engine Query Language Discovery", Intl. Workshop on Web-based Support Systems, China, 2004, pp. 171-178.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>356830</ref_obj_id>
				<ref_obj_pid>356827</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. Hall and G. Dowling, "Approximate String Matching", Computing Surveys, 1980, pp. 381-402.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. Mundluru, Z. Wu, V. Raghavan, J. Katukuri, and S. Celebi, "Automatically Mining Search Result Records", Technical Report, Center for Advanced Computer Studies, University of Louisiana at Lafayette, 2005. http://www.ucs.louisiana.edu/~dnm8925/TRI.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106443</article_id>
		<sort_key>753</sort_key>
		<display_label></display_label>
		<pages>753-756</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>126</seq_no>
		<title><![CDATA[Efficiently Mining Frequent Closed Partial Orders]]></title>
		<page_from>753</page_from>
		<page_to>756</page_to>
		<doi_number>10.1109/ICDM.2005.57</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106443</url>
		<abstract>
			<par><![CDATA[Mining ordering information from sequence data is an important data mining task. Sequential pattern mining [1] can be regarded as mining frequent segments of total orders from sequence data. However, sequential patterns are often insufficient to concisely capture the general ordering information.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>E.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011024.10011028</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language features->Data types and structures</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15029106</person_id>
				<author_profile_id><![CDATA[81100323054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040448</person_id>
				<author_profile_id><![CDATA[81452603632]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State University of New York at Buffalo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15026328</person_id>
				<author_profile_id><![CDATA[81455605782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Haixun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T.J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043696</person_id>
				<author_profile_id><![CDATA[81350574174]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T.J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043116</person_id>
				<author_profile_id><![CDATA[81451601319]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Jianyong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tsinghua University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Mining sequential patterns. In <i>ICDE'95</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>565203</ref_obj_id>
				<ref_obj_pid>565196</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Ben-Dor et al. Discovering local structure in gene expression data: the order-preserving submatrix problem. In <i>RECOMB'02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[G. Casas-Garriga. Summarizing sequential data with closed partial orders. In <i>Proc. 2005 SIAM Int. Conf. Data Mining</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956768</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Gionis et al. Fragments of order. In <i>KDD'03</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347122</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and C. Meek. Global partial orders from sequential data. In <i>KDD'00</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593449</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[H. Mannila et al. Discovery of frequent episodes in event sequences. <i>Data Mining and Knowledge Discovery</i>, 1:259- 289, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656379</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Pei et al. PrefixSpan: Mining sequential patterns efficiently by prefix-projected pattern growth. In <i>ICDE'01</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106444</article_id>
		<sort_key>757</sort_key>
		<display_label></display_label>
		<pages>757-760</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>127</seq_no>
		<title><![CDATA[CLUMP]]></title>
		<subtitle><![CDATA[A Scalable and Robust Framework for Structure Discovery]]></subtitle>
		<page_from>757</page_from>
		<page_to>760</page_to>
		<doi_number>10.1109/ICDM.2005.43</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106444</url>
		<abstract>
			<par><![CDATA[We introduce a robust and efficient framework called CLUMP (CLustering Using Multiple Prototypes) for unsupervised discovery of structure in data. CLUMP relies on finding multiple prototypes that summarize the data. Clustering the prototypes enables our algorithm to scale up to extremely large and high-dimensional domains such as text data. Other desirable properties include robustness to noise and parameter choices. In this paper, we describe the approach in detail, characterize its performance on a variety of datasets, and compare it to some existing model selection approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15042395</person_id>
				<author_profile_id><![CDATA[81502813002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kunal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Punera]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042756</person_id>
				<author_profile_id><![CDATA[81100558602]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Joydeep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ghosh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Banerjee, S. Merugu, I. Dhillon, and J. Ghosh. Clustering with Bregman divergences. In <i>SIAM International Conference on Data Mining (SDM)</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657466</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. S. Bradley and U. M. Fayyad. Refining initial points for k-means clustering. In <i>ICML '98</i>, pages 91-99, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>370699</ref_obj_id>
				<ref_obj_pid>370660</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon and D. S. Modha. Concept decompositions for large sparse text data using clustering. <i>Machine Learning</i>, 42(1):143-175, Jan 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Fred and A. K. Jain. Data clustering using evidence accumulation. In <i>16th Intl. Conference on Pattern Recognition, ICPR 2002</i>, pages 276-280, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276312</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Guha, R. Rastogi, and K. Shim. Cure: an efficient clustering algorithm for large databases. In <i>SIGMOD '98</i>, pages 73-84, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. K. Jain and R. C. Dubes. <i>Algorithms for clustering data</i>. Prentice-Hall Inc., 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1106444</ref_obj_id>
				<ref_obj_pid>1106326</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[K. Punera and J. Ghosh. Clump: A scalable and robust framework for structure discovery. Technical report, Electrical and Computer Engineering, University of Texas at Austin, {www.lans.ece.utexas.edu/~kunal/ papers/icdm05-clump-long.pdf}, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033653</ref_obj_id>
				<ref_obj_pid>1032651</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Salvador and P. Chan. Determining the number of clusters/ segments in hierarchical clustering/segmentation algorithms. In <i>16th IEEE International Conference on Tools with AI</i>, pages 576-584, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944935</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Strehl and J. Ghosh. Cluster ensembles - a knowledge reuse framework for combining multiple partitions. <i>Journal on Machine Learning Research (JMLR)</i>, 3:583-617, December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. Tibshirani, G. Walther, and T. Hastie. Estimating the number of clusters via the gap statistic. <i>Journal of Royal Statistical Society</i>, B, 63(2):411-423, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233324</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[T. Zhang, R. Ramakrishnan, and M. Livny. Birch: an efficient data clustering method for very large databases. In <i>SIGMOD '96</i>, pages 103-114, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106445</article_id>
		<sort_key>761</sort_key>
		<display_label></display_label>
		<pages>761-764</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>128</seq_no>
		<title><![CDATA[On the Tractability of Rule Discovery from Distributed Data]]></title>
		<page_from>761</page_from>
		<page_to>764</page_to>
		<doi_number>10.1109/ICDM.2005.110</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106445</url>
		<abstract>
			<par><![CDATA[This paper analyses the tractability of rule selection for supervised learning in distributed scenarios. The selection of rules is usually guided by a utility measure such as predictive accuracy or weighted relative accuracy. A common strategy to tackle rule selection from distributed data is to evaluate rules locally on each dataset. While this works well for homogeneously distributed data, this work proves limitations of this strategy if distributions are allowed to deviate. The identification of those subsets for which local and global distributions deviate, poses a learning task of its own, which is shown to be at least as complex as discovering the globally best rules from local data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Distributed databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003195</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Parallel and distributed DBMSs</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15041866</person_id>
				<author_profile_id><![CDATA[81100253041]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scholz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Dortmund]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large data bases. In <i>Proc. of the 20th Int. Conf. on Very Large Data Bases</i>, pages 478-499, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>692863</ref_obj_id>
				<ref_obj_pid>646416</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Cheung and Y. Xiao. Effect of Data Skewness in Parallel Mining of Association Rules. In <i>Pacific-Asia Conference on Knowledge Discovery and Data Mining</i>, pages 48-60, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. A. Flach. The Geometry of ROC Space: Understanding Machine Learning Metrics through ROC Isometrics. In <i>Proc. of the 20th Int. Conf. on Machine Learning</i>. 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1052021</ref_obj_id>
				<ref_obj_pid>1051979</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. F&#252;rnkranz and P. Flach. ROC 'n' Rule Learning - Towards a Better Understanding of Covering Algorithms. <i>Machine Learning</i>, 58(1):39-77, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>257965</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[W. Kl&#246;sgen. Explora: A Multipattern and Multistrategy Discovery Assistant. In <i>Advances in Knowledge Discovery and Data Mining</i>, chapter 3. AAAI Press/The MIT Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>586464</ref_obj_id>
				<ref_obj_pid>586459</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Lazarevic and Z. Obradovic. Boosting algorithms for parallel and distributed learning. <i>Distributed and Parallel Databases Journal</i>, 11(2):203-229, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944956</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Scheffer and S. Wrobel. Finding the Most Interesting Patterns in a Database Quickly by Using Sequential Sampling. <i>Journal of Machine Learning Research</i>, 3:833-862, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Scholz. On the Complexity of Rule Discovery from Distributed Data. <i>SFB 475, Technical Report No. 31</i>, University of Dortmund, Germany, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106446</article_id>
		<sort_key>765</sort_key>
		<display_label></display_label>
		<pages>765-768</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>129</seq_no>
		<title><![CDATA[Face Recognition Using Landmark-Based Bidimensional Regression]]></title>
		<page_from>765</page_from>
		<page_to>768</page_to>
		<doi_number>10.1109/ICDM.2005.61</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106446</url>
		<abstract>
			<par><![CDATA[This paper studies how biologically meaningful landmarks extracted from face images can be exploited for face recognition using the bidimensional regression. Incorporating the correlation statistics of landmarks, this paper also proposes a new approach called eigenvalue weighted bidimensional regression. Complex principal component analysis is used for computing eigenvalues and removing correlation among landmarks. We evaluate our approach using two standard face databases: the Purdue AR and the NIST FERET. Experimental results show that the bidimensional regression is an efficient method to exploit geometry information of face images.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Computer vision</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Correlation and regression analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.4.8</cat_node>
				<descriptor>Object recognition</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003691</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Regression analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245.10010251</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems->Object recognition</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010309.10010313</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Factorization methods->Canonical correlation analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15043790</person_id>
				<author_profile_id><![CDATA[81311481653]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jiazheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Nebraska - Lincoln]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043497</person_id>
				<author_profile_id><![CDATA[81100048997]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ashok]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Samal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Nebraska - Lincoln]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39054337</person_id>
				<author_profile_id><![CDATA[81100405703]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Marx]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Nebraska - Lincoln]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. J. Goldstein, L. D. Harmon, and A. B. Lesk, "Identification of human faces," <i>Proceedings of the IEEE</i>, vol. 59, no. 5, pp. 748-760, 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628531</ref_obj_id>
				<ref_obj_pid>628306</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Brunelli and T. Poggio, "Face recognition: Features versus templates," <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 15, no. 10, pp. 1042-1052, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>314274</ref_obj_id>
				<ref_obj_pid>314270</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[I. Craw, N. Costen, T. Kato, and S. Akamatsu, "How should we represent faces for automatic recognition," <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 21, no. 8, pp. 725-736, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[I. L. Dreden and K. V. Mardia, <i>Statistical Shape Analysis</i>. New York, NY: John Wiley and Sons, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[I. T. Jolliffe, <i>Principal Component Analysis</i>. New York, NY: Springer-Verlag, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. M. Martinez and R. Benavente, "The AR Face Database. CVC Technical Report #24," Tech. Rep., June 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>354178</ref_obj_id>
				<ref_obj_pid>354167</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. J. Phillips, H. Moon, S. A. Rizvi, and P. J. Rauss, "The feret evaluation methodology for face-recognition algorithms," <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 22, no. 10, pp. 1090-1104, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[SAS Institute Inc. SAS/STAT User's Guide, http://support.sas/com/91doc/docmainpage.jsp, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106447</article_id>
		<sort_key>769</sort_key>
		<display_label></display_label>
		<pages>769-772</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>130</seq_no>
		<title><![CDATA[Instability of Classifiers on Categorical Data]]></title>
		<page_from>769</page_from>
		<page_to>772</page_to>
		<doi_number>10.1109/ICDM.2005.81</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106447</url>
		<abstract>
			<par><![CDATA[In this paper we study the local behaviour of arbitrary classifiers using the instability of that classifier in a data point. Moreover, we introduce two algorithms. The first to find highly unstable points, the second to find islands of stability.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15041755</person_id>
				<author_profile_id><![CDATA[81100532533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Arno]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Siebes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universiteit Utrecht]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763109</person_id>
				<author_profile_id><![CDATA[81375599484]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Muhammad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Subianto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universiteit Utrecht]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041389</person_id>
				<author_profile_id><![CDATA[81100162409]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Feelders]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universiteit Utrecht]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[L. Breiman, J. Friedman, R. Olshen, and C. Stone. <i>Classification and Regression trees</i>. Chapman & Hall, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>954544</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Duda, P. Hart, and D. Stork. <i>Pattern Classification, 2nd edition</i>. John Wiley & Sons, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. J. Hand. <i>Construction and Assessment of Classification Rules</i>. John Wiley & Sons, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Hettich, C. Blake, and C. Merz. UCI repository of machine learning databases, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>599692</ref_obj_id>
				<ref_obj_pid>599615</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[O. Melnik. Decision region connectivity analysis: A method for analyzing high-dimensional classifiers. <i>Machine Learning</i>, 48:321-351, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[V. N. Vapnik. <i>Statistical Learning Theory</i>. John Wiley & Sons, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Warner, A. Toronto, L. Veasy, and R. Stephenson. A mathematical model for medical diagnosis - application to congenital heart disease. <i>Journal of the American Medical Association</i>, 177:177-184, 1961.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106448</article_id>
		<sort_key>773</sort_key>
		<display_label></display_label>
		<pages>773-776</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>131</seq_no>
		<title><![CDATA[Pruning Social Networks Using Structural Properties and Descriptive Attributes]]></title>
		<page_from>773</page_from>
		<page_to>776</page_to>
		<doi_number>10.1109/ICDM.2005.125</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106448</url>
		<abstract>
			<par><![CDATA[Scale is often an issue with understanding and making sense of large social networks. Here we investigate methods for pruning social networks by determining the most relevant relationships. We measure importance in terms of predictive accuracy on a set of target attributes of the social network. Our goal is to create a pruned network that models only the most informative affiliations and relationships. We present methods for pruning networks based on both structural properties and descriptive attributes demonstrate it on a network of NASDAQ and NYSE businesses and on a bibliographic network.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Network problems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003644</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Network flows</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003635.10003644</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Graph algorithms analysis->Network flows</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP45027984</person_id>
				<author_profile_id><![CDATA[81332528016]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lisa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Singh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgetown University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041702</person_id>
				<author_profile_id><![CDATA[81100205081]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lise]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Getoor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Maryland at College Park]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763084</person_id>
				<author_profile_id><![CDATA[81309482740]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Louis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Licamele]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Maryland at College Park]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>775227</ref_obj_id>
				<ref_obj_pid>775152</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, S. Rajagopalan, R. Srikant, and Y. Xu. Mining news-groups using networks arising from social behavior. In <i>International World Wide Web Conference</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502525</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. Domingos and M. Richadson. Mining the network value of customers. In <i>ACM Intl. Conf. on Knowledge Discovery and Data Mining</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956769</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. Kempe, J. Kleinberg, and &#201;. Tardos. Maximizing the spread of influence through a social network. In <i>ACM Intl. Conf. on Knowledge Discovery and Data Mining</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>670139</ref_obj_id>
				<ref_obj_pid>645805</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. J. Knobbe, M. de Haas, and A. Siebes. Propositionalisation and aggregates. In <i>Eur. Conf. on Principles of Data Mining and Knowledge Discovery</i>. Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956972</ref_obj_id>
				<ref_obj_pid>956863</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Liben-Nowell and J. Kleinberg. The link prediction problem for social networks. In <i>Intl. Conf. on Information and Knowledge Management</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Newman. The structure and function of complex networks. <i>IAM Review</i>, 45(2):167-256, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956772</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Perlich and F. Provost. Aggregation-based feature invention and relational concept classes. In <i>Intl. Conf. on Knowledge Discovery and Data Mining</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>163402</ref_obj_id>
				<ref_obj_pid>163381</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. F. Schwartz and D. C. Wood. Discovering shared interests using graph analysis. <i>Communications of the ACM</i>, 36(8), 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106449</article_id>
		<sort_key>777</sort_key>
		<display_label></display_label>
		<pages>777-780</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>132</seq_no>
		<title><![CDATA[Optimizing Constraint-Based Mining by Automatically Relaxing Constraints]]></title>
		<page_from>777</page_from>
		<page_to>780</page_to>
		<doi_number>10.1109/ICDM.2005.112</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106449</url>
		<abstract>
			<par><![CDATA[In constraint-based mining, the monotone and anti-monotone properties are exploited to reduce the search space. Even if a constraint has not such suitable properties, existing algorithms can be re-used thanks to an approximation, called relaxation. In this paper, we automatically compute monotone relaxations of primitive-based constraints. First, we show that the latter are a superclass of combinations of both kinds of monotone constraints. Second, we add two operators to detect the properties of monotonicity of such constraints. Finally, we define relaxing operators to obtain monotone relaxations of them.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Information filtering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003352</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Information extraction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003636</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Approximation algorithms analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003349</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Document filtering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003736.10003737</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Functional analysis->Approximation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP15041136</person_id>
				<author_profile_id><![CDATA[81365592401]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Arnaud]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Soulet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#233; de Caen]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP17002124</person_id>
				<author_profile_id><![CDATA[81100008622]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bruno]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cremilleux]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#233; de Caen]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. of VLDB</i>, pages 487-499, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033434</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[F. Bonchi and C. Lucchese. On closed constrained frequent pattern mining. In <i>Proc. of ICDM</i>, pages 35-42, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775054</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Bucila, J. Gehrke, D. Kifer, and W. White. Dualminer: A dual-pruning algorithm for itemsets with constraints. In <i>Proc. of SIGKDD</i>, pages 42-51, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. L. O. Claudia Antunes. Mining patterns using relaxations of user defined constraints. In <i>Post-proc. of KDID</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671514</ref_obj_id>
				<ref_obj_pid>645925</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. N. Garofalakis, R. Rastogi, and K. Shim. SPIRIT: Sequential pattern mining with regular expression constraints. In <i>Proc. of VLDB</i>, pages 223-234, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>240472</ref_obj_id>
				<ref_obj_pid>240455</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Imielinski and H. Mannila. A database perspective on knowledge discovery. <i>Comm. Of The Acm</i>, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>773180</ref_obj_id>
				<ref_obj_pid>773153</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Kiefer, J. Gehrke, C. Bucila, and W. White. How to quickly find a witness. In <i>Proc. of SIGMOD/PODS</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. D. Lee and L. D. Raedt. An algebra for inductive query evaluation. In <i>Proc. of KDID</i>, pages 80-96, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593448</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and H. Toivonen. Levelwise search and borders of theories in knowledge discovery. <i>Data Mining and Knowledge Discovery</i>, 1(3):241-258, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. Ng, L. V. S. Lakshmanan, J. Han, and T. Mah. Exploratory mining via constrained frequent set queries, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656372</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and L. V. S. Lakshmanan. Mining frequent item sets with convertible constraints. In <i>Proc. of ICDE</i>, pages 433-442, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2140920</ref_obj_id>
				<ref_obj_pid>2140831</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A. Soulet and B. Cr&#233;milleux. An efficient framework for mining flexible constraints. In <i>Proc. of PAKDD</i>, pages 661- 670, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106450</article_id>
		<sort_key>781</sort_key>
		<display_label></display_label>
		<pages>781-784</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>133</seq_no>
		<title><![CDATA[Bias Analysis in Text Classification for Highly Skewed Data]]></title>
		<page_from>781</page_from>
		<page_to>784</page_to>
		<doi_number>10.1109/ICDM.2005.34</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106450</url>
		<abstract>
			<par><![CDATA[Feature selection is often applied to high-dimensional data as a preprocessing step in text classification. When dealing with highly skewed data, we observe that typical feature selection metrics like information gain or chi-squared are biased toward selecting features for the minor class, and the metric of bi-normal separation can select features for both minor and major classes. In this work, we investigate how these feature selection metrics impact on the performance of frequently used classifiers such as Decision Trees, Na&#253;ve Bayes, and Support Vector Machines via bias analysis for highly skewed data. Three types of biases are metric bias, class bias, and classifier bias. Extensive experiments are designed to understand how these biases can be employed in concert and efficiently to achieve good classificationperformance. We report our findings and present recommended approaches to text classification based on bias analysis and the empirical study.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Text processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040901</person_id>
				<author_profile_id><![CDATA[81363600542]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040579</person_id>
				<author_profile_id><![CDATA[81367594306]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Huan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1007735</ref_obj_id>
				<ref_obj_pid>1007730</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[G. Batista, R. C. Prati, and M. C. Monard. A study of the behavior of several methods for balancing machine learning training data. <i>SIGKDD Explor. Newsl.</i>, 6(1):20-29, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944974</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[G. Forman. An extensive empirical study of feature selection metrics for text classification. <i>J. Mach. Learn. Res.</i>, 3:1289- 1305, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657649</ref_obj_id>
				<ref_obj_pid>645528</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. Mladenic and M. Grobelnik. Feature selection for unbalanced class distribution and naive bayes. In <i>Proc. ICML</i>, pages 258-267. Morgan Kaufmann Publishers Inc., 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Tang and H. Liu. Bias analysis in text classification for highly skewed data. Technical Report TR-06-005, Arizona State University, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622445</ref_obj_id>
				<ref_obj_pid>1622434</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Weiss and F. Provost. Learning when training data are costly: The effect of class distribution on tree induction. <i>JAIR</i>, 19:315-354, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657137</ref_obj_id>
				<ref_obj_pid>645526</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Yang and J. O. Pedersen. A comparative study on feature selection in text categorization. In <i>Proc. ICML</i>, pages 412- 420. Morgan Kaufmann Publishers Inc., 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106451</article_id>
		<sort_key>785</sort_key>
		<display_label></display_label>
		<pages>785-788</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>134</seq_no>
		<title><![CDATA[Efficient Mining of High Branching Factor Attribute Trees]]></title>
		<page_from>785</page_from>
		<page_to>788</page_to>
		<doi_number>10.1109/ICDM.2005.55</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106451</url>
		<abstract>
			<par><![CDATA[In this paper, we present a new tree mining algorithm, DRYADEPARENT, based on the hooking principle first introduced in DRYADE [9]. In the experiments, we demonstrate that the branching factor and depth of the frequent patterns to find are key factor of complexity for tree mining algorithms. We show that DRYADEPARENT outperforms the current fastest algorithm, CMTreeMiner, by orders of magnitude on datasets where the frequent patterns have a high branching factor.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044297</person_id>
				<author_profile_id><![CDATA[81100245571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexandre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Termier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45027917</person_id>
				<author_profile_id><![CDATA[81100273126]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Marie-Christine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rousset]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[CNRS, Universit&#233; Paris-Sud and INRIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15044696</person_id>
				<author_profile_id><![CDATA[81100614693]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michele]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sebag]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[CNRS, Universit&#233; Paris-Sud and INRIA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045005</person_id>
				<author_profile_id><![CDATA[81343501860]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Kouzou]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ohara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15022922</person_id>
				<author_profile_id><![CDATA[81100117705]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Takashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Washio]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39039263</person_id>
				<author_profile_id><![CDATA[81100358248]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Hiroshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Motoda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proceedings of the 20th VLDB Conference</i>, Santiago, Chile, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2153525</ref_obj_id>
				<ref_obj_pid>2153523</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H. Arimura and T. Uno. An output-polynomial time algorithm for mining frequent closed attribute trees. In <i>15th International Conference on Inductive Logic Programming (ILP'05)</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Asai, K. Abe, S. Kawasoe, H. Arimura, H. Sakamoto, and S. Arikawa. Efficient substructure discovery from large semi-structured data. In <i>In Proc. of the Second SIAM International Conference on Data Mining (SDM2002), Arlington, VA</i>, pages 158-174, April 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Asai, H. Arimura, T. Uno, and S. ichi Nakano. Discovering frequent substructures in large unordered trees. In <i>the Proc. of the 6th International Conference on Discovery Science (DS'03)</i>, pages 47-61, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Chalmers and K. Almeroth. Modeling the branching characteristics and efficiency gains of global multicast trees. In <i>Proceedings of the IEEE INFOCOM'2001</i>, April 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Chi, Y. Yang, Y. Xia, and R. R. Muntz. Cmtreeminer: Mining both closed and maximal frequent subtrees. In <i>The Eighth Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD'04)</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Nijssen and J. N. Kok. Efficient discovery of frequent unordered trees. In <i>First International Workshop on Mining Graphs, Trees and Sequences, 2003</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Termier. Extraction of frequent trees in an heterogeneous corpus of semi-structured data: application to xml documents mining. Technical Report 1388, LRI, May 2004. http://www.lri.fr/~termier/publis/phdTermierEN.ps.gz.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033526</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Termier, M. Rousset, and M. Sebag. Dryade : a new approach for discovering closed frequent trees in heterogeneous tree databases. In <i>International Conference on Data Mining ICDM'04, Brighton, England</i>, pages 543-546, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. Termier, M. Rousset, M. Sebag, K. Ohara, T. Washio, and H. Motoda. Computation-time efficient and robust attribute tree mining with DRYADEPARENT. In <i>Third International Workshop on Mining Graphs, Trees and Sequences (MGTS)</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[T. Uno, M. Kiyomi, and H. Arimura. Lcm v.2: Efficient mining algorithms for frequent/closed/maximal itemsets. In <i>2nd Workshop on Frequent Itemset Mining Implementations (FIMI'04)</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775058</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Efficiently mining frequent trees in a forest. In <i>In Proc. 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1227177</ref_obj_id>
				<ref_obj_pid>1227174</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Efficiently mining frequent embedded unordered trees. <i>Fundamenta Informaticae, special issue on Advances in Mining Graphs, Trees and Sequences</i>, 65(1-2):33-52, March/April 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106452</article_id>
		<sort_key>789</sort_key>
		<display_label></display_label>
		<pages>789-792</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>135</seq_no>
		<title><![CDATA[Anomaly Intrusion Detection Using Multi-Objective Genetic Fuzzy System and Agent-Based Evolutionary Computation Framework]]></title>
		<page_from>789</page_from>
		<page_to>792</page_to>
		<doi_number>10.1109/ICDM.2005.26</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106452</url>
		<abstract>
			<par><![CDATA[In this paper, we present a multi-objective genetic fuzzy system for anomaly intrusion detection. The proposed system extracts accurate and interpretable fuzzy rule-based knowledge from network data using an agent-based evolutionary computation framework. The experimental results on KDD-Cup99 intrusion detection benchmark data demonstrate that our system can achieve high detection rate for intrusion attacks and low false positive rate for normal network traffic.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>C.2.0</cat_node>
				<descriptor>Security and protection (e.g., firewalls)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Fuzzy set</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>K.6.5</cat_node>
				<descriptor>Invasive software (e.g., viruses, worms, Trojan horses)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.11</cat_node>
				<descriptor>Intelligent agents</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003462.10003574</concept_id>
				<concept_desc>CCS->Social and professional topics->Computing / technology policy->Computer crime</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010219.10010221</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Distributed artificial intelligence->Intelligent agents</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10002997</concept_id>
				<concept_desc>CCS->Security and privacy->Intrusion/anomaly detection and malware mitigation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Security</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P762994</person_id>
				<author_profile_id><![CDATA[81450592300]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chi-Ho]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[City University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041218</person_id>
				<author_profile_id><![CDATA[81100608038]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kwong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[City University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763033</person_id>
				<author_profile_id><![CDATA[81309481395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hanli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[City University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1708983</ref_obj_id>
				<ref_obj_pid>1708868</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[H. L. Wang, S. Kwong, Y. Jin, W. Wei, and K. F. Man, Multi-objective hierarchical genetic algorithm for interpretable fuzzy rule-based knowledge extraction, Fuzzy Sets and Systems, 149(1), Jan. 2005, pp. 149-186.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[K. S. Tang, K. F. Man, Z. F. Liu, and S. Kwong, Minimal fuzzy memberships and rules using hierarchical genetic algorithms, IEEE Trans. Industrial Electronics, 45(1), Feb. 1998, pp. 162- 169.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2234955</ref_obj_id>
				<ref_obj_pid>2234524</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H. Ishibuchi and T. Nakashima, Effect of rule weights in fuzzy rule-based classification systems, IEEE Trans. Fuzzy Systems, 9(4), Aug. 2001, pp. 506-515.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>144178</ref_obj_id>
				<ref_obj_pid>144170</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Ishibuchi, K. Nozaki, and H. Tanaka, Distributed representation of fuzzy rules and its application to pattern classification, Fuzzy Sets and Systems, 52(1), Nov. 1992, pp. 21-32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2221582</ref_obj_id>
				<ref_obj_pid>2221359</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan, A fast and elitist multiobjective genetic algorithm: NSGA-II, IEEE Trans. Evolutionary Computation, 6(2), Apr. 2002, pp. 182-197.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846199</ref_obj_id>
				<ref_obj_pid>846183</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Elkan, Results of the KDD'99 classifier learning, ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, Boston, MA, 1(2), 2000, pp. 63-64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. Agarwal and M. V. Joshi, PNrule: a new framework for learning classifier models in data mining (a case-study in network intrusion detection), In: Proc. First SIAM Conf. on Data Mining, Apr. 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106453</article_id>
		<sort_key>793</sort_key>
		<display_label></display_label>
		<pages>793-796</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>136</seq_no>
		<title><![CDATA[Mining Quantitative Frequent Itemsets Using Adaptive Density-Based Subspace Clustering]]></title>
		<page_from>793</page_from>
		<page_to>796</page_to>
		<doi_number>10.1109/ICDM.2005.100</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106453</url>
		<abstract>
			<par><![CDATA[A novel approach to subspace clustering is proposed to exhaustively and efficiently mine quantitative frequent itemsets (QFIs) from massive transaction data. For the computational tractability, our approach introduces adaptive density-based and Apriori-like algorithm. Its outstanding performance is shown through numerical experiments.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15022922</person_id>
				<author_profile_id><![CDATA[81100117705]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Takashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Washio]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763184</person_id>
				<author_profile_id><![CDATA[81309500228]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mitsunaga]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39039263</person_id>
				<author_profile_id><![CDATA[81100358248]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hiroshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Motoda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Osaka University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>304188</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal, J. L. W. Cecilia Procopiuc, P. S. Yu, and J. S. Park. Fast algorithms for projected clustering. <i>In Proc. of SIGMOD conference</i>, pages 61-72, June 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628205</ref_obj_id>
				<ref_obj_pid>627339</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal and P. S. Yu. Redefining clustering for high-dimensional applications. <i>IEEE Transactions on Knowledge and Data Engineering, (TKDE)</i>, 14(2), March 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276314</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, J. Gehrke, D. Gunopulos, and P. Raghavan. Automatic subspace clustering of high dimensional data for data mining applications. <i>Proc. of the 1998 ACM SIGMOD international conference on Management of data</i>, pages 94- 105, June 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312199</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C.-H. Cheng, A. W. Fu, and Y. Zhang. Entropy-based subspace clustering for mining numerical data. <i>Proc. of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining</i>, pages 84-93, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. A density-based algorithm for discovering clusters in large spatial databases with noise. <i>In Proc. 2nd Int. Conf. on Knowledge Discovery and Data Mining</i>, pages 226-231, August 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Goil, H. Nagesh, and A. Choudhary. Mafia: Efficient and scalable subspace clustering for very large data sets. <i>Tech. Report No. CPDC-TR-9906-010, Center for Parallel and Distributed Computing, Dept. of Electrical and Computer Engineering, Northwestern University</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[K. Kailing, H.-P. Kriegel, and P. Kroger. Density-connected subspace clustering for high-dimensional data. <i>Proc. Fourth SIAM International Conference on Data Mining (SDM'04)</i>, pages 246-257, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>354775</ref_obj_id>
				<ref_obj_pid>354756</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. Liu, Y. Xia, and P. S. Yu. Clustering through decision tree construction. <i>Proc. of the Ninth International Conference on Information and Knowledge Management</i>, pages 20-29, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1048855</ref_obj_id>
				<ref_obj_pid>1048718</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[E. K. Ng, A. W. Fu, and R. C. Wong. Projective clustering by histograms. <i>IEEE Transactions on Knowledge and Data Engineering, (TKDE)</i>, 17(3):369-383, March 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564739</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. M. Procopiuc, M. Jones, P. K. Agarwal, and T. M. Murali. A monte carlo algorithm for fast projective clustering. <i>Proceedings of the 2002 ACM SIGMOD international conference on Management of data</i>, pages 418-427, June 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033453</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[K. Sequeira and M. Zaki. Schism: A new approach for interesting subspace mining. <i>Proc. of Fourth IEEE International Conference on Data Mining</i>, pages 186-193, November 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233311</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. Srikant and R. Agrawal. Mining quantitative association rules in large relational tables. <i>Proc. of 1996 ACM SIGMOD Int. Conf. on Management of Data</i>, pages 1-12, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[U. C. I. (UCI). <i>UCI Machine Learning Repository</i>. UCI, http://www.ics.uci.edu/mlearn/MLRepository.html, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[K. Wang, S. Hock, W. Tay, and B. Liu. Interestingness-based interval merger for numeric association rules. <i>Proc. of 4th Int. Conf. on Knowledge Discovery and Data Mining (KDD)</i>, pages 121-128, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106454</article_id>
		<sort_key>797</sort_key>
		<display_label></display_label>
		<pages>797-800</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>137</seq_no>
		<title><![CDATA[Hot Item Mining and Summarization from Multiple Auction Web Sites]]></title>
		<page_from>797</page_from>
		<page_to>800</page_to>
		<doi_number>10.1109/ICDM.2005.78</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106454</url>
		<abstract>
			<par><![CDATA[Online auction Web sites are fast changing, highly dynamic, and complex as they involve tremendous sellers and potential buyers, as well as a huge amount of items listed for bidding. We develop a two-phase framework which aims at mining and summarizing hot items from multiple auctionWeb sites to assist decision making. The objective of the first phase is to automatically extract the product features and product feature values of the items from the descriptions provided by the sellers. We design a HMM-based learning method to train an extended HMM model which can adapt to the unseen Web page from which the information is extracted. The goal of the second phase is to discover and summarize the hot items based on the extracted information. We formulate the hot item mining task as a semi-supervised learning problem and employ the graph mincuts algorithm to accomplish this task. The summary of the hot items is then generated by considering the frequency and the position of the product features being mentioned in the descriptions. We have conducted extensive experiments from several real-world auction Web sites to demonstrate the effectiveness of our framework.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.4</cat_node>
				<descriptor>Text processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Markov processes</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003651</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Markov networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003700.10003701</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Stochastic processes->Markov processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>PP45027956</person_id>
				<author_profile_id><![CDATA[81343508867]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tak-Lam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041379</person_id>
				<author_profile_id><![CDATA[81423592360]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lam]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>336644</ref_obj_id>
				<ref_obj_pid>336597</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Agichtein and L. Gravano. Snowball: Extracting relations from large plain-text collections. In <i>Proceedings of the Fifth International Conference on Digital Libraries</i>, pages 85-95, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>757779</ref_obj_id>
				<ref_obj_pid>645530</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Blum and S. Chawla. Learning from labeled and unlabeled data using graph mincuts. In <i>Proceedings of the Eighteenth International Conference on Machine Learning (ICML-2001)</i>, pages 19-26, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081918</ref_obj_id>
				<ref_obj_pid>1081870</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Ghani. Price prediction and insurance for online auctions. In <i>Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD-2005)</i>, To appear, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014073</ref_obj_id>
				<ref_obj_pid>1014052</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Hu and B. Liu. Mining and summarizing customer reviews. In <i>Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD-2004)</i>, pages 168- 177, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1809365</ref_obj_id>
				<ref_obj_pid>1809359</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. Kushmerick and B. Thomas. Adaptive information extraction: Core technologies for information agents. In <i>Intelligents Information Agents R&D In Europe: An Agent Link Perspective</i>, pages 79-103, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>554275</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[I. Mani and M. Maybury. <i>Advances in Automatic Text Summarization</i>. MIT Press, Cambridge, MA, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1033463</ref_obj_id>
				<ref_obj_pid>1032649</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. L. Wong and W. Lam. A probabilistic approach for adapting information extraction wrappers and discovering new attributes. In <i>Proceedings of the 2004 IEEE International Conference on Data Mining (ICDM-2004)</i>, pages 257-264, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1054141</ref_obj_id>
				<ref_obj_pid>1053724</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Yi and W. Niblack. Sentiment mining in WebFountain. In <i>Proceedings of the 21st International Conference on Data Engineering (ICDE- 2005)</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944964</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Zelenko, C. Aone, A. Richardella, and A. Richardella. Kernel methods for relation extraction. <i>Journal of Machine Learning Research</i>, 3:1083-1106, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106455</article_id>
		<sort_key>801</sort_key>
		<display_label></display_label>
		<pages>801-804</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>138</seq_no>
		<title><![CDATA[Merging Interface Schemas on the Deep Web via Clustering Aggregation]]></title>
		<page_from>801</page_from>
		<page_to>804</page_to>
		<doi_number>10.1109/ICDM.2005.92</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106455</url>
		<abstract>
			<par><![CDATA[We consider the problem of integrating a large number of interface schemas over the Deep Web, The scale of the problem and the diversity of the sources present serious challenges to the conventional manual or rule-based approaches to schema integration. To address these challenges, we propose a novel formulation of schema integration as an optimization problem, with the objective of maximally satisfying the constraints given by individual schemas. Since the optimization problem can be shown to be NP-complete, we develop a novel approximation algorithm LMax, which builds the unified schema via recursive applications of clustering aggregation. We further extend LMax to handle the irregularities frequently occurring among the interface schemas. Extensive evaluation on real-world data sets shows the effectiveness of our approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.1</cat_node>
				<descriptor>Schema and subschema</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>World Wide Web (WWW)</descriptor>
				<type>P</type>
			</other_category>
			<other_category>
				<cat_node>G.1.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003736.10003737</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Functional analysis->Approximation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003636</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Approximation algorithms analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10010820</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Data model extensions</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15038841</person_id>
				<author_profile_id><![CDATA[81100657475]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wensheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Urbana-Champaign]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15024459</person_id>
				<author_profile_id><![CDATA[81100156196]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[AnHai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Doan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Urbana-Champaign]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040586</person_id>
				<author_profile_id><![CDATA[81350588112]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Clement]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Aho, Y. Sagiv, T. Szymanski, and J. Ullman. Inferring a tree from lowest common ancestors with an application to the optimization of relational expressions. <i>SIAM</i>, 10(3).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Barbosa and J. Freire. Searching for hidden-web databases. In <i>WebDB</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1054063</ref_obj_id>
				<ref_obj_pid>1053724</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Gionis, H. Mannila, and P. Tsaparas. Clustering aggregation. In <i>ICDE</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>872784</ref_obj_id>
				<ref_obj_pid>872757</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[B. He and K. Chang. Statistical schema matching across Web query interfaces. In <i>Proc. of SIGMOD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1315483</ref_obj_id>
				<ref_obj_pid>1315451</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. He, W. Meng, C. Yu, and Z. Wu. Wise-integrator: an automatic integrator of web search interfaces for e-commerce. In <i>VLDB</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007582</ref_obj_id>
				<ref_obj_pid>1007568</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[W. Wu, C. Yu, A. Doan, and W. Meng. An interactive clustering-based approach to integrating source query interfaces on the Deep Web. In <i>SIGMOD</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106456</article_id>
		<sort_key>805</sort_key>
		<display_label></display_label>
		<pages>805-808</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>139</seq_no>
		<title><![CDATA[On the Stationarity of Multivariate Time Series for Correlation-Based Data Analysis]]></title>
		<page_from>805</page_from>
		<page_to>808</page_to>
		<doi_number>10.1109/ICDM.2005.109</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106456</url>
		<abstract>
			<par><![CDATA[Multivariate time series (MTS) data sets are common in various multimedia, medical and financial application domains. These applications perform several data-analysis operations on large number of MTS data sets such as similarity searches, feature-subset-selection, clustering and classifications. Correlation-based techniques, such as Principal Component Analysis (PCA), have proven to improve the efficiency of many of the above-mentioned data-analysis operations on MTS, which implies that the correlation coefficientsconcisely represent the original MTS data. However, if the statistical properties (e.g., variance) of MTS data change over time dimension, i.e., MTS data is non-stationary, the correlation coefficients are not stable. In this paper, we propose to utilize the stationarity of the MTS data sets, in order to represent the original MTS data more stably, as well as concisely with the correlation coefficients. That is, before performing any correlation-based data analysis, we first executes the stationarity test to decide whether the MTS data is stationary or not, i.e., whether the correlation is stable or not. Subsequently, for a non-stationary MTS data set, we difference it to render the data set stationary. Even though our approach is general, to focus the discussion we describe our approach within the context of our previously proposed technique for MTS similarity search. In order to show the validity of our approach, we performed several experiments on four real-world data sets. The results show that the performance of our similarity search technique have significantly improved in terms of precision/recall.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Multivariate statistics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>Performance evaluation (efficiency and effectiveness)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003704</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Multivariate statistics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15040046</person_id>
				<author_profile_id><![CDATA[81100352740]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kiyoung]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40029093</person_id>
				<author_profile_id><![CDATA[81100616904]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Cyrus]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shahabi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>328959</ref_obj_id>
				<ref_obj_pid>328939</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Bozkaya and M. Ozsoyoglu. Indexing large metric spaces for similarity search queries. <i>ACM TODS</i>, 24(3), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. N. DeJong, J. C. Nankervis, N. E. Savin, and C. H. Whiteman. Integration versus trend stationary in time series. <i>Econometrica</i>, 60(2):423-433, March 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. A. Dickey and W. A. Fuller. Distribution of the estimators for autoregressive time series with a unit root. <i>Journal of the American Statistical Association</i>, 74(366):427-431, June 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. A. Dickey, D. W. Jansen, and D. L. Thornton. A primer on cointegration with an application to money and income. <i>Federal Reserve Bulletin, Federal Reserve Bank of St. Louis</i>, pages 58-78, March/April 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Elder and P. E. Kennedy. Testing for unit roots: What should students be taught? <i>Journal of Economic Education</i>, 31(2):137-146, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. F. Engle and C. W. J. Granger. Co-integration and error correction: Representation, estimation, and testing. <i>Econometrica</i>, 55(2):251-276, March 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>129687</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W. B. Frakes and R. Baeza-Yates. <i>Information Retrieval: Data Structures and Algorithms</i>. Prentice-Hall, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Johansen. <i>Likelihood-Based Inference in Cointegrated Vector Autoregressive Models</i>. Oxford University Press, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[I. T. Jolliffe. <i>Principal Component Analysis</i>. Springer, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1037668</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. W. Kadous. <i>Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series</i>. PhD thesis, University of New South Wales, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[W. Krzanowski. Between-groups comparison of principal components. <i>JASA</i>, 74(367), 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. N. Lal, T. Hinterberger, G. Widman, M. Schr&#246;der, N. J. Hill, W. Rosenstiel, C. E. Elger, B. Sch&#246;lkopf, and N. Birbaumer. Methods towards invasive human brain computer interfaces. In <i>Advances in Neural Information Processing Systems 17</i>, pages 737-744. Cambridge, MA, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[T. N. Lal, M. Schr&#246;der, T. Hinterberger, J. Weston, M. Bogdan, N. Birbaumer, and B. Sch&#246;lkopf. Support vector channel selection in BCI. <i>IEEE Trans. Biomed. Eng.</i>, 51(6), June 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1027721</ref_obj_id>
				<ref_obj_pid>1027527</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C. Li, P. Zhai, S.-Q. Zheng, and B. Prabhakaran. Segmentation and recognition of multi-attribute motion sequences. In <i>ACM MM '04</i>, pages 836-843, New York, NY, USA, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[P. Perron. The great crash, the oil price shock, and the unit root hypothesis. <i>Econometrica</i>, 57(6):1361-1401, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. Singhal and D. Seborg. Clustering of multivariate time-series data. In <i>Proc. of the American Control Conference</i>, volume 5, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2225844</ref_obj_id>
				<ref_obj_pid>2225287</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[A. Tucker, S. Swift, and X. Liu. Variable grouping in multivariate time series via correlation. <i>IEEE Trans. Syst., Man, Cybern. B</i>, 31(2):235-245, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1032616</ref_obj_id>
				<ref_obj_pid>1032604</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[K. Yang and C. Shahabi. A PCA-based similarity measure for multivariate time series. In <i>MMDB '04</i>, pages 65-74, Washington, DC, USA, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[K. Yang and C. Shahabi. On the stationarity of multivariate time series for correlation-based data analysis. Technical report, University of Southern California, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[K. Yang, H. Yoon, and C. Shahabi. A supervised feature subset selection technique for multivariate time series. In <i>FSDM</i>, Newport Beach, CA, April 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1080037</ref_obj_id>
				<ref_obj_pid>1079841</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[H. Yoon, K. Yang, and C. Shahabi. Feature subset selection and feature ranking for multivariate time series. <i>IEEE Trans. Knowledge Data Eng.</i>, 17(9), September 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106457</article_id>
		<sort_key>809</sort_key>
		<display_label></display_label>
		<pages>809-812</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>140</seq_no>
		<title><![CDATA[Speculative Markov Blanket Discovery for Optimal Feature Selection]]></title>
		<page_from>809</page_from>
		<page_to>812</page_to>
		<doi_number>10.1109/ICDM.2005.134</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106457</url>
		<abstract>
			<par><![CDATA[In this paper we address the problem of learning the Markov blanket of a quantity from data in an efficient manner. Markov blanket discovery can be used in the feature selection problem to find an optimal set of features for classificationtasks, and is a frequently-used preprocessing phase in data mining, especially for high-dimensional domains. Our contribution is a novel algorithm for the induction of Markov blankets from data, called Fast-IAMB, that employs a heuristic to quickly recover the Markov blanket. Empirical results show that Fast-IAMB performs in many cases faster and more reliably than existing algorithms without adversely affecting the accuracy of the recovered Markov blankets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Markov processes</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003651</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Markov networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003700.10003701</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Stochastic processes->Markov processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P763143</person_id>
				<author_profile_id><![CDATA[81309481440]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sandeep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yaramakala]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15042461</person_id>
				<author_profile_id><![CDATA[81100297647]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dimitris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Margaritis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Agresti. <i>Categorical Data Analysis</i>. New York: John Wiley and Sons Inc., 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. Hettich and S. D. Bay. The UCI KDD archive, 1999. {http://kdd.ics.uci.edu/} UC Irvine, Dept. of ICS.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Hettich, C. Blake, and C. Merz. UCI repository of machine learning databases, 1998. {http://www.ics.uci.edu/~mlearn/MLRepository.html} UC Irvine, Dept. of ICS.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Koller and M. Sahami. Toward optimal feature selection. In <i>International Conference on Machine Learning</i>, pages 284- 292, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Margaritis and S. Thrun. Bayesian network induction via local neighborhoods. In S. Solla, T. Leen, and K.-R. M&#252;ller, editors, <i>Proceedings of Conference on Neural Information Processing Systems (NIPS-12)</i>. MIT Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>52121</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Pearl. <i>Probabilistic reasoning in intelligent systems: Networks of plausible inference</i>. Morgan Kaufmann Publishers Inc., 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[I. Tsamardinos, C. Aliferis, and A. Statnikov. Algorithms for large scale Markov blanket discovery. In <i>The 16th International FLAIRS Conference</i>, St. Augustine, Florida, USA, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106458</article_id>
		<sort_key>813</sort_key>
		<display_label></display_label>
		<pages>813-816</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>141</seq_no>
		<title><![CDATA[A Join-Less Approach for Co-Location Pattern Mining]]></title>
		<subtitle><![CDATA[A Summary of Results]]></subtitle>
		<page_from>813</page_from>
		<page_to>816</page_to>
		<doi_number>10.1109/ICDM.2005.8</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106458</url>
		<abstract>
			<par><![CDATA[Spatial co-location patterns represent the subsets of features whose instances are frequently located together in geographic space. Co-location pattern discovery presents challenges since the instances of spatial features are embedded in a continuous space and share a variety of spatial relationships. A large fraction of the computation time is devoted to identifying the instances of co-location patterns. We propose a novel join-less approach for co-location pattern mining, which materializes spatial neighbor relationships with no loss of co-location instances and reduces the computational cost of identifying the instances. The join-less co-location mining algorithm is efficient since it uses an instance-lookup scheme instead of an expensive spatial or instance join operation for identifying co-location instances. The experimental evaluations show the join-less algorithm performs more efficiently than a current join-based algorithm and is scalable in dense spatial datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P647807</person_id>
				<author_profile_id><![CDATA[81100012648]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jin]]></first_name>
				<middle_name><![CDATA[Soung]]></middle_name>
				<last_name><![CDATA[Yoo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15041317</person_id>
				<author_profile_id><![CDATA[81100610476]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shekhar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763100</person_id>
				<author_profile_id><![CDATA[81309506932]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mete]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Celik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agarwal and R. Srikant. Fast algorithms for Mining association rules. In <i>Proc. of Int'l Conference on Very Large Databases(VLDB)</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Berg, M. Kreveld, O. M., and O. Schwarzkopf. <i>Computational Geometry</i>. Springer, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>718925</ref_obj_id>
				<ref_obj_pid>647224</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K. Koperski and J. Han. Discovery of Spatial Association Rules in Geographic Information Databases. In <i>Proc. of Int'l Symposium on Large Spatial Data bases, Maine. 47-66</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502564</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Y. Morimoto. Mining Frequent Neighboring Class Sets in Spatial Databases. In <i>Proc. ACM SIGKDD Int'l Conference on Knowledge Discovery and Data Mining</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Shekhar and S. Chawla. <i>Spatial Databases: A Tour</i> Prentice Hall, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Shekhar and Y. Huang. Co-location Rules Mining: A Summary of Results. In <i>Proc. of Int'l Symposium on Spatio and Temporal Database(SSTD)</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1032258</ref_obj_id>
				<ref_obj_pid>1032222</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Yoo and S. Shekhar. A Partial Join Approach for Mining Co-location Patterns. In <i>Proc. of ACM Int'l Symposium on Advances in Geographic Information Systems(ACM-GIS)</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106459</article_id>
		<sort_key>817</sort_key>
		<display_label></display_label>
		<pages>817-820</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>142</seq_no>
		<title><![CDATA[Learning through Changes]]></title>
		<subtitle><![CDATA[An Empirical Study of Dynamic Behaviors of Probability Estimation Trees]]></subtitle>
		<page_from>817</page_from>
		<page_to>820</page_to>
		<doi_number>10.1109/ICDM.2005.88</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106459</url>
		<abstract>
			<par><![CDATA[In practice, learning from data is often hampered by the limited training examples. In this paper, as the size of training data varies, we empirically investigate several probability estimation tree algorithms over eighteen binary classification problems. Nine metrics are used to evaluate their performances. Our aggregated results show that ensemble trees consistently outperform single trees. Confusion factor trees(CFT) register poor calibration even as training size increases, which shows that CFTs are potentially biased if data sets have small noise. We also provide analysis on the observed performance of the tree algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.1.2</cat_node>
				<descriptor>Analysis of algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010148.10010149</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044745</person_id>
				<author_profile_id><![CDATA[81309509249]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P763188</person_id>
				<author_profile_id><![CDATA[81309513080]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zujia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Dillard University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045003</person_id>
				<author_profile_id><![CDATA[81100023197]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39054660</person_id>
				<author_profile_id><![CDATA[81408603249]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Bill]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Buckles]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tulane University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. R. Quinlan. C4.5: programs for empirical learning. Morgan Kaufmann, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>779926</ref_obj_id>
				<ref_obj_pid>779909</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[F. Provost and P. Domingos. "Tree induction for probability based rankings". Machine Learning, 52(3), 2003, pp. 199-215.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952144</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W. Fan, H. X. Wang, P. S. Yu and S. Ma, "Is random model better? On its accuracy and efficiency", ICDM 2003, pp. 51-58.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1597204</ref_obj_id>
				<ref_obj_pid>1597148</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[W. Fan, "On the optimality of probability estimation by random decision trees", AAAI 2004, pp. 336-341.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2140913</ref_obj_id>
				<ref_obj_pid>2140831</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[F. Liu, K. M. Ting, W. Fan, "Maximizing tree diversity by building complete-random decision trees. PAKDD 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622445</ref_obj_id>
				<ref_obj_pid>1622434</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G. Weiss and F. Provost, "Learning when training data are costly: the effect of class distribution on tree induction", JAIR, 19, 2003, pp. 315-354.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Ling and R. Yan, "Decision Tree with better ranking", ICML, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649703</ref_obj_id>
				<ref_obj_pid>645326</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Bradford, C. Kunz, R. Kohavi, C. Brunk, C. Brodley, Pruning decision trees with misclassification costs", ECML 98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz, "UCI repository of machine learning database", UCI, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[G. P. Shapiro and B. Masand. "Estimating campaign benefits and modeling lift". KDD 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[T. Fawcett. "ROC graphs: notes and practical considerations for data mining researchers". HPL-2003-4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. DeGroot and S. Fienberg, "Assessing probability assessors: calibration and refinement", Statistica Decision Theory and Related Topics III, Vol. 1, 1982, pp. 291-314.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. H. Murphy, "A new vector partition of the probability score", J. Appl. Met., 12, 1973, pp. 534-537.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106460</article_id>
		<sort_key>821</sort_key>
		<display_label></display_label>
		<pages>821-824</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>143</seq_no>
		<title><![CDATA[Visualizing Global Manifold Based on Distributed Local Data Abstractions]]></title>
		<page_from>821</page_from>
		<page_to>824</page_to>
		<doi_number>10.1109/ICDM.2005.150</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106460</url>
		<abstract>
			<par><![CDATA[Mining distributed data for global knowledge is getting more attention recently. The problem is especially challenging when data sharing is prohibited due to local constraints like limited bandwidth and data privacy. In this paper, we investigate how to derive the embedded manifold (as a 2-D map)for a horizontally partitioned data set, where data cannot be shared among the partitions directly. We propose a model-based approach which computes hierarchical local data abstractions, aggregates the abstractions, and finally learns a global generative model &#8212; generative topographic mapping (GTM) based on the aggregated data abstraction. We applied the proposed method to two benchmarking data sets and demonstrated that the accuracy of the derived manifold can effectively be controlled by adjusting the data granularity level of the adopted local abstraction.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>Distributed systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003365.10003369</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Search engine architectures and scalability->Peer-to-peer retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152.10003517.10003519</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems->Storage architectures->Distributed storage</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003365.10003368</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Search engine architectures and scalability->Distributed retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15044722</person_id>
				<author_profile_id><![CDATA[81309509129]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiaofeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong Baptist University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P647294</person_id>
				<author_profile_id><![CDATA[81416597690]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Cheung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong Baptist University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>285457</ref_obj_id>
				<ref_obj_pid>285447</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. M. Bishop, M. Svensn, and C. K. I. Williams. GTM: The generative topographic mapping. <i>Neural Computation</i>, 10(1):215-235, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[G. J. McLachlan and K. E. Basford. <i>Mixture Models - Inference and Applications to Clustering</i>. Marcel Dekker, New York, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1630731</ref_obj_id>
				<ref_obj_pid>1630659</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Klusch, S. Lodi, and G. L. Moro. Distributed Clustering Based on Sampling Local Density Estimates. In <i>Proceedings of International Joint Conference on Artificial Intelligence (IJCAI 2003)</i>, pages 485-490, Mexico, August 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952185</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Merugu and J. Ghosh. Privacy-preserving Distributed Clustering using Generative Models. In <i>The Third IEEE International Conference on Data Mining (ICDM'03)</i>, Melbourne, FL, November 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642593</ref_obj_id>
				<ref_obj_pid>1642293</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[X. Zhang and W. K. Cheung. Learning Global Models Based on Distributed Data Abstractions. In <i>Proceedings of International Joint Conference on Artificial Intelligence (IJCAI 2005)</i>, Edinburgh, August 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106461</article_id>
		<sort_key>825</sort_key>
		<display_label></display_label>
		<pages>825-828</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>144</seq_no>
		<title><![CDATA[Bagging with Adaptive Costs]]></title>
		<page_from>825</page_from>
		<page_to>828</page_to>
		<doi_number>10.1109/ICDM.2005.32</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106461</url>
		<abstract>
			<par><![CDATA[Ensemble methods have proved to be highly effective in improving the performance of base learners under most circumstances. In this paper, we propose a new algorithm that combines the merits of some existing techniques, namely bagging, arcing and stacking. The basic structure of the algorithm resembles bagging, using a linear support vector machine (SVM). However, the misclassification cost of each training point is repeatedly adjusted according to its observed out-of-bag vote margin. In this way, the method gains the advantage of arcing &#8212; building the classifier the ensemble needs &#8212; without fixating on potentially noisy points. Computational experiments show that this algorithm performs consistently better than bagging and arcing.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP48025716</person_id>
				<author_profile_id><![CDATA[81309484837]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Iowa]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15040322</person_id>
				<author_profile_id><![CDATA[81100237093]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[Nick]]></middle_name>
				<last_name><![CDATA[Street]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Iowa]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>599607</ref_obj_id>
				<ref_obj_pid>599591</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Bauer and R. Kohavi. An empirical comparison of voting classification algorithms: Bagging, boosting, and variants. <i>Machine Learning</i>, 36(1-2):105-139, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz. UCI repository of machine learning databases, 1998. http://www.ics.uci.edu/~mlearn/MLRepository.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging predictors. <i>Machine Learning</i>, 24(2):123-140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Arcing classifiers. <i>Annals of Statistics</i>, 26:801-849, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>570182</ref_obj_id>
				<ref_obj_pid>570181</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Random forests. <i>Machine Learning</i>, 45(1):5-32, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>743935</ref_obj_id>
				<ref_obj_pid>648054</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. G. Dietterich. Ensemble methods in machine learning. <i>Lecture Notes in Computer Science</i>, 1857:1-15, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. E. Schapire. Experiments with a new boosting algorithm. In <i>International Conference on Machine Learning</i>, pages 148-156, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Krogh and J. Vedelsby. Neural network ensembles, cross validation, and active learning. In G. Tesauro, D. Touretzky, and T. Leen, editors, <i>Advances in Neural Information Processing Systems</i>, volume 7, pages 231-238. The MIT Press, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[V. N. Vapnik. <i>The Nature of Statistical Learning Theory</i>. Springer-Verlag, New York, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148453</ref_obj_id>
				<ref_obj_pid>148448</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. H. Wolpert. Stacked generalization. <i>Neural Networks</i>, 5:241-259, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106462</article_id>
		<sort_key>829</sort_key>
		<display_label></display_label>
		<pages>829-832</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>145</seq_no>
		<title><![CDATA[Example-Based Robust Outlier Detection in High Dimensional Datasets]]></title>
		<page_from>829</page_from>
		<page_to>832</page_to>
		<doi_number>10.1109/ICDM.2005.59</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106462</url>
		<abstract>
			<par><![CDATA[Detecting outliers is an important problem. Most of its applications typically possess high dimensional datasets. In high dimensional space, the data becomes sparse which implies that every object can be regarded as an outlier from the point of view of similarity. Furthermore, a fundamental issue is that the notion of which objects are outliers typically varies between users, problem domains or, even, datasets. In this paper, we present a novel robust solution which detects high dimensional outliers based on user examples and tolerates incorrect inputs. It studies the behavior of projections of such a few examples, to discover further objects that are outstanding in the projection where many examples are outlying. Our experiments on both real and synthetic datasets demonstrate the ability of the proposed method to detect outliers corresponding to the user examples.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003318</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Document representation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15042887</person_id>
				<author_profile_id><![CDATA[81482640748]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tsukuba]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15045410</person_id>
				<author_profile_id><![CDATA[81100037677]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hiroyuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kitagawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tsukuba]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043563</person_id>
				<author_profile_id><![CDATA[81100373169]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Christos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Faloutsos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>375668</ref_obj_id>
				<ref_obj_pid>375663</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Charu C. Aggarwal and Philip S. Yu. Outlier Detection for High Dimensional Data. In Proc. SIGMOD Conf., 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>907087</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[K. A. De Jong. Analysis of the Behavior of a Class of Genetic Adaptive Systems. Ph. D. Dissertation, University of Michigan, Ann Arbor, MI, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>534133</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. E. Goldberg. Genetic Algorithms in Search, Optimization and Machine Learning. Addison Wesley, Reading, MA, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331504</ref_obj_id>
				<ref_obj_pid>331499</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. K. Jain, M. N. Murty, and P. J. Flynn. Data Clustering: a Review. ACM Comp. Surveys, 31(3):264- 323, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671334</ref_obj_id>
				<ref_obj_pid>645924</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E. M. Knorr and R. T. Ng. Algorithms for Mining Distance-Based Outliers in Large Datasets. In Proc. VLDB, pp. 392-403, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656271</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[K. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft. When is Nearest Neighbors Meaningful?. In Proc. of the Int. Conf. Database Theories, pp. 217-235, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[http://www.ics.uci.edu/~mlearn/MLRepository.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335388</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. M. Breunig, H. P. Kriegel, R. T. Ng, and J. Sander. LOF: Identifying Density-Based Local Outliers. In Proc. SIGMOD Conf., pp. 93-104, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Papadimitriou, H. Kitagawa, P. B. Gibbons, and C. Faloutsos. LOCI: Fast Outlier Detection Using the Local Correlation Integral. In Proc. ICDE, pp. 315-326, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Johnson, I. Kwok, and R. T. Ng. Fast Computation of 2-Dimensional Depth Contours. In Proc. KDD, pp. 224-228, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[V. Barnett and T. Lewis. Outliers in Statistical Data. John Wiley and Sons, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[C. Zhu, H. Kitagawa, S. Papadimitriou, and C. Faloutsos. OBE: Outlier by Example. In Proc. PAKDD. pp. 222-234, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106463</article_id>
		<sort_key>833</sort_key>
		<display_label></display_label>
		<pages>833-836</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>146</seq_no>
		<title><![CDATA[CTC &#8212; Correlating Tree Patterns for Classification]]></title>
		<page_from>833</page_from>
		<page_to>836</page_to>
		<doi_number>10.1109/ICDM.2005.49</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106463</url>
		<abstract>
			<par><![CDATA[We present CTC, a new approach to structural classification. It uses the predictive power of tree patterns correlating with the class values, combining state-of-the-art tree mining with sophisticated pruning techniques to find the k most discriminative pattern in a dataset. In contrast to existing methods, CTC uses no heuristics and the only parameters to be chosen by the user are the maximum size of the rule set and a single, statistically well founded cut-off value. The experiments show that CTC classifiers achieve good accuracies while the induced models are smaller than those of existing approaches, facilitating comprehensibility.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Structural</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P762965</person_id>
				<author_profile_id><![CDATA[81309502970]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Albrecht]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zimmermann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Albert-Ludwigs-University Freiburg]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15043992</person_id>
				<author_profile_id><![CDATA[81100467326]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bjorn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bringmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Albert-Ludwigs-University Freiburg]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Bringmann and A. Karwath. Frequent SMILES. In <i>Lernen, Wissensentdeckung und Adaptivit&#228;;t, Workshop GI Fachgruppe Maschinelles Lernen, part of LWA 2004</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. Bringmann and A. Zimmermann. TREE&#60;sup&#62;2&#60;/sup&#62; - Decision trees for tree structured data. to appear in PKDD '05.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W. Geamsakul, T. Matsuda, T. Yoshida, H. Motoda, and T. Washio. Performance evaluation of decision tree graph-based induction. In G. Grieser, Y. Tanaka, and A. Yamamoto, editors, <i>Discovery Science</i>, pages 128-140, Sapporo, Japan, Oct. 2003. Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[P. Kilpel&#228;inen. <i>Tree Matching Problems with Applications to Structured Text Databases</i>. PhD thesis, University of Helsinki, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502533</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Kramer, L. De Raedt, and C. Helma. Molecular feature mining in HIV data. In F. Provost and R. Srikant, editors, <i>Proc. KDD-01</i>, pages 136-143, New York, Aug. 26-29 2001. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657866</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[W. Li, J. Han, and J. Pei. CMAR: Accurate and efficient classification based on multiple class-association rules. In N. Cercone, T. Y. Lin, and X. Wu, editors, <i>Proceedings of the 2001 IEEE International Conference on Data Mining</i>, pages 369-376, San Jos&#233;, California, USA, 2001. IEEE Computer Society.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B. Liu, W. Hsu, and Y. Ma. Integrating classification and association rule mining. In R. Agrawal, P. E. Stolorz, and G. Piatetsky-Shapiro, editors, <i>KDD</i>, pages 80-86, New York City, New York, USA, Aug. 1998. AAAI Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335226</ref_obj_id>
				<ref_obj_pid>335168</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Morishita and J. Sese. Traversing itemset lattices with statistical metric pruning. In <i>PODS</i>, pages 226-236, Dallas, Texas, USA, May 2000. ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Muggleton. Inverse entailment and PROGOL. <i>New Generation Computing</i>, 13(3&4):245-286, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2146886</ref_obj_id>
				<ref_obj_pid>2146834</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. Mutter, M. Hall, and F. Frank. Using classification to evaluate the output of confidence-based association rule mining. In G. I. Webb and X. Yu, editors, <i>Australian Conference on Artificial Intelligence</i>, pages 538-549, Cairns, Australia, Dec. 2004. Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>637817</ref_obj_id>
				<ref_obj_pid>97128</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. R. Quinlan. Learning logical definitions from relations. <i>Machine Learning</i>, 5:239-266, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956787</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki and C. C. Aggarwal. XRules: an effective structural classifier for XML data. In L. Getoor, T. E. Senator, P. Domingos, and C. Faloutsos, editors, <i>KDD</i>, pages 316- 325, Washington, DC, USA, Aug. 2003. ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. Zimmermann and L. De Raedt. Corclass: Correlated association rule mining for classification. In E. Suzuki and S. Arikawa, editors, <i>DS 2004</i>, pages 60-72, Padova, Italy, Oct. 2004. Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>1106471</article_id>
		<sort_key>837</sort_key>
		<display_label></display_label>
		<pages>837-838</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>147</seq_no>
		<title><![CDATA[Invited Talks]]></title>
		<page_from>837</page_from>
		<page_to>838</page_to>
		<doi_number>10.1109/ICDM.2005.83</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106471</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1106472</article_id>
		<sort_key>839</sort_key>
		<display_label></display_label>
		<pages>839</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>148</seq_no>
		<title><![CDATA[Tutorials]]></title>
		<page_from>839</page_from>
		<doi_number>10.1109/ICDM.2005.147</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106472</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1106473</article_id>
		<sort_key>840</sort_key>
		<display_label></display_label>
		<pages>840</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>149</seq_no>
		<title><![CDATA[Workshops]]></title>
		<page_from>840</page_from>
		<doi_number>10.1109/ICDM.2005.155</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106473</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1106474</article_id>
		<sort_key>841</sort_key>
		<display_label></display_label>
		<pages>841</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>150</seq_no>
		<title><![CDATA[Panel Session]]></title>
		<page_from>841</page_from>
		<doi_number>10.1109/ICDM.2005.115</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106474</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1106466</article_id>
		<sort_key>843</sort_key>
		<display_label></display_label>
		<pages>843-846</pages>
		<article_publication_date>11-27-2005</article_publication_date>
		<seq_no>151</seq_no>
		<title><![CDATA[Author Index]]></title>
		<page_from>843</page_from>
		<page_to>846</page_to>
		<doi_number>10.1109/ICDM.2005.29</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1106466</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
</content>
</proceeding>

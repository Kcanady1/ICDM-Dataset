<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>11-19-2003</start_date>
		<end_date>11-22-2003</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url>http://computer.org/proceedings/icdm/2003/1978</conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES11036</series_id>
		<series_title><![CDATA[ICDM]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>951949</proc_id>
	<acronym>ICDM '03</acronym>
	<proc_desc>Proceedings of the Third IEEE International Conference</proc_desc>
	<conference_number>3</conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Data Mining</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-7695-1978-4</isbn>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2003</copyright_year>
	<publication_date>11-19-2003</publication_date>
	<pages></pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB769</publisher_id>
		<publisher_code>IEEEW</publisher_code>
		<publisher_name>IEEE Computer Society</publisher_name>
		<publisher_address>1730 Massachusetts Ave., NW             Washington, DC</publisher_address>
		<publisher_city></publisher_city>
		<publisher_state></publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>20036-1992</publisher_zip_code>
		<publisher_contact></publisher_contact>
		<publisher_phone></publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url></publisher_url>
	</publisher>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>952190</article_id>
		<sort_key>.14</sort_key>
		<display_label></display_label>
		<pages>xiv</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Welcome to ICDM 2003]]></title>
		<page_from>.14</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952190</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>952193</article_id>
		<sort_key>.16</sort_key>
		<display_label></display_label>
		<pages>xvi</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Conference Organization]]></title>
		<page_from>.16</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952193</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>952192</article_id>
		<sort_key>.17</sort_key>
		<display_label></display_label>
		<pages>xvii</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Steering Committee]]></title>
		<page_from>.17</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952192</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>952195</article_id>
		<sort_key>.18</sort_key>
		<display_label></display_label>
		<pages>xviii</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Program Committee]]></title>
		<page_from>.18</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952195</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>952191</article_id>
		<sort_key>.22</sort_key>
		<display_label></display_label>
		<pages>xxii</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[External Reviewers]]></title>
		<page_from>.22</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952191</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>952194</article_id>
		<sort_key>.24</sort_key>
		<display_label></display_label>
		<pages>xxiv</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Corporate Sponsors]]></title>
		<page_from>.24</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952194</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>952135</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<pages>3</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Efficient Multidimensional Quantitative Hypotheses Generation]]></title>
		<page_from>3</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952135</url>
		<abstract>
			<par><![CDATA[Finding local interrelations (hypotheses) among attributeswithin very large databases of high dimensionalityis an acute problem for many databases and data miningapplications. These include, dependency modeling, clusteringlarge databases, correlation and link analysis.Traditional statistical methods are concerned with the corroborationof (a set of) hypotheses on a given body ofdata. Testing all of the hypotheses that can be generatedfrom a database with millions of records and dozens offields is clearly infeasible. Generating, on the other hand,a set of the most "promising" hypotheses (to be corroborated)requires much intuition and ingenuity.In this paper we present an efficient method for rankingthe multidimensional hypotheses using image processingof data visualization. In the heart of the method lies theuse of visualization techniques and image processing ideasto rank subsets of attributes according to the relation betweenthem in the databases. Some of the scalability issuesare solved by concise generalized histograms and by usingan efficient on-line computation of clustering around amedian with only five additional memory words. In additionto presenting our algorithmic methodology, we demonstrateits efficiency and performance by applying it to realcensus data sets, as well as synthetic data sets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Query processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Scientific databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010364</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Scientific visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011711</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Database query processing and optimization (theory)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003192</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Database query processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP309713900</person_id>
				<author_profile_id><![CDATA[81539552656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Amihood]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Amir]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P240932</person_id>
				<author_profile_id><![CDATA[81100651151]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Reuven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kashi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P207616</person_id>
				<author_profile_id><![CDATA[81100457395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Nathan]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Netanyahu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672215</ref_obj_id>
				<ref_obj_pid>645927</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Amir, R. Kashi, and N. S. Netanyahu. Analyzing quantitative databases: Image is everything. In <i>VLDB 2001, Proceedings of the 27th International Conference on Very Large Data Bases</i>, pages 89-98, Rome, Italy, September 11-14 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. M. Haralick. Statistical and structural approaches to texture. <i>Proceedings of the IEEE</i>, 67(5):786-804, May 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312219</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. J. Bayardo Jr. and R. Agrawal. Mining the most interesting rules. In <i>Proc. of the fifth ACM SIGKDD Int'l Conf. on Knowledge Discovery and Data Mining</i>, pages 145-154, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655120</ref_obj_id>
				<ref_obj_pid>645479</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. A. Keim, H-. P. Kriegel, and T. Seidl. Supporting data mining of large databases by visual feedback queries. In <i>Proc. 10th Data Engineering</i>, pages 302-303, Housten, TX, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Misra and D. Gries. Finding repeated elements. <i>Science of Computer Programming</i>, 2(2):143-152, November 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>269157</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[V. Poosala. <i>Histogram-based Estimation Techniques in Databases</i>. PhD thesis, Univ. of Wisconsin, Madison, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233342</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[V. Poosala, Y. Ioannidis, P. Haas, and E. Shekita. Improved histograms for selectivity estimation of range predicates. In <i>Proc. of ACM SIGMOD Conf.</i>, pages 294-305, June 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>40031</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P. J. Rousseeuw and A. M. Leroy. <i>Robust Regression and Outlier Detection</i>. Wiley Series in Probability and Mathematical Statistics. John Wiley and Sons, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952132</article_id>
		<sort_key>11</sort_key>
		<display_label></display_label>
		<pages>11</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[ExAMiner]]></title>
		<subtitle><![CDATA[Optimized Level-wise Frequent Pattern Mining with Monotone Constraints]]></subtitle>
		<page_from>11</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952132</url>
		<abstract>
			<par><![CDATA[The key point of this paper is that, in frequent patternmining, the most appropriate way of exploiting monotoneconstraints in conjunction with frequency is to use them inorder to reduce the problem input together with the searchspace. Following this intuition, we introduce ExAMiner, alevel-wise algorithm which exploits the real synergy of anti-monotoneand monotone constraints: the total benefit isgreater than the sum of the two individual benefits. ExAMinergeneralizes the basic idea of the preprocessing algorithmExAnte, embedding such ideas at all levels ofan Apriori-like computation. The resulting algorithm is thegeneralization of the Apriori algorithm when a conjunctionof monotone constraints is conjoined to the frequency anti-monotoneconstraint. Experimental results confirm that thisis, so far, the most efficient way of attacking the computationalproblem in analysis.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.0</cat_node>
				<descriptor>Numerical algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003714.10003715</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003724</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Numerical differentiation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31036424</person_id>
				<author_profile_id><![CDATA[81100305585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Francesco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bonchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15032764</person_id>
				<author_profile_id><![CDATA[81100458577]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fosca]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Giannotti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645215</person_id>
				<author_profile_id><![CDATA[81100577860]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Alessio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mazzanti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15029916</person_id>
				<author_profile_id><![CDATA[81100352341]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dino]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pedreschi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules in Large Databases. In <i>Proceedings of the Twentieth International Conference on Very Large Databases</i>, pages 487-499, Santiago, Chile, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>662686</ref_obj_id>
				<ref_obj_pid>645612</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Baraglia, D. Laforenza, S. Orlando, P. Palmerini, and R. Perego. Implementation issues in the design of I/O intensive data mining applications on clusters of workstations. In <i>Proc. of the 3rd Workshop on High Performance Data Mining, LNCS 1800</i>, pages 350-357, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[F. Bonchi, F. Giannotti, A. Mazzanti, and D. Pedreschi. Adaptive Constraint Pushing in frequent pattern mining. In <i>Proc. of the 7th Europ. Conf. on Principles and Practice of Knowledge Discovery in Databases (PKDD03)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[F. Bonchi, F. Giannotti, A. Mazzanti, and D. Pedreschi. Ex-Ante: Anticipated data reduction in constrained pattern mining. In <i>Proc. of the 7th Europ. Conf. on Principles and Practice of Knowledge Discovery in Databases (PKDD03)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775054</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Bucila, J. Gehrke, D. Kifer, and W. White. DualMiner: A dual-pruning algorithm for itemsets with constraints. In <i>Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>621300</ref_obj_id>
				<ref_obj_pid>619043</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Han, L. V. S. Lakshmanan, and R. T. Ng. Constraint-based, multidimensional data mining. <i>Computer</i>, 32(8):46- 50, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1293974</ref_obj_id>
				<ref_obj_pid>1293971</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B. Jeudy and J.-F. Boulicaut. Optimization of association rule mining queries. <i>Intelligent Data Analysis Journal</i>, 6(4):341-357, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276307</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. T. Ng, L. V. S. Lakshmanan, J. Han, and A. Pang. Exploratory mining and pruning optimizations of constrained associations rules. In <i>(SIGMOD-98)</i>, pages 13-24.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844714</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Orlando, P. Palmerini, R. Perego, and F. Silvestri. Adaptive and Resource-Aware Mining of Frequent Sets. In <i>(ICDM'02)</i>, pages 338-345, Maebashi City, Japan, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223813</ref_obj_id>
				<ref_obj_pid>223784</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. S. Park, M.-S. Chen, and P. S. Yu. An effective hash based algorithm for mining association rules. In <i>SIGMOD95</i>, pages 175-186, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656372</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and L. V. S. Lakshmanan. Mining frequent item sets with convertible constraints. In <i>(ICDE'01)</i>, pages 433-442, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. Srikant, Q. Vu, and R. Agrawal. Mining association rules with item constraints. In <i>Proc. 3rd Int. Conf. Knowledge Discovery and Data Mining, KDD</i>, pages 67-73, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502572</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Z. Zheng, R. Kohavi, and L. Mason. Real world performance of association rule algorithms. In <i>Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952150</article_id>
		<sort_key>19</sort_key>
		<display_label></display_label>
		<pages>19</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Mining High Utility Itemsets]]></title>
		<page_from>19</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952150</url>
		<abstract>
			<par><![CDATA[Traditional association rule mining algorithms onlygenerate a large number of highly frequent rules, butthese rules do not provide useful answers for what thehigh utility rules are. In this work, we develop a novelidea of top-K objective-directed data mining, which focuseson mining the top-K high utility closed patterns thatdirectly support a given business objective. To associationmining, we add the concept of utility to capture highly desirablestatistical patterns and present a level-wise item-setmining algorithm. With both positive and negativeutilities, the anti-monotone pruning strategy in Apriorialgorithm no longer holds. In response, we develop a newpruning strategy based on utilities that allow pruning oflow utility itemsets to be done by means of a weaker butanti-monotonic condition. Our experimental results showthat our algorithm does not require a user specifiedminimum utility and hence is effective in practice.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14071898</person_id>
				<author_profile_id><![CDATA[81539277056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Raymond]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79028479</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP94029603</person_id>
				<author_profile_id><![CDATA[81450594087]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yi-Dong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. Swami, "Mining association rules between sets of items in large datasets", <i>Proc. of the 1993 ACM SIGMOD Int. Conf on Management of Data</i>, Washington, D.C., USA, May 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant, "Fast algorithm for mining association rules", <i>Proc. of the 20th Int. Conf. on Very Large Databases</i>, Santiago, Chile, Sep. 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847249</ref_obj_id>
				<ref_obj_pid>846218</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Bayardo, R. Agrawal, and D. Gounopolos, "Constraint-based rule mining in large, dense databases", <i>Proc. of the 15'th Int. Conf. on Data Engineering</i>, Sydney, Australia, Mar 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Dougherty, R. Kohavi, and M. Sahami, "Supervised and unsupervised discretization of continuous features", <i>Proc. of the 12th Int. Conf. on Machine Learning</i>, Tahoe City, California, USA, Jul 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin, "Mining frequent patterns without candidate generation", <i>Proc. of the 2000 ACM SIGMOD Int. Conf. on Management of Data</i>, Dallas Texas, USA, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844747</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Wang, Y. Lu, and P. Tzvetkov, "Minillg top-<i>k</i> frequent closed patterns without minimum support", <i>Proc. of the IEEE Int. Conf. on Data Mining</i>, Japan, Dec 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>630575</ref_obj_id>
				<ref_obj_pid>630314</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B. Liu, W. Hsu, S. Chen, and Y. Ma, "Analyzing the subjective interestingness of association rules", <i>IEEE Intelligent Systems</i>, 15(5):47-55, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276307</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Ng, L. Lakshmanan, J. Han, and A. Pang, "Exploratory mining and pruning optimizations of constrained association rules", <i>Proc. ACM SIGMOD Int. Conf. on Management of Data</i>, Seattle, Washington, USA, Jun 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656256</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal, "Discovering frequent closed itemsets for association rules", <i>Proc. of the 7th Int. Conf. on Database Theory</i>, Jerusalem, Israel, Jan 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347166</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Pei and J. Han, "Can we push more constraints into frequent pattern mining?" <i>Proc. of the 6th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining</i>, Boston, MA, USA, Aug 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and R. Mao, "CLOSET: An efficient algorithm for mining frequent closed itemsets", <i>ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery</i>, Dallas, Texas, USA, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>758215</ref_obj_id>
				<ref_obj_pid>645806</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Sese and S. Morishita, "Answering the most corrdated <i>N</i> association rules efficiently", <i>Principles of Data Mining and Knowledge Discovery, 6th European Conference</i>, Helsinki, Finland, Aug 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844705</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Y.D. Shen, Q. Yang, and Z. Zhang, "Objective-oriented utility-based association mining", <i>Proc. of the IEEE Int. Conf on Data Mining</i>, Japan, Dec 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627804</ref_obj_id>
				<ref_obj_pid>627307</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. Silberschatz and A. Tuzhilin, "What makes patterns interesting in knowledge discovery system", <i>IEEE Trans. on Knowledge and Data Engineering</i>, 8(6):970-974, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[R. Srikant, Q. Vu, and R. Agrawal, "Mining association rules with item constraints", <i>Proc. of the 3rd Int. Conf. on Knowledge Discovery and Data Mining</i>, Newport Beach, California, USA, Aug 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347112</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[G. Webb, "Efficient search for association rules", <i>Proc. of the 6th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining</i>, Boston, MA, USA, Aug 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669035</ref_obj_id>
				<ref_obj_pid>645801</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[S. Wrobel, "An algorithm for multi-relational discovery of subgroups", <i>Principles of Data Mining and Knowledge Discovery, 1st European Symposium</i>, Trondheim, Norway, Jun 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Zaki and C.J. Hsiao, "CHARM: An efficient algorithm for closed itemset mining", <i>Second SIAM Int. Conf. on Data Mining</i>, Arlington, Virginia, USA, Apr 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952179</article_id>
		<sort_key>27</sort_key>
		<display_label></display_label>
		<pages>27</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Zigzag]]></title>
		<subtitle><![CDATA[a new algorithm for mining large inclusion dependencies in databases]]></subtitle>
		<page_from>27</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952179</url>
		<abstract>
			<par><![CDATA[In the relational model, inclusion dependencies (INDs)convey many information on data semantics. They generalizeforeign keys, which are very popular constraints inpractice. However, one seldom knows the set of satisfiedINDs in a database. The IND discovery problem in existingdatabases can be formulated as a data-mining problem.We underline in this article that the exploration of IND expressionsfrom most general (smallest) INDs to most specific(largest) INDs does not succeed whenever large INDshave to be discovered. To cope with this problem, we introducea new algorithm, called Zigzag , which combinesthe strength of levelwise algorithms (to find out some smallestINDs) with an optimistic criteria to jump more or lessto largest INDs. Preliminary tests, on synthetic databases,are presented and commented on. It is worth noting that themain result of this paper is general enough to be appliedto other data-mining problems, such as maximal frequentitemsets mining.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P456122</person_id>
				<author_profile_id><![CDATA[81100187373]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fabien]]></first_name>
				<middle_name><![CDATA[De]]></middle_name>
				<last_name><![CDATA[Marchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP17001015</person_id>
				<author_profile_id><![CDATA[81100324952]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jean-Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Petit]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>551350</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. Abiteboul, R. Hull, and V. Vianu. <i>Foundations of Databases</i>. Addison-Wesley, Reading, Mass., 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507537</ref_obj_id>
				<ref_obj_pid>507533</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal. Towards long pattern generation in dense databases. <i>SIGKDD Explorations</i>, 3(1):20-26, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In J. B. Bocca, M. Jarke, and C. Zaniolo, editors, <i>International Conference on Very Large Data Bases (VLDB'94), Santiago de Chile, Chile</i>, pages 487-499. Morgan Kaufmann, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>381017</ref_obj_id>
				<ref_obj_pid>380995</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Y. Bastide, R. Taouil, N. Pasquier, G. Stumme, and L. Lakhal. Mining frequent patterns with counting inference. <i>ACM SIGKDD Exploration</i>, 2(2):66-75, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276313</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. J. Bayardo. Efficiently mining long patterns from databases. In L. M. Haas and A. Tiwary, editors, <i>ACM SIGMOD International Conference on Management of Data, Seattle, USA</i>, pages 85-93. ACM Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649617</ref_obj_id>
				<ref_obj_pid>645324</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Bell and P. Brockhausen. Discovery of constraints and data dependencies in databases (extended abstract). In N. Lavrac and S. Wrobel, editors, <i>European Conference on Machine Learning (ECML'95), Crete, Greece</i>, pages 267- 270, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Berge. Hypergraphs. <i>North Holland Mathematic Library</i>, 45, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>608013</ref_obj_id>
				<ref_obj_pid>608006</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J.-F. Boulicaut, A. Bykowski, and C. Rigotti. Free-sets: A condensed representation of boolean data for the approximation of frequency queries. <i>Data Mining and Knowledge Discovery</i>, 7(1):5-22, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>670313</ref_obj_id>
				<ref_obj_pid>645806</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. Calders and B. Goethals. Mining all non-derivable frequent itemsets. In <i>Principles of Data Mining and Knowledge Discovery</i>, volume 2431 of <i>Lecture Notes in Computer Science</i>. Springer, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Casanova, R. Fagin, and C. Papadimitriou. Inclusion dependencies and their interaction with functional dependencies. <i>Journal of Computer and System Sciences</i>, 24(1):29- 59, Feb. 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671795</ref_obj_id>
				<ref_obj_pid>645915</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. A. Casanova, L. Tucherman, and A. L. Furtado. Enforcing inclusion dependencies and referencial integrity. In F. Bancilhon and D. J. DeWitt, editors, <i>International Conference on Very Large Data Bases (VLDB'88), Los Angeles, California, USA</i>, pages 38-49. Morgan Kaufmann, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671357</ref_obj_id>
				<ref_obj_pid>645925</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Q. Cheng, J. Gryz, F. Koo, T. Y. C. Leung, L. Liu, X. Qian, and B. Schiefer. Implementation of two semantic query optimization techniques in DB2 universal database. In M. P. Atkinson, M. E. Orlowska, P. Valduriez, S. B. Zdonik, and M. L. Brodie, editors, <i>International Conference on Very Large Data Bases (VLDB'99), Edinburgh, Scotland, UK</i>, pages 687-698. Morgan Kaufmann, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650245</ref_obj_id>
				<ref_obj_pid>645340</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[F. De Marchi, S. Lopes, and J.-M. Petit. Efficient algorithms for mining inclusion dependencies. In C. S. Jensen, K. G. Jeffery, J. Pokorny, S. Saltenis, E. Bertino, K. B&#246;hm, and M. Jarke, editors, <i>International Conference on Extending Database Technology (EDBT'02), Prague, Czech Republic</i>, volume 2287 of <i>Lecture Notes in Computer Science</i>, pages 464-476. Springer, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>640997</ref_obj_id>
				<ref_obj_pid>640990</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[F. DeMarchi, S. Lopes, J.-M. Petit, and F. Toumani. Analysis of existing databases at the logical level: the DBA companion project. <i>ACM Sigmod Record</i>, 32(1):47-52, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. Demetrovics and V. Thi. Some remarks on generating armstrong and inferring functional dependencies relation. <i>Acta Cybernetica</i>, 12(2):167-180, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>219403</ref_obj_id>
				<ref_obj_pid>219375</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. Eiter and G. Gottlob. Identifying the minimal transversals of a hypergraph and related problems. <i>SIAM Journal on Computing</i>, 24(6):1278-1304, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658047</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[K. Gouda and M. J. Zaki. Efficiently mining maximal frequent itemsets. In N. Cercone, T. Y. Lin, and X. Wu, editors, <i>International Conference on Data Mining, San Jose, USA</i>. IEEE Computer Society, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>653592</ref_obj_id>
				<ref_obj_pid>645483</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. Gryz. Query folding with inclusion dependencies. In <i>International Conference on Data Engineering (ICDE'98), Orlando, Florida, USA</i>, pages 126-133. IEEE Computer Society, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>263684</ref_obj_id>
				<ref_obj_pid>263661</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. Gunopulos, R. Khardon, H. Mannila, and H. Toivonen. Data mining, hypergraph transversals, and machine learning. In <i>Symposium on Principles of Database Systems (PODS'97), Tucson, Arizona</i>, pages 209-216. ACM Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[M. Kantola, H. Mannila, K. J. R&#228;ih&#228;, and H. Siirtola. Discovering functional and inclusion dependencies in relational databases. <i>International Journal of Intelligent Systems</i>, 7:591-607, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[A. Koeller and E. A. Rundensteiner. Discovery of high-dimentional inclusion dependencies (poster). In <i>International Conference on Data Engineering</i>. IEEE Computer Society, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>553537</ref_obj_id>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. Levene and G. Loizou. <i>A Guided Tour of Relational Databases and Beyond</i>. Springer, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628059</ref_obj_id>
				<ref_obj_pid>627327</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[M. Levene and M. W. Vincent. Justification for inclusion dependency normal form. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 12(2):281-291, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650396</ref_obj_id>
				<ref_obj_pid>645338</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[D.-I. Lin and Z. M. Kedem. Pincer search: A new algorithm for discovering the maximum frequent set. In H.-J. Schek, F. Saltor, I. Ramos, and G. Alonso, editors, <i>Extending Database Technology, Valencia, Spain</i>, volume 1377 of <i>Lecture Notes in Computer Science</i>, pages 105-119. Springer, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>603479</ref_obj_id>
				<ref_obj_pid>603478</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[S. Lopes, J.-M. Petit, and F. Toumani. Discovering interesting inclusion dependencies: Application to logical database tuning. <i>Information System</i>, 17(1):1-19, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655231</ref_obj_id>
				<ref_obj_pid>645471</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and K.-J. R&#228;ih&#228;. Inclusion dependencies in database design. In <i>International Conference on Data Engineering (ICDE'86), Los Angeles, California, USA</i>, pages 713-718. IEEE Computer Society, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593448</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and H. Toivonen. Levelwise Search and Borders of Theories in Knowledge Discovery. <i>Data Mining and Knowledge Discovery</i>, 1(1):241-258, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>373713</ref_obj_id>
				<ref_obj_pid>373626</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[R. J. Miller, M. A. Hern&#225;ndez, L. M. Haas, L. Yan, C. T. H. Ho, R. Fagin, and L. Popa. The clio project: Managing heterogeneity. <i>ACM SIGMOD Record</i>, 30(1):78-83, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>118</ref_obj_id>
				<ref_obj_pid>116</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[J. C. Mitchell. The implication problem for functional and inclusion dependencies. <i>Information and Control</i>, 56(3):154-173, Mar. 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>310660</ref_obj_id>
				<ref_obj_pid>310657</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Efficient mining of association rules using closed itemset lattices. <i>Information Systems</i>, 24(1):25-46, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952152</article_id>
		<sort_key>35</sort_key>
		<display_label></display_label>
		<pages>35</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Frequent Sub-Structure-Based Approaches for Classifying Chemical Compounds]]></title>
		<page_from>35</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952152</url>
		<abstract>
			<par><![CDATA[In this paper we study the problem of classifying chemical compounddatasets. We present a sub-structure-based classificationalgorithm that decouples the sub-structure discovery processfrom the classification model construction and uses frequentsubgraph discovery algorithms to find all topological and geometricsub-structures present in the dataset. The advantage ofour approach is that during classification model construction, allrelevant sub-structures are available allowing the classifier tointelligently select the most discriminating ones. The computationalscalability is ensured by the use of highly efficient frequentsubgraph discovery algorithms coupled with aggressive featureselection. Our experimental evaluation on eight different classificationproblems shows that our approach is computationallyscalable and on the average, outperforms existing schemes by10% to 35%.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Scientific databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010364</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Scientific visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39023382</person_id>
				<author_profile_id><![CDATA[81100017396]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mukund]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Deshpande]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P481304</person_id>
				<author_profile_id><![CDATA[81100101621]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michihiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuramochi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14015889</person_id>
				<author_profile_id><![CDATA[81100008465]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Karypis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>657856</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. An and Y. Wang. Comparisons of classification methods for screening potential compounds. In <i>ICDM</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844706</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Michael R. Berthold Christian Borgelt. Mining molecular fragments: Finding relevant substructures of molecules. In <i>Proc. of the (ICDM)</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>630532</ref_obj_id>
				<ref_obj_pid>630311</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. J. Cook and L. B. Holder. Graph-based data mining. <i>IEEE Intelligent Systems</i>, 15(2):32-41, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Mukund Deshpande and George Karypis. Automated approaches for classifying structure. In <i>Proc. of the 2nd ACM SIGKDD Workshop on Data Mining in Bioinformatics</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>584851</ref_obj_id>
				<ref_obj_pid>584792</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Mukund Deshpande and George Karypis. Using conjunction of attribute values for classification. In <i>Proc. of the eleventh CIKM</i>, pages 356-364. ACM Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Mukund Deshpande, Michihiro Kuramochi, and George Karypis. Frequent sub-structure-based approach for classifying chemical compounds. Technical Report TR# 03-016, Dept. of Computer Science, University of Minnesota, 2003. Available at http://www.cs.umn.edu/~karypis.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[dtp.nci.nih.gov. Dtp aids antiviral screen dataset.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Gasteiger, C. Rudolph, and J. Sadowski. Automatic generation of 3d-atomic coordinates for organic molecules. <i>Tetrahedron Comp. Method</i>, 3:537-547, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Gonzalez, L. Holder, and D. Cook. Application of graph based concept learning to the predictive toxicology domain. In <i>PTC, Workshop at the 5th PKDD</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. Hansch, P. P. Maolney, T. Fujita, and R. M. Muir. Correlation of biological activity of phenoxyacetic acids with hammett substituent constants and partition coefficients. <i>Nature</i>, 194:178-180, 1962.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[C. Hansch, R. M. Muir, T. Fujita, C. F. Maloney, and Streich M. The correlation of biological activity of plant growth-regulators and chloromycetin derivatives with hammett constants and partition coefficients. <i>Journal of American Chemical Society</i>, 85:2817-1824, 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[L. Holder, D. Cook, and S. Djoko. Substructure discovery in the subdue system. In <i>Proc. of the AAAI Workshop on Knowledge Discovery in Databases</i>, pages 169-180, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669817</ref_obj_id>
				<ref_obj_pid>645804</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Akihiro Inokuchi, Takashi Washio, and Hiroshi Motoda. An apriori-based algorithm for mining frequent substructures from graph data. In <i>Proc. of The 4th European Conf. on Principles and Practice of Knowledge Discovery in Databases</i>, pages 13-23, Lyon, France, September 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299104</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. <i>Advances in Kernel Methods: Support Vector Learning</i>, chapter Making large-Scale SVM Learning Practical. MIT-Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[George Karypis. CLUTO a clustering toolkit. Technical Report 02- 017, Dept. of Computer Science, University of Minnesota, 2002. Available at http://www.cs.umn.edu/~cluto.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Ross D. King, Stephen H. Muggleton, Ashwin Srinivasan, and Michael J. E. Sternberg. Strucutre-activity relationships derived by machine learning: The use of atoms and their bond connectivities to predict mutagenecity byd inductive logic programming. <i>PNAS</i>, 93:438-442, January 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502533</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[S. Kramer, L. De Raedt, and C. Helma. Molecular feature mining in hiv data. In <i>7th International Conference on Knowledge Discovery and Data Mining</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658027</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Michihiro Kuramochi and George Karypis. Frequent subgraph discovery. In <i>IEEE International Conference on Data Mining</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Michihiro Kuramochi and George Karypis. Discovering geometric frequent subgraph. In <i>IEEE International Conference on Data Mining</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1018323</ref_obj_id>
				<ref_obj_pid>1018031</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Michihiro Kuramochi and George Karypis. An efficient algorithm for discovering frequent subgraphs. <i>IEEE Transactions on Knowledge and Data Engineering</i>, (in press), 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Andrew R. Leach. <i>Molecular Modeling, Principles and Applications</i>. Prentice Hall, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Andrew R. Leach. <i>Molecular Modeling: Principles and Applications</i>. Prentice Hall, Englewood Cliffs, NJ, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657866</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Wenmin Li, Jiawei Han, and Jian Pei. Cmar: Accurate and efficient classification based on multiple class-association rules. In <i>IEEE International Conference on Data Mining</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Bing Liu, Wynne Hsu, and Yiming Ma. Integrating classification and association rule mining. In <i>4th Internation Conference on Knowledge Discovery and Data Mining</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>541177</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Tom M. Mitchell. <i>Machine Learning</i>. Mc Graw Hill, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657612</ref_obj_id>
				<ref_obj_pid>645528</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[K. Morik, P. Brockhausen, and T. Joachims. Combining statistical learning with a knowledge-based approach - a case study in intensive care monitoring. In <i>International Conference on Machine Learning</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>373425</ref_obj_id>
				<ref_obj_pid>373423</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[F. Provost and T. Fawcett. Robust classification for imprecise environments. <i>Machine Learning</i>, 42(3), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[J. Ross Quinlan. <i>C4.5: Programs for machine learning</i>. Morgan Kaufmann, San Mateo, CA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Graham W. Richards. Virtual screening using grid computing: the screensaver project. <i>Nature Reviews: Drug Discovery</i>, 1:551-554, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1624163</ref_obj_id>
				<ref_obj_pid>1624162</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[A. Srinivasan, R. D. King, S. H. Muggleton, and M. Sternberg. The predictive toxicology evaluation challenge. In <i>Proc. of the Fifteenth International Joint Conference on Artificial Intelligence (IJCAI-97)</i>, pages 1-6. Morgan-Kaufmann, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593476</ref_obj_id>
				<ref_obj_pid>593422</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Ashwin Sriniviasan and Ross King. Feature construction with inductive logic programming: a study of quantitative predictions of biological activity aided by structural attributes. <i>Knowledge Discovery and Data Mining Journal</i>, 3:37-57, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik. <i>Statistical Learning Theory</i>. John Wiley, New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844811</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Xifeng Yan and Jiawei Han. gSpan: Graph-based substructure pattern mining. In <i>ICDM</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952184</article_id>
		<sort_key>43</sort_key>
		<display_label></display_label>
		<pages>43</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Optimized Disjunctive Association Rules via Sampling]]></title>
		<page_from>43</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952184</url>
		<abstract>
			<par><![CDATA[The problem of finding optimized support associationrules for a single numerical attribute, where the optimizedregion is a union of k disjoint intervals from the range ofthe attribute, is investigated. The first polynomial timealgorithm for the problem of finding such a region maximizingsupport and meeting a minimum cumulative confidencethreshold is given. Because the algorithm is notpractical, an ostensibly easier, more constrained versionof the problem is considered. Experiments demonstratethat the best extant algorithm for the constrained versionhas significant performance degradation on both a syntheticmodel of patterned data and on real world data sets.Running the algorithm on a small random sample is proposedas a means of obtaining near optimal results withhigh probability. Theoretical bounds on sufficient samplesize to achieve a given performance level are proved, andrapid convergence on synthetic and real-world data is validatedexperimentally.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Experimentation</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645358</person_id>
				<author_profile_id><![CDATA[81100477247]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Elble]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43119895</person_id>
				<author_profile_id><![CDATA[81100374601]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Heeren]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43120590</person_id>
				<author_profile_id><![CDATA[81332521334]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pitt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In P. Bunemanand S. Jajodia, editors, <i>Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data</i>, pages 207-216, Washington, D.C., 26- 28 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>76371</ref_obj_id>
				<ref_obj_pid>76359</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. Learnability and the Vapnik-Chervonenkis dimension. <i>Journal of the ACM (JACM)</i>, 36(4):929-965, October 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233313</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Fukuda, Y. Morimoto, S. Morishita, and T. Tokuyama. Data mining using two-dimensional optimized association rules: scheme, algorithms, and visualization. In <i>Proceedings of the 1996 ACM SIGMOD international conference on Management of data</i>, pages 13-23. ACM Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237708</ref_obj_id>
				<ref_obj_pid>237661</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Fukuda, Y. Morimoto, S. Morishita, and T. Tokuyama. Mining optimized association rules for numeric attributes. In <i>Proceedings of the fifteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems</i>, pages 182-191. ACM Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360421</ref_obj_id>
				<ref_obj_pid>360402</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Hipp, U. Gntzer, and G. Nakhaeizadeh. Algorithms for association rule mining - a general survey and comparison. <i>SIGKDD Explorations</i>, 2(1):58-64, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564928</ref_obj_id>
				<ref_obj_pid>564927</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Rastogi and K. Shim. Mining optimized support rules for numeric attributes. <i>Information Systems</i>, 26(6):425- 444, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628189</ref_obj_id>
				<ref_obj_pid>627338</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. Rastogi and K. Shim. Mining optimized association rules with categorical and numeric attributes. <i>Knowledge and Data Engineering</i>, 14(1):29-50, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673325</ref_obj_id>
				<ref_obj_pid>645922</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Toivonen. Sampling large databases for association rules. In T. M. Vijayaraman, A. P. Buchmann, C. Mohan, and N. L. Sarda, editors, <i>In Proc. 1996 Int. Conf. Very Large Data Bases</i>, pages 134-145. Morgan Kaufman, 09 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>3165</ref_obj_id>
				<ref_obj_pid>3147</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. S. Vitter. Random sampling with a reservoir. <i>ACM Transactions on Mathematical Software</i>, 11(1):37-57, Mar. 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593468</ref_obj_id>
				<ref_obj_pid>593420</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Wijsen and R. Meersman. On the complexity of mining quantitative association rules. <i>Data Mining and Knowledge Discovery</i>, 2(3):263-281, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>827928</ref_obj_id>
				<ref_obj_pid>522455</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki, S. Parthasarathy, W. Li, and M. Ogihara. Evaluation of sampling for data mining of association rules. In <i>7th International Workshop on Research Issues in Data Engineering (RIDE'97)</i>, Birmingham, UK, Apr. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669525</ref_obj_id>
				<ref_obj_pid>645803</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. Zelenko. Optimizing disjunctive association rules. In <i>Proe. of PKDD '99, Lecture Notes in Computer Science (LNAI 1704)</i>, pages 204-213. Springer-Verlag, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952144</article_id>
		<sort_key>51</sort_key>
		<display_label></display_label>
		<pages>51</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Is random model better? On its accuracy and efficiency]]></title>
		<page_from>51</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952144</url>
		<abstract>
			<par><![CDATA[Inductive learning searches an optimal hypothesis thatminimizes a given loss function. It is usually assumed thatthe simplest hypothesis that fits the data is the best approximateto an optimal hypothesis. Since finding the simplesthypothesis is NP-hard for most representations, we generallyemploy various heuristics to search its closest match.Computing these heuristics incurs significant cost, makinglearning inefficient and unscalable for large dataset. In thesame time, it is still questionable if the simplest hypothesisis indeed the closest approximate to the optimal model.Recent success of combining multiple models, such as bagging,boosting and meta-learning, has greatly improved theaccuracy of the simplest hypothesis, providing a strong argumentagainst the optimality of the simplest hypothesis.However, computing these combined hypotheses incurs significantlyhigher cost. In this paper, we first advert that aslong as the error of a hypothesis on each example is withina range dictated by a given loss function, it can still be optimal.Contrary to common beliefs, we propose a completelyrandom decision tree algorithm that achieves much higheraccuracy than the single best hypothesis and is comparableto boosted or bagged multiple best hypotheses. The advantageof multiple random tree is its training efficiency aswell as minimal memory requirement.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Induction</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.0</cat_node>
				<descriptor>Error analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Heuristic methods</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010206</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Heuristic function construction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010067</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Error-correcting codes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010297.10010298</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Logical and relational learning->Inductive logic learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40027830</person_id>
				<author_profile_id><![CDATA[81367591181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP54029587</person_id>
				<author_profile_id><![CDATA[81455605782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haixun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P263310</person_id>
				<author_profile_id><![CDATA[81100447843]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Sheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>263042</ref_obj_id>
				<ref_obj_pid>263023</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Y. Amit and D. Geman. Shape quantization and recognition with randomized trees. <i>Neural Computation</i>, 9(7):1545- 1588, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649703</ref_obj_id>
				<ref_obj_pid>645326</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. P. Bradford, C. Kunz, R. Kohavi, C. Brunk, and C. E. Brodley. Pruning decision trees with misclassification costs. In <i>European Conference on Machine Learning</i>, pages 131-136, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging predictors. <i>Machine Learning</i>, 24(2):123-140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[W. Buntine. Learning classification trees. In D. J. Hand, editor, <i>Artificial Intelligence frontiers in statistics</i>, pages 182- 201. Chapman & Hall, London, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>924077</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Chan. <i>An Extensible Meta-learning Approach for Scalable and Accurate Inductive Learning</i>. PhD thesis, Columbia University, Oct 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. Domingos. Occam's two razors: The sharp and the blunt. In <i>Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining</i>. AAAI Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261549</ref_obj_id>
				<ref_obj_pid>261540</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. <i>Computer and System Sciences</i>, 55(1):119-139, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304197</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Gehrke, V. Ganti, R. Ramakrishnan, and W.-Y. Loh. BOAT-optimistic decision tree construction. In <i>Proceedings of ACM SIGMOD International Conference on Management of Data (SIGMOD 1999)</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237994</ref_obj_id>
				<ref_obj_pid>237814</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Kearns and Y. Mansour. On the boosting ability of top-down decision tree learning algorithms. In <i>Proceedings of the Annual ACM Symposium on the Theory of Computing</i>, pages 459-468, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650384</ref_obj_id>
				<ref_obj_pid>645337</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Mehta, R. Agrawal, and J. Rissanen. SLIQ: A fast scalable classifier for data mining. In <i>Extending Database Technology</i>, pages 18-32, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Mehta, J. Rissanen, and R. Agrawal. MDL-based decision tree pruning. In <i>Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD'95)</i>, pages 216-221, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. Quinlan. <i>C4.5: Programs for Machine Learning</i>. Morgan Kaufmann, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673491</ref_obj_id>
				<ref_obj_pid>645922</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Shafer, R. Agrawl, and M. Mehta. SPRINT: A scalable parallel classifier for data mining. In <i>Proceedings of Twenty-second International Conference on Very Large Databases (VLDB-96)</i>, pages 544-555, San Francisco, California, 1996. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>302626</ref_obj_id>
				<ref_obj_pid>302528</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Shawe-Taylor and N. Cristianini. Data-dependent structural risk minimisation for perceptron decision trees. In M. Jordan, M. Kearns, and S. Solla, editors, <i>Advances in Neural Information Processing Systems 10</i>, pages 336-342. MIT Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502540</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[B. Zadrozny and C. Elkan. Learning and making decisions when costs and probabilities are both unknown. In <i>Proceedings of the Seventh ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD01)</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952163</article_id>
		<sort_key>59</sort_key>
		<display_label></display_label>
		<pages>59</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Identifying Markov Blankets with Decision Tree Induction]]></title>
		<page_from>59</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952163</url>
		<abstract>
			<par><![CDATA[The Markov Blanket of a target variable is theminimum conditioning set of variables that makes thetarget independent of all other variables. MarkovBlankets inform feature selection, aid in causal discoveryand serve as a basis for scalable methods of constructingBayesian networks. This paper applies decision treeinduction to the task of Markov Blanket identification.Notably, we compare (a) C5.0, a widely used algorithmfor decision rule induction, (b) C5C, which post-processesC5.0's rule set to retain the most frequentlyreferenced variables and (c) PC, a standard method forBayesian Network induction. C5C performs as well as orbetter than C5.0 and PC across a number of data sets.Our modest variation of an inexpensive, accurate, off-the-shelfinduction engine mitigates the need for specializedprocedures, and establishes baseline performance againstwhich specialized algorithms can be compared.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Induction</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Markov processes</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003651</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Markov networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003700.10003701</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Stochastic processes->Markov processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010297.10010298</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Logical and relational learning->Inductive logic learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645419</person_id>
				<author_profile_id><![CDATA[81339499803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lewis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Frey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39048210</person_id>
				<author_profile_id><![CDATA[81100550958]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Douglas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fisher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P116664</person_id>
				<author_profile_id><![CDATA[81100095159]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ioannis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsamardinos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645271</person_id>
				<author_profile_id><![CDATA[81100472111]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Constantin]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Aliferis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645218</person_id>
				<author_profile_id><![CDATA[81100244833]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Statnikov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abramson, B., Brown, J., Edwards, W., Murphy, A. and Winkler, R.L, Hailfinder: A Bayesian system for forecasting severe weather, <i>International Journal of Forecasting</i>, (1996), 12, 57-71.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Aluallim, H., and Dietterich, T. G., Learning with many irrelevant features, <i>Proceedings, Ninth National Conference on Artificial Intelligence</i>, Anaheim, CA. AAAI Press/The MIT Press, (1991), pp. 547-552.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Arnone, M.I. and Davidson, E.H., The hardwiring of development: organization and function of genomic regulatory systems, <i>Development</i>, (1997), 12(4), pp. 1851-1864.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1623928</ref_obj_id>
				<ref_obj_pid>1623891</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Andersen, S.K., Olesen, K.G., Jensen, F. V. and Jensen, F., HUGIN - a shell for building bayesian belief universes for expert systems, in <i>Proceedings of the Eleventh International Joint Conference on Artificial Intelligence</i>, (1989), pp. 1080- 1085.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Beinlich, I., Suermondt, G., Chavez R. and Cooper G., The ALARM monitoring system: A case study with two probabilistic inference techniques for belief networks, <i>Proceedings of 2'nd European Conference on AI and Medicine</i>, Springer-Verlag, Berlin, (1989).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274164</ref_obj_id>
				<ref_obj_pid>274158</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Binder, J., Koller, D., Russell, S. and Kanazawa, K., Adaptive Probabilistic Networks with Hidden Variables, <i>Machine Learning</i>, (1997), 29, 213-244.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cardie, C., Using decision trees to improve case-based learning, in <i>Proceedings of the Tenth International Conference on Machine Learning</i>, (1993), pp. 25-32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Caruana, R. and D. Freitag, Greedy Attribute Selection, <i>in International Conference on Machine Learning</i>, (1994).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>570382</ref_obj_id>
				<ref_obj_pid>570380</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cheng, J., Greiner, R., Kelly, J., Bell D. and Liu, W., Learning Bayesian networks from data: an information-theory based approach, <i>Artificial Intelligence</i>, (2002), 137, pp. 43-90.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Glymour, C. & Cooper, G.F., <i>Computation, Causation and Discovery</i>, AAAI/The MIT Press, (1999).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>270627</ref_obj_id>
				<ref_obj_pid>270613</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kohavi, R. and G.H. John, Wrappers for Feature Subset Selection, <i>Artificial Intelligence</i>, (1997), 97(1-2), pp. 273-324.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kristensen, K. and Rasmussen, I.A., The use of a Bayesian network in the design of a decision support system for growing malting barley without use of pesticides, <i>Computers and Electronics in Agriculture</i>, (2002), 33, pp. 197-217.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Koller, D and M. Sahami, Toward Optimal Feature Selection, in <i>Thirteenth International Conference in Machine Learning</i>, (1996), pp. 284-292.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Li, L., Pedersen, L.G., Darden, T.A. and Weinberg, C.R., Computational Analysis of Leukemia Micorarray Expression Data Using the GA/KNN Method, CAMDA'01, (2001).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Margaritis, D. and Thrun, S., Bayesian Network Induction via Local Neighborhoods, Technical Report: CMU-CS-99-134, (1999).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>77340</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Neapolitan, R.E., <i>Probabilistic Reasoning in Expert Systems: Theory and Algorithms</i>, John Wiley and Sons (1990).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>52121</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Pearl, J., <i>Probabilistic Reasoning in Intelligent Systems</i>, San Mateo, CA: Morgan Kaufman, (1988).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Spirtes, P., C. Glymour, and R. Scheines, <i>Causation, Prediction and Search</i>, Cambridge, MA: MIT Press, (2000).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>637969</ref_obj_id>
				<ref_obj_pid>637962</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Quinlan, J.R., Induction of decision trees, <i>Machine Learning</i>, (1987), 1 pp. 81-106.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Tsamardinos, I. and Aliferis, C.F., Towards Principled Feature Selection: Relevancy, Filters and Wrappers, in <i>Proceedings of the Ninth International Workshop on Artificial Intelligence and Statistics</i>, (2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Tsamardinos, I., Aliferis, C.F. and Statnikov, A., Algorithms for Large Scale Markov Blanket Discovery to appear, in <i>Proceedings of the 16th International FLAIRS Conference</i>, (2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956838</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Tsamardinos, I., Aliferis, C. F., and Statnikov A., Time and Sample Efficient Discovery of Markov Blankets and Direct Causal Relations, in <i>The Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, (2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952158</article_id>
		<sort_key>67</sort_key>
		<display_label></display_label>
		<pages>67</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Reliable Detection of Episodes in Event Sequences]]></title>
		<page_from>67</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952158</url>
		<abstract>
			<par><![CDATA[Suppose one wants to detect "bad" or "suspicious" subsequencesin event sequences.Whether an observed patternof activity (in the form of a particular subsequence) is significantand should be a cause for alarm, depends on howlikely it is to occur fortuitously.A long enough sequenceof observed events will almost certainly contain any subsequence,and setting thresholds for alarm is an important issuein a monitoring system that seeks to avoid false alarms.Suppose a long sequence T of observed events contains asuspicious subsequence pattern S within it, where the suspicioussubsequence S consists of m events and spans a windowof size w within T.We address the fundamental problem:is a certain number of occurrences of a particular subsequenceunlikely to be fortuitous (i.e., indicative of suspiciousactivity)?If the probability of fortuitous occurrencesis high and an automated monitoring system flags it as suspiciousanyway, then such a system will suffer from generatingtoo many false alarms.This paper quantifies the probabilityof such an S occuring in T within a window of sizew, the number of distinct windows containing S as a subsequence,the expected number of such occurrences, its variance,and establishes its limiting distribution that allows toset up an alarm threshold so that the probability of falsealarms is very small.We report on experiments confirmingthe theory and showing that we can detect bad subsequenceswith low false alarm rate.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Sequencing and scheduling</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010261.10010272</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Reinforcement learning->Sequential decision making</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010047.10010048.10003808</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Online algorithms->Online learning algorithms->Scheduling algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003636.10003808</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Approximation algorithms analysis->Scheduling algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP45024052</person_id>
				<author_profile_id><![CDATA[81343493912]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gwadera]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14127532</person_id>
				<author_profile_id><![CDATA[81100355888]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mikhail]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Atallah]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39029192</person_id>
				<author_profile_id><![CDATA[81100136191]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wojciech]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Szpankowski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Aho and M. Corasick, Efficient String Matching: An Aid to Bibliographic Search <i>Programming Techniques</i>, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>570558</ref_obj_id>
				<ref_obj_pid>570554</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Apostolico and M. Atallah, Compact Recognizers of Episode Sequences, <i>Information and Computation</i>, 174, 180-192, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Billingsley, <i>Probability and measure</i>, John Wiley, New York, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304008</ref_obj_id>
				<ref_obj_pid>303976</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Boasson, P. Cegielski, I. Guessarian, and Y. Matiyasevich, Window-Accumulated Subsequence Matching Problem is Linear, <i>Proc. PODS</i>, 327-336, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199269</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Crochemore and W. Rytter, <i>Text Algorithms</i>, Oxford University Press, New York, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>738462</ref_obj_id>
				<ref_obj_pid>647816</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G. Das, R. Fleischer, L. Gasieniec, D. Gunopulos, and J. K&#228;rkk&#228;inen, Episode Matching, In <i>Combinatorial Pattern Matching, 8th Annual Symposium, Lecture Notes in Computer Science</i> vol. 1264, 12-27, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>684117</ref_obj_id>
				<ref_obj_pid>646254</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. Flajolet, Y. Guivarc'h, W. Szpankowski, and B. Vall&#233;e, Hidden Pattern Statistics, ICALP 2001, Crete, Greece, LNCS 2076, 152-165, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Gwadera, M. Atallah and W. Szpankowski, Reliable Detection of Episodes in Event Sequences, http://www.cs.purdue.edu/homes/spa/ papers/gwadera.ps]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>254673</ref_obj_id>
				<ref_obj_pid>254663</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[G. Kucherov, M. Rusinowitch Matching a Set of Strings with Variable Length Don't Cares, <i>Theoretical Computer Science</i> 178, 129-154, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. Kumar and E.H. Spafford, A Pattern-Matching Model for Intrusion Detection, <i>Proceedings of the National Computer Security Conference</i>, 11-21, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593449</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[H. Mannila, H. Toivonen, and A. Verkamo Discovery of frequent episodes in event sequences <i>Data Mining and Knowledge Discovery</i>, 1(3), 241-258, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>740299</ref_obj_id>
				<ref_obj_pid>647909</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[P. Nicod&#232;me, B. Salvy, and P. Flajolet, Motif Statistics, <i>European Symposium on Algorithms, Lecture Notes in Computer Science</i>, No. 1643, 194-211, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[P. Pevzner, <i>Computational Molecular Biology: An Algorithmic Approach</i>, MIT Press, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[M. R&#233;gnier and W. Szpankowski, On pattern frequency occurrences in a Markovian sequence <i>Algorithmica</i>, 22, 631- 649, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[I. Rigoutsos, A. Floratos, L. Parida, Y. Gao and D. Platt, The Emergence of Pattern Discovery Techniques in Computational Biology, <i>Metabolic Engineering</i>, 2, 159-177, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>227351</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[R. Sedgewick and P. Flajolet, <i>An Introduction to the Analysis of Algorithms</i>, Addison-Wesley, Reading, MA, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>517168</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[W. Szpankowski, <i>Average Case Analysis of Algorithms on Sequence</i>, John Wiley, New York, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Waterman, <i>Introduction to Computational Biology</i>, Chapman and Hall, London, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1297830</ref_obj_id>
				<ref_obj_pid>1297828</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[A. Wespi, H. Debar, M. Dacier, and M. Nassehi, Fixed vs. Variable-Length Patterns For Detecting Suspicious Process Behavior, <i>J. Computer Security</i>, 8, 159-181, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>135244</ref_obj_id>
				<ref_obj_pid>135239</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. Wu and U. Manber, Fast Text Searching Allowing Errors, <i>Comm. ACM</i>, 35:10, 83-991, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952187</article_id>
		<sort_key>75</sort_key>
		<display_label></display_label>
		<pages>75</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[A Dynamic Adaptive Self-Organising Hybrid Model for Text Clustering]]></title>
		<page_from>75</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952187</url>
		<abstract>
			<par><![CDATA[Clustering by document concepts is a powerful way ofretrieving information from a large number of documents.This task in general does not make any assumption on thedata distribution. In this paper, for this task we propose anew competitive Self-Organising (SOM) model, namelythe Dynamic Adaptive Self-Organising Hybrid model(DASH). The features of DASH are a dynamic structure,hierarchical clustering, non-stationary data learning andparameter self-adjustment. All features are data-oriented:DASH adjusts its behaviour not only by modifying itsparameters but also by an adaptive structure. Thehierarchical growing architecture is a useful facility forsuch a competitive neural model which is designed fortext clustering. In this paper, we have presented a newtype of self-organising dynamic growing neural networkwhich can deal with the non-uniform data distributionand the non-stationary data sets and represent the innerdata structure by a hierarchical view.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Textual databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39027826</person_id>
				<author_profile_id><![CDATA[81547540156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chihli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15037035</person_id>
				<author_profile_id><![CDATA[81100591344]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wermter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Honkela, S. Kaski, K. Lagus, and T. Kohonen, "News group exploration with WEBSOM method and browsing interface", <i>Report A32</i>, Helsinki University of Technology, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>69371</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[T. Kohonen, <i>Self-organization and associative memory</i> Springer-Verlag, Berlin, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Grossberg, "Adaptive pattern classification and universal recoding: I. Parallel development and coding of neural feature detectors", <i>Biological Cybernetics</i>, vol. 23, 1976, pp. 121-131.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Martinetz and K. Schulten, "A 'Neural-Gas' network learns topologies", <i>Artificial Neural Network</i>, vol. I, 1991, pp. 397-402.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[B. Fritzke, "Growing grid-a self-organizing network with constant neighborhood range and adaptation strength", <i>Neural Processing Letters</i>, vol. 2 no. 5, 1995, pp. 9-13.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326577</ref_obj_id>
				<ref_obj_pid>2325773</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Alahakoon, S.K. Halgamuge and B. Srinivasan, "Dynamic self-organizing maps with controlled growth for knowledge discovery", <i>IEEE Tractions on Neural Networks</i>, vol. 11, no. 3, 2000, pp. 601-614.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[V. Hodge and J. Austin, "Hierarchical growing cell structures: TreeGCS", <i>Proceedings of the Fourth International Conference on Knowledge-Based Intelligent Engineering Systems</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Chen, C. Schuffels and R. Orwig, "Internet categorization and search: a self-organizing approach", <i>Journal of Visual Communication and Image Representation</i>, vol. 7, no. 1, March, 1996, pp. 88-102.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326962</ref_obj_id>
				<ref_obj_pid>2325788</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Rauber, D. Merkl and M. Dittenbach, "The growing hierarchical self-organizing maps: exploratory analysis of high-dimensional data", <i>IEEE Transactions on Neural Networks</i>, vol. 13, no. 6, 2002, pp. 1331-1341.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>195912</ref_obj_id>
				<ref_obj_pid>195882</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[B. Fritzke, "Growing cell structures - a self-organizing network for unsupervised and supervised learning", <i>Neural Networks</i>, vol. 7, no. 9, 1994, pp. 1441-1460.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[B. Fritzke, "A growing neural gas network learns topologies", <i>Advances in Neural Information Precessing Systems 7</i>, G. Tesauro, D.S. Touretzky, and T.K. Leen, eds., MIT Press, Cambridge MA, 1995, pp. 625-632.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Blackmore and R. Miikkulainen, "Incremental grid growing: encoding high-dimensional structure into a two-dimensional feature map", <i>Proceedings of the IEEE International Conference on Neural Networks</i> (ICNN' 93), San Francisco, CA, USA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>685895</ref_obj_id>
				<ref_obj_pid>646257</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[B. Fritzke, "A self-organizing network that can follow non-stationary distributions", <i>Proceedings of ICANN '97, International Conference on Artificial Neural Ndworks</i>, Springer, 1997, pp. 613-618.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Lang and K. Warwick, "The plastic selforganising map", <i>IEEE World Congress on Computational Intelligence</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>776107</ref_obj_id>
				<ref_obj_pid>776097</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. Marsland, J. Shapiro and U. Nehmzow, "A selforganising network that grows when required", <i>Neural Networks</i>, vol. 15, 2002, pp. 1041-1058.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>558021</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. Kohonen, <i>Self-organizing maps</i>, Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326575</ref_obj_id>
				<ref_obj_pid>2325773</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[T. Kohonen, S. Kaski, K. Lagus, J. Saloj&#228;rvi, J. Honkela, V. Paatero and A. Saarela, "Self organization of a massive document collection", <i>IEEE Transactions on Neural Networks</i>, vol. 11, no. 3, 2000, pp. 574-585.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1072315</ref_obj_id>
				<ref_obj_pid>1072228</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[S. Wermter and C. Hung, "Selforganising Classification on the Reuters News Corpus", <i>The 19th International Conference on Computational Linguistics (COLING2002)</i>, Taipei, Taiwan, 2002, pp.1086-1092.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[T.G. Rose, M. Stevenson and M. Whitehead, "The Reuters Corpus Volume 1 - from Yesterday's News to Tomorrow's Language Resources", <i>Proceedings of the Third International Conference on Language Resources and Evaluation</i>, Las Palmas de Gran Canaria, 2002, pp. 29-31.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>77013</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[G. Salton, <i>Automatic Text Processing: the Transformation, Analysis, and Retrieval of Information by Computer</i>, Addison-Wesley, USA, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[G.A. Miller, "WordNet: a dictionary browser", <i>Proceedings of the First International Conference on Information in Data</i>, University of Waterloo, Waterloo, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846187</ref_obj_id>
				<ref_obj_pid>846183</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[S. Chakrabarti, "Data mining for hypertext: a tutorial survey", <i>ACM SIGKDD Explorations</i>, vol. 1, no. 2, 2000, pp. 1-11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>54260</ref_obj_id>
				<ref_obj_pid>54259</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[G. Salton, and C. Buckley, "Term-weighting approaches in automatic text retrieval", <i>Information Processing & Management</i>, vol. 24, no. 5, 1988, pp. 513-523.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952149</article_id>
		<sort_key>83</sort_key>
		<display_label></display_label>
		<pages>83</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Mining Significant Pairs of Patterns from Graph Structures with Class Labels]]></title>
		<page_from>83</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952149</url>
		<abstract>
			<par><![CDATA[In recent years, the problem of mining association rulesover frequent itemsets in transactional data has been frequentlystudied and yielded several algorithms that can findassociation rules within a limited amount of time. Alsomore complex patterns have been considered such as orderedtrees, unordered trees, or labeled graphs. Althoughsome approaches can efficiently derive all frequent subgraphsfrom a massive dataset of graphs, a subgraph orsubtree that is mathematically defined is not necessarily abetter knowledge representation. In this paper, we proposean efficient approach to discover significant rules to classifypositive and negative graph examples by estimating atight upper bound on the statistical metric. This approachabandons unimportant rules earlier in the computations,and thereby accelerates the overall performance. The performancehas been evaluated using real world datasets, andthe efficiency and effect of our approach has been confirmedwith respect to the amount of data and the computation time.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.1</cat_node>
				<descriptor>Schema and subschema</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10010820</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Data model extensions</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P417876</person_id>
				<author_profile_id><![CDATA[81100361535]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Akihiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Inokuchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P463032</person_id>
				<author_profile_id><![CDATA[81100105757]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hisashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kashima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Asai, T., Abe, K., Kawasoe, S., Arimura, H., Sakamoto, H, & Arikawa, S. Efficient Substructure Discovery from Large Semi-structured Data, <i>Proc. of the 2nd SIAM International Conference on Data Mining</i> (SDM-2002), pp. 158-174, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642208</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[De Raedt, L., & Kramer, S. The Levelwise Version Space Algorithm and its Application to Molecular Fragment Finding. <i>Proc. of the 17th International Joint Conference on Artificial Intelligence</i> (IJCAI- 2001), pp. 853-859, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656000</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gonzalez, J., Holder, L., & Cook, D. Graph-Based Relational Concept Learning. <i>Proc. of the 19th International Conference on Machine Learning</i> (ICML-2002), pp. 219-226, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[AIDS Antiviral Screen, http://dtp.nci.nih.gov/docs/aids/aids_data.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Horst, R. and Tuy, H. <i>Global Optimization Deterministic Approaches</i>. Springer, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669817</ref_obj_id>
				<ref_obj_pid>645804</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Inokuchi, A., Washio, T., & Motoda, H. An A priori-based Algorithm for Mining Frequent Substructures from Graph Data. <i>Proc. of the 4th European Conference on Principles and Practice of Knowledge Discovery in Databases</i> (PKDD-2000), pp. 13-23, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Inokuchi, A., Washio, T., Nishimura, Y., & Motoda, H. A Fast Algorithm for Mining Frequent Connected Subgraphs. <i>IBM Research Report</i>, RT0448 February, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>608123</ref_obj_id>
				<ref_obj_pid>608108</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Inokuchi, A., Washio, T. & Motoda, H. Complete Mining of Frequent Patterns from Graphs: Mining Graph Data, <i>Machine Learning</i>, 50 (3): 321-354, March, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502533</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Kramer, S., De Raedt, L., & Helma, C. Molecular Feature Mining in HIV Data. <i>Proc. of the 17th International Conference on Knowledge Discovery and Data Mining</i> (KDD-2001), pp. 136-143, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658027</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kuramochi, M., & Karypis, G. Frequent Subgraph Discovery. <i>Proc. of the 1st International Conference on Data Mining</i> (ICDM-2001), pp. 313-320, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312216</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Liu, B., Hsu, W. & Ma, Y. Pruning and Summarizing the Discovered Associations <i>Proc. of the 5th International Conference on Knowledge Discovery and Data Mining</i> (KDD-99), pp. 125-134, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335226</ref_obj_id>
				<ref_obj_pid>335168</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Motishita, S. and Sese, J. Traversing Lattice Itemset with Statistical Metric Pruning. <i>Proc. of Symposium on Principles of Database Systems</i> (PODS- 2000), pp. 226-236, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[PTE, http://oldwww.comlab.ox.ac.uk/oucl/ groups/machlearn/PTE]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>758215</ref_obj_id>
				<ref_obj_pid>645806</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Sese, J. and Morishita, S. Answering the Most Correlated N Association Rules Efficiently. <i>Proc. of 6th European Conference on Principles and Practice of Knowledge Discovery in Databases</i> (PKDD-02), pp. 410-422, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Suzuki, E. Discovering Unexpected Exceptions: A Stochastic Approach. <i>Proc. of the 4th International Workshop on Rough Sets, Fuzzy Sets, and Machine Discovery</i> (RSFD-96), pp. 225-232, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669327</ref_obj_id>
				<ref_obj_pid>645802</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Suzuki, E. & Kodratoff, Y. Discovery of Surprising Exception Rules based on Intensity of Implication. <i>Proc of Principles of Data Mining and Knowledge Discovery</i> (PKDD-98), pp. 10-18, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669840</ref_obj_id>
				<ref_obj_pid>645804</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Suzuki, E & Zytkow, J. M. Unified Algorithm for Undirected Discovery of Exception Rules. <i>Proc. of Principles of Data Mining and Knowledge Discovery</i> (PKDD-2000), pp. 169-180, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655984</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Wu, X., Zhang, C., & Zhang, S. Mining Both Positive and Negative Association Rules. <i>Proc. of the 19th International Conference on Machine Learning</i>, pp. 658-665, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844811</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Yan, X. & Han, J. gSpan: Graph-Based Substructure Pattern Mining. <i>Proc. of the 3rd International Conference on Data Mining</i>, (ICDM-2002), pp. 721-724, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775058</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Zaki, M. Efficiently Mining Frequent Trees in a Forest. <i>Proc. of the 8th International Conference on Knowledge Discovery and Data Mining</i> (KDD-2002), pp. 71-80, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952167</article_id>
		<sort_key>91</sort_key>
		<display_label></display_label>
		<pages>91</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Scalable Model-based Clustering by Working on Data Summaries]]></title>
		<page_from>91</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952167</url>
		<abstract>
			<par><![CDATA[The scalability problem in data mining involves the developmentof methods for handling large databases withlimited computational resources. In this paper, we presenta two-phase scalable model-based clustering framework:First, a large data set is summed up into sub-clusters; Then,clusters are directly generated from the summary statisticsof sub-clusters by a specifically designed Expectation-Maximization(EM) algorithm. Taking example for Gaussianmixture models, we establish a provably convergentEM algorithm, EMADS, which embodies cardinality, mean,and covariance information of each sub-cluster explicitly.Combining with different data summarization procedures,EMADS is used to construct two clustering systems:gEMADS and bEMADS. The experimental results demonstratethat they run several orders of magnitude faster thanthe classic EM algorithm with little loss of accuracy. Theygenerate significantly better results than other model-basedclustering systems using similar computational resources.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39025152</person_id>
				<author_profile_id><![CDATA[81100055106]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Huidong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31031274</person_id>
				<author_profile_id><![CDATA[81451594378]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Man-Leung]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39036661</person_id>
				<author_profile_id><![CDATA[81451595717]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kwong-Sak]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[P. Bradley, U. Fayyad, and C. Reina. Clustering very large databases using EM mixture models. In <i>ICPR'00</i>, volume 2, pages 76-80, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347119</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[I. Cadez, S. Gaffney, and P. Smyth. A general probabilistic framework for clustering individuals. In <i>KDD-2000</i>, pages 140-149, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>257954</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Cheeseman and J. Stutz. Bayesian classification (Auto-Class): Theory and results. In U. M. Fayyad and et al., editors, <i>Advances in Knowledge Discovery and Data Mining</i>, pages 153-180, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502549</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Chiu, D. Fang, J. Chen, Y. Wang, and C. Jeris. A robust and scalable clustering algorithm for mixed type attributes in large database environment. In <i>KDD-2001</i>, pages 263-268, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312184</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[W. DuMouchel, C. Volinsky, T. Johnson, C. Cortes, and D. Pregibon. Squashing flat files flatter. In <i>KDD-1999</i>, pages 6-15, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>305240</ref_obj_id>
				<ref_obj_pid>305219</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Fraley. Algorithms for model-based Gaussian hierarchical clustering. <i>SIAM Journal on Scientific Computing</i>, 20(1):270-281, Jan. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076797</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Han and M. Kamber. <i>Data Mining: Concepts and Techniques</i>. Morgan Kaufmann Publishers, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>936419</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H.-D. Jin. <i>Scalable Model-based Clustering Algorithms for Large Databases and Their Applications</i>. Ph.D. thesis, the Chinese University of Hong Kong, Hong Kong, Aug. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[G. J. McLachlan and T. Krishnan. <i>The EM Algorithm and Extensions</i>. John Wiley & Sons, Inc., New York, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>370665</ref_obj_id>
				<ref_obj_pid>370660</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Meila and D. Heckerman. An experimental comparison of model-based clustering methods. <i>Machine Learning</i>, 42(1/2):9-29, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>340731</ref_obj_id>
				<ref_obj_pid>340534</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Moore. Very fast EM-based mixture model clustering using multiresolution KD-trees. In <i>NIPS'99</i>, pages 543-549, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672827</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. T. Ng and J. Han. Efficient and effective clustering methods for spatial data mining. In <i>VLDB'94</i>, pages 144-155, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335384</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[C. R. Palmer and C. Faloutsos. Density biased sampling: An improved method for data mining and clustering. In <i>SIGMOD-2000</i>, pages 82-92, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312231</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Shanmugasundaram, U. Fayyad, and P. S. Bradley. Compressed data cubes for OLAP aggregate query approximation on continuous dimensions. In <i>KDD-1999</i>, pages 223- 232, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>514918</ref_obj_id>
				<ref_obj_pid>514915</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[B. Thiesson, C. Meek, and D. Heckerman. Accelerating EM for large databases. <i>Machine Learning</i>, 45:279-299, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593443</ref_obj_id>
				<ref_obj_pid>593415</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. Zhang, R. Ramakrishnan, and M. Livny. BIRCH: A new data clustering algorithm and its applications. <i>Data Mining and Knowledge Discovery</i>, 1(2):141-182, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952160</article_id>
		<sort_key>99</sort_key>
		<display_label></display_label>
		<pages>99</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[On the Privacy Preserving Properties of Random Data Perturbation Techniques]]></title>
		<page_from>99</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952160</url>
		<abstract>
			<par><![CDATA[Privacy is becoming an increasingly important issue inmany data mining applications. This has triggered the developmentof many privacy-preserving data mining techniques.A large fraction of them use randomized data distortiontechniques to mask the data for preserving the privacyof sensitive data. This methodology attempts to hidethe sensitive data by randomly modifying the data values oftenusing additive noise. This paper questions the utility ofthe random value distortion technique in privacy preservation.The paper notes that random objects (particularly randommatrices) have "predictable" structures in the spectraldomain and it develops a random matrix-based spectral filteringtechnique to retrieve original data from the datasetdistorted by adding random values. The paper presents thetheoretical foundation of this filtering method and extensiveexperimental results to demonstrate that in many cases randomdata distortion preserve very little data privacy. Thepaper also points out possible avenues for the developmentof new privacy-preserving data mining techniques like exploitingmultiplicative and colored noise for preserving privacyin data mining applications.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Information filtering</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Selection process</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003338</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval models and ranking</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003349</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Document filtering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003352</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Information extraction</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39029854</person_id>
				<author_profile_id><![CDATA[81100150749]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hillol]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kargupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645550</person_id>
				<author_profile_id><![CDATA[81100067641]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Souptik]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Datta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14083265</person_id>
				<author_profile_id><![CDATA[81452594777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Qi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P163158</person_id>
				<author_profile_id><![CDATA[81100106585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Krishnamoorthy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sivakumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>375602</ref_obj_id>
				<ref_obj_pid>375551</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Agrawal and C. C. Aggawal. On the design and quantification of privacy preserving data mining algorithms. In <i>Proceedings of the 20th ACM SIMOD Symposium on Principles of Database Systems</i>, pages 247-255, Santa Barbara, May 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335438</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Privacy-preserving data mining. In <i>Proceeding of the ACM SIGMOD Conference on Management of Data</i>, pages 439-450, Dallas, Texas, May 2000. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>679107</ref_obj_id>
				<ref_obj_pid>646108</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[V. Estivill-Castro and L. Brankovic. Data swaping: Balancing privacy against precision in mining for logic rules. In <i>Proceedings of the first Conference on Data Warehousing and Knowledge Discovery (DaWaK-99)</i>, pages 389-398, Florence, Italy, 1999. Springer Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>773174</ref_obj_id>
				<ref_obj_pid>773153</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Evfimevski, J. Gehrke, and R. Srikant. Limiting privacy breaches in privacy preserving data mining. In <i>Proceedings of the ACM SIMOD/PODS Conference</i>, San Diego, CA, June 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775080</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Evfimevski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. In <i>Proceedings of the ACM SIKDD Conference</i>, Edmonton, Canada, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>772869</ref_obj_id>
				<ref_obj_pid>772862</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Evfimievski. Randomization techniques for privacy preserving association rule mining. In <i>SIGKDD Explorations</i>, volume 4(2), Dec 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Janson, T. L., and A. Rucinski. <i>Random Graphs</i>. Wiley Publishers, 1 edition, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. Jonsson. Some limit theorems for the eigenvalues of a sample covariance matrix. <i>Journal of Multivariate Analysis</i>, 12:1-38, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In <i>SIGMOD Workshop on DMKD</i>, Madison, WI, June 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>670175</ref_obj_id>
				<ref_obj_pid>645806</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[H. Kargupta, K. Sivakumar, and S. Ghosh. Dependency detection in mobimine and random matrices. In <i>Proceedings of the 6th European Conference on Principles and Practice of Knowledge Discovery in Databases</i>, pages 250-262. Springer, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[K. Liu, H. Kargupta, and J. Ryan. Random projection and privacy preserving correlation computation from distributed data. Technical report, University of Maryland Baltimore County, Computer Science and Electrical Engineering Department, Technical Report TR-CS-03-24, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. G. Manolakis, V. K. Ingle, and S. M. Kogon. <i>Statistical and Adaptive Signal Processing</i>. McGraw Hill, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M. L. Mehta. <i>Random Matrices</i>. Academic Press, London, 2 edition, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[U. M. L. Repository. http://www.ics.uci.edu/mlearn/mlsummary.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287428</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. In <i>Proceedings of the 28th VLDB Conference</i>, Hong Kong, China, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J. W. Silverstein and P. L. Combettes. Signal detection via spectral theory of large dimensional random matrices. <i>IEEE Transactions on Signal Processing</i>, 40(8):2100-2105, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[G. W. Stewart. Error and perturbation bounds for subspaces associated with certain eigenvalue problems. <i>SIAM Review</i>, 15(4):727-764, October 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383392</ref_obj_id>
				<ref_obj_pid>1994</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. F. Traub, Y. Yemini, and H. Woz'niakowski. The statistical security of a statistical database. <i>ACM Transactions on Database Systems (TODS)</i>, 9(4):672-679, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775142</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. Vaidya and C. Clifton. Privacy preserving association rule mining in vertically partitioned data. In <i>The Eighth ACM SIGKDD International conference on Knowledge Discovery and Data Mining</i>, Edmonton, Alberta, CA, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[H. Weyl. Inequalities between the two kinds of eigenvalues of a linear transformation. In <i>Proceedings of the National Academy of Sciences</i>, volume 35, pages 408-411, 1949.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952140</article_id>
		<sort_key>107</sort_key>
		<display_label></display_label>
		<pages>107</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Semantic Log Analysis Based on a User Query Behavior Model]]></title>
		<page_from>107</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952140</url>
		<abstract>
			<par><![CDATA[We propose a novel log analysis method to capture thesemantic relations among words appearing in Web searchlogs. Our method focuses on the reciprocal relations amonga user's intentions, stages of information need, and querybehavior in seeking information via a search engine. Theapproach works because it is based on the assumption that auser's intentions in each query can be derived as a model onthe basis of his stage of information need and query behavior,through multiple empirical observations of search logs.The user's intentions drive user to change the words in eachsuccessive queries and can thus be used to clarify the semanticrelations among words. As a result, this method hasthe advantage of capturing the semantic relations amongwords without requiring either manual or natural languageprocessing. Our experimental results indicate that semanticrelations could successfully be derived from search logs,confirming that an ontology and thesaurus could be constructedautomatically.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Search process</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Query processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Language parsing and understanding</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003192</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Database query processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011711</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Database query processing and optimization (theory)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003325</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Information retrieval query processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645400</person_id>
				<author_profile_id><![CDATA[81100293926]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kawamae]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Noriaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645466</person_id>
				<author_profile_id><![CDATA[81100299466]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mukaigaito]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takeya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645336</person_id>
				<author_profile_id><![CDATA[81100093304]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hanaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miyoshi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Berners. <i>Semantic Web Road Map</i>. http://www.w3.org/DesignIssues/Semantic.html, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>792552</ref_obj_id>
				<ref_obj_pid>792550</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Broder. <i>A Taxonomy ot Web Search, SIGIR Forum</i>. Vol. 36, No. 2, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>206540</ref_obj_id>
				<ref_obj_pid>206478</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. D. Catledge and J. E. Pitkow. <i>Characterizing Browsing Strategies in the Worid-Wide Web</i>. In Proceedings of the 3rd WWW Conference, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Cooley, B. Mobasher, and J. Srivastava. <i>Data Preparation for Mining World Wide Web Browsing Patterns</i>. Knowledge and Information Systems 1(1):5-32, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>728048</ref_obj_id>
				<ref_obj_pid>647457</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Goker and D. He. <i>Analysing Web search logs to determine session boundaries for user-oriented learning</i>. Adaptive Hypermedia and Adaptive Web-Based Systems International Conference (AH2000), 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>992154</ref_obj_id>
				<ref_obj_pid>992133</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Hearst. <i>Automatic Acquisition of Hyponyms from Large Text Corpora</i>. In Proceedings of the Fourteenth International Conference on Computational Linguistics, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1072029</ref_obj_id>
				<ref_obj_pid>1072017</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Hobbs. <i>The Generic Information Extraction System</i>. In Proceedings of the Fifth Message Understanding Conference (MUC-5), 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. Huberman, P. L. T. Pirolli, J. E. Pitkow, and R. M. Lukose. <i>Strong regularities in World Wide Web surfing</i>. Science, Vol. 280(5360), 95-97, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[L. Kaufman and P. J. Rousseeuw. <i>Finding Groups in Data: An Introduction to Cluster Analysis</i>. John Wiley & Sons, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>317340</ref_obj_id>
				<ref_obj_pid>317328</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Lau and E. Horvitz. <i>Patterns ot Search: Analyzing and Modeling Web Query Refinement</i>. In Proceedings of the Seventh International Conference on User Modeling. ACM Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Lawrence and C. L. Giles. <i>Searching the World Wide Web</i>. Web, Science, 280 (5360), 98-100, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A. J. Lotka. <i>The Frequency Distribution of Scientific Productivity</i>. Journal of the Washington Academy of Sciences, 16 (12), 317-323, 1926.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. Maedche and R. Volz. <i>The Text-To-Ontology Extraction and Maintenance System</i>. ICDM-Workshop on Integrating Data Mining and Knowledge Management, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311445</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C. Manning and H. Schuetze. <i>Foundations of Statistical Language Processing</i>. MIT Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Y. Niwa. <i>Dynamic Co-occurrence Analysis for Interactive Document Retrieval</i>. IPSJ SIGNotes Natural Language Abstract No. 115-014, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. Ohkubo, M. Sugizaki, T. Inoue, and K. Tanaka. <i>Extracting Information Demand by Analyzing a WWW Search Log</i>. IPSJ Vol. 39, No. 07, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>981598</ref_obj_id>
				<ref_obj_pid>981574</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[F. Pereira, N. Tishby, and L. Lee. <i>Distributional Clustering of English Words</i>. In Proceedings of the 31st ACL, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>372097</ref_obj_id>
				<ref_obj_pid>371920</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[S. Ramakrishnan and Y. Yinghui. <i>Mining web logs to improve website organization</i>. In Proceedings of the Tenth International WWW Conference (WWW2001), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[S. Sato, M. Harada, and K. Kazama. <i>Some Results from an Analysis of Queries to a Search Engine</i>. IPSJ SIG Notes, 2000-FI-57-18, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[C. Silverstein, M. Henzinger, H. Marais, and M. Moricz. <i>Analysis of a Very Large AltaVista Query Log</i>. Technical Report 1998-014, Digital Systems Research Center, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[R. Taylor. <i>Question-negotiation and information seeking in libraries</i>. College Research Libraries, 29(3), 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. Weintraub, Y. Aksu, S. Dharanipragada, S. Khudanpur, H. Ney, J. Prange, A. Stolcke, F. Jelinek, and E. Shriberg. <i>Lm95 project report: Fast training and portability.</i> Research Notes No. 1, Center for Language and Speech Processing, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952156</article_id>
		<sort_key>115</sort_key>
		<display_label></display_label>
		<pages>115</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Clustering of Time Series Subsequences is Meaningless]]></title>
		<subtitle><![CDATA[Implications for Previous and Future Research]]></subtitle>
		<page_from>115</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952156</url>
		<abstract>
			<par><![CDATA[Time series data is perhaps the most frequently encountered typeof data examined by the data mining community. Clustering isperhaps the most frequently used data mining algorithm, beinguseful in it's own right as an exploratory technique, and also as asubroutine in more complex data mining algorithms such as rulediscovery, indexing, summarization, anomaly detection, andclassification. Given these two facts, it is hardly surprising thattime series clustering has attracted much attention. The data to beclustered can be in one of two formats: many individual timeseries, or a single time series, from which individual time seriesare extracted with a sliding window. Given the recent explosion ofinterest in streaming data and online algorithms, the latter casehas received much attention.In this work we make an amazing claim. Clustering of streamingtime series is completely meaningless. More concretely, clustersextracted from streaming time series are forced to obey a certainconstraint that is pathologically unlikely to be satisfied by anydataset, and because of this, the clusters extracted by anyclustering algorithm are essentially random. While this constraintcan be intuitively demonstrated with a simple illustration and issimple to prove, it has never appeared in the literature.We can justify calling our claim surprising, since it invalidatesthe contribution of dozens of previously published papers. We willjustify our claim with a theorem, illustrative examples, and acomprehensive set of experiments on reimplementations ofprevious work.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Time Series, Data Mining, Clustering, Rule Discovery]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15025741</person_id>
				<author_profile_id><![CDATA[81100209161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eamonn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Keogh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40025032</person_id>
				<author_profile_id><![CDATA[81100222615]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jessica]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P587676</person_id>
				<author_profile_id><![CDATA[81100547819]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wagner]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Truppel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>656414</ref_obj_id>
				<ref_obj_pid>645504</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Aggarwal, C., Hinneburg, A, & Keim, D. A. (2001). On the Surprising Behavior of Distance Metrics in High Dimensional Space. In <i>proceedings of the 8th Int'l Conference on Database Theory</i>. London, UK, Jan. 4-6. pp. 420- 434.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Agrawal, R., Imielinski, T. & Swami, A (1993). Mining Association Rules Between Sets of Items in Large Databases. In <i>proceeding, of the 1993 ACM SIGMOD International Conference on Management on Data</i>. Washington, D.C., May 26-28. pp. 207-216.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>565202</ref_obj_id>
				<ref_obj_pid>565196</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bar-Joseph, Z., Gerber, G., Gifford, D., Jaakkola, T. & Simon, I. (2002). A New Approach to Analyzing Gene Expression Time Series Data. In <i>proceedings the 6th Annual Int'l Conference on Research in Computational Molecular Biology</i>. Washington, D.C. pp. 39-48.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656271</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Beyer, K., Goldstein, J., Ramakrishnan, R. & Shaft, U. (1999). When is Nearest Neighbor Meaningful? In <i>proceedings of the 7th Int'l Conference on Database theory</i>. Jerusalem, Israel, pp. 217-235.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657466</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bradley, P. S. & Fayyad, U.M. (1998). Refining Initial Points for K-Means Clustering. In <i>proceedings of the 15th Int'l Conference on Machine Learning</i>. Madison, WI, July 24-27, pp. 91-99.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[British Iris Society, Species Group Staff. (1997). A Guide to Species Irises: Their Identification and Cultivation. <i>Cambridge University Press</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cotofrei, P. (2002). Statistical Temporal Rules. In <i>proceedings of the 15th Conference on Computational Statistics</i> - Short Communications and Posters. Berlin, Germany, Aug 24-28.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655326</ref_obj_id>
				<ref_obj_pid>645457</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cotofrei, P. & Stoffel, K. (2002). Classification Rules + Time = Temporal Rules. In <i>proceedings of the 2002 Int'l Conference on Computational Science</i>. Amsterdan, Netherlands, pp. 572-581.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Das, G., Lin, K., Mannila, H., Renganathan, G. & Smyth, P. (1998). Rule Discovery from Time Series. In <i>proceedings of the 4th Int'l Conference on Knowledge Discovery and Data Mining</i>. New York, NY, Aug. 27-31. pp 16-22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Fisher, R. A. (1936). The Use of Multiple Measures in Taxonomic Problems. <i>Annals of Eugenics</i>. Vol. 7, No. 2, pp. 179-188.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fu, T. C., Chung, F. L., Ng, V. & Luk, R. (2001). Pattern Discovery from Stock Time Series Using Self-Organizing Maps. <i>Workshop Notes of KDD2001 Workshop on Temporal Data Mining</i>. San Francisco, CA, Aug 26- 29, pp 27-37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347189</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Gavrilov, M., Anguelov, D., Indyk, P. & Motwani, R. (2000). Mining the Stock Market: Which Measure is Best? In <i>proceedings of the 6th ACM Int'l Conference on Knowledge Discovery and Data Mining</i> Boston, MA, Aug 20- 23. pp 487-496.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>796588</ref_obj_id>
				<ref_obj_pid>795666</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Guha, S. Mishra, N. Motwani, R. & O'Callaghan, L (2000). Clustering Data Streams. In <i>Proceedings of the 41st Annual Symposium on Foundations of Computer Science</i>. Redondo Beach, CA pp. 359-366.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>607609</ref_obj_id>
				<ref_obj_pid>607585</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Halkidi, M., Batistakis, Y. & Vazirgiannis, M. (2001). On Clustering Validation Techniques. <i>Journal of Intelligent Information Systems</i> (JIIS), Vol. 17, No. 2-3. pp. 107-145.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>690279</ref_obj_id>
				<ref_obj_pid>646360</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Harms, S. K.. Deogun, J. & Tadesse, T. (2002), Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences. In <i>proceedings qf the 13th Int'l Symposium on Methodologies for Intelligent Systems</i>. Lyon, France, pp 432-441.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Harms, S. K., Reichenbach, S. Goddard, S. E., Tadesse, T. & Waltman, W. J. (2002). Data Mining in a Geospatial Decision Support system for Drought Risk Management. In <i>proceedings of the 1st National Conference on Digital Government</i>. Los Angeles, CA, pp. 9-16.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Hetland, M. L & S&#230;&#230;trom, P. (2002). Temporal Rules Discovery Using Genetic Programming and Specialized Hardware. In <i>proceedings of the 4th Int'l Conference on Recent Advances in Soft Computing</i>. Nottingham, UK.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>607630</ref_obj_id>
				<ref_obj_pid>607587</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Honda, R, Wang, S., Kikuchi, T. & Konishi, O. (2002). Mining of Moving Objects from Time-Series Images and its Application to Satellite Weather Imagery. <i>The Journal of Intelligent Information Systems</i>, Vol. 19, No. 1, pp. 79-93.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846195</ref_obj_id>
				<ref_obj_pid>846183</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Jensen, D. (2000). Data Snooping, Dredging and Fishing: The dark Side of Data Mining. SIGKDD99 panel report, <i>ACM SIGKDD Explorations</i>, Vol. 1, No. 2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>693672</ref_obj_id>
				<ref_obj_pid>646420</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Jin, X., Lu, Y. & Shi, C (2002). Distribution Discovery: Local Analysis of Temporal Rules. In <i>proceedings of the 6th Pacific-Asia Conference on Knowledge Discovery and Data Mining</i>. Taipei, Taiwan, pp 469-480.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>686612</ref_obj_id>
				<ref_obj_pid>646288</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Jin, X., Wang, L, Lu, Y & Shi, C. (2002). Indexing and Mining of the Local Patterns in Sequence Database. In <i>proceedings of the 3rd International Conference on Intelligent Data Engineering and Automated Learning</i>. Manchester, UK, Aug 12-14. pp 68-73.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Kendall, M. (1976) Time-Series. 2nd Edition. Charles Griffin and Company, Ltd., London.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Keogh, E. (2002). The UCR Time Series Data Mining Archive {http://www.cs.ucr.edu/~eamonn/TSDMA/index.html}. Riverside CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287405</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Keogh, E. (2002). Exact Indexing of Dynamic Time Warping. <i>In proceedings of the 28th International Conference on Very Large Data Base</i>. Hong Kong, Aug 20-23 pp 406-417.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Keogh, E. Chakrabarti, K. Pazzani, M & Mehrotra, S. (2001), Dimensionality Reduction for Fast Similarity Search in Large Time Series Databases. KAIS Vol. 3, No. 3, pp. 263-286.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775062</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Keogh, E. & Kasetty, S. (2002). On the Need for Time Series, Data Mining Benchmarks: A Survey and Empirical Demonstration. <i>In proceeding of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, Alberta, Canada. pp 102-111.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288666</ref_obj_id>
				<ref_obj_pid>288627</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Li, C., Yu, P. S. & Castelli, V. (1998). MALM: A Framework for Mining Sequence Database at Multiple Abstraction Levels. In <i>proceedings of the 7th ACM CIKM Int'l Conference on Information and Knowledge Management</i>. Bethesda, MD, Nov 3-7. pp 267-272.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Lin, J. Keogh, E. Patel, P. & Lonardi, S. (2002). Finding motifs in time series. In <i>the 2nd Workshop on Temporal Data Mining, at the 8th ACM SIGKDD international Conference on Knowledge Discovery and Data Mining</i>. July 23 -26, 2002. Edmonton, Alberta, Canada.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Mantegna., R. N. (1999). Hierarchical Structure in Financial Markets. <i>European. Physical Journal</i>. B11, pp. 193-197.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>738592</ref_obj_id>
				<ref_obj_pid>647884</ref_obj_pid>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Mori, T. & Uehara, K. (2001). Extraction of Primitive Motion and Discovery of Association Rules from Human Motion. In <i>proceedings of the 10th IEEE Int'l Workshop on Robot and Human Communication</i>, Bordeaux-Paris, France, Sept 18-21. pp 200-206.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312268</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Oates, T. (1999). Identifying Distinctive Subsequences in Multivariate Time Series by Clustering. <i>In proceedings of the 5th International Conference on Knowledge Discovery and Data Mining</i>, pp 322-326.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>719961</ref_obj_id>
				<ref_obj_pid>647250</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Osaki, R., Shimada, M. & Uehara, K. (2000). A Motion Recognition Method by Using Primitive Motions, Arisawa, H. and Catarci, T. (eds.) <i>Advances in Visual Information Management, Visual Database Systems</i>, Kluwer Academic Pub. pp 117-127.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Radhakrishnan, N., Wilson, J. D. & Loizou, P. C (2000). An Alternate Partitioning Technique to Quantify the Regularity of Complex Time Series. <i>International Journal of Bifurcation and Chaos</i>, Vol. 10, No. 7, World Scientific Publishing. pp 1773-1779.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Reinert, G., Schbath, S. & Waterman, M. S. (2000). Probabilistic and statistical properties of words: An overview. J. <i>Comput. Bio.</i>, Vol. 7, pp 1-46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628245</ref_obj_id>
				<ref_obj_pid>627341</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Roddick, J F. & Spiliopoulou, M. (2002). A Survey of Temporal Knowledge Discovery Paradigms and Methods. <i>Transactions on Data Engineering</i>. Vol. 14, No. 4, pp 750-767.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Sarker, B. K., Mori, T & Uehara, K. (2002). Parallel Algorithms for Mining Association Rules in Time Series Data. TR-CS24-2002-1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Schittenkopf, C, Tino, P. & Dorffner, G. (2000). The Benefit of Information Reduction for Trading Strategies. <i>Report Series for Adaptive Information Systems and Management in Economics and Management Science</i>, July. Report #45.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Steinback, M., Tan, P.N., Kumar, V., Klooster, S. & Potter. C (2002). Temporal Data Mining for the Discovery and Analysis of Ocean Climate Indices. In the 2nd <i>Workshop on Temporal Data Mining, at the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>. Edmonton, Alberta, Canada. July 23.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Timmermann, A, Sullivan, R. & White, H. (1998). The Dangers of Data-Driven Inference: The Case of Calendar Effects in Stock Returns. <i>FMG Discussion Papers dp0304</i>, Financial Markets Group and ESRC.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Tino, P., Schittenkopf, C & Dorffner, G. (2000). Temporal Pattern Recognition in Noisy Non-stationary Time Series Based on Quantization into Symbolic Streams: Lessons Learned from Financial Volatility Trading. <i>Report Series for Adaptive Information Systems and Management in Economics and Management Science</i>, July. Report #46.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Truppel, Keogh, Lin (2003). A Hidden Constraint When Clustering Streaming Time Series. UCR Tech Report.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>738592</ref_obj_id>
				<ref_obj_pid>647884</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Uehara, K. & Shimada, M. (2002). Extraction of Primitive Motion and Discovery of Association Rules from Human Motion Data <i>Progress in Discovery Science 2002, Lecture Notes in Artificial Intelligence</i>, Vol. 2281. Springer-Verlag. pp 338-348.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>683987</ref_obj_id>
				<ref_obj_pid>646258</ref_obj_pid>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Van Laerhoven, K. (2001). Combining the Kohonen Self-Organizing Map and K-Means for On-line Classification of Sensor data. <i>Artifical Neural Networks</i>, Dorffner, G., Bischof, H. & Hornik, K. (Eds.), Vienna, Austria: Lecture Notes in Artificial Intelligence. Vol. 2130, Springer Verlag, pp. 464- 470.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Walker, J. (2001). HotBits: Genuine Random Numbers Generated by Radioactive Decay. www.fourmilab.ch/hotbits/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Yairi, T., Kato, Y. & Hori, K. (2001). Fault Detection by Mining Association Rules in House-keeping Data. In <i>proceedings of the 6th International Symposium on Artifical Intelligence, Robotics and Automation in Space</i>. Montreal, Canada, June 18-21.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952136</article_id>
		<sort_key>123</sort_key>
		<display_label></display_label>
		<pages>123</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Dynamic Weighted Majority]]></title>
		<subtitle><![CDATA[A New Ensemble Method for Tracking Concept Drift]]></subtitle>
		<page_from>123</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952136</url>
		<abstract>
			<par><![CDATA[Algorithms for tracking concept drift are important formany applications. We present a general method basedon the Weighted Majority algorithm for using any on-linelearner for concept drift. Dynamic Weighted Majority(DWM) maintains an ensemble of base learners, predictsusing a weighted-majority vote of these "experts",and dynamically creates and deletes experts in response tochanges in performance. We empirically evaluated two experimentalsystems based on the method using incrementalnaive Bayes and Incremental Tree Inducer (ITI) as experts.For the sake of comparison, we also included Blum's implementationof Weighted Majority. On the STAGGER Conceptsand on the SEA Concepts, results suggest that the ensemblemethod learns drifting concepts almost as well as the basealgorithms learn each concept individually. Indeed, we reportthe best overall results for these problems to date.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Concept learning</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Heuristic methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.11</cat_node>
				<descriptor>Intelligent agents</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010206</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Heuristic function construction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010219.10010221</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Distributed artificial intelligence->Intelligent agents</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645370</person_id>
				<author_profile_id><![CDATA[81100095014]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jeremy]]></first_name>
				<middle_name><![CDATA[Z.]]></middle_name>
				<last_name><![CDATA[Kolter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14062915</person_id>
				<author_profile_id><![CDATA[81100151275]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Marcus]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Maloof]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>599607</ref_obj_id>
				<ref_obj_pid>599591</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Bauer and R. Kohavi. An empirical comparison of voting classification algorithms: Bagging, boosting, and variants. <i>Machine Learning</i>, 36:105-139, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz. UCI Repository of machine learning databases. Web site, http://www.ics.uci.edu/ ~mlearn/MLRepository.html, Department of Information and Computer Sciences, University of California, Irvine, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>251917</ref_obj_id>
				<ref_obj_pid>251913</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Blum. Empirical support for Winnow and Weighted-Majority algorithms: Results on a calendar scheduling domain. <i>Machine Learning</i>, 26:5-23, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging predictors. <i>Machine Learning</i>, 24:123-140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>350131</ref_obj_id>
				<ref_obj_pid>350128</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. Dietterich. An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization. <i>Machine Learning</i>, 40:139- 158, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347107</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. Domingos and G. Hulten. Mining high-speed data streams. In <i>Proceedings of the 6th ACM International Conference on Knowledge Discovery and Data Mining</i>, pages 71-80, ACM Press, New York, NY, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312283</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[W. Fan, S. Stolfo, and J. Zhang. The application of AdaBoost for distributed, scalable and on-line learning. In <i>Proceedings of the 5th ACM International Conference on Knowledge Discovery and Data Mining</i>, pages 362-366, ACM Press, New York, NY, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>940877</ref_obj_id>
				<ref_obj_pid>940854</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Fern and R. Givan. Online ensemble learning: An empirical study. <i>Machine Learning</i>, 53, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. Schapire. Experiments with a new boosting algorithm. In <i>Proceedings of the 13th International Conference on Machine Learning</i>, pages 148-156, Morgan Kaufmann, San Francisco, CA, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[W. Hoeffding. Probability inequalities for sums of bounded random variables. <i>Journal of the American Statistical Association</i>, 58(301):13-30, 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502529</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G. Hulten, L. Spencer, and P. Domingos. Mining time-changing data streams. In <i>Proceedings of the 7th ACM International Conference on Knowledge Discovery and Data Mining</i>, pages 97-106, ACM Press, New York, NY, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2074196</ref_obj_id>
				<ref_obj_pid>2074158</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[G. John and P. Langley. Estimating continuous distributions in Bayesian classifiers. In <i>Proceedings of the 11th Conference on Uncertainty in Artificial Intelligence</i>, pages 338- 345, Morgan Kaufmann, San Francisco, CA, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[R. Kohavi. Scaling up the accuracy of naive-Bayes classifiers: A decision-tree hybrid. In <i>Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining</i>, pages 202-207, AAAI Press, Menlo Park, CA, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>639994</ref_obj_id>
				<ref_obj_pid>639961</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. <i>Machine Learning</i>, 2:285-318, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>184040</ref_obj_id>
				<ref_obj_pid>184036</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[N. Littlestone and M. Warmuth. The Weighted Majority algorithm. <i>Information and Computation</i>, 108:212-261, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1867491</ref_obj_id>
				<ref_obj_pid>1867406</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[R. Maclin and D. Opitz. An empirical evaluation of bagging and boosting. In <i>Proceedings of the 4th National Conference on Artificial Intelligence</i>, pages 546-551, AAAI Press, Menlo Park, CA, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>690276</ref_obj_id>
				<ref_obj_pid>646360</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[M. Maloof. Incremental rule learning with partial instance memory for changing concepts. In <i>Proceedings of the International Joint Conference on Neural Networks</i>, pages 2764- 2769, IEEE Press, Los Alamitos, CA, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360547</ref_obj_id>
				<ref_obj_pid>360540</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Maloof and R. Michalski. Selecting examples for partial memory learning. <i>Machine Learning</i>, 41:27-52, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>985175</ref_obj_id>
				<ref_obj_pid>985172</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[M. Maloof and R. Michalski. Incremental learning with partial instance memory. <i>Artificial Intelligence</i>, to appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[R. Michalski and J. Larson. Incremental generation of VL&#60;inf&#62;1&#60;/inf&#62; hypotheses: The underlying methodology and the description of program AQ11. Technical Report UIUCDCS-F-83- 905, Department of Computer Science, University of Illinois, Urbana, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[D. Opitz and R. Maclin. Popular ensemble methods: An empirical study. <i>Journal of Artificial Intelligence Research&lt;/i&#62;, 11:169-198, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[J. Quinlan. <i>C4.5: Programs for machine learning</i>. Morgan Kaufmann, San Francisco, CA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[J. Schlimmer and R. Granger. Beyond incremental processing: Tracking concept drift. In <i>Proceedings of the 5th National Conference on Artificial Intelligence</i>, pages 502-507, AAAI Press, Menlo Park, CA, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502568</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[W. Street and Y. Kim. A streaming ensemble algorithm (SEA) for large-scale classification. In <i>Proceedings of the 7th ACM International Conference on Knowledge Discovery and Data Mining</i>, pages 377-382, ACM Press, New York, NY, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274067</ref_obj_id>
				<ref_obj_pid>274065</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[P. Utgoff, N. Berkman, and J. Clouse. Decision tree induction based on efficient tree restructuring. <i>Machine Learning</i>, 29:5-44, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>226798</ref_obj_id>
				<ref_obj_pid>226791</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[G. Widmer and M. Kubat. Learning in the presence of concept drift and hidden contexts. <i>Machine Learning</i>, 23:69- 101, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952157</article_id>
		<sort_key>131</sort_key>
		<display_label></display_label>
		<pages>131</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Probabilistic Noise Identification and Data Cleaning]]></title>
		<page_from>131</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952157</url>
		<abstract>
			<par><![CDATA[Real world data is never as perfect as we would like itto be and can often suffer from corruptions that may impactinterpretations of the data, models created from thedata, and decisions made based on the data.One approachto this problem is to identify and remove records that containcorruptions.Unfortunately, if only certain fields in arecord have been corrupted then usable, uncorrupted datawill be lost.In this paper we present LENS, an approach foridentifying corrupted fields and using the remaining non-corruptedfields for subsequent modeling and analysis.Ourapproach uses the data to learn a probabilistic model containingthree components: a generative model of the cleanrecords, a generative model of the noise values, and a probabilisticmodel of the corruption process.We provide an algorithmfor the unsupervised discovery of such models andempirically evaluate both its performance at detecting corruptedfields and, as one example application, the resultingimprovement this gives to a classifier.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P467939</person_id>
				<author_profile_id><![CDATA[81100580238]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jeremy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kubica]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39024558</person_id>
				<author_profile_id><![CDATA[81100042782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moore]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Arning, R. Agrawal, and P. Raghavan. A linear method for deviation detection in large databases. In <i>Knowledge Discovery and Data Mining</i>, pages 164-169, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H. Attias, L. Deng, A. Acero, and J. C. Platt. A new method for speech denoising and robust speech recognition using probabilistic models for clean speech and for noist. In <i>Proc. of the Eurospeech Conference</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz. UCI repository of machine learning databases. http://www.ics.uci.edu/~mlearn/mlrepository.html, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1892994</ref_obj_id>
				<ref_obj_pid>1892875</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. E. Brodley and M. A. Friedl. Identifying and eliminating mislabeled training instances. In <i>AAAI/IAAI, Vol 1</i>, pages 799-805, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>257954</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Cheeseman and J. Stutz. Bayesian classification (autoclass): Theory and results. In U. M. Fayyad, G. Piatctsky-Shapiro, P. Smyth, and R. Uthurusamy, editors, <i>Advances in Knowledge Discovery and Data Mining</i>. AAAI Press/MIT Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657632</ref_obj_id>
				<ref_obj_pid>645528</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Gamberger, N. Lavra, and C. Groelj. Experiments with noise filtering in a medical domain. In <i>Proc. 16th International Conf. on Machine Learning</i>, pages 143-151 Morgan Kaufmann, San Francisco, CA, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Z. Ghahramani and M. I. Jordan. Supervised learning from incomplete data via an EM approach. In J. D. Cowan, G. Tesauro, and J. Alspector, editors, <i>Advances in Neural Information Processing Systems</i>, volume 6, pages 120-127. Morgan Kaufmann Publishers, Inc., 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>257955</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[I. Guyon, N. Matic, and V. Vapnik. Discovering informative patterns and data cleaning. In <i>Advances in Knowledge Discovery and Data Mining</i>, pages 181-203. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[F. R. Hampel, P. J. Rousseeuw, E. M. Ronchetti, and W. A. Stahel. <i>Robust Statistics: The Approach based on influence Functions</i>. Wiley International, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. J. Huber. <i>Robust Statistics</i>. John Wiley and Sons, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G. H. John. Robust decision trees: Removing outliers from databases. In <i>Knowledge Discovery and Data Mining</i>, pages, 174-179, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. I. Maletic and A. Marcus. Data cleansing: Beyond integrity analysis. In <i>Proceedings of the Conference on Information Quality</i>, pages 200-209, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[V. T. Raisinghani. Cleaning methods in data warehousing. Seminar Report, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[B. Raj, M. L. Seltzer, and R. M. Stern. Reconstruction of damaged spectrographic features for robust speech recognition. In <i>Proceedings of the International Conference on Spoken Language Processing</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. Roweis. One microphone source separation. In <i>Neural Information Processing Systems</i>, volume 13, pages 793-799, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[S. Schwarm and S. Wolfman. Cleaning data with bayesian methods. 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657619</ref_obj_id>
				<ref_obj_pid>645528</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[C. M. Teng. Correcting noisy data. In <i>Proc. 16th International Conf. on Machine Learning</i>, pages 239-248. Morgan Kaufmann, San Francisco. CA, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952180</article_id>
		<sort_key>139</sort_key>
		<display_label></display_label>
		<pages>139</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Localized Prediction of Continuous Target Variables Using Hierarchical Clustering]]></title>
		<page_from>139</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952180</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a novel technique for the efficientprediction of multiple continuous target variablesfrom high-dimensional and heterogeneous data sets usinga hierarchical clustering approach. The proposed approachconsists of three phases applied recursively:partitioning, localization and prediction. In thepartitioning step, similar target variables are groupedtogether by a clustering algorithm. In the localizationstep, a classification model is used to predict which groupof target variables is of particular interest. If theidentified group of target variables still contains a largenumber of target variables, the partitioning andlocalization steps are repeated recursively and theidentified group is further split into subgroups with moresimilar target variables. When the number of targetvariables per identified subgroup is sufficiently small, thethird step predicts target variables using localized predictionmodels built from only those data records thatcorrespond to the particular subgroup. Experimentsperformed on the problem of damage prediction incomplex mechanical structures indicate that ourproposed hierarchical approach is computationally moreefficient and more accurate than straightforward methodsof predicting each target variable individually orsimultaneously using global prediction models.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P339910</person_id>
				<author_profile_id><![CDATA[81100052105]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Aleksandar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lazarevic]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P517483</person_id>
				<author_profile_id><![CDATA[81100650416]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ramdev]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kanapady]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030891</person_id>
				<author_profile_id><![CDATA[81100172655]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chandrika]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kamath]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43140745</person_id>
				<author_profile_id><![CDATA[81452613746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Vipin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645406</person_id>
				<author_profile_id><![CDATA[81100202359]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Kumar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tamma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>296644</ref_obj_id>
				<ref_obj_pid>296635</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Baxter, Theoretical Models of Learning to Learn, In T. Mitchell, S. Thrun, Eds, <i>Learning to Learn</i>. Kluwer, Boston, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Breiman, J. Friedman, Predicting Multivariate Responses in Multiple Linear Regression, <i>Journal of the Royal Statistical Society</i>, Series B 59, 3-54, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>262872</ref_obj_id>
				<ref_obj_pid>262868</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Caruana, Multitask Learning, <i>Machine Learning</i>, 28:41- 75, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Chen, N. Bicanoc, Assessment of Damage in Continuum Structures Based in Incomplete Modal Information, <i>Computers and Structures</i>, 74:559-570, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Hagan, M. Menhaj, Training feedforward networks with the Marquardt algorithm, <i>IEEE Transactions on Neural Networks</i>, 5:989-993, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[N. Intrator, S. Edelman, How to Make a Low-dimensional Representation Suitable for Diverse Tasks, <i>Connection Science</i>, 8, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>188106</ref_obj_id>
				<ref_obj_pid>188104</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Jordan, M. I., Jacobs, R. A., Hierarchical Mixtures of Experts and The EM Algorithm, <i>Neural Computation</i>, 6 (2), 181-214, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952180</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Lazarevic, R. Kanapady, C. Kamath, V. Kumar, K. Tamma, Localized Prediction of Continuous Target Variables Using Hierarchical Clustering, <i>AHPCRC Technical Report</i> 2003-123, www.cs.umn.edu/~aleks/pub_list.htm]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Lazarevic, Z. Obradovic, Knowledge Discovery in Multiple Spatial Databases, <i>Journal of Neural Computing and Applications</i>, Vol. 10, pp. 339-350, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Powell, Nonconvex minimization calculations and the conjugate gradient method, In D. Griffths Ed., <i>Numerical Analysis, Lecture Notes in Mathematics</i>, Springer-Verlag, Berlin, 1066: 122-141, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Riedmiller, T. Braun, A Direst Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm, <i>IEEE International Conference on Neural Networks</i>, San Francisco, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[G. J. Rix, Interpretation of Nondestructive Integrity tests using artificial neural networks, <i>Structure Congress 12, ASCE</i>, Reston VA, 1246-1351, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. Sandhu, R. Kanapady, K. Tamma, C. Kamath, V. Kumar, A sub-structuring approach via data mining for damage prediction and estimation in complex structures, SIAM International Conference on Data Mining, Arlington, VA, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Z. Szewczyk, P. Hajela, Damage detection in structures based on feature sensitive neural networks, <i>Journal of Computation in Civil Engineering</i>, ASCE, 8(2):163-179, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. Thrun, J. O'Sullivan, Clustering Learning Tasks and the Selective Cross-task Transfer of Knowledge, <i>Technical Report</i> CMU-CS-95-209, Carnegie Mellon University, Pittsburgh, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Y. Zhao and G. Karypis, Criterion Functions for Document Clustering Experiments and Analysis, <i>AHPCRC Technical Report</i> #01-40, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952154</article_id>
		<sort_key>147</sort_key>
		<display_label></display_label>
		<pages>147</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[An Algebra for Inductive Query Evaluation]]></title>
		<page_from>147</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952154</url>
		<abstract>
			<par><![CDATA[Inductive queries are queries that generate pattern sets.This paper studies properties of boolean inductive queries,i.e. queries that are boolean expressions over monotonicand anti-monotonic constraints. More specifically, we introduceand study algebraic operations on the answer setsof such queries and show how these can be used for constructingand optimizing query plans. Special attention isdevoted to the dimension of the queries, i.e. the minimumnumber of version spaces needed to represent the answersets. The framework has been implemented for the patterndomain of strings and experimentally validated.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Query formulation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Query processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Induction</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010297.10010298</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Logical and relational learning->Inductive logic learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011711</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Database query processing and optimization (theory)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003192</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Database query processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003325</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Information retrieval query processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P313677</person_id>
				<author_profile_id><![CDATA[81100411220]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sau]]></first_name>
				<middle_name><![CDATA[Dan]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P356047</person_id>
				<author_profile_id><![CDATA[81100274695]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Luc]]></first_name>
				<middle_name><![CDATA[De]]></middle_name>
				<last_name><![CDATA[Raedt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. 20th VLDB</i>, pages 487-499. Morgan Kaufmann, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>679143</ref_obj_id>
				<ref_obj_pid>646108</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[E. Baralis and G. Psaila. Incremental refinement of mining queries. In <i>Proc. 1st DaWaK</i>, LNCS 1676, pages 173-182, Florence, Italy, August 30-September 1 1999. Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775054</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Bucila, J. Gehrke, D. Kifer, and W. White. DualMiner: A dual-pruning algorithm for itemsets with constraints. In <i>Proc. 8th ACM SIGKDD</i>, Edmonton, Alberta, Canada, July 23-26 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>703155</ref_obj_id>
				<ref_obj_pid>646711</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. W. L. Cheung, S. D. Lee, and B. Kao. A general incremental technique for maintaining discovered association rules. In <i>Proc. 5th DASFAA</i>, pages 185-194, Melbourne, Australia, 1-4 Apr. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Clare and R. D. King. Machine learning of functional class from phenotype data. <i>Bioinformatics</i>, 18(1):160-166, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>772871</ref_obj_id>
				<ref_obj_pid>772862</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[L. De Raedt. A perspective on inductive databases. <i>SIGKDD Explorations</i>, 4(2):69-77, January 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844746</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[L. De Raedt, M. Jaeger, S. D. Lee, and H. Mannila. A theory of inductive query answering (extended abstract). In <i>Proc. 2nd IEEE ICDM</i>, pages 123-130, Maebashi, Japan, December 9-12 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642208</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[L. De Raedt and S. Kramer. The levelwise version space algorithm and its application to molecular fragment finding. In <i>Proc. 17th IJCAI</i>, August 4-10 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Greenberg. Using unix: Collected traces of 168 users. Research Report 88/333/45, Department of Computer Science, University of Calgary, Canada, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1631561</ref_obj_id>
				<ref_obj_pid>1631552</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[H. Hirsh. Theoretical underpinnings of version spaces. In <i>Proc. 12th IJCAI</i>, pages 665-670. Morgan Kaufmann Publishers, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>197873</ref_obj_id>
				<ref_obj_pid>197872</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[H. Hirsh. Generalizing version spaces. <i>Machine Learning</i>, 17(1):5-46, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502533</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Kramer, L. De Raedt, and C. Helma. Molecular feature mining in hiv data. In <i>Proc. 7th ACM SIGKDD</i>, Association for Computing Machinery, August 26-29 2001. ISBN: 158113391X.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. D. Lee and D. Cheung. <i>Maintenance of Discovered Association Rules</i>, volume 600 of <i>The Kluwer International Series in Engineering and Computer Science</i>, chapter 8. Kluwer Academic Publishers, Boston, November 2000. ISBN-0-7923-7243-3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593448</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and H. Toivonen. Levelwise search and borders of theories in knowledge discovery. <i>Data Mining and Knowledge Discovery</i>, 1(3):241-258, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[T. M. Mitchell. Generalization as search. <i>Artificial Intelligence</i>, 18(2):203-226, March 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[E. Ukkonen. On-line construction of suffix trees. <i>Algorithmica</i>, 14(3):249-260, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1441766</ref_obj_id>
				<ref_obj_pid>1441424</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[P. Weiner. Linear pattern matching algorithm. In <i>Proc. 14 IEEE Symposium on Switching and Automata Theory</i>, pages 1-11, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952178</article_id>
		<sort_key>155</sort_key>
		<display_label></display_label>
		<pages>155</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Direct Interesting Rule Generation]]></title>
		<page_from>155</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952178</url>
		<abstract>
			<par><![CDATA[An association rule generation algorithm usually generatestoo many rules including a lot of uninteresting ones.Many interestingness criteria are proposed to prune thoseuninteresting rules. However, they work in post-pruningprocess and hence do not improve the rule generation efciency. In this paper, we discuss properties of informativerule set and conclude that the informative rule set includesall interesting rules measured by many commonly used interestingnesscriteria, and that rules excluded by the informativerule set are forwardly prunable, i.e. they can be removedin the rule generation process instead of post pruning.Based on these properties, we propose a Direct Interestingrule Generation algorithm, DIG, to directly generateinteresting rules dened by any of 12 interestingness criteriadiscussed in this paper. We further show experimentallythat DIG is faster and uses less memory than Apriori.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14170459</person_id>
				<author_profile_id><![CDATA[81100486291]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jiuyong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15023461</person_id>
				<author_profile_id><![CDATA[81100126776]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yanchun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. Swami. Mining associations between sets of items in massive databases. In <i>Proc. of the ACM SIGMOD Int'l Conference on Management of Data</i>, pages 207-216, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In <i>Proceedings of the Twentieth International Conference on Very Large Databases</i>, pages 487-499, Santiago, Chile, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312219</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Bayardo and R. Agrawal. Mining the most interesting rules. In <i>Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 145-154, N.Y., 1999. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847249</ref_obj_id>
				<ref_obj_pid>846218</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Bayardo, R. Agrawal, and D. Gunopulos. Constraint-based rule mining in large, dense database. In <i>Proc. of the 15th Int'l Conf. on Data Engineering</i>, pages 188-197, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253327</ref_obj_id>
				<ref_obj_pid>253262</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, and C. Silverstein. Beyond market baskets: Generalizing association rules to correlations. <i>SIGMOD Record (ACM Special Interest Group on Management of Data)</i>, 26(2):265, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253325</ref_obj_id>
				<ref_obj_pid>253260</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, J. D. Ullman, and S. Tsur. Dynamic itemset counting and implication rules for market basket data. In <i>Proceedings, ACM SIGMOD International Conference on Management of Data: SIGMOD 1997: May 13-15, 1997, Tucson, Arizona, USA</i>, volume 26(2), pages 255-264, NY, USA, 1997. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649520</ref_obj_id>
				<ref_obj_pid>645322</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. Clark and R. Boswell. Rule induction with CN2: Some recent improvements. In <i>Machine Learning - EWSL-91</i>, pages 151-163, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847313</ref_obj_id>
				<ref_obj_pid>846219</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[E. Cohen, M. Datar, S. Fujiwara, A. Gionis, P. Indyk, R. Motwani, J. Ullman, and C. Yang. Finding interesting associations without support pruning. In <i>16th International Conference on Data Engineering (ICDE' 00)</i>, pages 489- 500, Washington - Brussels - Tokyo, 2000. IEEE.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642896</ref_obj_id>
				<ref_obj_pid>642891</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[V. Dhar and A. Tuzhilin. Abstract-driven pattern discovery in databases. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 5(6), 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233313</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Fukuda, Y. Morimoto, S. Morishita, and T. Tokuyama. Data mining using two-dimensional optimized association rules: scheme, algorithms, and visualization. In <i>Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data, Montreal, Quebec, Canada, June 4-6, 1996</i>, pages 13-23, New York, 1996. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>Proc. 2000 ACM-SIGMOD Int. Conf. on Management of Data (SIGMOD'00)</i>, pages 1-12, May, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657868</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Li, H. Shen, and R. Topor. Mining the smallest association rule set for prediction. In <i>Proceedings of 2001 IEEE International Conference on Data Mining (ICDM 2001)</i>, pages 361-368. IEEE Computer Society Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Li, H. Shen, and R. Topor. Mining the optimal class association rule set. <i>Knowledge-Based System</i>, 15(7):399-405, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>965869</ref_obj_id>
				<ref_obj_pid>965846</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Li, H. Shen, and R. Topor. Mining informative rule set for prediction. <i>Journal of intelligent information systems</i>, in press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[R. Michalski, I. Mozetic, J. Hong, and N. Lavrac. The AQ15 inductive learning system: an overview and experiments. In <i>Proceedings of IMAL 1986</i>, Orsay, 1986. Universit&#233; de Paris-Sud.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>541177</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. M. Mitchell. <i>Machine Learning</i>. McGraw-Hill, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223813</ref_obj_id>
				<ref_obj_pid>223784</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. S. Park, M. Chen, and P. S. Yu. An effective hash based algorithm for mining association rules. In <i>ACM SIGMOD Intl. Conf. Management of Data</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[G. Piatetsky-Shapiro. Discovery, analysis and presentation of strong rules. In G. Piatetsky-Shapiro, editor, <i>Knowledge Discovery in Databases</i>, pages 229-248. AAAI Press / The MIT Press, Menlo Park, California, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335376</ref_obj_id>
				<ref_obj_pid>335191</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[P. Shenoy, J. R. Haritsa, S. Sudarshan, G. Bhalotia, M. Bawa, and D. Shah. Turbo-charging vertical mining of large databases. In <i>Proceedings of the ACM SIGMOD International Conference on Management of Data (SIGMOD- 99)</i>, ACM SIGMOD Record 29(2), pages 22-33, Dallas, Texas, 1999. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775053</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[P. Tan, V. Kumar, and J. Srivastava. Selecting the right interestingness measure for association patterns. In <i>Proceedings of the eighth ACMKDD international conference on knowledge discovery and data mining</i>, pages 32-41, Edmonton, Canada, 2002. ACM press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622635</ref_obj_id>
				<ref_obj_pid>1622620</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[G. I. Webb. OPUS: An efficient admissible algorithm for unordered search. In <i>Journal of Artificial Intelligence Research</i>, volume 3, pages 431-465, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347112</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[G. I. Webb. Efficient search for association rules. In <i>Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-00)</i>, pages 99-107, N. Y., 2000. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347101</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Generating non-redundant association rules. In <i>6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 34-43, August 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. New algorithms for fast discovery of association rules. In <i>Proceedings of the Third International Conference on Knowledge Discovery and Data Mining (KDD-97)</i>, page 283. AAAI Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502572</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Z. Zheng, R. Kohavi, and L. Mason. Real world performance of association rule algorithms. In <i>Proceedings of the seventh International Conference on Knowledge Discovery and Data Mining (SIGKDD-01)</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952148</article_id>
		<sort_key>163</sort_key>
		<display_label></display_label>
		<pages>163</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Spatial Interest Pixels (SIPs)]]></title>
		<subtitle><![CDATA[Useful Low-Level Features of Visual Media Data]]></subtitle>
		<page_from>163</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952148</url>
		<abstract>
			<par><![CDATA[Visual media data such as an image is the raw data representationfor many important applications. The biggestchallenge in using visual media data comes from the extremelyhigh dimensionality. We present a comparativestudy on spatial interest pixels (SIPs), including eight-way(a novel SIP miner), Harris, and Lucas-Kanade, whose extractionis considered as an important step in reducing thedimensionality of visual media data. With extensive casestudies, we have shown the usefulness of SIPs as the low-levelfeatures of visual media data. A class-preserving dimensionreduction algorithm (using GSVD) is applied tofurther reduce the dimension of feature vectors based onSIPs. The experiments showed its superiority over PCA.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Image databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.4.10</cat_node>
				<descriptor>Multidimensional</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240.10010241</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations->Image representations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010240</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision representations</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003253</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Multimedia databases</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14166024</person_id>
				<author_profile_id><![CDATA[81100475605]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Qi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14026671</person_id>
				<author_profile_id><![CDATA[81100042425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jieping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ye]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P42724</person_id>
				<author_profile_id><![CDATA[81100616375]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chandra]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kambhamettu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>241358</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. Arya. Nearest neighbor searching and applications. In <i>Ph. D. Thesis, University of Maryland, College Park, MD</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261512</ref_obj_id>
				<ref_obj_pid>261506</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. Belhumeur, J. Hespanha, and D. Kriegman. Eigenfaces vs. fisherfaces: Recognition using class specific linear projection. <i>IEEE TPAMI</i>, 19(7):711-720, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Bergen and M. Landy. Computational modeling of visual texture segregation. In <i>Computational Models of Visual Perception</i>, pages 253-271. MIT Press, Cambridge MA, 1991., 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Chellappa, C. Wilson, and S. Sirohey. Human and machine recognition of faces: A survey. <i>Proceedings of the IEEE</i>, 83(5):705-740, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Ekman and W. Friesen. Pictures of facial affect. In <i>Consulting psychologist, Palo Alto, CA</i>, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Fisher. The use of multiple measurements in taxonomic problems. In <i>Annals of Eugenics 7</i>, pages 179-188, 1936.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>939141</ref_obj_id>
				<ref_obj_pid>938978</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Gevers and A. W. M. Smeulders. Image indexing using composite color and shape invariant features. In <i>ICCV</i>, pages 576-581.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P. Hancock, A. Burton, and V. Bruce. Face processing : Human perception and principal components analysis. In <i>Memory Cognition, 24</i>, pages 26-40, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. Harris and M. Stephens. A combined corner and edge detector. In <i>Proc. 4th Alvey Vision Conference, Manchester</i>, pages 147-151, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. Huber. <i>Robust Statistics</i>. Wiley, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[I. Jolliffe. Principle component analysis. <i>Journal of Educational Psychology</i>, 24:417-441, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. Joyce, P. lewis, R. Tansley, M. Dobie, and W. Hall. Semiotics and agents for integrating and navigating through multimedia representations of concepts. In <i>Proceedings of SPIE Vol. 3972, Storage and Retrieval for Media Databases 2000</i>, pages 132-143, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>641075</ref_obj_id>
				<ref_obj_pid>641007</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[W.-H. Lin and A. Hauptmann. News video classification using svm-based multimodal classifiers and combination strategies. In <i>ACM Multimedia, Juan-les-Pins, France</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C. V. Loan. Generalizing the singular value decomposition. <i>SIAM Journal on Numerical Analysis</i>, 13(1):76-83, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[E. Loupias and N. Sebe. Wavelet-based salient points for image retrieval. In <i>RR 99.11, Laboratoire Reconnaissance de Formes et Vision, INSA Lyon</i>, November 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>354403</ref_obj_id>
				<ref_obj_pid>354384</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Y. Lu, C. Hu, X. Zhu, H. Zhang, and Q. Yang. A unified framework for semantics and feature based relevance feedback in image retrieval systems. In <i>ACM Multimedia</i>, pages 31-37, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1623280</ref_obj_id>
				<ref_obj_pid>1623264</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[B. D. Lucas and T. Kanade. An iterative image registration technique with an application to stereo vision. In <i>International Joint Conference on Artificial Intelligence</i>, pages 674-679, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>330501</ref_obj_id>
				<ref_obj_pid>330473</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[M. Lyons, J. Budynek, and S. Akamatsu. Automatic classification of single facial images. <i>IEEE transcations on PAMI</i>, 21(12):1357-1362, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[A. Martinez and R. Benavente. The ar face database. Technical Report CVC Tech. Report No. 24, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364294</ref_obj_id>
				<ref_obj_pid>364267</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[A. Martinez and A. Kak. PCA versus LDA. <i>IEEE TPAMI</i>, 23(2):228-233, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[C. Paige and M.A. Saunders. Towards a generalized singular value decomposition. <i>SIAM Journal on Numerical Analysis</i>, 18:398-405, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>782166</ref_obj_id>
				<ref_obj_pid>782132</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[H. Park, P. Howland, and M. Jeon. Cluster structure preserving dimension reduction based on the generalized singular value decomposition. <i>SIAM Journal on Matrix Analysis and Applications</i>, to appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>350678</ref_obj_id>
				<ref_obj_pid>350676</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[C. Schmid, R. Mohr, and C. Bauckhage. Evaluation of interest point detectors. <i>International Journal of Computer Vision</i>, 37(2):151-172, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>796195</ref_obj_id>
				<ref_obj_pid>795661</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[T. Sim, R. Sukthankar, M. Mullin, and S. Baluja. Memory-based face recognition for visitor identification. In <i>Proc. 4th Intl. Conf. on FG'00</i>, pages 214-220.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>795500</ref_obj_id>
				<ref_obj_pid>795495</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[J. Smith. Integrated spatial and feature image systems: Retrieval and compression. In <i>PhD thesis, Graduate School of Arts and Sciences, Columbia University, New York, NY</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134841</ref_obj_id>
				<ref_obj_pid>134839</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[M. Swain and D. Ballard. Color indexing. <i>Int. J. computer vision</i>, 7:11-32, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1326894</ref_obj_id>
				<ref_obj_pid>1326887</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[M. Turk and A. Pentland. Eigenfaces for recognition. <i>Journal of Cognitive Neuroscience</i>, 3(1):71-86, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[J. Ye, R. Janardan, C. park, and H. Park. A new optimization criterion for generalized discriminant analysis on undersampled problems. Technical Report TR-026-03, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Z. Zhang. Feature-based facial expression recognition: experiments with a multi-layer perceptron. <i>Intl. Journal of Pattern Recognition and Artificial Intelligence</i>, 13(6):893-911, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[W. Zhao, R. Chellappa, A. Rosenfeld, and P. Phillips. Face recognition: A literature survey. Technical Report CAR-TR- 948, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952188</article_id>
		<sort_key>171</sort_key>
		<display_label></display_label>
		<pages>171</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Unsupervised Link Discovery in Multi-relational Data via Rarity Analysis]]></title>
		<page_from>171</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952188</url>
		<abstract>
			<par><![CDATA[A significant portion of knowledge discovery and datamining research focuses on finding patterns of interest indata. Once a pattern is found, it can be used to recognizesatisfying instances. The new area of link discoveryrequires a complementary approach, since patterns ofinterest might not yet be known or might have too fewexamples to be learnable. This paper presents anunsupervised link discovery method aimed at discoveringunusual, interestingly linked entities in multi-relationaldatasets. Various notions of rarity are introduced tomeasure the "interestingness" of sets of paths andentities. These measurements have been implemented andapplied to a real-world bibliographic dataset where theygive very promising results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14086918</person_id>
				<author_profile_id><![CDATA[81100221379]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shou-de]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P106789</person_id>
				<author_profile_id><![CDATA[81100586213]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hans]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chalupsky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Kovalerchuk, E. Vityaev. <i>Correlation of complex evidences and link discovery. The Fifth International Conference on Forensic Statistics</i>. 2002. Venice, Italy.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375668</ref_obj_id>
				<ref_obj_pid>375663</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Aggarwal, P. Yu. <i>Outlier detection for high dimensional data. ACM SIGMOD Conference</i>. 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671334</ref_obj_id>
				<ref_obj_pid>645924</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[E.M. Knorr, R.T. Ng. <i>Algorithms for Mining Distance-Based Outliers in Large Datasets. Proc. of VLDB Conf.</i> 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. A. Freitas, <i>On rule interestingness measures. Knowledge-Based Systems</i>. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>234651</ref_obj_id>
				<ref_obj_pid>234644</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Kimball, <i>Dealing with Dirty Data, DBMS Magazine</i>. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>630532</ref_obj_id>
				<ref_obj_pid>630311</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[L. B. Holder, D. J. Cook, <i>Graph-based data mining</i>. IEEE Intelligent Systems 15, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669364</ref_obj_id>
				<ref_obj_pid>645803</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M.M. Breunig, H.P. Kriegel, R. T. Ng, and J. Sander. <i>Optics-of: Identifying local outliers. Proc. of PKDD '99</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P.N. Tan, V. Kumar. <i>Interestingness measures for association patterns: A perspective. KDD</i>. 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R. Hilderman, H. Hamilton, <i>Knowledge discovery and interestingness measures: A survey</i>. 1999, Technical Report, University of Regina:]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. J. Mooney, P. Melville, L. P. Rupert Tang, J. Shavlik, I.d. Dutra, D. Page, V. S. Costa. <i>Relational Data Mining with Inductive Logic Programming for Link Discovery. Proceedings of the National Science Foundation Workshop on Next Generation Data Mining</i>. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R.J. Mooney, P. Melville, L. P. Rupert Tang, J. Shavlik, I.d. Dutra, D. Page, V. S. Costa. <i>Relational Data Mining with Inductive Logic Programming for Link Discovery. Proceedings of the National Science Foundation Workshop on Next Generation Data Mining</i>. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>297827</ref_obj_id>
				<ref_obj_pid>297805</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Brin, L. Page. <i>The anatomy of a large-scale hypertextual Web search engine. Proceedings of the 7th International World Wide Web Conference</i>. 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>605153</ref_obj_id>
				<ref_obj_pid>605152</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. Candan, W.S. Li, <i>Reasoning for Web Document Associations and Its Applications in Site Map Construction</i>. International Journal of Data and Knowledge Engineering, 2002: p. 121-150.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335437</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S. Ramaswamy, R. Rastogi, K. Shim. <i>Efficient algorithms for mining outliers from large data sets. Proceedings of the ACM SIGMOD Conference</i>. 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502567</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. Shekhar, C.T. Lu, P. Zhang. <i>Detecting Graph-based Spatial Outliers: Algorithms and Applications. The Seventh ACM SIGKDD</i> 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[S. Wasserman, K. Faust, <i>Social Network Analysis: Methods & Applications</i>. 1994: Cambridge, UK: Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[T. Senator, <i>Evidence Extraction and Link Discovery Program</i>. 2002, DARPATech 2002: http://www.darpa.mil/DARPATech2002/presentations/iao_ pdf/speeches/SENATOR.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[D. R. Swanson, <i>Fish Oil, Raynaud's syndrome and undiscovered public knowledge</i>. Perspectives in Biology and Medicine, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. R. Swanson, <i>Somatomedin C and arginine: Implicit connections between mutually isolated literatures</i>. Perspectives in Biology and Medicine, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>240464</ref_obj_id>
				<ref_obj_pid>240455</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[U. Fayyad, G. Piatetsky-Shapiro, P. Smyth, <i>The KDD Process for Extracting Useful Knowledge from Volumes of Data</i>. Communications of the ACM, 1996. p. 27-34.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1643281</ref_obj_id>
				<ref_obj_pid>1643272</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[R. E. Valdes-Perez, <i>Principles of human-computer collaboration for knowledge discovery in science</i>. Artificial Intelligence, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952139</article_id>
		<sort_key>179</sort_key>
		<display_label></display_label>
		<pages>179</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Building Text Classifiers Using Positive and Unlabeled Examples]]></title>
		<page_from>179</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952139</url>
		<abstract>
			<par><![CDATA[This paper studies the problem of building text classifiersusing positive and unlabeled examples. The key feature ofthis problem is that there is no negative example forlearning. Recently, a few techniques for solving thisproblem were proposed in the literature. These techniquesare based on the same idea, which builds a classifier intwo steps. Each existing technique uses a different methodfor each step. In this paper, we first introduce some newmethods for the two steps, and perform a comprehensiveevaluation of all possible combinations of methods of thetwo steps. We then propose a more principled approachto solving the problem based on a biased formulation ofSVM, and show experimentally that it is more accuratethan the existing techniques.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Textual databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.7.5</cat_node>
				<descriptor>Document analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010505</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP79025396</person_id>
				<author_profile_id><![CDATA[81414615435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14070445</person_id>
				<author_profile_id><![CDATA[81430613294]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP80031517</person_id>
				<author_profile_id><![CDATA[81423594355]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xiaoli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77034429</person_id>
				<author_profile_id><![CDATA[81409594078]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wee]]></first_name>
				<middle_name><![CDATA[Sun]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79026458</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>650134</ref_obj_id>
				<ref_obj_pid>645339</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agrawal, R., Bayardo Jr., R. & Srikant, R. (2000) "Athena: Mining-based interactive management of text databases." <i>EDBT</i>-00.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656012</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Basu, S., Banerjee, A., & Mooney, R. (2002) "Semi-supervised clustering by seeding." <i>ICML-02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>340671</ref_obj_id>
				<ref_obj_pid>340534</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bennett, K., and Demiriz. (1998) "A Semi-supervised support vector machines." <i>Advances in Neural information processing systems</i> 11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>279962</ref_obj_id>
				<ref_obj_pid>279943</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blum, A., Mitchell, T. (1998) "Combining labeled and unlabeled data with co-training," <i>COLT-98</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655985</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bockhorst, J., and Craven, M. (2002) "Exploiting relations among concepts to acquire weakly labeled training data." <i>ICML-02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>188586</ref_obj_id>
				<ref_obj_pid>188490</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Buckley, C., Salton G., and Allan J. (1994) "The effect of adding relevance information in a relevance feedback environment," <i>SIGIR-94</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Dempster, A., Laird, N. M. & Rubin. D. (1997) "Maximum likelihood from incomplete data via the EM algorithm." <i>Journal of the Royal Statistical Society</i>, B:39, 1-38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>757188</ref_obj_id>
				<ref_obj_pid>647716</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Denis, F. "PAC learning from positive statistical queries." <i>ALT-98</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1162432</ref_obj_id>
				<ref_obj_pid>1162426</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Denis, F. Gilleron, R. and Tommasi, M. (2002). "Text classification from positive and unlabeled examples." <i>IPMU</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656160</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Ghani, R. (2002) "Combining labeled and unlabeled data for multiclass text categorization." <i>ICML-2002</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658273</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Goldman, S. and Zhou, Y. (2000) "Enhancing supervised learning with unlabeled data." <i>ICML-00</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>668062</ref_obj_id>
				<ref_obj_pid>645753</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Guyon, I., Boser, B. and Vapnik, V. (1993). "Automatic capacity tuning of very large VC-dimension classifiers." <i>Advances in Neural Information Processing Systems</i>, Vol. 5.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649721</ref_obj_id>
				<ref_obj_pid>645326</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Joachims, T. (1998) "Text categorization with support vector machines: Learning with many relevant features." <i>ECML-98</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299104</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Joachims, T. (1999). "Making large-scale SVM learning practical." <i>Advances in Kernel Methods - Support Vector Learning</i>, B. Sch&#246;lkopf and C. Burges and A. Smola (ed.).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Lang, K. (1995). "Newsweeder: Learning to filter netnews." <i>ICML-95</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lee, W. S, and Liu, B. (2003) "Learning with positive and unlabeled examples using weighted logistic regression." <i>ICML-2003</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>188495</ref_obj_id>
				<ref_obj_pid>188490</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Lewis, D., and Gale, W. (1994). "A sequential algorithm for training text classifiers." <i>SIGIR-94</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1630746</ref_obj_id>
				<ref_obj_pid>1630659</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Li, X., and Liu, B. (2003). "Learning to classify text using positive and unlabeled data." <i>IJCAI-03</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Lidstone, G. (1920). "Note on the general case of the Bayes-Laplace formula for inductive or a posteriori probabilities." <i>Transactions of the Faculty of Actuaries</i>, 8:182-192.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656022</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Liu, B., Lee, W. S., Yu, P., and Li, X. (2002). "Partially supervised classification of text documents." <i>ICML-02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944808</ref_obj_id>
				<ref_obj_pid>944790</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Manevitz, L. & Yousef, M. (2001). "One-class SVMs for document classification." <i>J. of Machine Learning research</i>, 2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[McCallum, A., Nigam, K. (1998) "A comparison of event models for na&#239;ve Bayes text classification." <i>AAAI-98 Workshop on Learning for Text Categorization</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657612</ref_obj_id>
				<ref_obj_pid>645528</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Morik, K., Brockhausen, P. and Joachims, T. (1999) "<i>Combining statistical learning with a knowledge-based approach - A case study in intensive care monitoring." ICML-99</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Muggleton, S. (2001). "Learning from the positive data." <i>Machine Learning</i>, Accepted.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655845</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Muslea, I., Minton, S., and Knoblock, C. A. (2002). "Active + semi-supervised learning = robust multiview learning." <i>ICML-02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347724</ref_obj_id>
				<ref_obj_pid>347709</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Nigam, K., McCallum, A., Thrun, S. and & Mitchell, T. (2000). "Text classification from labeled and unlabeled documents using EM." <i>Machine Learning</i>, 39.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>889148</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Osuna, E., R. Freund, and F. Girosi (1997). Support vector machines: Training and applications. AI Memo 1602, Massachusetts Institute of Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656163</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Rakutti, B. Ferra, H. Kowalczyk, A. (2002). "Using unlabeled data for text classification through addition of cluster parameters." <i>ICML-02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Rocchio, J. (1971). "Relevant feedback in information retrieval." In G. Salton (ed.). <i>The smart retrieval system- experiments in automatic document processing</i>, Englewood Cliffs, NJ.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>576628</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Salton, G. and McGill, M. (1983). <i>Introduction to Modern Information Retrieval</i>. McGraw-Hill.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Scholkopf, S. Platt, J. Shawe, J. Smola, A. & Williamson, R. (1999). "Estimating the support of a high-dimensional distribution." <i>Technical Report MSR-TR-99-87</i>, Microsoft Research.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Vapnik, V. (1995). <i>The nature of statistical learning theory</i>, Springer-Verlag, NY, USA, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312647</ref_obj_id>
				<ref_obj_pid>312624</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Yang, Y. and Liu, X. (1999). "A re-examination of text categorization methods." <i>SIGIR-99</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775083</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Yu, H., Han, J. & Chang, K. (2002). "PEBL: Positive example based learning for Web page classification using SVM." <i>KDD-02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Zhang, T. (2000). "The value of unlabeled data for classification problems," <i>ICML-00</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952138</article_id>
		<sort_key>187</sort_key>
		<display_label></display_label>
		<pages>187</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[OP-Cluster]]></title>
		<subtitle><![CDATA[Clustering by Tendency in High Dimensional Space]]></subtitle>
		<page_from>187</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952138</url>
		<abstract>
			<par><![CDATA[Clustering is the process of grouping a set of objects intoclasses of similar objects. Because of unknownness of thehidden patterns in the data sets, the definition of similarityis very subtle. Until recently, similarity measures are typicallybased on distances, e.g Euclidean distance and cosinedistance. In this paper, we propose a flexible yet powerfulclustering model, namely OP-Cluster (Order PreservingCluster). Under this new model, two objects are similaron a subset of dimensions if the values of these twoobjects induce the same relative order of those dimensions.Such a cluster might arise when the expression levels of (co-regulated)genes can rise or fall synchronously in responseto a sequence of environment stimuli. Hence, discovery ofOP-Cluster is essential in revealing significant gene regulatorynetworks. A deterministic algorithm is designed andimplemented to discover all the significant OP-Clusters. Aset of extensive experiments has been done on several realbiological data sets to demonstrate its effectiveness and efficiencyin detecting co-regulated patterns.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Scientific databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010364</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Scientific visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP77048063</person_id>
				<author_profile_id><![CDATA[81414602335]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jinze]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77036336</person_id>
				<author_profile_id><![CDATA[81452601906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>775109</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Ayres, J. E. Gehrke, T. Yiu, and J. Flannick. Sequential PAttern Mining Using Bitmaps. In <i>SIGKDD</i>, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347114</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. C. Agarwal, C. C. Aggarwal, and V. Parsad. Depth first generation of long patterns. In <i>SIGKDD</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304188</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal, C. Procopiuc, J. Wolf, P. S. Yu, and J. S. Park. Fast algorithms for projected clustering. In <i>SIGMOD</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335383</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal and P. S. Yu. Finding generalized projected clusters in high dimensional spaces. In <i>SIGMOD</i>, pages 70-81, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Mining sequential patterns. In <i>ICDE</i>, 3-14, Mar. 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276314</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, J. Gehrke, D. Gunopulos, and P. Raghavan. Authomatic subspace clustering of high dimensional data for data mining applications. In <i>SIGMOD</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>565203</ref_obj_id>
				<ref_obj_pid>565196</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. Ben-Dor, B. Chor, R. Karp, and Z. Yakhini. Discovering Local Structure in Gene Expression Data: The Order-Preserving Submatrix Problem. In <i>RECOMB</i> 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656271</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[K. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft. When is nearest neighbors meaningful. In <i>Proc. of the Int. Conf. Database Theories</i>, pages 217-235, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312199</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. H. Cheng, A.W. Fu, and Y. Zhang. Entropy-based subspace clustering for mining numerical data. In <i>SIGKDD</i>, pages 84-93, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>660833</ref_obj_id>
				<ref_obj_pid>645635</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Y. Cheng and G. Church. Biclustering of expression data. In <i>Proc. of 8th International Conference on Intelligent System for Molecular Biology</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Ester, H. Kriegel, J. Sander, and X. Xu. A density-bsed algorithm for discovering clusters in large spatial databases with noise. In <i>SIGKDD</i>, pages 226-231, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671667</ref_obj_id>
				<ref_obj_pid>645925</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[H.V. Jagadish, J. Madar, and R. Ng. Semantic compression and pattern extraction with fasicicles. In <i>VLDB</i>, pages 186-196, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Liu and W. Wang. Flexible clustering by tendency in high dimensional spaces. Technical Report TR03-009, Computer Science Department, UNC-CH, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656379</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen U. Dayal, and M.-C. Hsu. PrefixSpan mining sequential patterns efficiently by prefix projected pattern growth. In <i>ICDE</i> 2001, pages 215- 226, Apr. 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650382</ref_obj_id>
				<ref_obj_pid>645337</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[R. Srikant and R. Agrawal. Mining sequential patterns: Generalizations and performance improvements. In <i>EDBT</i>'96, pages 3-17, Mar. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[S. Tavazoie, J. Hughes, M. Campbell, R. Cho, and G. Church. Yeast micro data set. In http://arep.med.harvard.edu/biclustering/yeast.matrix, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564737</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[H. Wang, W. Wang, J. Yang, and P. Yu. Clustering by pattern similarity in large data sets, in <i>SIGMOD</i>, pp. 394-405, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>878990</ref_obj_id>
				<ref_obj_pid>876875</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. Yang, W. Wang, H. Wang, and P. S. Yu. -clusters: Capturing subspace correlation in a large data set. In <i>ICDE</i>, pages 517-528, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564738</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[J. Yang, W. Wang, P. Yu, and J. Han. Mining long sequential patterns in a noisy environment. In <i>SIGMOD</i>, pp.406-417, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233324</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[T. Zhang, R. Ramakrishnan, and M. Livny. Birch: An efficient data clustering method for very large databases. In <i>SIGMOD</i>, pages 103-114, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593453</ref_obj_id>
				<ref_obj_pid>593417</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki, S. Parthasarathy, M. Orihara, and W. Li. Parallel algorithm for discovery of association rules. In <i>DMKD</i>, 343- 374, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952151</article_id>
		<sort_key>195</sort_key>
		<display_label></display_label>
		<pages>195</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[Parsing Without a Grammar]]></title>
		<subtitle><![CDATA[Making Sense of Unknown File Formats]]></subtitle>
		<page_from>195</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952151</url>
		<abstract>
			<par><![CDATA[The thousands of specialized structured file formats inuse today present a substantial barrier to freely exchanginginformation between applications programs. We considerthe problem of deducing such basic features as thewhitespace characters, bracketing delimiter symbols, andself-delimiter characters of a given file format from one ormore example files. We demonstrate that for sufficientlylarge example files, we can typically identify the basic featuresof interest.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.7.5</cat_node>
				<descriptor>Graphics recognition and interpretation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.7.5</cat_node>
				<descriptor>Optical character recognition (OCR)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.7.5</cat_node>
				<descriptor>Document analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010505</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010508</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Optical character recognition</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645418</person_id>
				<author_profile_id><![CDATA[81100028673]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Levon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lloyd]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39034392</person_id>
				<author_profile_id><![CDATA[81100248225]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Skiena]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>562056</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Graham, D. Knuth, and O. Patashnik. <i>Concrete Mathematics</i>. Addison-Wesley, second edition, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>262228</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Gusfield. <i>Algorithms on Strings, Trees, and Sequences: Computer Science and Computational Biology</i>. Cambridge University Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Jain and R. Dubes. <i>Algorithms for Clustering Data</i>. Prentice-Hall, Englewood Cliffs NJ, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Lifantsev. Yuntis: Collaborative web resource categorization and ranking project. http://www.ecsl.cs.sunysb.edu/yuntis/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>379726</ref_obj_id>
				<ref_obj_pid>379437</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Lorie. Long term preservation of digital information. In <i>Proceedings of the First ACM/IEEE-CS Joint Conference on Digital Libraries</i>, pages 346-352, Roanoke, Virginia, United States, January 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>279863</ref_obj_id>
				<ref_obj_pid>279860</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Nevill-Manning, T. Reed, and I. Witten. Extracting text from postscript. <i>Software Practice and Experience</i>, pages 481-491, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>644125</ref_obj_id>
				<ref_obj_pid>644108</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[I. Witten. Browsing around a digital library. In <i>Proceedings of the ACM-SIAM Symposium on Discrete Algorithms</i>, Baltimore, Maryland, United States, January 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952173</article_id>
		<sort_key>203</sort_key>
		<display_label></display_label>
		<pages>203</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Probabilistic User Behavior Models]]></title>
		<page_from>203</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952173</url>
		<abstract>
			<par><![CDATA[We present a mixture model based approach for learningindividualized behavior models for the Web users. Weinvestigate the use of maximum entropy and Markov mixturemodels for generating probabilistic behavior models.We first build a global behavior model for the entire populationand then personalize this global model for the existingusers by assigning each user individual componentweights for the mixture model. We then use these individualweights to group the users into behavior model clusters.We show that the clusters generated in this manner areinterpretable and able to represent dominant behavior patterns.We conduct offline experiments on around two monthsworth of data from CiteSeer, an online digital library forcomputer science research papers currently storing morethan 470,000 documents. We show that both maximum entropyand Markov based personal user behavior modelsare strong predictive models. We also show that maximumentropy based mixture model outperforms Markov mixturemodels in recognizing complex user behavior patterns.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>User-centered design</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.1.2</cat_node>
				<descriptor>Probabilistic computation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>World Wide Web (WWW)</descriptor>
				<type>P</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003152</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003757</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Probabilistic computation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003123.10010860.10010859</concept_id>
				<concept_desc>CCS->Human-centered computing->Interaction design->Interaction design process and methods->User centered design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P523299</person_id>
				<author_profile_id><![CDATA[81100486448]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eren]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Manavoglu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P67670</person_id>
				<author_profile_id><![CDATA[81100051841]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dmitry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pavlov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43116611</person_id>
				<author_profile_id><![CDATA[81100126614]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[Lee]]></middle_name>
				<last_name><![CDATA[Giles]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>306124</ref_obj_id>
				<ref_obj_pid>306101</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. G. Buchner and M. D. Mulvenna. Discovering internet marketing intelligence through online analytical web usage mining. <i>SIGMOD Record</i>, 27(4):54-61, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347151</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[I. V. Cadez, D. Heckerman, C. Meek, P. Smyth, and S. White. Visualization of navigation patterns on a web site using model-based clustering. In <i>Knowledge Discovery and Data Mining</i>, pages 280-284, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[I. V. Cadez, P. Smyth, E. Ip, and H. Mannila. Predictive profiles for transaction data using finite mixture models. Technical Report UCI-ICS 01-67, UC Irvine, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Chen and R. Rosenfeld. A gaussian prior for smoothing maximum entropy models. Technical Report CMUCS-99- 108, Carnegie Mellon University, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Cooley, B. Mobasher, and J. Srivastava. Data preparation for mining world wide web browsing patterns. <i>Knowledge and Information Systems</i>, 1(1):5-32, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. P. D. Pavlov, E. Manavoglu and C. L. Giles. Collaborative filtering with maximum entropy. Technical Report 2003- L001, NEC Labs, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. N. Darroch and D. Ratcliff. Generalized iterative scaling for log-linear models. <i>Annals of Mathematical Statistics</i>, 43:1470-1480, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. <i>Journal of the Royal Statistical Society</i>, B-39:1-38, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Goodman. Classes for fast maximum entropy training. In <i>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073086</ref_obj_id>
				<ref_obj_pid>1073083</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Goodman. Sequential conditional generalized iterative scaling. In <i>Proceedings of ACL</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593440</ref_obj_id>
				<ref_obj_pid>593414</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[D. Heckerman. Bayesian networks for data mining. <i>Data Mining and Knowledge Discovery</i>, 1(1):79-119, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944735</ref_obj_id>
				<ref_obj_pid>944733</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. Heckerman, D. Chickering, C. Meek, R. Rounthwaite, and C. Kadie. Dependency networks for density estimation, collaborative filtering, and data visualization. <i>Journal of Machine Learning Research</i>, 1:49-75, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280484</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[F. Jelinek. <i>Statistical Methods for Speech Recognition</i>. Cambridge. MA:MIT Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>621256</ref_obj_id>
				<ref_obj_pid>619041</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S. Lawrence, C. L. Giles, and K. Bollacker. Digital libraries and Autonomous Citation Indexing. <i>IEEE Computer</i>, 32(6):67-71, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[B. Liu, W. Hsu, and Y. Ma. Integrating classification and association rule mining. In <i>Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining</i>, pages 80-96, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345169</ref_obj_id>
				<ref_obj_pid>345124</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[B. Mobasher, R. Cooley, and J. Srivastava. Automatic personalization based on Web usage mining. <i>Communications of the ACM</i>, 43(8):142-151, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952137</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[D. Pavlov. Sequence modeling with mixtures of conditional maximum entropy distributions. In <i>Proceedings of the Third IEEE Conference on Data Mining (ICDM'03)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[D. Pavlov and D. Pennock. A maximum entropy approach to collaborative filtering in dynamic, sparse, high-dimensional domains. In <i>Proceedings of Neural Information Processing Systems</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>295797</ref_obj_id>
				<ref_obj_pid>295240</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[M. Perkowitz and O. Etzioni. Adaptive web sites: Automatically synthesizing web pages. In <i>Proceedings of the Fifteenth National Conference on Artificial Intelligence</i>, pages 727-732, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>251709</ref_obj_id>
				<ref_obj_pid>251695</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. D. Pietra, V. D. Pietra, and J. Lafferty. Inducing features of random fields. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 19(4):380-393, April 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192905</ref_obj_id>
				<ref_obj_pid>192844</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[P. Resnick, N. Iacovou, M. Suchak, P. Bergstorm, and J. Riedl. GroupLens: An Open Architecture for Collaborative Filtering of Netnews. In <i>Proceedings of ACM 1994 Conference on Computer Supported Cooperative Work</i>, pages 175-186, Chapel Hill, North Carolina, 1994. ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952185</article_id>
		<sort_key>211</sort_key>
		<display_label></display_label>
		<pages>211</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Privacy-preserving Distributed Clustering using Generative Models]]></title>
		<page_from>211</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952185</url>
		<abstract>
			<par><![CDATA[We present a framework for clustering distributed datain unsupervised and semi-supervised scenarios, taking intoaccount privacy requirements and communication costs.Rather than sharing parts of the original or perturbed data,we instead transmit the parameters of suitable generativemodels built at each local data site to a central location.We mathematically show that the best representative of allthe data is a certain "mean" model, and empirically showthat this model can be approximated quite well by generatingartificial samples from the underlying distributions usingMarkov Chain Monte Carlo techniques, and then fittinga combined global model with a chosen parametric form tothese samples. We also propose a new measure that quantifiesprivacy based on information theoretic concepts, andshow that decreasing privacy leads to a higher quality of thecombined model and vice versa. We provide empirical resultson different data types to highlight the generality of ourframework. The results show that high quality distributedclustering can be achieved with little privacy loss and lowcommunication cost.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.1</cat_node>
				<descriptor>Data models</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40026113</person_id>
				<author_profile_id><![CDATA[81100331031]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Srujana]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Merugu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15036181</person_id>
				<author_profile_id><![CDATA[81100558602]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Joydeep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ghosh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>375602</ref_obj_id>
				<ref_obj_pid>375551</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Agrawal and C. C. Aggarwal. On the design and quantification of privacy preserving data mining algorithms. In <i>Symposium on Principles of Database Systems</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335438</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Privacy-preserving data mining. In <i>ACM SIGMOD</i>, pages 439-450, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>599643</ref_obj_id>
				<ref_obj_pid>599611</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K. S. Azoury and M. K. Warmuth. Relative loss bounds for on-line density estimation with the exponential family of distributions. <i>Machine Learning</i>, 43(3):211-246, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging predictors. <i>Machine Learning</i>, 24(2):123-140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>129837</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T.M. Cover and J. A. Thomas. <i>Elements of Information Theory</i>. Wiley, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. <i>J. Royal Statistical Society. Series B (Methodological)</i>, 39(1):1-38, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>744385</ref_obj_id>
				<ref_obj_pid>648035</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon and D. S. Modha. A data-clustering algorithm on distributed memory multiprocessors. In <i>ACM SIGKDD</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775080</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. In <i>KDD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[U. M. Fayyad, C. Reina, and P. S. Bradley. Initialization of iterative refinement clustering algorithms. In <i>ICML</i>, pages 194-198, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. L. N. Fred and A. K. Jain. Data clustering using evidence accumulation. In <i>ICPR</i>, pages IV:276-280, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Ghosh. Scalable clustering methods for data mining. In N. Ye, editor, <i>Handbook of Data Mining</i>, pages 247-277. Lawrence Erlbaum, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>761140</ref_obj_id>
				<ref_obj_pid>648035</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[E. Johnson and H. Kargupta. Collective, hierarchical clustering from distributed, heterogeneous data. In M. Zaki and C. Ho, editors, <i>Large-Scale Parallel KDD Systems</i>, volume 1759 of <i>LNCS</i>, pages 221-244. Springer-Verlag, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>704129</ref_obj_id>
				<ref_obj_pid>646765</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Y. Lindell and B. Pinkas. Privacy preserving data mining. <i>LNCS</i>, 1880:36-77, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. M. Neal. Probabilistic inference using Markov Chain Monte Carlo methods. Technical Report CRG-TR-93-1, Dept. of Computer Science, University of Toronto, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347724</ref_obj_id>
				<ref_obj_pid>347709</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[K. Nigam, A. K. Mccallum, S. Thrun, and T. Mitchell. Text classification from labeled and unlabeled documents using EM. <i>Machine Learning</i>, 39(2/3):103-134, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. Papoulis. <i>Probability, Random Variables, and Stochastic Processes</i>. McGraw-Hill, New York, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>599605</ref_obj_id>
				<ref_obj_pid>599591</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[P. Smyth and D. Wolpert. An evaluation of linearly combining density estimators via stacking. <i>Machine Learning</i>, 36(1/2):53-89, July 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944935</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[A. Strehl and J. Ghosh. Cluster ensembles - a knowledge reuse framework for combining partitionings. <i>JMLR</i>, pages 3:583-617, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300550</ref_obj_id>
				<ref_obj_pid>300547</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[K. Yamanishi. Distributed cooperative Bayesian learning strategies. <i>Information and Computation</i>, 150:22-56, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952183</article_id>
		<sort_key>219</sort_key>
		<display_label></display_label>
		<pages>219</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[Change Profiles]]></title>
		<page_from>219</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952183</url>
		<abstract>
			<par><![CDATA[In this paper we introduce a generalization of associationrules: change profiles. We analyze their properties, describetheir relationship to other structures in pattern discoveryand sketch their possible applications. We studyhow the frequent patterns can be clustered based on theirchange profiles and propose methods for approximating thefrequencies of the patterns from the approximate changeprofiles and bounding the intervals where the frequencies ofthe patterns are guaranteed to be. We evaluate empiricallythe methods for estimating the frequencies and the stabilityof their frequency estimates under different kinds of noise.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP36026833</person_id>
				<author_profile_id><![CDATA[81321495651]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Taneli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mielik&#228;inen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>257975</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I. Verkamo. Fast discovery of association rules. In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors, <i>Advances in Knowledge Discovery and Data Mining</i>, chapter 12, pages 307-328. AAAI/MIT Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>554706</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[G. Ausiello, P. Crescenzi, V. Kann, A. Marchetti-Spaccamela, and M. Protasi. <i>Complexity and Approximation: Combinatorial Optimization Problems and Their Approximability Properties</i>. Springer-Verlag, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>381017</ref_obj_id>
				<ref_obj_pid>380995</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Y. Bastide, R. Taouil, N. Pasquier, G. Stumme, and L. Lakhai. Mining frequent patterns with counting inference. <i>SIGKDD Explorations</i>, 2(2):66-75, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. Borgelt and R. Kruse. Induction of association rules: Apriori implementation. In W. H&#228;rdle and B. R&#246;nz, editors, <i>15th Conference on Computational Statistics (Compstat 2002)</i>, pages 395-400. Physika Verlag, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>693194</ref_obj_id>
				<ref_obj_pid>646418</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J.-F. Boulicaut and A. Bykowski. Frequent closures as a concise representation for binary data mining. In T. Terano, H. Liu, and A. L. P. Chen, editors, <i>Knowledge Discovery and Data Mining</i>, volume 1805 of <i>Lecture Notes in Artificial Intelligence</i>, pages 62-73. Springer-Verlag, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>608013</ref_obj_id>
				<ref_obj_pid>608006</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J.-F. Boulicaut, A. Bykowski, and C. Rigotti. Free-sets: a condensed representation of Boolean data for the approximation of frequency queries. <i>Data Mining and Knowledge Discovery</i>, 7(1):5-22, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375604</ref_obj_id>
				<ref_obj_pid>375551</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. Bykowski and C. Rigotti. A condensed representation to find frequent patterns. In <i>Proceedings of the Twenteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems</i>. ACM, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>670313</ref_obj_id>
				<ref_obj_pid>645806</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Calders and B. Goethals. Mining all non-derivable frequent itemsets. In T. Elomaa, H. Mannila, and H. Toivonen, editors, <i>Principles of Data Mining and Knowledge Discovery</i>, volume 2431 of <i>Lecture Notes in Artificial Intelligence</i>, pages 74-865. Springer-Verlag, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. Calders and B. Goethals. Minimal <i>k</i>-free representations of frequent sets. In N. Lavrac, D. Gamberger, L. Todorovski, and H. Blockeel, editors, <i>Knowledge Discovery in Databases: PKDD 2003</i>, volume 2838 of <i>Lecture Notes in Artificial Intelligence</i>. Springer-Verlag, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>588815</ref_obj_id>
				<ref_obj_pid>588732</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E. G. Coffman Jr., C. Courcoubetis, M. R. Garey, D. S. Johnson, P. W. Shor, R. R. Weber, and M. Yannakakis. Perfect packing theorems and the average-case behaviour of optimal and online bin packing. <i>SIAM Review</i>, 44(1):95-108, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>755473</ref_obj_id>
				<ref_obj_pid>648301</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Dasgupta. Performance guarantees for hierarchical clustering. In J. Kivinen and R. H. Sloan, editors, <i>Computational Learning Theory</i>, volume 2375 of <i>Lecture Notes in Artificial Intelligence</i>, pages 351-363. Springer-Verlag, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>780550</ref_obj_id>
				<ref_obj_pid>780542</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[W. F. de la Vega, M. Karpinski, C. Kenyon, and Y. Rabani. Approximation schemes for clustering problems. In <i>Proceedings on 35th Annual ACM Symposium on Theory of Computing</i>. ACM, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>568575</ref_obj_id>
				<ref_obj_pid>568574</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[V. Estivill-Castro. Why so many clustering algorithms - a position paper. <i>SIGKDD Explorations</i>, 4(1):65-75, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>62255</ref_obj_id>
				<ref_obj_pid>62212</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[T. Feder and D. H. Greene. Optimal algorithms for approximate clustering. In <i>Proceedings of the twentieth annual ACM Symposium on Theory of Computing, Chicago, Illinois, May 2-4, 1988</i>, pages 434-444. ACM, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>302499</ref_obj_id>
				<ref_obj_pid>302490</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[U. Feige and J. Kilian. Zero knowledge and the chromatic number. <i>Journal of Computer and Systems Science</i>, 57(2):187-199, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628230</ref_obj_id>
				<ref_obj_pid>627340</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. Garofalakis, R. Rastogi, and K. Shim. Mining sequential patterns with regular expression constraints. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 14(3):530-552, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657870</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[F. Geerts, B. Goethals, and J. Van den Bussche. A tight upper bound on the number of candidate patterns. In N. Cercone, T. Y. Lin, and X. Wu, editors, <i>Proceedings of the 2001 IEEE International Conference on Data Mining (ICDM 2001)</i>, pages 155-162. IEEE Computer Society, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In W. Chen, J. F. Naughton, and P. A. Bernstein, editors, <i>Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data</i>, pages 1- 12. ACM, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>738871</ref_obj_id>
				<ref_obj_pid>647915</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. J. Hand. Pattern detection and discovery. In D. Hand, N. Adams, and R. Bolton, editors, <i>Pattern Detection and Discovery</i>, volume 2447 of <i>Lecture Notes in Artificial Intelligence</i>, pages 1-12. Springer-Verlag, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[T. Hastie, R. Tibshirani, and J. Friedman. <i>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</i>. Springer Series in Statistics. Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>360421</ref_obj_id>
				<ref_obj_pid>360402</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. Hipp, U. G&#252;ntzer, and G. Nakhaeizadeh. Algorithms for association rule mining - a general survey and comparison. <i>SIGKDD Explorations</i>, 1(2):58-64, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>608115</ref_obj_id>
				<ref_obj_pid>608109</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[J. D. Holt and S. M. Chung. Mining association rules using inverted hashing and pruning. <i>Information Processing Letters</i>, 82:211-220, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593530</ref_obj_id>
				<ref_obj_pid>593434</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[T. Imielinski, L. Khachiyan, and A. Abdulghani. Cube-grades: Generalizing association rules. <i>Data Mining and Knowledge Discovery</i>, 6(3):219-257, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[J. Kleinberg. An impossibility theorem for clustering. In <i>Advances in Neural Information Processing Systems (NIPS)</i>, volume 15, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657874</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[M. Kryszkiewicz. Concise representation of frequent patterns based on disjunction-free generators. In N. Cercone, T. Y. Lin, and X. Wu, editors, <i>Proceedings of the 2001 IEEE International Conference on Data Mining</i>, pages 305-312. IEEE Computer Society, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844733</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[M. Kurakochi and G. Karypis. Discovering frequent geometric subgraphs. In <i>Proceedings of the 2002 IEEE International Conference on Data Mining</i>. IEEE Computer Society, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>684421</ref_obj_id>
				<ref_obj_pid>646255</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[H. Mannila. Local and global methods in data mining: Basic techniques and open problems. In P. Widmayer, F. Triguero, R. Morales, M. Hennessy, S. Eidenbenz, and R. Conejo, editors, <i>Automata, Languages and Programming</i>, volume 2380 of <i>Lecture Notes in Computer Science</i>, pages 57-68. Springer-Verlag, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593448</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and H. Toivonen. Levelwise search and borders of theories in knowledge discovery. <i>Data Mining and Knowledge Discovery</i>, 1(3):241-258, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593449</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[H. Mannila, H. Toivonen, and A. I. Verkamo. Discovery of frequent episodes in event sequences. <i>Data Mining and Knowledge Discovery</i>, 1(3):259-289, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[T. Mielik&#228;inen. Chaining patterns. In G. Grieser, Y. Tanaka, and A. Yamamoto, editors, <i>Discovery Science</i>, volume 2843 of <i>Lecture Notes in Artificial Intelligence</i>, pages 232-243. Springer-Verlag, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1141021</ref_obj_id>
				<ref_obj_pid>1141014</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[T. Mielik&#228;inen. Frequency-based views to pattern collections. In <i>IFIP/SIAM Workshop on Discrete Mathematics and Data Mining</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[T. Mielik&#228;inen and H. Mannila. The pattern ordering problem. In N. Lavrac, D. Gamberger, L. Todorovski, and H. Blockeel, editors, <i>Knowledge Discovery in Databases: PKDD 2003</i>, volume 2838 of <i>Lecture Notes in Artificial Intelligence</i>. Springer-Verlag, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[T. M. Mitchell. Generalization as search. <i>Artificial Intelligence</i>, 18(2):203-226, 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656256</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets for association rules. In C. Beeri and P. Buneman, editors, <i>Database Theory - ICDT'99</i>, volume 1540 of <i>Lecture Notes in Computer Science</i>, pages 398- 416. Springer-Verlag, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844709</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[J. Pei, G. Dong, W. Zou, and J. Han. On computing condensed pattern bases. In <i>Proceedings of the 2002 IEEE International Conference on Data Mining (ICDM 2002)</i>, pages 378-385. IEEE Computer Society, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>588811</ref_obj_id>
				<ref_obj_pid>588732</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[C. M. Reidys and P. F. Stadler. Combinatorial landscapes. <i>SIAM Review</i>, 44(1):3-54, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628066</ref_obj_id>
				<ref_obj_pid>627328</ref_obj_pid>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Scalable algorithms for association mining. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 12(3):372-390, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775058</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Efficiently mining frequent trees in a forest. In D. Hand, D. Keim, and R. Ng, editors, <i>Proceedings of the Eight International Conference on Knowledge Discovery and Data Mining (KDD-2002)</i>. ACM, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952166</article_id>
		<sort_key>227</sort_key>
		<display_label></display_label>
		<pages>227</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Complex Spatial Relationships]]></title>
		<page_from>227</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952166</url>
		<abstract>
			<par><![CDATA[This paper describes the need for mining complex relationshipsin spatial data. Complex relationships are definedas those involving two or more of: multi-feature colocation,self-colocation, one-to-many relationships, self-exclusionand multi-feature exclusion. We demonstrate that even inthe mining of simple relationships, knowledge of complexrelationships is necessary to accurately calculate the significanceof results. We implement a representation of spatialdata such that it contains known 'weak-monotonic' properties,which are exploited for the efficient mining of complexrelationships, and discuss the strengths and limitations ofthis representation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.1</cat_node>
				<descriptor>Data models</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14187045</person_id>
				<author_profile_id><![CDATA[81100538198]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Munro]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15019435</person_id>
				<author_profile_id><![CDATA[81100002847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sanjay]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chawla]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14156753</person_id>
				<author_profile_id><![CDATA[81539770956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Pei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In J. B. Bocca, M. Jarke, and C. Zaniolo, editors, <i>Proc. 20th Int. Conf. Very Large Data Bases, VLDB</i>, pages 487-499. Morgan Kaufmann, 12-15 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[T. C. Bailey and A. T. Gatrell. <i>Interactive spatial data analysis</i>. Longman Scientific & Technical, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642942</ref_obj_id>
				<ref_obj_pid>642936</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Rastogi, and K. Shim. Mining optimized gain rules for numeric attributes. <i>IEEE transactions on knowledge and data engineering</i>, 15, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. Piatetsky-Shapiro. <i>Discovery, analysis and presentation of strong rules</i>. AAAI/MIT Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In W. Chen, J. Naughton, and P. A. Bernstein, editors, <i>2000 ACM SIGMOD Intl. Conference on Management of Data</i>, pages 1-12. ACM Press, 05 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952630</ref_obj_id>
				<ref_obj_pid>952532</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Huang, H. Xiong, and S. Shekhar. Mining confident colocation rules without a support threshold. In <i>Proc. 18th ACM Symposium on Applied Computing (ACM SAC)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>718925</ref_obj_id>
				<ref_obj_pid>647224</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[K. Koperski and J. Han. Discovery of spatial association rules in geographic information databases. In M. J. Egenhofer and J. R. Herring, editors, <i>Proc. 4th Int. Symp. Advances in Spatial Databases, SSD</i>, volume 951, pages 47-66. Springer-Verlag, 6-9 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952166</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Munro, S. Chawla, and P. Sun. Complex spatial relationships. <i>University of Sydney, School of Information Technologies Technical Report 539</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. J. Peuquet. <i>Representations of space and time</i>. Guilford Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. Shekhar and S. Chawla. <i>Spatial Databases, A Tour</i>. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>719094</ref_obj_id>
				<ref_obj_pid>647227</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Shekhar and Y. Huang. Discovering spatial co-location patterns: A summary of results. <i>Lecture Notes in Computer Science</i>, 2121, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655984</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[X. Wu, C. Zhang, and S. Zhang. Mining both positive and negative association rules. In <i>19th International Conference on Machine Learning (ICML-2002)</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952186</article_id>
		<sort_key>235</sort_key>
		<display_label></display_label>
		<pages>235</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[TECNO-STREAMS]]></title>
		<subtitle><![CDATA[Tracking Evolving Clusters in Noisy Data Streams with a Scalable Immune System Learning Model]]></subtitle>
		<page_from>235</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952186</url>
		<abstract>
			<par><![CDATA[Artificial Immune System (AIS) models hold many promises inthe field of unsupervised learning. However, existing models arenot scalable, which makes them of limited use in data mining. Wepropose a new AIS based clustering approach (TECNO-STREAMS)that addresses the weaknesses of current AIS models. Comparedto existing AIS based techniques, our approach exhibits superiorlearning abilities, while at the same time, requiring low memoryand computational costs. Like the natural immune system, thestrongest advantage of immune based learning compared to otherapproaches is expected to be its ease of adaptation to the dynamicenvironment that characterizes several applications, particularlyin mining data streams. We illustrate the ability of the proposedapproach in detecting clusters in noisy data sets, and in miningevolving user profiles from Web clickstream data in a single pass.TECNO-STREAMS adheres to all the requirements of clusteringdata streams: compactness of representation, fast incremental processingof new data points, and clear and fast identification of outliers.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Parameter learning</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010316</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39026125</person_id>
				<author_profile_id><![CDATA[81100078028]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Olfa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nasraoui]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645257</person_id>
				<author_profile_id><![CDATA[81100417183]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Cesar]]></first_name>
				<middle_name><![CDATA[Cardona]]></middle_name>
				<last_name><![CDATA[Uribe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645256</person_id>
				<author_profile_id><![CDATA[81100341411]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Carlos]]></first_name>
				<middle_name><![CDATA[Rojas]]></middle_name>
				<last_name><![CDATA[Coronel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14211386</person_id>
				<author_profile_id><![CDATA[81100613608]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Fabio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gonzalez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>603884</ref_obj_id>
				<ref_obj_pid>603867</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. Babu and J. Widom. Continuous queries over data streams. In <i>SIGMOD Record'01</i>, pages 109-120, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507519</ref_obj_id>
				<ref_obj_pid>507515</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Barbara. Requirements for clustering data streams. <i>ACM SIGKDD Explorations Newsletter</i>, 3(2):23-27, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Bradley, U. Fayyad, and C. Reina. Scaling clustering algorithms to large databases. In <i>Proceedings of the 4th international conf. on Knowledge Discovery and Data Mining (KDD98)</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287398</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Y. Chen, G. Dong, J. Han, B. W. Wah, and J. Wang. Multi-dimensional regression analysis of time-series data streams. In <i>2002 Int. Conf. on Very Large Data Bases (VLDB'02)</i>, Hong Kong, China, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[I. Cohen. <i>Tending Adam's Garden</i>. Springer Verlag, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Ester, H. P. Kriegel, J. Sander, and X. Xu. A density-based algorithm for discovering clusters in large spatial databases with noise. In <i>Proceedings of the 2nd international conf. on Knowledge Discovery and Data Mining (KDD96)</i>, Portland Oregon, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>796588</ref_obj_id>
				<ref_obj_pid>795666</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Guha, N. Mishra, R. Motwani, and L. O'Callaghan. Clustering data streams. In <i>IEEE Symposium on Foundations of Computer Science (FOCS'00)</i>, Redondo Beach, CA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[F. R. Hampel, E. M. Ronchetti, P. J. Rousseeuw, and W. A. Stahel. <i>Robust Statistics the Approach Based on Influence Functions</i>. John Wiley & Sons, New York, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Hinneburg and D. A. Keim. An efficient approach to clustering in large multimedia databases with noise. In <i>Knowledge Discovery and Data Mining</i>, pages 58-65, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Hunt and D. Cooke. An adaptative, distributed learning system, based on immune system. In <i>IEEE International Conference on Systems, Man and Cybernetics</i>, pages 2494-2499, Los Alamitos, CA, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[N. K. Jerne. The immune system. <i>Scientific American</i>, 229(1):52-60, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[O. Nasraoui, D. Dasgupta, and F. Gonzalez. An artificial immune system approach to robust data mining. In <i>Genetic and Evolutionary Computation Conference (GECCO)</i>, pages 356-363, New York, NY, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[O. Nasraoui , H. Frigui, R. Krishnapuram, and A. Joshi. Mining web access logs using relational competitive fuzzy clustering. In <i>Eighth International Fuzzy Systems Association Congress</i>, Hsinchu, Taiwan, Aug. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[O. Nasraoui and R. Krishnapuram. One step evolutionary mining of context sensitive associations and web navigation patterns. In <i>SIAM conference on Data Mining</i>, pages 531-547, Arlington, VA, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. Timmis, M. Neal, and J. Hunt. An artificial immune system for data analysis. <i>Biosystems</i>, 55(1).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233324</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. Zhang, R. Ramakrishnan, and M. Livny. Birch: An efficient data clustering method for large databases. In <i>ACM SIGMOD International Conference on Management of Data</i>, pages 103-114, New York, NY, 1996. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952176</article_id>
		<sort_key>243</sort_key>
		<display_label></display_label>
		<pages>243</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[Efficient Nonlinear Dimension Reduction for Clustered Data Using Kernel Functions]]></title>
		<page_from>243</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952176</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a nonlinear feature extractionmethod which is based on centroids and kernel functions.The dimension reducing nonlinear transformation isobtained by implicitly mapping the input data into a featurespace using a kernel function, and then finding a linearmapping based on an orthonormal basis of centroids in thefeature space that maximally separates the between-classrelationship. The proposed method utilizes an efficient algorithmto compute an orthonormal basis of centroids in thefeature space transformed by a kernel function and achievesdramatic computational savings. The experimental resultsdemonstrate that our method is capable of extracting non-linearfeatures effectively so that competitive performanceof classification can be obtained in the reduced dimensionalspace.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39030187</person_id>
				<author_profile_id><![CDATA[81384617662]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cheong]]></first_name>
				<middle_name><![CDATA[Hee]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030206</person_id>
				<author_profile_id><![CDATA[81100158952]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haesun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>954544</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R.O. Duda, P.E. Hart, and D.G. Stork. <i>Pattern Classification</i>. Wiley-interscience, New York, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>92131</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[K. Fukunaga. <i>Introduction to Statistical Pattern Recognition</i>. Acadamic Press, second edition, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Saitoh. <i>Theory of Reproducing Kernels and its Applications</i>. Longman Scientific & Technical, Harlow, England, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326465</ref_obj_id>
				<ref_obj_pid>2325769</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[B. Sch&#246;lkopf, S. Mika, C.J.C. Burges, P. Knirsch, K.-R. M&#252;ller, G. R&#228;tsch, and A.J. Smola. Input space versus feature space in kernel-based methods. <i>IEEE transactions on neural networks</i>, 10(5):1000-1017, September 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>295960</ref_obj_id>
				<ref_obj_pid>295919</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[B. Sch&#246;lkopf, A.J. Smola, and K.-R. M&#252;ller. Nonlinear component analysis as a kernel eigenvalue problem. <i>Neural computation</i>, 10:1299-1319, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Mika, G. R&#228;tsch, J. Weston, B. Sch&#246;lkopf, and K.-R. M&#252;ller. Fisher discriminant analysis with kernels. In E. Wilson J. Larsen and S. Douglas, editors, <i>Neural networks for signal processing IX</i>, pages 41-48. IEEE, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1121922</ref_obj_id>
				<ref_obj_pid>1121912</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[G. Baudat and F. Anouar. Generalized discriminant analysis using a kernel approach. <i>Neural computation</i>, 12:2385-2404, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[V. Roth and V. Steinhage. Nonlinear discriminant analysis using kernel functions. <i>Advances in neural information processing systems</i>, 12:568-574, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>607598</ref_obj_id>
				<ref_obj_pid>607589</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S.A. Billings and K.L. Lee. Nonlinear fisher discriminant analysis using a minimum squared error cost function and the orthogonal least squares algorithm. <i>Neural networks</i>, 15(2):263-270, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[H. Park, M. Jeon, and J.B. Rosen. Lower dimensional representation of text data based on centroids and least squares. <i>BIT Numerical Mathematics</i>, 43(2):1-22, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[P. Howland and H. Park. Generalizing discriminant analysis using the generalized singular value decomposition. Technical Reports 03-013, Department of Computer Science and Engineering, University of Minnesosta, Twin Cities.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952131</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Ye, R. Janardan, C.H. Park, and H. Park. A new optimization criterion for generalized discriminant analysis on undersampled problems. To appear in the Proceedings of the third IEEE International Conference on Data Mining.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345662</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[N. Cristianini and J. Shawe-Taylor. <i>An Introduction to Support Vector Machines and other kernel-based learning methods</i>. Cambridge, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593463</ref_obj_id>
				<ref_obj_pid>593419</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C.J.C. Burges. A tutorial on support vector machines for pattern recognition. <i>Data Mining and Knowledge Discovery</i>, 2(2):121-167, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[G.H. Golub and C.F. Van Loan. <i>Matrix Computations</i>. Johns Hopkins University Press, first edition, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. Making large-scale svm learning practical. LS8-Report 24, Universit&#228;t Dortmund, LS VIII-Report, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[http://www.ics.uci.edu/~mlearn/MLRepository.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[S. Mika, G. R&#228;tsch, J. Weston, B. Sch&#246;lkopf, A.J. Smola, and K.-R. M&#252;ller. Invariant feature extraction and classification in kernel spaces. <i>Advances in neural information processing systems</i>, 12:526-532, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952137</article_id>
		<sort_key>251</sort_key>
		<display_label></display_label>
		<pages>251</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Sequence Modeling with Mixtures of Conditional Maximum Entropy Distributions]]></title>
		<page_from>251</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952137</url>
		<abstract>
			<par><![CDATA[We present a novel approach to modeling sequences usingmixtures of conditional maximum entropy (maxent) distributions.Our method generalizes the mixture of first-orderMarkov models by including the "long-term" dependenciesin model components.The "long-term" dependenciesare represented by the frequently used in the naturallanguage processing (NLP) domain probabilistic triggersor rules (suc as "A occured k positions back" \Longrightarrow"the current symbol is B" with probability P).The maxentframework is then used to create a coherent global probabilisticmodel from all selected triggers.In this paper, weenhance this formalism by using probabilistic mixtures withmaxent models as components, thus representing hidden orunobserved effects in the data.We demonstrate how ourmixture of conditional maxent models can be learned fromdata using the generalized EM algorithm that scales linearlyin the dimensions of the data and the number of mixturecomponents.We present empirical results on the simulatedand real-world data sets and demonstrate that theproposed approach enables us to create better quality modelsthan the mixtures of first-order Markov models and resistoverfitting and curse of dimensionality that would inevitablypresent themselves for the higher order Markov models.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>F.1.2</cat_node>
				<descriptor>Probabilistic computation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Language parsing and understanding</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Markov processes</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003651</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Markov networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003700.10003701</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Stochastic processes->Markov processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003757</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Probabilistic computation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P67670</person_id>
				<author_profile_id><![CDATA[81100051841]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dmitry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pavlov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>234289</ref_obj_id>
				<ref_obj_pid>234285</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Berger, S. Della Pietra, and V. Della Pietra. A maximum entropy approach to natural language processing. <i>Computational Linguistics</i>, 22(1):39-72, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[E. C. Buehler and L. H. Ungar. Maximum entropy methods for biological sequence modeling. In <i>BIOKDD</i>, pages 60-64, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347151</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[I. Cadez, D. Heckerman, C. Meek, P. Smyth, and S. White. Visualization of navigation patterns on a web site using model-based clustering. In <i>Knowledge Discovery and Data Mining</i>, pages 280-284, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[I. Cadez, P. Smyth, E. Ip, and H. Mannila. Predictive profiles for transaction data using finite mixture models. Technical Report UCI-ICS 01-67, UC Irvine, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Chen and R. Rosenfeld. A Gaussian prior for smoothing maximum entropy models. Technical Report CMUCS-99-108, Carnegie Mellon University, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. N. Darroch and D. Ratcliff. Generalized iterative scaling for log-linear models. <i>Annals of Mathematical Statistics</i>, 43:1470-1480, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>251709</ref_obj_id>
				<ref_obj_pid>251695</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Della Pietra, V. Della Pietra, and J. Lafferty. Inducing features of random fields. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 19(4):380-393, April 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the em algorithm. <i>Journal of the Royal Statistical Society</i>, B-39:1-38, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Goodman. Classes for fast maximum entropy training. In <i>Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073086</ref_obj_id>
				<ref_obj_pid>1073083</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Goodman. Sequential conditional generalized iterative scaling. In <i>Association for Computational Linguistics Annual Meeting</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[E. T. Jaynes. Where do we stand on maximum entropy? In <i>The Maximum Entropy Formalism</i>, pages 15-118, Cambridge MA, 1979. MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280484</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[F. Jelinek. <i>Statistical Methods for Speech Recognition</i>. Cambridge. MA:MIT Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952173</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[E. Manavoglu, D. Pavlov, and C. L. Giles. Probabilstic user behavior models. In <i>Proceedings of the Third IEEE International Conference on Data Mining (ICDM'03)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312281</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[H. Mannila, D. Pavlov, and P. Smyth. Predictions with local patterns using cross-entropy. In <i>Proc. of Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 357-361. New York, NY: ACM Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2100633</ref_obj_id>
				<ref_obj_pid>2100584</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[A. McCallum. Efficiently inducing features of conditional ramdom fields. In <i>Proceedings of the 19th Conference on Uncertainty in Artficial Intelligence (UAI'03)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[G. McLachlan and K. Basford. <i>Mixture Models</i>. Marcel Dekker, New York, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[G. McLachlan and T. Krishnan. <i>The EM Algorithm and Extensions</i>. John Wiley and Sons, New York, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[D. Pavlov. Sequence modeling with mixtures of conditional maximum entropy distributions. Technical Report NEC Laboratories TR, NEC Laboratories America, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. Pavlov and D. Pennock. A maximum entropy approach to collaborative filtering in dynamic, sparse, high-dimensional domains. In <i>Proceedings of Neural Information Processing Systems (NIPS-2002)</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952137</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[D. Pavlov, A. Popescul, D. Pennock, and L. Ungar. Mixtures of conditional maximum entropy models. In <i>International Conference on Machine Learning (ICML-2003)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502536</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[D. Pavlov and P. Smyth. Probabilistic query models for transaction data. In <i>Proceedings of Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, pages 164-173. New York, NY: ACM Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[A. Ratnaparkhi. A maximum entropy model for part-of-speech tagging. In <i>Proceedings of the Conference on Empirical Methods in Natural Language Processing</i>, pages 133-142. ACL, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[P. Smyth. Clustering sequences with hidden markov models. In M. C. Mozer, M. I. Jordan, and T. Petsche, editors, <i>Advances in Neural Information Processing Systems</i>, volume 9, page 648. The MIT Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[S. Wang, R. Rosenfeld, Y. Zhao, and D. Shuurmans. The latent maximum entropy principle. In <i>IEEE International Symposium on Information Theory (ISIT)</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952164</article_id>
		<sort_key>259</sort_key>
		<display_label></display_label>
		<pages>259</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[MaPle]]></title>
		<subtitle><![CDATA[A Fast Algorithm for Maximal Pattern-based Clustering]]></subtitle>
		<page_from>259</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952164</url>
		<abstract>
			<par><![CDATA[Pattern-based clustering is important in many applications,such as DNA micro-array data analysis, automaticrecommendation systems and target marketing systems.However, pattern-based clustering in large databasesis challenging. On the one hand, there can be a huge numberof clusters and many of them can be redundant and thusmake the pattern-based clustering ineffective. On the otherhand, the previous proposed methods may not be efficient orscalable in mining large databases.In this paper, we study the problem of maximal pattern-basedclustering. Redundant clusters are avoided completelyby mining only the maximal pattern-based clusters.MaPle, an efficient and scalable mining algorithm is developed.It conducts a depth-first, divide-and-conquer searchand prunes unnecessary branches smartly. Our extensiveperformance study on both synthetic data sets and real datasets shows that maximal pattern-based clustering is effective.It reduces the number of clusters substantially. Moreover,MaPle is more efficient and scalable than the previouslyproposed pattern-based clustering methods in mininglarge databases.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15029106</person_id>
				<author_profile_id><![CDATA[81100323054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645604</person_id>
				<author_profile_id><![CDATA[81350600847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xiaoling]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645465</person_id>
				<author_profile_id><![CDATA[81100371562]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Moonjung]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP54031121</person_id>
				<author_profile_id><![CDATA[81455605782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Haixun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP132031764</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>304188</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C.C. Aggarwal et al. Fast algorithms for projected clustering. In <i>SIGMOD'99</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335383</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C.C. Aggarwal and P.S. Yu. Finding generalized projected clusters in high dimensional spaces. In <i>SIGMOD'00</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276314</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal et al. Automatic subspace clustering of high dimensional data for data mining applications. In <i>SIGMOD'98</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal et al. Mining association rules between sets of items in large databases. In SIGMOD'93.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>VLDB'94</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656271</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[K. S. Beyer et al. When is "nearest neighbor" meaningful? In <i>ICDT'99</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312199</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. H. Cheng et al. Entropy-based subspace clustering for mining numerical data. In <i>KDD'99</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>660833</ref_obj_id>
				<ref_obj_pid>645635</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Y. Cheng and G.M. Church. Biclustering of expression data. In <i>Proc. of the 8th Int'l Conf on Intelligent System for Molecular Biology</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Han et al. Mining frequent patterns without candidate generation. In <i>SIGMOD'00</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671667</ref_obj_id>
				<ref_obj_pid>645925</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[H. V. Jagadish et al. Semantic compression and pattern extraction with fascicles. In <i>VLDB'99</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Tavazoie et al. Yeast micro data set. In http://arep.med.harvard.edu/biclustering/yeast.matrix, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564737</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[H. Wang et al. Clustering by pattern similarity in large data sets. In <i>SIGMOD'02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Yang et al. -cluster: Capturing subspace correlation in a large data set. In <i>ICDE'02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952174</article_id>
		<sort_key>267</sort_key>
		<display_label></display_label>
		<pages>267</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[Exploiting Unlabeled Data for Improving Accuracy of Predictive Data Mining]]></title>
		<page_from>267</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952174</url>
		<abstract>
			<par><![CDATA[Predictive data mining typically relies on labeled datawithout exploiting a much larger amount of availableunlabeled data. The goal of this paper is to show thatusing unlabeled data can be beneficial in a range ofimportant prediction problems and therefore should be anintegral part of the learning process. Given an unlabeleddataset representative of the underlying distribution and aK-class labeled sample that might be biased, ourapproach is to learn K contrast classifiers each trained todiscriminate a certain class of labeled data from theunlabeled population. We illustrate that contrastclassifiers can be useful in one-class classification, outlierdetection, density estimation, and learning from biaseddata. The advantages of the proposed approach aredemonstrated by an extensive evaluation on synthetic datafollowed by real-life bioinformatics applications for (1)ranking PubMed articles by their relevance to proteindisorder and (2) cost-effective enlargement of adisordered protein database.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Scientific databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010364</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Scientific visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP37022829</person_id>
				<author_profile_id><![CDATA[81340488981]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P494568</person_id>
				<author_profile_id><![CDATA[81100461872]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Slobodan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vucetic]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14029092</person_id>
				<author_profile_id><![CDATA[81324489811]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645346</person_id>
				<author_profile_id><![CDATA[81537193756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hongbo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xie]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14026203</person_id>
				<author_profile_id><![CDATA[81100041040]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Zoran]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Obradovic]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S.F. Altschul, T.L. Madden, A.A. Schiffer, J. Zhang, Z. Zhang, W. Miller and D.J. Lipman, "Gapped BLAST and PSI-BLAST: a new generation of protein database search programs", <i>Nucleic Acids Res.</i>, 1997, vol. 25, pp. 3389-3402.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>279962</ref_obj_id>
				<ref_obj_pid>279943</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Blum and T. Mitchell, "Combining labeled and unlabeled data with co-training", In <i>Proc. of COLT'98</i>, 1998, pp. 92-100.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[B. Boeckmann, A. Bairoch, R. Apweiler, M. C. Blatter, A. Estreicher, E. Gasteiger, M. J. Martin, K. Michoud, C. O'Donovan, I. Phan, S. Pilbout and M. Schneider, "The SWISS-PROT protein knowledgebase and its supplement TrEMBL in 2003", <i>Nucleic Acids Res.</i>, 2003, vol. 31, pp. 365-370.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone, <i>Classification and regression trees</i>, Wadsworth Inc., 1984, pp. 43-49.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[L. Breiman, "Bias, variance, and arcing classifiers", Technical Report 460, UC-Berkeley, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. P. Dempster, N. M. Laird and D. B. Rubin, "Maximum likelihood from incomplete data via the EM algorithm", <i>J. Roy. Statistical Society (B)</i>, 1977, vol. 39, pp. 1-38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. K. Dunker, C. J. Brown, J. D. Lawson, L. M. Iakoucheva and Z. Obradovic, "Intrinsic disorder and protein function", <i>Biochemistry</i>, 2002, vol. 41(21), pp. 6573-6582.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[N. Japkowicz, "The class imbalance problem: significance and strategies", In <i>Proc. of IC-AI'00</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656022</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[B. Liu, W. S. Lee, P. S. Yu and X. Li, "Partially supervised classification of text documents", In <i>Proc. of ICML'02</i>, 2002, pp. 387-394.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347724</ref_obj_id>
				<ref_obj_pid>347709</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[K. Nigam, A. McCallum, S. Thrun and T. Mitchell, "Text classification from labeled and unlabeled documents using EM", <i>Mach. Learning</i>, 2000, vol. 39(2/3), pp. 103-134.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Z. Obradovic, K. Peng, S. Vucetic, P. Radivojac, C. J. Brown and A. K. Dunker, "Predicting intrinsic disorder from amino acid sequence", <i>Proteins, Special Issue on CASP5</i>, in press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. C. Platt, "Probabilistic outputs for support vector machines and comparison to regularized likelihood methods", In <i>Advances in Large Margin Classifiers</i>, A. J. Smola, P. Bartlett, B. Scholkopf, D. Schuurmans (eds.): MIT Press, 1999, pp. 61-74.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M. F. Porter, "An algorithm for suffix stripping", <i>Program</i>, 1980, vol. 14(3), pp. 130-137.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[F. Provost and P. Domingos, "Well-trained PETs: Improving probability estimation trees", CeDER Working Paper #IS-0004, Stern School of Business, New York University, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. D. Richard and R. P. Lippmann, "Neural network classifiers estimate Bayesian a posteriori probabilities", <i>Neural Comput.</i>, 1991, vol. 3, pp. 461-483.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>54260</ref_obj_id>
				<ref_obj_pid>54259</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[G. Salton and C. Buckley, "Term-weighting approaches in automatic text retrieval", <i>Inf. Process. Manage.</i>, 1988, vol. 24(5), pp. 513-523.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[M. Seeger, "Learning with labeled and unlabeled data", Technical Report, Institute for Adaptive and Neural Computation, University of Edinburgh, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[B. Shahshahani and D. Landgrebe, "The effect of unlabeled samples in reducing the small sample size problem and mitigating the Hughes phenomenon", <i>IEEE Trans. Geosci. Remote Sens.</i>, 1994, vol. 32(5), pp. 1087-1095.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944809</ref_obj_id>
				<ref_obj_pid>944790</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. M. J. Tax and R. P. W. Duin, "Uniform Object Generation for Optimizing One-class Classifiers", <i>J. Mach. Learn. Res., Special Issue on Kernel Methods</i>, 2002, vol. 2(2), pp. 155-173.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[V. N. Vapnik, <i>Statistical Learning Theory</i>, Wiley, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[S. Vucetic, D. Pokrajac, H. Xie and Z. Obradovic, "Detection of underrepresented biological sequences using class-conditional distribution models", In <i>Proc. of SIAM SDM'03</i>, 2003, pp. 279-283.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>877297</ref_obj_id>
				<ref_obj_pid>876866</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Y. Wu, Q. Tian and T. S. Huang, "Integrating unlabeled images for image retrieval based on relevance feedback", In <i>Proc. of ICPR'00</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[G. Yona, N. Linial and M. Linial, "ProtoMap: Automatic classification of protein sequences, a hierarchy of protein families, and local maps of the protein space", <i>Proteins</i>, 1999, vol. 37, pp. 360-378.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775151</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[B. Zadrozny and C. Elkan, "Transforming classifier scores into accurate multiclass probability estimates", In <i>Proc. of KDD'02</i>, 2002, pp. 694-699.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952168</article_id>
		<sort_key>275</sort_key>
		<display_label></display_label>
		<pages>275</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[Statistical Relational Learning for Document Mining]]></title>
		<page_from>275</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952168</url>
		<abstract>
			<par><![CDATA[A major obstacle to fully integrated deployment of manydata mining algorithms is the assumption that data sitsin a single table, even though most real-world databaseshave complex relational structures. We propose an integratedapproach to statistical modeling from relationaldatabases. We structure the search space based on "refinementgraphs", which are widely used in inductive logic programmingfor learning logic descriptions. The use of statisticsallows us to extend the search space to include richerset of features, including many which are not boolean.Search and model selection are integrated into a single process,allowing information criteria native to the statisticalmodel, for example logistic regression, to make feature selectiondecisions in a step-wise manner. We present experimentalresults for the task of predicting where scientific paperswill be published based on relational data taken fromCiteSeer. Our approach results in classification accuraciessuperior to those achieved when using classical "flat" features.The resulting classifier can be used to recommendwhere to publish articles.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.4.1</cat_node>
				<descriptor>Logic and constraint programming</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003790.10003795</concept_id>
				<concept_desc>CCS->Theory of computation->Logic->Constraint and logic programming</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP16000583</person_id>
				<author_profile_id><![CDATA[81100662170]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexandrin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Popescul]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14130288</person_id>
				<author_profile_id><![CDATA[81100365076]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lyle]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Ungar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P269352</person_id>
				<author_profile_id><![CDATA[81100574544]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Steve]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lawrence]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P339921</person_id>
				<author_profile_id><![CDATA[81100186104]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Pennock]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[H. Akaike. Information theory and an extension of the maximum likelihood principle. In <i>2nd Int'l Symposium on Information Theory</i>, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775068</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Anderson, P. Domingos, and D. Weld. Relational Markov models and their application to adaptive web navigation. In <i>KDD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H. Blockeel and L. Dehaspe. Cumulativity as inductive bias. In <i>Workshops: Data Mining, Decision Support, Meta-Learning and ILP at PKDD</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1643308</ref_obj_id>
				<ref_obj_pid>1643275</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Blockeel and L. D. Raedt. Top-down induction of logical decision trees. <i>Artificial Intelligence</i>, 101(1-2), 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276332</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Chakrabarti, B. E. Dom, and P. Indyk. Enhanced hypertext categorization using hyperlinks. In <i>SIGMOD</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Cohn and T. Hofmann. The missing link - A probabilistic model of document content and hypertext connectivity. In <i>NIPS</i>, volume 13. MIT Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375500</ref_obj_id>
				<ref_obj_pid>375487</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Craven and S. Slattery. Relational learning with statistical predicate invention: Better models for hypertext. <i>Machine Learning</i>, 43(1/2), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>761056</ref_obj_id>
				<ref_obj_pid>647997</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[L. Dehaspe. Maximum entropy modeling with clausal constraints. In <i>ILP</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593475</ref_obj_id>
				<ref_obj_pid>593422</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[L. Dehaspe and H. Toivonen. Discovery of frequent data-log patterns. <i>Data Mining and Knowledge Discovery</i>, 3(1), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>567226</ref_obj_id>
				<ref_obj_pid>567222</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. Dzeroski and N. Lavrac. An introduction to inductive logic programming. In S. Dzeroski and N. Lavrac, editors, <i>Relational Data Mining</i>. Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657460</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Dzeroski, L. D. Raedt, and H. Blockeel. Relational reinforcement learning. In <i>ICML</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. Foster and L. Ungar. A proposal for learning by ontological leaps. In <i>Snowbird Learning Conference</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>741464</ref_obj_id>
				<ref_obj_pid>647966</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Furnkranz. Exploiting structural information for text classification on the WWW. <i>Intelligent Data Analysis</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655682</ref_obj_id>
				<ref_obj_pid>645530</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[L. Getoor, N. Friedman, D. Koller, and A. Pfeffer. Learning probabilistic relational models. In S. Dzeroski and N. Lavrac, editors, <i>Relational Data Mining</i>. Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>511520</ref_obj_id>
				<ref_obj_pid>511446</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[E. J. Glover, K. Tsioutsiouliklis, S. Lawrence, D. M. Pennock, and G. Flake. Using web structure for classifying and describing web pages. In <i>Int'l WWW Conference</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[P. Hoff. Random effects models for network data. In <i>National Academy of Sciences: Symposium on Social Network Analysis for National Security</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655828</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[D. Jensen and J. Neville. Linkage and autocorrelation cause feature selection bias in relational learning. In <i>ICML</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>251651</ref_obj_id>
				<ref_obj_pid>251646</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[A. Karalic and I. Bratko. First order regression. <i>Machine Learning</i>, 26, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>742956</ref_obj_id>
				<ref_obj_pid>648001</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[K. Kersting and L. D. Raedt. Towards combining inductive logic programming and Bayesian networks. In <i>ILP</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>670139</ref_obj_id>
				<ref_obj_pid>645805</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[A. J. Knobbe, M. D. Haas, and A. Siebes. Propositionalisation and aggregates. In <i>PKDD</i>. 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>567236</ref_obj_id>
				<ref_obj_pid>567222</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[S. Kramer, N. Lavrac, and P. Flach. Propositionalization approaches to relational data mining. In S. Dzeroski and N. Lavrac, editors, <i>Relational Data Mining</i>. Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>567230</ref_obj_id>
				<ref_obj_pid>567222</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[S. Kramer and G. Widmer. Inducing classification and regression trees in first order logic. In S. Dzeroski and N. Lavrac, editors, <i>Relational Data Mining</i>. Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>567235</ref_obj_id>
				<ref_obj_pid>567222</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[W. V. Laer and L. D. Raedt. How to upgrade propositional learners to first order logic: A case study. In S. Dzeroski and N. Lavrac, editors, <i>Relational Data Mining</i>. Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>621256</ref_obj_id>
				<ref_obj_pid>619041</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[S. Lawrence, C. L. Giles, and K. Bollacker. Digital libraries and autonomous citation indexing. <i>IEEE Computer</i>, 32(6), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>352648</ref_obj_id>
				<ref_obj_pid>352644</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[T.-S. Lim, W.-Y. Loh, and Y.-S. Shih. A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms. <i>Machine Learning</i>, 40, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[S. Muggleton. Stochastic logic programs. In <i>ILP</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[J. Neville and D. Jensen. Iterative classification in relational data. In <i>AAAI Workshop on Learning Statistical Models from Relational Data</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956772</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[C. Perlich and F. Provost. Aggregation-based feature invention and relational concept classes. In <i>KDD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952168</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[A. Popescul and L. H. Ungar. Statistical relational learning for link prediction. In <i>IJCAI Workshop on Learning Statistical Models from Relational Data</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[A. Popescul, L. H. Ungar, S. Lawrence, and D. M. Pennock. Towards structural logistic regression: Combining relational and statistical learning. In <i>KDD Workshop on Multi-Relational Data Mining</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642262</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[D. Roth and W. Yih. Relational learning via propositional algorithms. In <i>IJCAI</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[T. Sato. A statistical learning method for logic programs with distribution semantics. In <i>ICLP</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[G. Schwartz. Estimating the dimension of a model. <i>The Annals of Statistics</i>, 6(2), 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>538679</ref_obj_id>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[E. Shapiro. <i>Algorithmic Program Debugging</i>. MIT, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593476</ref_obj_id>
				<ref_obj_pid>593422</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[A. Srinivasan and R. King. Feature construction with inductive logic programming: A study of quantitative predictions of biological activity aided by structural attributes. <i>Data Mining and Knowledge Discovery</i>, 3(1), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2073934</ref_obj_id>
				<ref_obj_pid>2073876</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[B. Taskar, P. Abbeel, and D. Koller. Discriminative probabilistic models for relational data. In <i>UAI</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952143</article_id>
		<sort_key>283</sort_key>
		<display_label></display_label>
		<pages>283</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[Integrating Customer Value Considerations into Predictive Modeling]]></title>
		<page_from>283</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952143</url>
		<abstract>
			<par><![CDATA[The success of prediction models for business purposesshould not be measured by their accuracy only. Theirevaluation should also take into account the higherimportance of precise prediction for "valuable"customers. We illustrate this idea through the example ofchurn modeling in telecommunications, where it isobviously much more important to identify potentialchurn among valuable customers. We discuss, boththeoretically and empirically, the optimal use of"customer value" data in the model training, modelevaluation and scoring stages. Our main conclusion isthat a non-trivial approach of using "decayed" value-weightsfor training is usually preferable to the twoobvious approaches of either using non-decayed customervalues as weights or ignoring them.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.1</cat_node>
				<descriptor>Business</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.7</cat_node>
				<descriptor>Consumer products</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Combined</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010481.10003558</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Consumer products</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010406</concept_id>
				<concept_desc>CCS->Applied computing->Enterprise computing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010406.10010412</concept_id>
				<concept_desc>CCS->Applied computing->Enterprise computing->Business process management</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Economics</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP36029880</person_id>
				<author_profile_id><![CDATA[81100549576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Saharon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rosset]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P76036</person_id>
				<author_profile_id><![CDATA[81100662412]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Einat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Neumann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Chan, P. K., and Stolfo, S. J. (1998) Toward Scalable Learning with Non-unifonn Class and Cost Distributions: A Case Study in Credit Card Fraud Detection, <i>KDD-98</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Elkan, C. (2000) Cost-Sensitive Learning and Decision-Making when Costs Are Unknown. <i>WCSL at ICML-2000</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Korn, E.L., Graubard, B.I. (1995) Examples of Differing Weighted and Unweighted Estimates from a Sample Survey. <i>The American Statistician</i>, 49:291-295.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hastie, T., Tibshirani, R., Friedman J. (2001). <i>The Elements of Statistical Learning</i>. Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669352</ref_obj_id>
				<ref_obj_pid>645803</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Murad, U., Pinkas, G. (1999). Unsupervised Profiling for Identifying Superimposed Fraud. <i>PKDD-99</i>: 251-261.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[McCullagh, P., Neider, J.A. (1989). <i>Generalized Linear Models</i>. Chapman & Hall, second edition, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Provost, F.; Fawcett, T. (1997). Analysis and Visualization of Classifier Performance: Comparison under Imprecise Class and Cost Distribution. <i>KDD-97</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593450</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Provost, F., Fawcett, T. (1998). Adaptive fraud detection. <i>Data Mining and Knowledge Discovery</i>, 1 (3).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Rosset, S. (2003). Building prediction models for data with observation importance weights. In preparation. www-stat.stanford.edu/~saharon/papers/vwpaper.ps]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502581</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Rosset, S., Neumann, E., Eick, U., Vatnik, N., Idan, I. (2001). Evaluation of prediction models for marketing campaigns. <i>KDD-2001</i>: 456-461.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775097</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Rosset, S., Neumann, E., Eick, U., Vatnik, N., Idan, I. (2002). Customer lifetime value modeling and its use for customer retention planning. <i>KDD-2002</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Rosset, S., Zhu, J., Hastie, T. (2002). Boosting as a regularized path to a maximum margin classifier. <i>Technical report, Dept. of Statistics, Stanford Univ.</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Turney, P.D. (2000). Types of cost in inductive concept learning. <i>WCSL at ICML-2000</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Weisberg, S. (1985). <i>Applied Linear Regression</i>, John Wiley and Sons, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952147</article_id>
		<sort_key>291</sort_key>
		<display_label></display_label>
		<pages>291</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[A High-Performance Distributed Algorithm for Mining Association Rules]]></title>
		<page_from>291</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952147</url>
		<abstract>
			<par><![CDATA[We present a new distributed association rule mining(D-ARM) algorithm that demonstrates superlinear speedupwith the number of computing nodes. The algorithm isthe first D-ARM algorithm to perform a single scan overthe database. As such, its performance is unmatched byany previous algorithm. Scale-up experiments over standard synthetic benchmarks demonstrate stable run time regardless of the number of computers. Theoretical analysisreveals a tighter bound on error probability than the oneshown in the corresponding sequential algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Sorting and searching</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010031.10010033</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Data structures design and analysis->Sorting and searching</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P22680</person_id>
				<author_profile_id><![CDATA[81100625706]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Assaf]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schuster]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31050862</person_id>
				<author_profile_id><![CDATA[81100634917]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ran]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wolff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645285</person_id>
				<author_profile_id><![CDATA[81100372344]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Trock]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In <i>Proc. of the 1993 ACM SIGMOD Int'l. Conference on Management of Data</i>, pages 207-216, Washington, D.C., June 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627803</ref_obj_id>
				<ref_obj_pid>627307</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and J. Shafer. Parallel mining of association rules. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 8(6):962-969, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. of the 20th Int'l. Conference on Very Large Databases (VLDB'94)</i>, pages 487-499, Santiago, Chile, September 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>653196</ref_obj_id>
				<ref_obj_pid>645446</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[V. S. Ananthanarayana, D. K. Subramanian, and M. N. Murty. Scalable, distributed and dynamic mining of association rules. In <i>Proceedings of HiPC'00</i>, pages 559-566, Bangalore, India, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253325</ref_obj_id>
				<ref_obj_pid>253262</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, J. Ullman, and S. Tsur. Dynamic item-set counting and implication rules for market basket data. <i>SIGMOD Record</i>, 6(2):255-264, June 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383194</ref_obj_id>
				<ref_obj_pid>382006</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Cheung, J. Han, V. Ng, A. Fu, and Y. Fu. A fast distributed algorithm for mining association rules. In <i>Proc. of 1996 Int'l. Conf. on Parallel and Distributed Information Systems</i>, pages 31-44, Miami Beach, Florida, December 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>79799</ref_obj_id>
				<ref_obj_pid>79790</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Hagerup and C. Rub. A guided tour of Chernoff bounds. <i>Information Processing Letters</i>, 33:305-308, 1989/90.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. Technical Report 99-12, Simon Fraser University, October 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Z. Jarai, A. Virmani, and L. Iftode. Towards a cost-effective parallel data mining approach. Workshop on High Performance Data Mining (held in conjunction with IPPS'98), March 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650396</ref_obj_id>
				<ref_obj_pid>645338</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D.-I. Lin and Z. M. Kedem. Pincer search: A new algorithm for discovering the maximum frequent set. In <i>Extending Database Technology</i>, pages 105-119, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223813</ref_obj_id>
				<ref_obj_pid>223784</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. S. Park, M.-S. Chen, and P. S. Yu. An effective hash-based algorithm for mining association rules. In <i>Proc. of ACM SIGMOD Int'l. Conference on Management of Data</i>, pages 175-186, San Jose, California, May 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>221320</ref_obj_id>
				<ref_obj_pid>221270</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. S. Park, M.-S. Chen, and P. S. Yu. Efficient parallel data mining for association rules. In <i>Proc. of ACM Int'l. Conference on Information and Knowledge Management</i>, pages 31-36, Baltimore, MD, November 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347166</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Pei and J. Han. Can we push more constraints into frequent pattern mining? In <i>Proc. of the ACM SIGKDD Conf. on Knowledge Discovery and Data Mining</i>, pages 350-354, Boston, MA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673300</ref_obj_id>
				<ref_obj_pid>645921</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. Savasere, E. Omiecinski, and S. B. Navathe. An efficient algorithm for mining association rules in large databases. <i>The VLDB Journal</i>, pages 432-444, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375728</ref_obj_id>
				<ref_obj_pid>375663</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[A. Schuster and R. Wolff. Communication-efficient distributed mining of association rules. In <i>Proc. of the 2001 ACM SIGMOD Int'l. Conference on Management of Data</i>, pages 473-484, Santa Barbara, California, May 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673304</ref_obj_id>
				<ref_obj_pid>645921</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[R. Srikant and R. Agrawal. Mining generalized association rules. In <i>Proc. of the 20th Int'l. Conference on Very Large Databases (VLDB'94)</i>, pages 407-419, Santiago, Chile, September 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673325</ref_obj_id>
				<ref_obj_pid>645922</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[H. Toivonen. Sampling large databases for association rules. In <i>The VLDB Journal</i>, pages 134-145, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658024</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[O. R. Zaiane, M. El-Hajj, and P. Lu. Fast parallel association rules mining without candidacy generation. In <i>IEEE 2001 International Conference on Data Mining (ICDM'2001)</i>, pages 665-668, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952175</article_id>
		<sort_key>299</sort_key>
		<display_label></display_label>
		<pages>299</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>44</seq_no>
		<title><![CDATA[Introducing Uncertainty into Pattern Discovery in Temporal Event Sequences]]></title>
		<page_from>299</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952175</url>
		<abstract>
			<par><![CDATA[Pattern discovery in temporal event sequences is of greatimportance in many application domains, such as telecommunicationnetwork fault analysis. In reality, not every typeof event has an accurate timestamp. Some of them, definedas inaccurate events in this paper, may only have an intervalas possible time of occurrence. The existence of inaccurateevents may cause uncertainty in event ordering. Thetraditional support model cannot deal with this uncertainty,which would cause some interesting patterns to be missing.In this paper, a new concept, precise support, is introducedto evaluate the probability of a pattern contained in a sequence.Based on this new metric, we define the uncertaintymodel and present an algorithm to discover interesting patternsin the sequence database that has one type of inaccurateevent. In our model, the number of types of inaccurateevents can be extended to k readily, however, at a cost ofincreasing computational complexity.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Fuzzy set</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.3</cat_node>
				<descriptor>Uncertainty, "fuzzy," and probabilistic reasoning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010191</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Vagueness and fuzzy logic</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010190</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Probabilistic reasoning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP27003726</person_id>
				<author_profile_id><![CDATA[81392596129]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xingzhi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15028744</person_id>
				<author_profile_id><![CDATA[81100310261]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Maria]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Orlowska]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14169345</person_id>
				<author_profile_id><![CDATA[81452599228]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xue]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. 20th VLDB</i>, pages 487-499, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Mining sequential patterns. In <i>Proc. 11th ICDE</i>, pages 3-14, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347167</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, B. Mortazavi-Asl, Q. Chen, U. Dayal, and M. Hsu. Freespan: Frequent pattern-projected sequential pattern mining. In <i>Proc. 6th ACM SIGKDD</i>, pages 355-359, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656369</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Ma and J. L. Hellerstein. Mining partially periodic event patterns with unknown periods. In <i>Proc. 17th ICDE</i>, pages 205-214, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593449</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Mannila, H. Toivonen, and A. I. Verkamo. Discovery of frequent episodes in event sequences. <i>Data Mining and Knowledge Discovery</i>, 1(3):259-289, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656379</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, U. Dayal, and M.-C. Hsu. PrefixSpan mining sequential patterns efficiently by prefix projected pattern growth. In <i>Proc. 17th ICDE</i>, pages 215-226, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Pei, A. K. H. Tung, and J. Han. Fault-tolerant frequent pattern mining: Problems and challenges. In <i>DMKD</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650382</ref_obj_id>
				<ref_obj_pid>645337</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Srikant and R. Agrawal. Mining sequential patterns: Generalizations and performance improvements. In <i>Proc. 5th EDBT</i>, pages 3-17, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1760899</ref_obj_id>
				<ref_obj_pid>1760894</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[X. Sun, M. E. Orlowska, and X. Zhou. Finding event-oriented patterns in long temporal sequences. In <i>Proc. 7th PAKDD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347150</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Yang, W. Wang, and P. S. Yu. Mining asynchronous periodic patterns in time series data. In <i>Knowledge Discovery and Data Mining</i>, pages 275-279, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502571</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Yang, W. Wang, and P. S. Yu. Infominer: mining surprising periodic patterns. In <i>Knowledge Discovery and Data Mining</i>, pages 395-400, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564738</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Yang, W. Wang, P. S. Yu, and J. Han. Mining long sequential patterns in a noisy environment. In <i>SIGMOD Conference</i>, pages 406-417, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952177</article_id>
		<sort_key>307</sort_key>
		<display_label></display_label>
		<pages>307</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>45</seq_no>
		<title><![CDATA[Evolutionary Gabor Filter Optimization with Application to Vehicle Detection]]></title>
		<page_from>307</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952177</url>
		<abstract>
			<par><![CDATA[Despite the considerable amount of research work on the applicationof Gabor filters in pattern classification, their design and selectionhave been mostly done on a trial and error basis. Existing techniques areeither only suitable for a small number of filters or less problem-oriented.A systematic and general evolutionary Gabor filter optimization (EGFO)approach that yields a more optimal, problem-specific, set of filters is proposedin this study. The EGFO approach unifies filter design with filter selectionby integrating Genetic Algorithms (GAs) with an incremental clusteringapproach. Specifically, filter design is performed using GAs, a globaloptimization approach that encodes the parameters of the Gabor filters ina chromosome and uses genetic operators to optimize them. Filter selectionis performed by grouping together filters having similar characteristics(i.e., similar parameters) using incremental clustering in the parameterspace. Each group of filters is represented by a single filter whose parameterscorrespond to the average parameters of the filters in the group. Thisstep eliminates redundant filters, leading to a compact, optimized set of filters.The average filters are evaluated using an application-oriented fitnesscriterion based on Support Vector Machines (SVMs). To demonstrate theeffectiveness of the proposed framework, we have considered the challengingproblem of vehicle detection from gray-scale images. Our experimentalresults illustrate that the set of Gabor filters, specifically optimized for theproblem of vehicle detection, yield better performance than using traditionalfilter banks.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Heuristic methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Information filtering</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003352</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Information extraction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003349</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Document filtering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010206</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Heuristic function construction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P553176</person_id>
				<author_profile_id><![CDATA[81100446737]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zehang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15019859</person_id>
				<author_profile_id><![CDATA[81100022965]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bebis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15024595</person_id>
				<author_profile_id><![CDATA[81100162310]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ronald]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Daugman, "Complete discrete 2-d gabor transforms by neural network for image analysis and compression," <i>IEEE Transactions on Acoustics, Speech, and Signal Processing</i>, vol. 36, no. 7, pp. 1169-1179, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Mehrotra, K. Namuduri, and N. Ranganathan, "Gabor filter-based edge detection," <i>Pattern Recognition</i>, vol. 25, pp. 1479-1493, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Weldon, W. Higgins and D. Dunn, "Efficient gabor filter design for texture segmentation," <i>Pattern Recognition</i>, vol. 29, no. 12, pp. 2005-2015, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>146917</ref_obj_id>
				<ref_obj_pid>146913</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Jain and F. Farrokhnia, "Unsupervised texture segementation using gabor filters," <i>Pattern Recognition</i>, vol. 23, pp. 1167-1186, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>284984</ref_obj_id>
				<ref_obj_pid>284980</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. Hofmann, J. Puzicha, and J. Buhmann, "Unsupervised texture segmentation in a deterministic annealing framework," <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 20, pp. 803-818, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Hamamoto, S. Uchimura, M. Watanabe, T. Yasuda, Y. Mitani, and S. Tomota, "A gabor filter-based method for recognizing handwritten numerals," <i>Pattern Recognition</i>, vol. 31, no.4, pp. 395-400, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>827758</ref_obj_id>
				<ref_obj_pid>520789</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[K. Chung, S. Kee, and S. Kim, "Face recognition using independent component analysis og gabor filter responses," <i>IAPR Workshop on machine vision applications</i>, pp. 331-334, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Z. Sun, G. Bebis, and R. Miller, "Improving the performance of on-road vehicle detection by combining gabor and wavelet features," <i>The IEEE Fifth International Conference on Intelligent Transportation Systems</i>, September, 2002, Singapore.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>236272</ref_obj_id>
				<ref_obj_pid>236262</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[B. Manjunath and W. Ma, "Texture features for browsing and retrieval of image data," <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 18, no. 8, pp. 837-842, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Weldon, W. Higgins and D. Dunn, "Gabor filter desing for multiple texture segmentation," <i>Optical Engineering</i>, vol. 35, pp. 2852-2863, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>81083</ref_obj_id>
				<ref_obj_pid>81077</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Bovik, M. Clark, and W. Geisler, "Multichannel texture analysis using localized spatial filters," <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 12, pp. 55-73, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[B. Okombi-Diba, J. Miyamichi, and K. Shoji, "Edge-based segmentation of textured images uing otimally selected gabor filters," <i>IAPR Workshop on machine vision applications</i>, pp. 267-270, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2322048</ref_obj_id>
				<ref_obj_pid>2319112</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[D. Dunn, and W. Higgins, "Optimal gabor filters for texture segementation," <i>IEEE Transactions on Image Processing</i>, vol. 4, pp. 947-964, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>11683</ref_obj_id>
				<ref_obj_pid>11682</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[M. Turner, "Texture discrimination by gabor functions," <i>Biological Cybernetics</i>, vol. 55, pp. 71-82, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>534133</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[D. Goldberg, <i>Genetic Algorithms in Search, Optimization, and Machine Learning</i>. Addison Wesley, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>551277</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[E. Trucco, and A. Verri, <i>Introductory Techniques for 3-D Computer Vision</i>. Prentice Hall, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331504</ref_obj_id>
				<ref_obj_pid>331499</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[A. Jain, M. Murty and P. Flynn, "Data clustering: A review," <i>ACM Computing Surveys</i>, vol. 31, pp. 265-323, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>840748</ref_obj_id>
				<ref_obj_pid>839281</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[P. Kuizinga, N. Petkov and S. Grigorescu, "Comparison of texture features based on gabor filters," <i>Proceedings of the 10th International Conference on Image Analysis and Processing</i>, pp. 142-147, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik, <i>The Nature of Statistical Learning Theory</i>. Springer Verlag, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593463</ref_obj_id>
				<ref_obj_pid>593419</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[C. Burges, "Tutorial on support vector machines for pattern recognition," <i>Data Mining and Knowledge Discovery</i>, vol. 2, no. 2, pp. 955-974, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>355341</ref_obj_id>
				<ref_obj_pid>355338</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[C. Papageorgiou and T. Poggio, "A trainable system for object detection," <i>International Journal of Computer Vision</i>, vol. 38, no. 1, pp. 15-33, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[G. Bebis, S. Uthiram, and M. Georgiopoulos, "Face detection and verification using genetic search," <i>International Journal on Artificial Intelligence Tools</i>, vol. 9, no. 2, pp. 225-246, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>117688</ref_obj_id>
				<ref_obj_pid>117684</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[W. T. Freeman and E. H. Adelson, "The design and use of steerable filters," <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 13, pp. 891-906, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952145</article_id>
		<sort_key>315</sort_key>
		<display_label></display_label>
		<pages>315</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>46</seq_no>
		<title><![CDATA[Detecting Interesting Exceptions from Medical Test Data with Visual Summarization]]></title>
		<page_from>315</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952145</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a method which visualizes irregularmulti-dimensional time-series data as a sequence ofprobabilistic prototypes for detecting exceptions from medicaltest data. Conventional visualization methods often requireiterative analysis and considerable skill thus are nottotally supported by a wide range of medical experts. OurPrototypeLines displays summarized information based ona probabilistic mixture model by using hue only thus is consideredto exhibit novelty. The effectiveness of the summarizationis pursued mainly through use of a novel informationcriterion. We report our endeavor with chronic hepatitisdata, especially discoveries of interesting exceptions bya non-expert and an untrained expert.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Medical information systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010447</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health care information systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP25001545</person_id>
				<author_profile_id><![CDATA[81100183879]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Einoshin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Suzuki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645571</person_id>
				<author_profile_id><![CDATA[81100364001]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Takeshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Watanabe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645342</person_id>
				<author_profile_id><![CDATA[81100564365]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hideto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yokoi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645399</person_id>
				<author_profile_id><![CDATA[81100222153]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Katsuhiko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takabayashi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[P. Berka. ECML/PKDD 2002 discovery challenge, download data about hepatitis. http://lisp.vse.cz/challenge/ ecmlpkdd2002/, 2002. (current September 28th, 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300679</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. K. Card, J. D. Makinlay, and B. Shneiderman, editors. <i>Readings in Information Visualization</i>, San Francisco, 1999. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>637942</ref_obj_id>
				<ref_obj_pid>637913</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Clark and T. Niblett. The CN2 induction algorithm. <i>Machine Learning</i>, 3(4):261-283, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. <i>Journal of the Royal Statistical Society B</i>, 39(1):1-38, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383784</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[U. Fayyad, G. G. Grinstein, and A. Wierse, editors. <i>Information Visualization in Data Mining and Knowledge Discovery</i>, San Francisco, 2002. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1624046</ref_obj_id>
				<ref_obj_pid>1624025</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[I. J. Haimowitz and I. S. Kohane. Automated trend detection with alternate temporal hypotheses. In <i>Proc. Thirteenth International Joint Conference on Artificial Intelligence (IJCAI)</i>, pages 146-151. 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>764218</ref_obj_id>
				<ref_obj_pid>764212</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. M. Knorr, R. T. Ng, and V. Tucakov. Distance-based outliers: Algorithms and applications. <i>VLDB Journal</i>, 8(3- 4):237-253, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Motoda, editor. <i>Active Mining</i>, Amsterdam, 2002. IOS Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[B. Padmanabhan and A. Tuzhilin. A belief-driven method for discovering unexpected patterns. In <i>Proc. Fourth Int'l Conf. Knowledge Discovery and Data Mining (KDD)</i>, pages 94-100. 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>546466</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[B. D. Ripley. <i>Pattern Recognition and Neural Networks</i>. Cambridge Univ. Press, Cambridge, U.K., 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627804</ref_obj_id>
				<ref_obj_pid>627307</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Silberschatz and A. Tuzhilin. What makes patterns interesting in knowledge discovery systems. <i>IEEE Trans. Knowledge and Data Eng.</i>, 8(6):970-974, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2306349</ref_obj_id>
				<ref_obj_pid>2306295</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. Spenke. Visualization and interactive analysis of blood parameters with infozoom. <i>Artificial Intelligence in Medicine</i>, 22(2):159-172, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. Sugaya, E. Suzuki, and S. Tsumoto. Instance selection based on support vector machine for knowledge discovery in medical database. In <i>Instance Selection and Construction for Data Mining</i>, pages 395-412. Kluwer, Norwell, Mass., 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[E. Suzuki. Autonomous discovery of reliable exception rules. In <i>Proc. Third Int'l Conf. on Knowledge Discovery and Data Mining (KDD)</i>, pages 259-262. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[E. Suzuki. Undirected discovery of interesting exception rules. <i>International Journal of Pattern Recognition and Artificial Intelligence</i>, 16(8):1065-1086, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952145</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[E. Suzuki. Color figures in detecting exceptions from medical test data with visual summarization. http://www.slab.dnj.ynu.ac.jp/paper/20030910/figs.pdf, 2003. (current September 10th, 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669491</ref_obj_id>
				<ref_obj_pid>645803</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[S. Tsumoto. Rule discovery in large time-series medical databases. In <i>Principles of Data Mining and Knowledge Discovery (PKDD)</i> LNAI 1704, pages 561-567. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[T. Watanabe, E. Suzuki, H. Yokoi, and K. Takabayashi. Prototyping medical test results in chronic hepatitis data with the EM algorithm on multi-dice models. In <i>Proc. International Workshop on Active Mining (AM)</i>, pages 45-51. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[C. Westphal and T. Blaxton. <i>Data Mining Solutions</i>. John Wiley and Sons, New York, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[G. Wyszecki and W. S. Stiles. <i>Color Science</i>. John Wiley and Sons, New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952141</article_id>
		<sort_key>323</sort_key>
		<display_label></display_label>
		<pages>323</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>47</seq_no>
		<title><![CDATA[Learning Bayesian Networks from Incomplete Data Based on EMI Method]]></title>
		<page_from>323</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952141</url>
		<abstract>
			<par><![CDATA[Currently, there are few efficient methods in practice forlearning Bayesian networks from incomplete data, whichaffects their use in real world data mining applications.This paper presents a general-duty method that estimatesthe (Conditional) Mutual Information directly from incompletedatasets, EMI. EMI starts by computing the intervalestimates of a joint probability of a variable set, which areobtained from the possible completions of the incompletedataset. And then computes a point estimate via a convexcombination of the extreme points, with weights dependingon the assumed pattern of missing data. Finally, based onthese point estimates, EMI gets the estimated (conditional)Mutual Information. This paper also applies EMI to the dependencyanalysis based learning algorithm by J. Cheng soas to efficiently learn BNs with incomplete data. The experimentalresults on Asia and Alarm networks show that EMIbased algorithm is much more efficient than two search&scoring based algorithms, SEM and EM-EA algorithms. Interms of accuracy, EMI based algorithm is more accuratethan SEM algorithm, and comparable with EM-EA algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>F.1.2</cat_node>
				<descriptor>Probabilistic computation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Relevance feedback</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003359.10003361</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results->Relevance assessment</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003757</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Probabilistic computation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP45023369</person_id>
				<author_profile_id><![CDATA[81340493235]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fengzhan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP48030212</person_id>
				<author_profile_id><![CDATA[81344500804]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hongwei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP54030026</person_id>
				<author_profile_id><![CDATA[81350589703]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yuchang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>627737</ref_obj_id>
				<ref_obj_pid>627303</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[W. Buntine. A guide to the literature on learning probabilistic networks from data. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 8(2):195-210, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>266920</ref_obj_id>
				<ref_obj_pid>266714</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Cheng, D. Bell, and W. Liu. Learning belief networks from data: An information theory based approach. <i>Proceeding of the sixth ACM International Conference on Information and Knowledge Management</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>570382</ref_obj_id>
				<ref_obj_pid>570380</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Cheng, R. Greiner, J. Kelly, D. Bell, and W. Liu. Learning bayesian networks from data: an information-theory based approach. <i>The Artificial Intelligence Journal</i>, 137:43-90, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274163</ref_obj_id>
				<ref_obj_pid>274158</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. M. Chickering and D. Heckerman. Efficient approximations for the marginal likelihood of bayesian networks with hidden variables. <i>Machine Learning</i>, 29(2-3):181-212, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Chow and C. Liu. Approximating discrete probability distributions with dependence trees. <i>IEEE Transactions on Information Theory</i>, 14:462-467, November 1968.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>145259</ref_obj_id>
				<ref_obj_pid>145254</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G. Cooper and E. Herskovits. A bayesian method for the induction of probabilistic networks from data. <i>Machine Learning</i>, 9:309-347, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2074110</ref_obj_id>
				<ref_obj_pid>2074094</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[N. Friedman. The bayesian structural em algorithm. <i>Fourteenth Conf. on Uncertainty in Artificial Intelligence</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218921</ref_obj_id>
				<ref_obj_pid>218919</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. Heckerman, D. Geiger, and D. Chickering. Learning bayesian networks: The combination of knowledge and statistical data. <i>Machine Learning</i>, 20:197-243, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[W. Lam and F. Bacchus. Learning bayesian belief networks: An approach based on the mdl principle. <i>Computational Intelligence</i>, 10:269-293, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2073850</ref_obj_id>
				<ref_obj_pid>2073796</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. W. Myers, K. B. Laskey, and K. A. DeJong. Learning bayesian networks from incomplete data using evolutionary algorithms. <i>GECCO'99</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>52121</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Pearl. Probabilistic reasoning in intelligent systems: Networks of plausible inference. <i>Morgan Kaufmann, Inc., San Mateo, CA</i>, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[G. Rebane and J. Pearl. The recovery of causal poly-trees from statistical data. <i>Third Annual Conf. on Uncertainty in Artificial Intelligence</i>, pages 175-182, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[P. Sebastiani and M. Ramoni. Bayesian inference with missing data using bound and collapse. <i>Journal of Computational and Graphical Statistics</i>, 9(4):779-800, DECEMBER 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[M. Singh. Learning bayesian networks from incomplete data. <i>The 14th National Conf. on Artificial Intelligence</i>, July 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>693506</ref_obj_id>
				<ref_obj_pid>646419</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[F. Tian, Y. Lu, and C. Shi. Learning bayesian networks with hidden variables using the combination of em and evolutionary algorithm. <i>PAKDD 2001, Hong Kong, China, Aril 2001 Proceeding</i>, pages 568-574, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952159</article_id>
		<sort_key>331</sort_key>
		<display_label></display_label>
		<pages>331</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>48</seq_no>
		<title><![CDATA[Combining Multiple Weak Clusterings]]></title>
		<page_from>331</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952159</url>
		<abstract>
			<par><![CDATA[A data set can be clustered in many ways dependingon the clustering algorithm employed, parameter settingsused and other factors. Can multiple clusterings becombined so that the final partitioning of data providesbetter clustering? The answer depends on the quality ofclusterings to be combined as well as the properties of thefusion method. First, we introduce a unifiedrepresentation for multiple clusterings and formulate thecorresponding categorical clustering problem. As aresult, we show that the consensus function is related tothe classical intra-class variance criterion using thegeneralized mutual information definition. Second, weshow the efficacy of combining partitions generated byweak clustering algorithms that use data projections andrandom data splits. A simple explanatory model is offeredfor the behavior of combinations of such weak clusteringcomponents. We analyze the combination accuracy as afunction of parameters controlling the power andresolution of component partitions as well as the learningdynamics vs. the number of clusterings involved. Finally,some empirical studies compare the effectiveness ofseveral consensus functions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Representations (procedural and rule-based)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010187</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010314</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Rule learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14227223</person_id>
				<author_profile_id><![CDATA[81100661928]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Topchy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15022472</person_id>
				<author_profile_id><![CDATA[81100113904]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Anil]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Jain]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39035666</person_id>
				<author_profile_id><![CDATA[81100277850]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Punch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Kleinberg. "An Impossibility Theorem for Clustering", <i>Proc. of Adv. in Neural Information Processing Sys.</i> (NIPS 15), 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>743949</ref_obj_id>
				<ref_obj_pid>648055</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A.L.N. Fred, "Finding Consistent Clusters in Data Partitions". In <i>Proc. 3d Int. Workshop on Multiple Classifier Systems</i>. Eds. F. Roli, J. Kittler, LNCS 2364, 2002, pp. 309-318.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944935</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Strehl and J. Ghosh, "Cluster ensembles - a knowledge reuse framework for combining multiple partitions. <i>Journal of Machine Learning Research</i>, 3, 2002, pp. 583-617.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>848563</ref_obj_id>
				<ref_obj_pid>846227</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A.L.N. Fred and A.K. Jain, "Data Clustering Using Evidence Accumulation", In <i>Proc. of the 16th International Conference on Pattern Recognition</i>, ICPR 2002, Quebec City, 2002, pp. 276- 280.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331504</ref_obj_id>
				<ref_obj_pid>331499</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Jain, M. N. Murty, and P. Flynn, "Data clustering: A review. <i>ACM Computing Surveys</i>", 31(3), 1999, pp. 264-323.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A.K. Jain and R.C. Dubes, <i>Algorithms for Clustering Data</i>. Prentice-Hall Inc., New Jersey, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1892983</ref_obj_id>
				<ref_obj_pid>1892875</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. R. Quinlan, "Bagging, boosting, and C4.5", In <i>Proc. of the 13th AAAI Conference on Artificial Intelligence</i>, AAAI Press, Menlo Park, CA, 1996, pp. 725-30.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[E.M. Kleinberg, "Stochastic Discrimination", <i>Annals of Mathematics and Artificial Intelligence</i>, 1, 1990, pp. 207-239.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Y. Freund, R.E. Schapire, "Experiments with a New Boosting Algorithm", in <i>Proc. of the Thirteenth International Conference on Machine Learning</i>, Morgan Kaufmann, 1996, pp. 148-156.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. Kellam, X. Liu, N.J. Martin, C. Orengo, S. Swift and A. Tucker, "Comparing, contrasting and combining clusters in viral gene expression data", Proc. of 6th Workshop on Intelligent Data Analysis in Medicine and Pharmocology, 2001, pp. 56-62.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[F. Leisch, "Bagged clustering", Working Papers SFB "Adaptive Information Systems and Modelling in Economics and Management Science", 51, Institut f&#252;r Informationsverarbeitung, Abt. Produktionsmanagement, Wien, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>686050</ref_obj_id>
				<ref_obj_pid>646258</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[E. Dimitriadou, A. Weingessel and K. Hornik, "Voting-merging: An ensemble method for clustering", In <i>Proc. Int. Conf. on Artificial Neural Networks</i>, Vienna, 2001, pp. 217-224.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>761140</ref_obj_id>
				<ref_obj_pid>648035</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[E. Johnson and H. Kargupta, "Collective, hierarchical clustering from distributed, heterogeneous data", In <i>Large-Scale Parallel KDD Systems</i>, Eds. Zaki M. and Ho C., LNCS 1759, Springer-Verlag, 1999, pp. 221-244.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>639990</ref_obj_id>
				<ref_obj_pid>639960</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[D. H. Fisher, "Knowledge acquisition via incremental conceptual clustering", <i>Machine Learning</i>, 2, 1987, pp. 139- 172.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M.A. Gluck and J.E. Corter, "Information, uncertainty, and the utility of categories", In <i>Proc. of the Seventh Annual Conference of the Cognitive Science Society</i>, Hillsdale, NJ: Lawrence Erlbaum, 1985, pp. 283-287.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>513545</ref_obj_id>
				<ref_obj_pid>513540</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[B. Mirkin, "Reinterpreting the Category Utility Function", <i>Machine Learning</i>, 45(2), 2001, pp. 219-228.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[L. Breiman, J. Friedman, R. Olshen, C. Stone, <i>Classification and Regression Trees</i>. Wadsworth, Monterrey, Ca, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[S.C. Odewahn, E.B. Stockwell, R.L. Pennington, R.M. Humphreys and W.A. Zumach, "Automated Star/Galaxy Discrimination with Neural Networks", <i>Astronomical Journal</i>, 103: 1992, pp. 308-331.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952171</article_id>
		<sort_key>339</sort_key>
		<display_label></display_label>
		<pages>339</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>49</seq_no>
		<title><![CDATA[Visualization of Rule's Similarity using Multidimensional Scaling]]></title>
		<page_from>339</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952171</url>
		<abstract>
			<par><![CDATA[One of the most important problems with rule inductionmethods is that it is very difficult for domain experts to checkmillions of rules generated from large datasets. The discoveryfrom these rules requires deep interpretation from domainknowledge. Although several solutions have been proposedin the studies on data mining and knowledge discovery,these studies are not focused on similarities betweenrules obtained. When one rule r1 has reasonable featuresand the other rule r2 with high similarity to r1 includes unexpectedfactors, the relations between these rules will becomea trigger to the discovery of knowledge. In this paper,we propose a visualization approach to show the similarrelations between rules based on multidimensional scaling,which assign a two-dimensional cartesian coordinateto each data point from the information about similiariesbetween this data and others data. We evaluated this methodon two medical data sets, whose experimental results showthat knowledge useful for domain experts could be found.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Geometric</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Knowledge acquisition</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010282</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning settings</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40025004</person_id>
				<author_profile_id><![CDATA[81100219997]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shusaku]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsumoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P432865</person_id>
				<author_profile_id><![CDATA[81100281744]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shoji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hirano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Adams and M. Victor. <i>Principles of Neurology 5th Edition</i>. McGraw-Hill, New York, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[T. Cox and M. Cox. <i>Multidimensional Scaling</i>. Chapman & Hall/CRC, Boca Raton, 2nd edition, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Eckart and G. Young. Approximation of one matrix by another of lower rank. <i>Psychometrika</i>, 1:211-218, 1936.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[B. Everitt. <i>Cluster Analysis</i>. John Wiley & Son, London, 3rd edition, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>240464</ref_obj_id>
				<ref_obj_pid>240455</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[U. Fayyad, G. Piatetsky-Shapiro, and P. Smyth. The kdd process for extracting useful knowledge from volumes of data. <i>CACM</i>, 29:27-34, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>29379</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. Langley, H. Simon, G. Bradshow, and J. Zytkow. <i>Scientific Discovery: Computational Explorations of the Creative Processes</i>. MIT Press, Cambridge, MA, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[H. Motoda, editor. <i>Active Mining</i>. Number 79 in Frontiers in Artificial Intelligence and Applications. IOS Press, Amsterdam, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Z. Pawlak. <i>Rough Sets</i>. Kluwer Academic Publishers, Dordrecht, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>187235</ref_obj_id>
				<ref_obj_pid>186965</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Skowron and J. Grzymala-Busse. From rough set theory to evidence theory. In R. Yager, M. Fedrizzi, and J. Kacprzyk, editors, <i>Advances in the Dempster-Shafer Theory of Evidence</i>, pages 193-236. John Wiley & Sons, New York, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>305768</ref_obj_id>
				<ref_obj_pid>305762</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[S. Tsumoto. Automated induction of medical expert system rules from clinical databases based on rough set theory. <i>Information Sciences</i>, 112:67-84, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952169</article_id>
		<sort_key>347</sort_key>
		<display_label></display_label>
		<pages>347</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>50</seq_no>
		<title><![CDATA[TSP]]></title>
		<subtitle><![CDATA[Mining Top-K Closed Sequential Patterns]]></subtitle>
		<page_from>347</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952169</url>
		<abstract>
			<par><![CDATA[Sequential pattern mining has been studied extensivelyin data mining community.Most previous studies requirethe specification of a minimum support threshold to performthe mining.However, it is difficult for users to providean appropriate threshold in practice.To overcomethis difficulty, we propose an alternative task: mining top-kfrequent closed sequential patterns of length no less thanmin_l, where k is the desired number of closed sequentialpatterns to be mined, and min_l is the minimum length ofeach pattern.We mine closed patterns since they are compactrepresentations of frequent patterns.We developed an efficient algorithm, called TSP, whichmakes use of the length constraint and the properties of top-kclosed sequential patterns to perform dynamic support-raisingand projected database-pruning.Our extensive performancestudy shows that TSP outperforms the closed sequentialpattern mining algorithm even when the latter isrunning with the best tuned minimum support threshold.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P560165</person_id>
				<author_profile_id><![CDATA[81100234849]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Petre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tzvetkov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P560532</person_id>
				<author_profile_id><![CDATA[81100044779]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xifeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023202</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Mining sequential patterns. In <i>Proc. 1995 Int. Conf. Data Engineering (ICDE'95)</i>, pages 3-14, Taipei, Taiwan, Mar. 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775109</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Ayres, J. E. Gehrke, T. Yiu, and J. Flannick. Sequential pattern mining using bitmaps. In <i>Proc. 2002 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD'02)</i>, pages 429-435, Edmonton, Canada, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847264</ref_obj_id>
				<ref_obj_pid>846218</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Guha, R. Rastogi, and K. Shim. Rock: A robust clustering algorithm for categorical attributes. In <i>Proc. 1999 Int. Conf. Data Engineering (ICDE'99)</i>, pages 512-521, Sydney, Australia, Mar. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844747</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Wang, Y. Lu, and P. Tzvetkov. Mining top-k frequent closed patterns without minimum support. In <i>Proc. 2002 Int. Conf. on Data Mining (ICDM'02)</i>, pages 211-218, Maebashi, Japan, Dec. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Mannila, H. Toivonen, and A. I. Verkamo. Discovering frequent episodes in sequences. In <i>Proc. 1995 Int. Conf. Knowledge Discovery and Data Mining (KDD'95)</i>, pages 210-215, Montreal, Canada, Aug. 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and R. Mao. CLOSET: An efficient algorithm for mining frequent closed itemsets. In <i>Proc. 2000 ACM-SIGMOD Int. Workshop Data Mining and Knowledge Discovery (DMKD'00)</i>, pages 11-20, Dallas, TX, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656379</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, U. Dayal, and M.-C. Hsu. PrefixSpan: Mining sequential patterns efficiently by prefix-projected pattern growth. In <i>Proc. 2001 Int. Conf. Data Engineering (ICDE'01)</i>, pages 215-224, Heidelberg, Germany, April 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650382</ref_obj_id>
				<ref_obj_pid>645337</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Srikant and R. Agrawal. Mining sequential patterns: Generalizations and performance improvements. In <i>Proc. 5th Int. Conf. Extending Database Technology (EDBT'96)</i>, pages 3- 17, Avignon, France, Mar. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956784</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[X. Yan and J. Han. CloseGraph: Mining closed frequent graph patterns. In <i>Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD'03)</i>, Washington, D.C., Aug. 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956784</ref_obj_id>
				<ref_obj_pid>956750</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[X. Yan, J. Han, and R. Afshar. CloSpan: Mining closed sequential patterns in large datasets. In <i>Proc. 2003 SIAM Int. Conf. Data Mining (SDM'03)</i>, pages 166-177, San Fransisco, CA, May 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>370671</ref_obj_id>
				<ref_obj_pid>370660</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Zaki. SPADE: An efficient algorithm for mining frequent sequences. <i>Machine Learning</i>, 40:31-60, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki and C. J. Hsiao. CHARM: An efficient algorithm for closed itemset mining. In <i>Proc. 2002 SIAM Int. Conf. Data Mining (SDM'02)</i>, pages 457-473, Arlington, VA, April 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952170</article_id>
		<sort_key>355</sort_key>
		<display_label></display_label>
		<pages>355</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>51</seq_no>
		<title><![CDATA[Interactive Visualization and Navigation in Large Data Collections using the Hyperbolic Space]]></title>
		<page_from>355</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952170</url>
		<abstract>
			<par><![CDATA[We propose the combination of two recently introducedmethods for the interactive visual data mining of largecollections of data. Both, Hyperbolic Multi-DimensionalScaling (HMDS) and Hyperbolic Self-Organizing Maps(HSOM) employ the extraordinary advantages of the hyperbolicplane (H2): (i) the underlying space grows exponentiallywith its radius around each point - ideal for embeddinghigh-dimensional (or hierarchical) data; (ii) thePoincar&#233; model of the IH2 exhibits a fish-eye perspectivewith a focus area and a context preserving surrounding; (iii)the mouse binding of focus-transfer allows intuitive interactivenavigation.The HMDS approach extends multi-dimensional scalingand generates a spatial embedding of the data representingtheir dissimilarity structure as faithfully as possible. Itis very suitable for interactive browsing of data object collections,but calls for batch precomputation for larger collectionsizes.The HSOM is an extension of Kohonen's Self-OrganizingMap and generates a partitioning of the data collection assignedto an IH2 tessellating grid. While the algorithm'scomplexity is linear in the collection size, the data browsingis rigidly bound to the underlying grid.By integrating the two approaches we gain the synergetic effectof adding advantages of both. And the hybrid architectureuses consistently the IH2 visualization and navigationconcept. We present the successfully application to a textmining example involving the Reuters-21578 text corpus.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Geometric</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Visual</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10010365</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Visual analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645394</person_id>
				<author_profile_id><![CDATA[81100009342]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J&#246;rg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Walter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645393</person_id>
				<author_profile_id><![CDATA[81100616908]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J&#246;rg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ontrup]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645287</person_id>
				<author_profile_id><![CDATA[81100106587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wessling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14064595</person_id>
				<author_profile_id><![CDATA[81100156166]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Helge]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ritter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Cox and M. Cox. <i>Multidimensional Scaling</i>. Chapman and Hall, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H.S.M. Coxeter. <i>Non-Euclidean Geometry</i>. University of Toronto Press, 1957.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>526829</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Kohonen. <i>Self-Organizing Maps</i>, volume 30 of <i>Springer Series in Information Sciences</i>. Springer, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326575</ref_obj_id>
				<ref_obj_pid>2325773</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Kohonen et al. Organization of a massive document collection. <i>IEEE TNN Spec Issue Neural Networks for Data Mining and Knowledge Discovery</i>, 11(3):574-585, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223956</ref_obj_id>
				<ref_obj_pid>223904</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Lamping, R. Rao, and P. Pirolli. A focus+context technique based on hyperbolic geometry for viewing large hierarchies. In <i>ACM SIGCHI</i>, pages 401-408, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192430</ref_obj_id>
				<ref_obj_pid>192426</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Lamping and R. Rao. Laying out and visualizing large trees using a hyperbolic space. In <i>ACM Symp User Interface Software and Technology</i>, pages 13-14, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[F. Morgan. <i>Riemannian Geometry: A Beginner's Guide</i>. Jones and Bartlett Publishers, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>857627</ref_obj_id>
				<ref_obj_pid>857188</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Munzner. H3: Laying out large directed graphs in 3d hyperbolic space. In <i>Proc IEEE Symp Info Vis</i>, pages 2-10, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>365337</ref_obj_id>
				<ref_obj_pid>365024</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[P. Pirolli, S. Card, and M. M. Van Der Wege. Visual information foraging in a focus + context visualization. In <i>CHI</i>, pages 506-513, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>362769</ref_obj_id>
				<ref_obj_pid>362757</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[K. Risden, M. Czerwinski, T. Munzner, and D. Cook. An initial examination of ease of use for 2d and 3d information visualizations of web content. <i>Int J Human Computer Studies</i>, 53(5):695-714, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[H. Ritter. Self-organizing maps on non-euclidean spaces. In <i>Kohonen Maps</i>, pages 97-110. Elsevier, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1310727</ref_obj_id>
				<ref_obj_pid>1310162</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. W. Sammon, Jr. A non-linear mapping for data structure analysis. <i>IEEE Trans Computers</i>, 18:401-409, 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2295801</ref_obj_id>
				<ref_obj_pid>616074</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A. Skupin. A cartographic approach to visualizing conference abstracts. <i>IEEE Computer Graphics and Applications</i>, pages 50-58, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J.A. Thorpe. <i>Elementary Topics in Differential Geometry</i>. Springer, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>985331</ref_obj_id>
				<ref_obj_pid>985329</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. Walter. H-MDS: a new approach for interactive visualization with multidimensional scaling in the hyperbolic space. <i>Information Systems&lt;/i&#62;, (in print), 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775065</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J. Walter and H. Ritter. On interactive visualization of high-dimensional data using the hyperbolic plane. In <i>ACM SIGKDD Int Conf Knowledge Discovery and Data Mining</i>, pages 123-131. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>320410</ref_obj_id>
				<ref_obj_pid>320396</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. Wise. The ecological approach to text visualizationt. <i>J Am Soc Information Sci</i>, 50(13):1224-1233, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952182</article_id>
		<sort_key>363</sort_key>
		<display_label></display_label>
		<pages>363</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>52</seq_no>
		<title><![CDATA[Association Rule Mining in Peer-to-Peer Systems]]></title>
		<page_from>363</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952182</url>
		<abstract>
			<par><![CDATA[We extend the problem of association rule mining -a key data mining problem - to systems in which thedatabase is partitioned among a very large number ofcomputers that are dispersed over a wide area. Such computing systems include GRID computing platforms, federated database systems, and peer-to-peer computing environments. The scale of these systems poses several difficulties, such as the impracticality of global communications and global synchronization, dynamic topology changes ofthe network, on-the-fly data updates, the need to share resources with other applications, and the frequent failureand recovery of resources.We present an algorithm by which every node in thesystem can reach the exact solution, as if it were giventhe combined database. The algorithm is entirely asynchronous, imposes very little communication overhead,transparently tolerates network topology changes andnode failures, and quickly adjusts to changes in the dataas they occur. Simulation of up to 10,000 nodes show thatthe algorithm is local: all rules, except for those whoseconfidence is about equal to the confidence threshold, arediscovered using information gathered from a very smallvicinity, whose size is independent of the size of the system.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>C.2.4</cat_node>
				<descriptor>Distributed databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003195</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Parallel and distributed DBMSs</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010521.10010537</concept_id>
				<concept_desc>CCS->Computer systems organization->Architectures->Distributed architectures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31050862</person_id>
				<author_profile_id><![CDATA[81100634917]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ran]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wolff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P22680</person_id>
				<author_profile_id><![CDATA[81100625706]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Assaf]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schuster]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In <i>Proc. of the 1993 ACM SIGMOD Int'l. Conference on Management of Data</i>, pages 207-216, Washington, D.C., June 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627803</ref_obj_id>
				<ref_obj_pid>627307</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and J. Shafer. Parallel mining of association rules. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 8(6):962-969, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. of the 20th Int'l. Conference on Very Large Databases (VLDB'94)</i>, pages 487-499, Santiago, Chile, September 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253325</ref_obj_id>
				<ref_obj_pid>253262</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, J. Ullman, and S. Tsur. Dynamic itemset counting and implication rules for market basket data. <i>SIGMOD Record</i>, 6(2):255-264, June 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383194</ref_obj_id>
				<ref_obj_pid>382006</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Cheung, J. Han, V. Ng, A. Fu, and Y. Fu. A fast distributed algorithm for mining association rules. In <i>Proc. of 1996 Int'l. Conf. on Parallel and Distributed Information Systems</i>, pages 31-44, Miami Beach, Florida, December 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Entropia. http://www.entropia.com.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628064</ref_obj_id>
				<ref_obj_pid>627328</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E.-H. S. Han, G. Karypis, and V. Kumar. Scalable parallel data mining for association rules. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 12(3):352-377, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>653597</ref_obj_id>
				<ref_obj_pid>645483</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J.-L. Lin and M. H. Dunham. Mining association rules: Anti-skew algorithms. In <i>Proceedings of the 14th Int'l. Conference on Data Engineering (ICDE'98)</i>, pages 486- 493, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287400</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[G. S. Manku and R. Motwani. Approximate frequency counts over data streams. In <i>Proceedings of the 28th International Conference on Very Large Data Bases (VLDB'02)</i>, Hong Kong, China, August 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. C. Project. http://www.cs.wisc.edu/ condor/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375728</ref_obj_id>
				<ref_obj_pid>375663</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Schuster and R. Wolff. Communication-efficient distributed mining of association rules. In <i>Proc. of the 2001 ACM SIGMOD Int'l. Conference on Management of Data</i>, pages 473-484, Santa Barbara, California, May 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Seti@home. http://setiathome.ssl. berkeley.edu/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>653189</ref_obj_id>
				<ref_obj_pid>645446</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. Thomas andi S. Chakravarthy. Incremental mining of constrained associations. In <i>HiPC</i>, pages 547-558. 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[United devices inc. http://www.ud.com/home.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593453</ref_obj_id>
				<ref_obj_pid>593417</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. Parallel algorithms for discovery of association rules. <i>Data Mining and Knowledge Discovery</i>, 1(4):343-373, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952162</article_id>
		<sort_key>371</sort_key>
		<display_label></display_label>
		<pages>371</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>53</seq_no>
		<title><![CDATA[MPIS]]></title>
		<subtitle><![CDATA[Maximal-Profit Item Selection with Cross-Selling Considerations]]></subtitle>
		<page_from>371</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952162</url>
		<abstract>
			<par><![CDATA[In the literature of data mining, many different algorithmsfor association rule mining have been proposed. However,there is relatively little study on how association rules can aidin more specific targets. In this paper, one of the applicationsfor association rules - maximal-profit item selection with cross-selling effect (MPIS) problem - is investigated. The problemis about selecting a subset of items which can give the maximalprofit with the consideration of cross-selling. We provethat a simple version of this problem is NP-hard. We proposea new approach to the problem with the consideration of theloss rule - a kind of association rule to model the cross-sellingeffect. We show that the problem can be transformed to aquadratic programming problem. In case quadratic programmingis not applicable, we also propose a heuristic approach.Experiments are conducted to show that both of the proposedmethods are highly effective and efficient.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.6</cat_node>
				<descriptor>Quadratic programming methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003716.10011138.10011139</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Mathematical optimization->Continuous optimization->Quadratic programming</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003716.10011138.10011139</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Mathematical optimization->Continuous optimization->Quadratic programming</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP36025118</person_id>
				<author_profile_id><![CDATA[81406592097]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Raymond]]></first_name>
				<middle_name><![CDATA[Chi-Wing]]></middle_name>
				<last_name><![CDATA[Wong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15027215</person_id>
				<author_profile_id><![CDATA[81451592510]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ada]]></first_name>
				<middle_name><![CDATA[Wai-Chee]]></middle_name>
				<last_name><![CDATA[Fu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15025877</person_id>
				<author_profile_id><![CDATA[81350574174]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Frontline systems solver, http://www.solver.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal. Ibm synthetic data generator, http://www.almaden.ibm.com/cs/quest/syndata.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imilienski, and Swami. Mining association rules between sets of items in large databases. In <i>SIGMOD</i>, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>VLDB</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J.E. Beasley. Heuristic algorithms for the unconstrained binary quadratic programming problem. In <i>Technical report, the Management School, Imperial College, London</i>, Dec 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Blischok. Every transaction tells a story. In <i>Chain Store Age Executive with Shopping Center Age 71 (3)</i>, pages 50-57, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347156</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Brijs, B. Goethals, G. Swinnen, K. Vanhoof, and G. Wets. A data mining framework for optimal product selection in retail supermarket data: The generalized profset model. In <i>SIGKDD</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312241</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Brijs, G. Swinnen, K. Vanhoof, and G. Wets. Using association rules for product assortment decisions: A case study. In <i>SIGKDD</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>578533</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M.R. Garey and D.S. Johnson. Computers and intractability: A guide to the theory of np-completeness. In <i>Freeman</i>, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>SIGMOD</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Hedberg. The data gold rush. In <i>BYTE, October</i>, pages 83- 99, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1197683</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hiller and Lieberman. Introduction to operations research. In <i>McGraw Hill, Seventh Edition</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[B. V. Hohenbalken. A finite algorithm to maximize certain pseudoconcave functions on polytopes. In <i>Mathematical Programming 8</i>, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1214491</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Horst, P. M. Pardalos, and N. V. Thoai. Introduction to global optimization. In <i>Kluwer Academic Publishers, Second Edition</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[J. C. Hull. Options, futures, and other derivatives. In <i>prentice Hall International, Inc. (3rd Edition)</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[L.D. Iasemidis, P. Pardalos, J.C. Sackellares, and D.S. Shiau. Quadratic binary programming and dynamical system approach to determine the predictability of epileptic seizures. In <i>Journal of Combinatorial Optimization, Kluwer Academic.</i>, pages 9-26, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593470</ref_obj_id>
				<ref_obj_pid>593421</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. Kleinberg, C. Papadimitriou, and P. Raghavan. A microeconomic view of data mining. In <i>Knowledge Discovery Journal</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>315045</ref_obj_id>
				<ref_obj_pid>314613</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[J. M. Kleinberg. Authoritative sources in a hyperlinked environment. In <i>Proc. ACM-SIAM Symp. on Discrete Algorithms</i>, 1998, Also in JACM 46:5, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[S. J. Leon. Linear algebra with applications. In <i>Prentice Hall, Fifth Edition</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[J. Luo, K. R. Pattipati, and P.K. Willett. A sub-optimal soft decision pda method for binary quadratic programming. In <i>Proc. of the IEEE Systems, Man, and Cybernetics Conference</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656095</ref_obj_id>
				<ref_obj_pid>645502</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[H. Mannila. Methods and problems in data mining. In <i>Proc. of Int. Conf. on Database Theory</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[H. Mannila, H. Toivonen, and A. I. Verkamo. Efficient algorithms for discovering association rules. In <i>KDD</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>598769</ref_obj_id>
				<ref_obj_pid>598691</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[V. Safronov and M. Parashar. Optimizing web servers using page rank prefetching for clustered accesses. In <i>World Wide Web: Internet and Web Information Systems Volume 5, Number 1</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[S. Sahni. Computationally related problems. In <i>SIAM J. Comput. 3</i>, pages 262-279, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[J. Ullman. Lecture notes on searching the web, http://wwwdb.stanford.edu/ullman/mining/mining.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775144</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[K. Wang and M.Y. Su. Item selection by "hub-authority" profit ranking. In <i>SIGKDD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952165</article_id>
		<sort_key>379</sort_key>
		<display_label></display_label>
		<pages>379</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>54</seq_no>
		<title><![CDATA[Efficient Data Mining for Maximal Frequent Subtrees]]></title>
		<page_from>379</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952165</url>
		<abstract>
			<par><![CDATA[A new type of tree mining is defined in this paper,which uncovers maximal frequent induced subtrees from adatabase of unordered labeled trees. A novel algorithm,PathJoin, is proposed. The algorithm uses a compact datastructure, FST-Forest, which compresses the trees and stillkeeps the original tree structure. PathJoin generates candidatesubtrees by joining the frequent paths in FST-Forest.Such candidate subtree generation is localized and thussubstantially reduces the number of candidate subtrees. Experimentswith synthetic data sets show that the algorithmis effective and efficient.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP79024731</person_id>
				<author_profile_id><![CDATA[81470650968]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yongqiao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xiao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645368</person_id>
				<author_profile_id><![CDATA[81100542656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jenq-Foung]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14166640</person_id>
				<author_profile_id><![CDATA[81414607847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Zhigang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77028826</person_id>
				<author_profile_id><![CDATA[81409595451]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Margaret]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Dunham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for minmg association rules in large databases. In <i>Proceedings of the Twentieth International Conference on Very Large Databases</i>, pages 487-499, Santiago, Chile, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Mining sequential patterns. In <i>Proceedings of the 11th International Conference on Data Engineering</i>, Taipei, Taiwan, Mar. 1995. IEEE Computer Society Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Asai, K. Abe, S. Kawasoe, H. Arimura, H. Satamoto, and S. Arikawa. Efficiently substructure discovery from large semi-structured data. In <i>Proceedings of the 2nd SIAM Int'l Conference on Data Mining</i>, april 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627906</ref_obj_id>
				<ref_obj_pid>627315</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M.-S. Chen, J. S. Park, and P. S. Yu. Efficient data mining for path traversal patterns. <i>IEEE Transactions on Knowledge and Data Engineering</i>, 10(2):209-221, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Cong, L. Yi, B. Liu, and K. Wang. Discovering frequent substructures from hierarchical semi-structured data. In <i>Proceedings of the 2nd SIAM Int'l Conference on Data Mining</i>, Arlington, VA, april 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>Proceedings of the ACM SlGMOD Conference</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669817</ref_obj_id>
				<ref_obj_pid>645804</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. Inokuchi, T. Washio, and H. Motoda. An apriori-pased algorithm for mining frequent substructures from graph data. In <i>Proceedings of the 4th European Conference on Principles of Knowledge Discovery and Data Mining</i>, sep 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658027</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Kuramochi and G. Karypis. Frequent subgraph discovery. In <i>Proceedings of the 1st IEEE Int'l Conference on Data Mining</i>, nov 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>543620</ref_obj_id>
				<ref_obj_pid>543613</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Shasha, J. Wang, and R. Giugno. Algorithms and applications of tree and graph searching. In <i>Proceedings of the 21st ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems</i>, pages 39-52, Madison, Wisconsin, june 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>543184</ref_obj_id>
				<ref_obj_pid>543180</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Y. Xiao and M. H. Dunham. Efficient mining of traversal patterns. <i>Data and Knowledge Engineering</i>, 39:191-214, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844811</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[X. Yan and J. Han. gspan: Graph-based substructure pattern mining. In <i>Proceedings of the 2002 IEEE International Conference on Data Mining (ICDM 2002), 9-12 December 2002, Maebashi City, Japan</i>, pages 721-724. IEEE Computer Society, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775058</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Efficiently mining frequent trees in a forest. In <i>Proceedings of the 8th ACM SIGKDD Int'l Conference on Knowledge Discovery and Data Mining</i>, Edmonton, Canada, jul 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952153</article_id>
		<sort_key>387</sort_key>
		<display_label></display_label>
		<pages>387</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>55</seq_no>
		<title><![CDATA[Mining Strong Affinity Association Patterns in Data Sets with Skewed Support Distribution]]></title>
		<page_from>387</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952153</url>
		<abstract>
			<par><![CDATA[Existing association-rule mining algorithms often relyon the support-based pruning strategy to prune its combinatorialsearch space. This strategy is not quite effectivefor data sets with skewed support distributions because theytend to generate many spurious patterns involving itemsfrom different support levels or miss potentially interestinglow-support patterns. To overcome these problems, we proposethe concept of hyperclique pattern, which uses an objectivemeasure called h-confidence to identify strong affinitypatterns. We also introduce the novel concept of cross-supportproperty for eliminating patterns involving itemswith substantially different support levels. Our experimentalresults demonstrate the effectiveness of this method forfinding patterns in dense data sets even at very low supportthresholds, where most of the existing algorithms wouldbreak down. Finally, hyperclique patterns also show greatpromise for clustering items in high dimensional space.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14114668</person_id>
				<author_profile_id><![CDATA[81451596433]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xiong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15028879</person_id>
				<author_profile_id><![CDATA[81100314838]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pang-Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95033804</person_id>
				<author_profile_id><![CDATA[81452613746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Vipin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>170072</ref_obj_id>
				<ref_obj_pid>170035</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases. In <i>Proc. of the ACM SIGMOD</i>, pages 207-216, May 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. of the 20th VLDB</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276313</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. J. Bayardo. Efficiently mining long patterns from databases. In <i>Proc. of the ACM SIGMOD</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253327</ref_obj_id>
				<ref_obj_pid>253260</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, and C. Silverstein. Beyond market baskets: Generalizing association rules to correlations. In <i>Proc. of the ACM SIGMOD</i>, pages 265-276, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656386</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Burdick, M. Calimlim, and J. Gehrke. Mafia: A maximal frequent itemset algorithm for transactional databases. In <i>Proc. of the ICDE</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628111</ref_obj_id>
				<ref_obj_pid>627332</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[E. Cohen, M. Datar, S. Fujiwara, A. Gionis, P. Indyk, R. Motwani, J. Ullman, and C. Yang. Finding interesting associations without support pruning. In <i>ICDE</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Han, G. Karypis, and V. Kumar. Hypergraph based clustering in high-dimensional data sets: A summary of results. <i>Bulletin of the Technical Committee on Data Engineering</i>, 21(1), March 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Hastie, R. Tibshirani, and J. Friedman. <i>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</i>. Springer, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Jain and R. Dubes. <i>Algorithms for Clustering Data</i>. Prentice Hall, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642922</ref_obj_id>
				<ref_obj_pid>642913</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E. Omiecinski. Alternative interest measures for mining associations. In <i>IEEE TKDE</i>, Jan/Feb 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, and R. Mao. Closet: An efficient algorithm for mining frequent closed itemsets. In <i>DMKD</i>, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>539927</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[C. J. V. Rijsbergen. <i>Information Retrieval (2nd Edition)</i>. Butterworths, London, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775053</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[P. Tan, V. Kumar, and J. Srivastava. Selecting the right interestingness measure for association patterns. In <i>Proc of the Eighth ACM SIGKDD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502601</ref_obj_id>
				<ref_obj_pid>502585</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[K. Wang, Y. He, D. Cheung, and Y. Chin. Mining confident rules without support requirement. In <i>ACM CIKM</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[H. Xiong, P. Tan, and V. Kumar. Mining hyperclique patterns with confidence pruning. In <i>Technical Report 03-006, Computer Science, Univ. of Minnesota.</i>, Jan 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. Zaki and C.-J. Hsiao. Charm: An efficient algorithm for closed itemset mining. In <i>Proc. of the 2nd SDM</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952172</article_id>
		<sort_key>395</sort_key>
		<display_label></display_label>
		<pages>395</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>56</seq_no>
		<title><![CDATA[On Precision and Recall of Multi-Attribute Data Extraction from Semistructured Sources]]></title>
		<page_from>395</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952172</url>
		<abstract>
			<par><![CDATA[Machine learning techniques for data extraction fromsemistructured sources exhibit different precision and recallcharacteristics. However to date the formal relationship betweenlearning algorithms and their impact on these twometrics remains unexplored. This paper proposes a formalizationof precision and recall of extraction and investigatesthe complexity-theoretic aspects of learning algorithms formulti-attribute data extraction based on this formalism. Weshow that there is a tradeoff between precision/recall of extractionand computational efficiency and present experimentalresults to demonstrate the practical utility of theseconcepts in designing scalable data extraction algorithmsfor improving recall without compromising on precision.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.3</cat_node>
				<descriptor>Answer/reason extraction</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Parameter learning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010316</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010196</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Logic programming and answer set programming</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P100427</person_id>
				<author_profile_id><![CDATA[81100353095]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Guizhen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43125311</person_id>
				<author_profile_id><![CDATA[81337491961]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Saikat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mukherjee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43123319</person_id>
				<author_profile_id><![CDATA[81452611166]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[I.]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Ramakrishnan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>276330</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Adelberg. NoDoSe: A tool for semi-automatically extracting structured and semi-structured data from text documents. In <i>ACM International Conference on Management of Data (SIGMOD)</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Angluin. On the complexity of minimum inference of regular sets. <i>Information and Control</i>, 39(3):337-350, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>872799</ref_obj_id>
				<ref_obj_pid>872757</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Arasu and H. Garcia-Molina. Extracting structured data from Web pages. In <i>ACM International Conference on Management of Data (SIGMOD)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>271078</ref_obj_id>
				<ref_obj_pid>271074</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[N. Ashish and C. Knoblock. Wrapper generation for semistructured Internet sources. <i>SIGMOD Record</i>, 26(4):8-15, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>511477</ref_obj_id>
				<ref_obj_pid>511446</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[W. Cohen, M. Hurst, and L. Jensen. A flexible learning system for wrapping tables and lists in HTML documents. In <i>International World Wide Web Conference (WWW)</i> 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672370</ref_obj_id>
				<ref_obj_pid>645927</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[V. Crescenzi, G. Mecca, and P. Merialdo. RoadRunner: Towards automatic data extraction from large Web sites. In <i>International Conference on Very Large Data Bases (VLDB)</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288641</ref_obj_id>
				<ref_obj_pid>288627</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. W. Embley, D. M. Campbell, R. D. Smith, and S. W. Liddle. Ontology-based extraction and structuring of information from data-rich unstructured documents. In <i>ACM Internation Conference on Information and Knowleage Management (CIKM)</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304223</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. W. Embley, Y. Jiang, and Y.-K. Ng. Record-boundary discovery in Web documents. In <i>ACM International Conference on Management of Data (SIGMOD)</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[E. M. Gold. Complexity of automaton identification from given data. <i>Information and Control</i>, 37(3):302-320, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253395</ref_obj_id>
				<ref_obj_pid>253260</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Hammer, H. Garcia-Molina, S. Nestorov, R. Yerneni, M. M. Breunig, and V. Vassalos. Template-based Wrappers in the TSIMMIS system. In <i>ACM International Conference on Managemenl of Data (SIGMOD)</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>306775</ref_obj_id>
				<ref_obj_pid>306766</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[C.-N. Hsu and M.-T. Dung. Generating finite-state transducers for semi-structured data extraction from the Web. <i>Information Systems</i>, 23(8):521-538, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>162440</ref_obj_id>
				<ref_obj_pid>162406</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. Jiang and M. Li. On the complexity of learning strings and sequences. <i>Theoretical Computer Science</i>, 119(2):363- 371, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[N. Kushmerick, D. S. Weld, and R. B. Doorenbos. Wrapper induction for information extraction. In <i>International Joint Conference on Artificial Intelligence (IJCAI)</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>322075</ref_obj_id>
				<ref_obj_pid>322063</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[D. Maier. The complexity of some problems on subsequences and supersequences. <i>Journal of ACM</i>, 25(2):322- 336, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>208847</ref_obj_id>
				<ref_obj_pid>208810</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. Middendrof. On finding various minimal, maximal, and consistent sequences over a binary alphabet. <i>Theoretical Computer Science</i>, 145(1-2):317-327, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>301191</ref_obj_id>
				<ref_obj_pid>301136</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[I. Muslea, S. Minton, and C. Knoblock. A hierarchical approach to wrapper induction. In <i>Third International Conference on Autonomous Agents (Agents '99)</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>255480</ref_obj_id>
				<ref_obj_pid>255478</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[M. Perkowitz, R. B. Doorenbos, O. Etzioni, and D. S. Weld. Learning to understand information on the Internet: An example-based approach. <i>Journal of Intelligent Information Systems</i>, 8(2):133-153, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[K.-J. R&#228;ih&#228; and E. Ukkonen. The shortest common supersequence problem over binary alphabet is NP-complete. <i>Theoretical Computer Science</i>, 16:187-198, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[A. Sahuguet and F. Azavant. Web Ecology: Recycling HTML pages as XML documents using W4F. In <i>ACM SIGMOD Workshop on the Web and Databases (WebDB)</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>309510</ref_obj_id>
				<ref_obj_pid>309497</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. Soderland. Learning information extraction rules for semi-structured and free text. <i>Machine Learning</i> 34(1-3), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956907</ref_obj_id>
				<ref_obj_pid>956863</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[G. Yang, I. V. Ramakrishnan, and M. Kifer. On the complexity of schema inference from Web pages in the presence of nullalbe data attributes. In <i>ACM Internation Conference on Information and Knowledge Management (CIKM)</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952146</article_id>
		<sort_key>403</sort_key>
		<display_label></display_label>
		<pages>403</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>57</seq_no>
		<title><![CDATA[Mining Plans for Customer-Class Transformation]]></title>
		<page_from>403</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952146</url>
		<abstract>
			<par><![CDATA[We consider the problem of mining high-utility plansfrom historical plan databases that can be used to transformcustomers from one class to other, more desirable classes.Traditional data mining algorithms are focused on findingfrequent sequences. But high frequency may not imply lowcosts and high benefits. Traditional Markov Decision Process(MDP) algorithms are designed to address this issueby bringing in the concept of utility, but these algorithmsare also known to be expensive to execute. In this paper,we present a novel algorithm AUPlan which automaticallygenerates sequential plans with high utility by combiningdata mining and AI planning. These high-utility plans couldbe used to convert groups of customers from less desirablestates to more desirable ones. Our algorithm adapts theApriori algorithm by considering the concepts of plans andutilities. We show through empirical studies that planningusing our integrated algorithm produces high-utility plansefficiently.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Plan execution, formation, and generation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Markov processes</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010199</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Planning and scheduling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003651</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Markov networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003700.10003701</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Stochastic processes->Markov processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP77025026</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77040952</person_id>
				<author_profile_id><![CDATA[81460641808]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cheng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Mining sequential patterns. In P. Yu and A. Chen, editors, <i>Proceedings of 11th International Conference on Data Engineering (ICDE'95)</i>, pages 3-14, Taipei, Taiwan, March 1995. lEEE Computer Society Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347167</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, Mortazavi-Asl, Q. Chen, U. Dayal, and M.-C. Hsu. Freespan: Frequent pattern-projected sequential pattern mining. In <i>Proceedings of the 2000 International Conference on Knowledge Discovery and Data Mining (KDD'00)</i>, pages 355-359, Boston, MA, August 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Han, Q. Yang, and E. Kim. Plan mining by divide-and-conquer. In <i>Proceedings of SIGMOD'99 Workshop on Research Issues on Data Mining and Knowledge Discovery (DMKD'99)</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622748</ref_obj_id>
				<ref_obj_pid>1622737</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Kaelbling, M. Littman, and A. Moore. Reinforcement learning: A survey. <i>Journal of Artificial Intelligence Research</i>, 4:237-285, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>864920</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[L. P. Kaelbling, M. L. Littman, and A. R. Cassandra. Planning and acting in partially observable stochastic domains. Technical Report CS-96-08, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Ling and C. Li. Data mining for direct marketing: Problems and solutions. In <i>Proceedings of the Fourth International Conference on Knowledge Discovery and Date Mining (KDD'98)</i>, pages 73-79, New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669334</ref_obj_id>
				<ref_obj_pid>645802</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[F. Masseglia, F. Cathala, and P. Poncelet. The psp approach for mining sequential patterns. <i>Principles of Data Mining and Knowledge Discovery</i>, pages 176-184, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775086</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[E. Pednault, N. Abe, and B. Zadrozny. Sequential cost-sensitive decision making with reinforcement learning. In <i>Proceedings of the Eighth International Conference on Knowledge Discovery and Data Mining (KDD'02)</i>, pages 259-268, Edmonton, Canada, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656379</ref_obj_id>
				<ref_obj_pid>645484</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, U. Dayal, and M.-C. Hsu. Prefixspan: Mining sequential patterns efficienlly by prefix projected pattern growth. In <i>Proceedings of the 2001 International Conference on Data Engineering (ICDE'01)</i>, pages 215-226, Heidelberg Germany, April 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. R. Quinlan. <i>C4.5: Programming for Machine Learning</i>. Morgan Kaufmann Publishers, San Mateo, CA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>193191</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Russell and P. Norvig. <i>Artificial Intelligence: A Modern Approach</i>. Prentice-Hall, Upper Saddle River, NJ, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650382</ref_obj_id>
				<ref_obj_pid>645337</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[R. Srikant and R. Agrawal. Mining sequential patterns Generalizations and performance improvements. In P. Apers, M. Bouzeghoub, and G. Gardarin, editors, <i>Proceedings of 5th International Conference on Extending Database Technology (EDBT'96)</i>, volume 1057, pages 3-17, Springer Verlag, March 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>508442</ref_obj_id>
				<ref_obj_pid>508440</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[R. Sun and C. Sessions. Learning plans without a priori knowledge. <i>Adaptive Behavior</i>, 8(3/4):225-253, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>551283</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Sutton and A. Barto. <i>Reinforcement Learning: An Introduction</i>. MIT Press, Cambridge, MA, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. Zaki, N. Lesh, and M. Ogihara. Planmine: Sequence mining for plan failures. In <i>Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining (KDD'98)</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>370671</ref_obj_id>
				<ref_obj_pid>370660</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Spade: An efficient algorithm for mining frequent sequences. <i>Machine Learning, special issue on Unsupervised Learning</i>, 42(1/2):31-60, Jan/Feb 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952142</article_id>
		<sort_key>411</sort_key>
		<display_label></display_label>
		<pages>411</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>58</seq_no>
		<title><![CDATA[Segmenting Customer Transactions Using a Pattern-Based Clustering Approach]]></title>
		<page_from>411</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952142</url>
		<abstract>
			<par><![CDATA[Grouping customer transactions into categories helpsunderstand customers better. The marketing literaturehas concentrated on identifying important segmentationvariables (e.g. customer loyalty) and on using clusteringand mixture models for segmentation. The data miningliterature has provided various clustering algorithms forsegmentation. In this paper we investigate using"pattern-based" clustering approaches to groupingcustomer transactions. We argue that there are clustersin transaction data based on natural behavioral patterns,and present a new technique, YACA, that groupstransactions such that itemsets generated from eachcluster, while similar to each other, are different fromones generated from others. We present experimentalresults from user-centric Web usage data thatdemonstrates that YACA generates a highly effectiveclustering of transactions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP95034726</person_id>
				<author_profile_id><![CDATA[81452598812]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yinghui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14060415</person_id>
				<author_profile_id><![CDATA[81100143010]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Balaji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Padmanabhan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>257975</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agrawal, R., Mannila, H., Srikant, R., Toivonen, H. and Verkamo, A. I., "Fast Discovery of Association Rules", Advances in Know. Discovery and Data Mining, Chapter 12, AAAI/MIT Press, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Allenby, G. M. and Rossi, P. E., "Marketing Models of Consumer Heterogeneity", Journal of Econometrics 89(1999) 57-78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775110</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Beil, F., Eater, M. and Xu, X., "Frequent Term-Based Text Clustering", Proc. 8th Int. Conf. on Knowledge Discovery and Data Mining (KDD '2002), Edmonton, Alberta, Canada, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fraley, C. and Raftery, A. E., "How many clusters? Which clustering method? - Answers via Model-Based Cluster Analysis". Technical Report no. 329, Department of Statistics, University of Washington, Computer Journal 41:578-588 (1998).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fraley, C. and Raftery, A. E., "Model-Based Clustering, Discriminant Analysis, and Density Estimation", Tech Rep. 380, Department of Statistics, University of Washington, Seattle, WA, Oct. 2000. Journal of the American Statistical Association 97:611-631 (2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671202</ref_obj_id>
				<ref_obj_pid>645924</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gibson, D., Kleinberg, J., Raghavan P., "Clustering Categorical Data: An Approach Based on Dynamical Systems", the VLDB Conference, New York City, New York, August 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847264</ref_obj_id>
				<ref_obj_pid>846218</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Guha, S., Rastogi, R., Shim K., "ROCK: A Clustering Algorithm for Categorical Attributes", the 15th International Conference on IEEE Data Engineering, Sydney, Australia, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Han, E., Karypis, G., Kumar, V. and Mobasher, B., "Clustering based on association rule hypergraphs", in Proceedings of the SIGMOD'97 Workshop on Research Issues in Data Mining and Knowledge Discovery. 1997, ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>266273</ref_obj_id>
				<ref_obj_pid>266021</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Karypis, G., Aggarwal, R., Kumar, V. and Shekhar, S., "Multilevel hypergraph partitioning: application in VLSI domain". In Proceedings of the ACM/IEEE Design Automation Conference, Canada (1997).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kimbrough, S., Padmanabhan, B. and Zheng, Z., "On Usage Metric for Determining Authoritative Sites", Procs. Workshop on Information Technology and Systems WITS 2000, December 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564737</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wang, H., Yang, J., Wang, W., and Yu, P.S., "Clustering by Pattern Similarity in Large Data Sets", Proc. ACM SIGMOD Conference, Madison, WI, June 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>320054</ref_obj_id>
				<ref_obj_pid>319950</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Wang, K., Xu, C. and Liu, B. "Clustering Transactions Using Large Items", Proc. 8th Int. Conf. on Information and Knowledge Management (ACM CIKM'99), Kansas City, November, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775149</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Yang, Y., Guan, X., You, J., "CLOPE: A Fast and Effective Clustering Algorithm for Transactional Data", SIGKDD '02, July 23-26, 2002, Edmonton, Alberta, Canada.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Zhao, Y. and Karypis, G., "Criterion functions for document clustering: experiments and analysis", Tech. Report #01-40, Department of Comp. Sci. & Eng., U. Minnesota, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952131</article_id>
		<sort_key>419</sort_key>
		<display_label></display_label>
		<pages>419</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>59</seq_no>
		<title><![CDATA[A new optimization criterion for generalized discriminant analysis on undersampled problems]]></title>
		<page_from>419</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952131</url>
		<abstract>
			<par><![CDATA[A new optimization criterion for discriminant analysis ispresented. The new criterion extends the optimization criteriaof the classical linear discriminant analysis (LDA) byintroducing the pseudo-inverse when the scatter matricesare singular. It is applicable regardless of the relative sizesof the data dimension and sample size, overcoming a limitationof the classical LDA. Recently, a new algorithm calledLDA/GSVD for structure-preserving dimension reductionhas been introduced, which extends the classical LDA tovery high-dimensional undersampled problems by using thegeneralized singular value decomposition (GSVD). The solutionfrom the LDA/GSVD algorithm is a special case of thesolution for our generalized criterion in this paper, which isalso based on GSVD.We also present an approximate solution for our GSVD-basedsolution, which reduces computational complexity byfinding sub-clusters of each cluster, and using their centroidsto capture the structure of each cluster. This reducedproblem yields much smaller matrices of which the GSVDcan be applied efficiently. Experiments on text data, withup to 7000 dimensions, show that the approximation algorithmproduces results that are close to those produced bythe exact algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.1.3</cat_node>
				<descriptor>Matrix inversion</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.1</cat_node>
				<descriptor>Computations on matrices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.3</cat_node>
				<descriptor>Eigenvalues and eigenvectors (direct and iterative methods)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003719</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on matrices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010148.10010149.10010158</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms->Linear algebra algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14026671</person_id>
				<author_profile_id><![CDATA[81100042425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jieping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ye]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14185212</person_id>
				<author_profile_id><![CDATA[81100533794]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ravi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Janardan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030187</person_id>
				<author_profile_id><![CDATA[81384617662]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Cheong]]></first_name>
				<middle_name><![CDATA[Hee]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030206</person_id>
				<author_profile_id><![CDATA[81100158952]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Haesun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>222514</ref_obj_id>
				<ref_obj_pid>222504</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M.W. Berry, S.T. Dumais, and G.W. O'Brien. Using linear algebra for intelligent information retrieval. <i>SIAM Review</i>, 37:573-595, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. Deerwester, S.T. Dumais, G.W. Furnas, T.K. Landauer, and R. Harshman. Indexing by latent semantic analysis. <i>J. of the Society for Information Science</i>, 41, pp. 391-407, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>370699</ref_obj_id>
				<ref_obj_pid>370660</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[I.S. Dhillon and D.S. Modha. Concept Decompositions for Large Sparse Text Data using Clustering. <i>Machine Learning</i>. 42, pp. 143-175, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>954544</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R.O. Duda and P.E. Hart, and D. Stork. Pattern Classification. Wiley, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>92131</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[K. Fukunaga. <i>Introduction to Statistical Pattern Recognition</i>, 2nd edition. Academic Press, Inc., 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G.H. Golub, and C.F. Van Loan. Matrix Computations, John Hopkins Univ. Press, 3rd edition, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>782166</ref_obj_id>
				<ref_obj_pid>782132</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. Howland, M. Jeon, and H. Park. Cluster structure preserving dimension reduction based on the generalized singular value decomposition. <i>SIMAX</i>, 25(1), pp. 165-179, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A.K. Jain, and R.C. Dubes. Algorithms for Clustering Data. <i>Prentice Hall</i>, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C.C. Paige, and M.A. Saunders. Towards a generalized singular value decomposition, <i>SIAM Journal on Numerical Analysis</i>. 18, pp. 398-405, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[H. Park, M. Jeon and J.B. Rosen. Lower dimensional representation of text data based on centroids and least squares. <i>BIT</i>, 43(2), pp. 1-22, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[C. F. Van Loan. Generalizing the singular value decomposition. <i>SIAM Journal on Numerical Analysis</i>, 13(1), pp. 76-83, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Ye, R. Janardan, C.H. Park, and H. park. A new optimization criterion for generalized discriminant analysis on undersampled problems. Technical Report TR03-026. University of Minnesota, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952133</article_id>
		<sort_key>427</sort_key>
		<display_label></display_label>
		<pages>427</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>60</seq_no>
		<title><![CDATA[Sentiment Analyzer]]></title>
		<subtitle><![CDATA[Extracting Sentiments about a Given Topic using Natural Language Processing Techniques]]></subtitle>
		<page_from>427</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952133</url>
		<abstract>
			<par><![CDATA[We present Sentiment Analyzer (SA) that extracts sentiment(or opinion) about a subject from online text documents.Instead of classifying the sentiment of an entire documentabout a subject, SA detects all references to the givensubject, and determines sentiment in each of the referencesusing natural language processing (NLP) techniques. Oursentiment analysis consists of 1) a topic specific featureterm extraction, 2) sentiment extraction, and 3) (subject,sentiment) association by relationship analysis. SA utilizestwo linguistic resources for the analysis: the sentiment lexiconand the sentiment pattern database. The performanceof the algorithms was verified on online product review articles("digital camera" and "music" reviews), and moregeneral documents including general webpages and newsarticles.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Textual databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.7.5</cat_node>
				<descriptor>Document analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010505</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P138667</person_id>
				<author_profile_id><![CDATA[81451594723]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jeonghee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P642596</person_id>
				<author_profile_id><![CDATA[81100434738]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tetsuya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nasukawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645513</person_id>
				<author_profile_id><![CDATA[81100589066]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Razvan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bunescu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P297012</person_id>
				<author_profile_id><![CDATA[81100054223]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wayne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Niblack]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1034697</ref_obj_id>
				<ref_obj_pid>1034678</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Berland and E. Charniak. Finding parts in very large corpora. In <i>Proc. of the 37th ACL Conf.</i>, pages 57-64, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. Das and M. Chen. Yahoo! for anazon: Extracting market sentiment from stock message boards. In <i>Proc. of the 8th APFA</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775226</ref_obj_id>
				<ref_obj_pid>775152</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K. Dave, S. Lawrence, and D. M. Pennock. Mining the peanut gallery: Opinion extraction and semantic classification of product reviews. In <i>Proc. of the 12th Int. WWW Conf.</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>972454</ref_obj_id>
				<ref_obj_pid>972450</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. E. Dunning. Accurate methods for the statistics of surprise and coincidence. <i>Computational Linguistics</i>, 19(1), 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>979640</ref_obj_id>
				<ref_obj_pid>979617</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[V. Hatzivassiloglou and K. R. McKeown. Predicting the semantic orientation of adjectives. In <i>Proc. of the 35th ACL Conf.</i>, pages 174-181, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>132429</ref_obj_id>
				<ref_obj_pid>132407</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Hearst. Direction-based text interpretation as an information access refinement. <i>Text-Based Intelligent Systems</i>, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B. Katz. From sentence processing to information access on the world wide web. In <i>Proc. of AAAI Spring Symp. on NLP</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502579</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Li and K. Yamanishi. Mining from open answers in questionnaire data. In <i>Proc. of the 7th ACM SIGKDD Conf.</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311445</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. Manning and H. Schutze. <i>Foundations of Statistical Natural Language Processing</i>. MIT Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>972475</ref_obj_id>
				<ref_obj_pid>972470</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. Building a large annotated corpus of english: the penn treebank. <i>Computational Linguistics</i>, 19, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G. A. Miller. Nouns in WordNet: A lexical inheritance system. <i>Int. J. of Lexicography</i>, 2(4):245-264, 1990. Also available from ftp://ftp.cogsci.princeton.edu/pub/wordnet/5papers.ps.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775098</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Morinaga, K. Yamanishi, K. Teteishi, and T. Fukushima. Mining product reputations on the web. In <i>Proc. of the 8th ACM SIGKDD Conf.</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1118704</ref_obj_id>
				<ref_obj_pid>1118693</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up? sentiment classification using machine learning techniques. In <i>Proc. of the 2002 ACL EMNLP Conf.</i>, pages 79-86, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. Ratnaparkhi. A maximum entropy model for part-of-speech tagging. In <i>Proc. of the EMNLP Conf.</i>, plges 133- 142, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[L. Rovinelli and C. Whissell. Emotion and style in 30-second television advertisements targeted at men, women, boys, and girls. <i>Perceptual and Motor Skills</i>, 86:1048-1050, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199839</ref_obj_id>
				<ref_obj_pid>199480</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[W. Sack. On the computation of point of view. In <i>Proc. of the 12th AAAI Conf.</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2234953</ref_obj_id>
				<ref_obj_pid>2234524</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[P. Subasic and A. Huettner. Affect analysis of text using fuzzy semantic typing. <i>IEEE Trans. on Fuzzy Systems, Special Issue</i>, Aug., 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245122</ref_obj_id>
				<ref_obj_pid>245108</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[L. Terveen, W. Hill, B. Amento, D. McDonald, and J. Creter. PHOAKS: A system for sharing recommendations. <i>CACM</i>, 40(3):59-62, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[R. M. Tong. An operational system for detecting and tracking opinions in on-line discussion. In <i>SIGIR Workshop on Operational Text Classification</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073153</ref_obj_id>
				<ref_obj_pid>1073083</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[P. D. Turney. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews. In <i>Proc. of the 40th ACL Conf.</i>, pages 417-424, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[C. Whissell. The dictionary of affect in language. <i>Emotion: Theory, Research, and Experience</i>, pages 113-131.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>721121</ref_obj_id>
				<ref_obj_pid>647288</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[J. M. Wiebe. Learning subjective adjectives from corpora. In <i>Proc. of the 17th AAAI Conf.</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502654</ref_obj_id>
				<ref_obj_pid>502585</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[C. Zhai and J. Lafferty. Model-based feedback in the lanuage modeling approach to information retrieval. In <i>Proc. of the 10th Information and Knowledge Management Conf.</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Y. Zhang, W. Xu, and J. Callan. Exact maximum likelihood estimation for word mixtures. In <i>ICML Workshop on Text Learning</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952181</article_id>
		<sort_key>435</sort_key>
		<display_label></display_label>
		<pages>435</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>61</seq_no>
		<title><![CDATA[Cost-Sensitive Learning by Cost-Proportionate Example Weighting]]></title>
		<page_from>435</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952181</url>
		<abstract>
			<par><![CDATA[We propose and evaluate a family of methods for convertingclassifier learning algorithms and classification theoryinto cost-sensitive algorithms and theory. The proposedconversion is based on cost-proportionate weighting of thetraining examples, which can be realized either by feedingthe weights to the classification algorithm (as often done inboosting), or by careful subsampling. We give some theoreticalperformance guarantees on the proposed methods,as well as empirical evidence that they are practical alternativesto existing approaches. In particular, we proposecosting, a method based on cost-proportionate rejectionsampling and ensemble aggregation, which achievesexcellent predictive performance on two publicly availabledatasets, while drastically reducing the computation requiredby other methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Knowledge acquisition</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010282</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning settings</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39035715</person_id>
				<author_profile_id><![CDATA[81100278691]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bianca]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zadrozny]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP33026310</person_id>
				<author_profile_id><![CDATA[81100453722]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Langford]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40025918</person_id>
				<author_profile_id><![CDATA[81100308592]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Naoki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Abe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anifantis, S. The DMEF Data Set Library. The Direct Marketing Association, New York, NY, 2002. {http://www.the-dma.org/dmef/dmefdset.shtml}]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312220</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Domingos, P. MetaCost: A general method for making classifiers cost sensitive. <i>Proceedings of the 5th International Conference on Knowledge Discovery and Data Mining</i>, 155-I64, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658143</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Drummond, C. & Holte, R. Exploiting the cost (in)sensitivity of decision tree splitting criteria. <i>Proceedings of the 17th International Conference on Machine Learning</i>, 239-246, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>70771</ref_obj_id>
				<ref_obj_pid>70769</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Ehrenfeucht, A., Haussler, D., Kearns, M. & Valiant. A general lower bound on the number of examples needed for learning. <i>Information and Computation, 82:3</i>, 247-261, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Elkan, C. <i>Boosting and naive bayesian learning</i> (Technical Report). University of California, San Diego, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642224</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Elkan, C. The foundations of cost-sensitive learning. <i>Proceedings of the 17th International Joint Conference on Artificial Intelligence</i>, 973-978, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657651</ref_obj_id>
				<ref_obj_pid>645528</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fan, W., Stolfo, S., Zhang, J. & Chan, P. AdaCost: Misclassification cost-sensitive boosting. <i>Proceedings of the 16th International Conference on Machine Learning</i>, 97-105, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261549</ref_obj_id>
				<ref_obj_pid>261540</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Freund, Y. & Schapire, R. E. A decision-theoretic generalization of on-line learning and an application to boosting. <i>Journal of Computer and System Sciences, 55:1</i>, 119-139, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hettich, S. & Bay, S. D. The UCI KDD Archive. University of California, Irvine. {http://kdd.ics.uci.edu/}.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299104</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Joachims, T. Making large-scale SVM learning practical. In <i>Advances in Kernel Methods - Support Vector Learning</i>. MIT Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658142</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Joachims, T. Estimating the generalization performance of a SVM efficiently. <i>Proceedings of the 17th International Conference on Machine Learning</i>, 431-438, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>197868</ref_obj_id>
				<ref_obj_pid>197867</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Kearns, M., Schapire, R., & Sellie, L. Toward Efficient Agnostic Learning. <i>Machine Learning, 17</i>, 115-141, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>293351</ref_obj_id>
				<ref_obj_pid>293347</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kearns, M. Efficient noise-tolerant learning from statistical queries. <i>Journal of the ACM, 45:6</i>, 983-1006, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>650055</ref_obj_id>
				<ref_obj_pid>645329</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Margineantu, D. Class probability estimation and cost-sensitive classification decisions. <i>Proceedings of the 13th European Conference on Machine Learning</i>, 270-281, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1892983</ref_obj_id>
				<ref_obj_pid>1892875</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Quinlan, J. R. Boosting, Bagging, and C4.5. <i>Proceedings of the Thirteenth National Conference on Artificial Intelligence</i>, 725-730, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Quinlan, J. R. <i>C4.5: Programs for Machine Learning</i>. San Mateo, CA: Morgan Kaufmann, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1972</ref_obj_id>
				<ref_obj_pid>1968</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Valiant, L. A theory of the learnable. <i>Communications of the ACM, 27:11</i>, 1134-1142, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[von Neumann, J. Various techniques used in connection with random digits, <i>National Bureau of Standards, Applied Mathematics Series, 12</i>, 36-38, 1951.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502540</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Zadrozny, B. and Elkan, C. Learning and making decisions when costs and probabilities are both unknown. <i>Proceedings of the 7th International Conference on Knowledge Discovery and Data Mining</i>, 203-213, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952155</article_id>
		<sort_key>443</sort_key>
		<display_label></display_label>
		<pages>443</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>62</seq_no>
		<title><![CDATA[CBC]]></title>
		<subtitle><![CDATA[Clustering Based Text Classification Requiring Minimal Labeled Data]]></subtitle>
		<page_from>443</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952155</url>
		<abstract>
			<par><![CDATA[Semi-supervised learning methods construct classifiersusing both labeled and unlabeled training data samples.While unlabeled data samples can help to improve theaccuracy of trained models to certain extent, existingmethods still face difficulties when labeled data is notsufficient and biased against the underlying datadistribution. In this paper, we present a clustering basedclassification (CBC) approach. Using this approach,training data, including both the labeled and unlabeleddata, is first clustered with the guidance of the labeleddata. Some of unlabeled data samples are then labeledbased on the clusters obtained. Discriminative classifierscan subsequently be trained with the expanded labeleddataset. The effectiveness of the proposed method isjustified analytically. Our experimental resultsdemonstrated that CBC outperforms existing algorithmswhen the size of labeled dataset is very small.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Textual databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14216704</person_id>
				<author_profile_id><![CDATA[81100630328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hua-Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zeng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645609</person_id>
				<author_profile_id><![CDATA[81384609599]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xuan-Hui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95039750</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95035807</person_id>
				<author_profile_id><![CDATA[81451594025]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hongjun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P297313</person_id>
				<author_profile_id><![CDATA[81350592994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Wei-Ying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>183423</ref_obj_id>
				<ref_obj_pid>183422</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Apte, C., Damerau, F., & Weiss, S.M. (1994) Automated learning of decision rules for text categorization. ACM TOIS, Vol 12, No.3. 223-251.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775139</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bhavani Raskutti, Herman Ferra, & Adam Kowalczyk. (2002). Combining Clustering and Co-Training to enhance text classification using unlabeled data. In Proceedings of the SIGKDD Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>279962</ref_obj_id>
				<ref_obj_pid>279943</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blum, A. & Mitchell, T. (1998). Combining labeled and unlabeled data with Co-Training. In Proceedings of the 11th COLT Conference (pp. 92-100).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Dempster, A. P., Laird, N.M., & Rubin, D. B. (1977). Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, Series B, 39(1), 1-38.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649721</ref_obj_id>
				<ref_obj_pid>645326</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Joachims, T. (1998). Text categorization with support vector machines: Learning with Many Relevant Features. In Proceedings of the ECML'98 (pp. 137-142).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649721</ref_obj_id>
				<ref_obj_pid>645326</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Joachims, T. (1998). Text categorization with support vector machines: Learning with many relevant features. In Proceedings of ECML'98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657646</ref_obj_id>
				<ref_obj_pid>645528</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Joachims, T. (1999). Transductive inference for text classification using support vector machines. In Proceedings of 16th ICML Conference (pp. 200-209).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655989</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Klein, D., Kamvar, S. D., & Maning, C. D. (2002). From instance-level constraints to space-level constraints: making the most of prior knowldege in data clustering. In Proceedings of the 19th ICML Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649711</ref_obj_id>
				<ref_obj_pid>645326</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lewis, D.D (1998). Naive Bayes at forty: The independence assumption in information retrieval. In Proceedings of ECML'98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>133177</ref_obj_id>
				<ref_obj_pid>133160</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Masand, B., Linoff, G., & Waltz, D. (1992). Classifying news stories using memory based reasoning. In Proceedings of the 15th ACM SIGIR Conference, 59- 64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Ng, A. Y., & Jordan, M. I. (2002). On discriminative vs. generative classifiers: A comparison of logistic regression and naive Bayes. Advances in Neural Information Processing Systems 14.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258537</ref_obj_id>
				<ref_obj_pid>258525</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Ng, T.H., Goh, W.B., & Low, K.L. (1997) Feature selection, perception learning and a usability case study for text categorization. In Proceedings of the 20th SIGIR Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>354805</ref_obj_id>
				<ref_obj_pid>354756</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Nigam K. & Ghani R. (2002). Analyzing the effectiveness and applicability of co-training. In Proceedings of 9th CIKM Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347724</ref_obj_id>
				<ref_obj_pid>347709</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Nigam, K., McCallurn, A. K., Thrun, S. & Mitchell, T. (2000). Text classification from labeled and unlabeled documents using EM. Machine Learning, 39(2/3):103- 134.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Salton, G. (1991). Developments in automatic text retrieval. Science, 253:974-979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Seeger, M. (2001). Learning with labeled and unlabeled data. Technical report, Edinburgh University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Vapnik, V. N. (1995). The nature of statistical learning theory. New York: Springer-Verlag.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655669</ref_obj_id>
				<ref_obj_pid>645530</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Wagstaff, K., Cardie, C., Rogers, S., & Caruana, R. (2001). Constrained k-means clustering with background knowledge. In Proceedings of the 18th ICML Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>183424</ref_obj_id>
				<ref_obj_pid>183422</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Yang, Y. & Chute, C.G. (1994). An example-based mapping method for text categorization and retrieval. ACM TOIS, Vol 12, No.3, 252-277.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312647</ref_obj_id>
				<ref_obj_pid>312624</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Yang, Y. & Liu, X. (1999). An re-examination of text categorization. In Proceedings of the 22th ACM SIGIR Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Zhang, T. & Oles, F. (2000). A probability analysis on the value of unlabeled data for classification problems. In Proceedings of the 17th ICML Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952134</article_id>
		<sort_key>451</sort_key>
		<display_label></display_label>
		<pages>451</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>63</seq_no>
		<title><![CDATA[Regression Clustering]]></title>
		<page_from>451</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952134</url>
		<abstract>
			<par><![CDATA[Complex distribution in real-world data is oftenmodeled by a mixture of simpler distributions. Clusteringis one of the tools to reveal the structure of this mixture.The same is true to the datasets with chosen responsevariables that people run regression on. Withoutseparating the clusters with very different responseproperties, the residue error of the regression is large.Input variable selection could also be misguided to ahigher complexity by the mixture. In RegressionClustering (RC), K (>1) regression functions are appliedto the dataset simultaneously which guide the clusteringof the dataset into K subsets each with a simplerdistribution matching its guiding function. Each functionis regressed on its own subset of data with a muchsmaller residue error. Both the regressions and theclustering optimize a common objective function. Wepresent a RC algorithm based on K-Harmonic Meansclustering algorithm and compare it with other existingRC algorithms based on K-Means and EM.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Correlation and regression analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010309.10010313</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Factorization methods->Canonical correlation analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003691</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Regression analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15022822</person_id>
				<author_profile_id><![CDATA[81100115403]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Dempster. A. P., Laird, N.M., and Rubin, D.B. (1977). "<i>Miximum Likelyhood from Incomplete Data via the EM Algorithm", Journal of the Royal Statistical Society, Series B, 39(1):1-38</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[DeSarbo, W. S., Corn, L. W. (1988), "A Maximum Likelihood Methodology for Cluterwise Linear Regression," J. of Classification, 5:249-282.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Duda, R., Hart, P. (1972), "Pattern Classification and Scene Analysis", John Wiley & Sons.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312198</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gaffney, S., and P. Smyth, 'Trajectory clustering using mixtures of regression models,' in Proceedings of the ACM 1999 Conference on Knowledge Disovery and Data Mining, S. Chaudhuri and D. Madigan (eds.), New York, NY: ACM, 63-72, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hamerly, G. and Elkan C., Learning the <i>k</i> in <i>k</i>-means. To appear in the Seventeenth Annaul Conference on Neural Information Processing Systems (NIPS 2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hennig, C (1997), "Datenanalyse mit Modellen Fur Cluster Linear Regression," Dissertation, Institut Fur Mathmatsche Stochastik, Universitat Hamburg.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hennig, C. (1999): <i>Models and Methods for Clusterwise Linear Regression in Gaul</i>, W. and Locarek-Junge, H. (Eds.): Classification in the Information Age, Springer, Berlin, p. 179-187.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Hennig, C. (2002): Fixed point clusters for linear regression: computation and comparison (Part of Preprint 2000-02) Journal of Classification 19, 249-276.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lazarevic A. Xu X., Fietz T. and Obradovic Z. (1999): "Clustering-Regression-Ordering Steps for Knowledge Discovery in Spatial Databases", International Joint Conference on Neural Networks (IJCNN'99), July 10-16, Washington, DC. Paper (pdf 221 k)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[MacQueen, J. (1967), "Some Methods for Classification and Analysis of Multivariate Obser-vations". pp. 281-297 in: L M. Le Cam & J. Neyman {eds.} Proceedings of the fifth Berkeley symposium on mathematical statistics and probability, Vol. 1. University of California Press, Berkeley. xvii + 666 P.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[McLachlan, G. J. and Krishnan, T (1997), "<i>The EM Algorithm and Extensions.", John Wiley & Sons</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1196925</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Montgomery, D. C. Peck, E. A., Vining, G. G. (2001), "<i>Introduction to Linear Regression Analysis", John Wiley & Sons; 3rd edition, April</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Silverman, B. W. (1998), "Density Estimation for Statistics and Data Analysis," Chapman & Hall/CRC.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Spath, H. (1979), Algorithm 39: Clusterwise Linear Regression, Computing, 22, 367-73.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Spath, H. (1981), "Correction to Algorithm 39: Clusterwise Linear Regression," Computing, 26, 275.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Spath, H. (1982), "Algorithm 48: A Fast Algorithm for Clusterwise Linear Regression," Computing, 29, 175-181.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>537092</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Spath, H. (1985), "Cluster Dissection and Analysis," New York: Wiley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Tibshirani, R., Walther, G., and Hastie, T (2000), "Estimating the Number of Clusters in a Dataset via the Gap Statistic", Available at http://www-stat.stanford.edu/~tibs /research.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>608122</ref_obj_id>
				<ref_obj_pid>608108</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Torgo, L., and Pinto da Costa, J. (2000): "Clustered Partial Linear Regression," <i>Machine Learning</i>, &#60;b&#62;50&#60;/b&#62; (3), pp, 303- 319. Kluwer Academic Publishers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Williams, J. (2000), "Fitting Regression Models to Finite Mixtures," ANZMAC Visionary Marketing for the 21th Century: Facing the Challenge, 1409-1414.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Wedel, M. and Steenkamp, J. B. (1991) 'A clusterwise regression method for simultaneous fuzzy market structuring and benefit segmentation,' Journal of Marketing Research, 28, pp. 385-96.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Zhang, B., Hsu, M., Dayal, U. (2000), "K-Harmonic Means", Intl. Workshop on Temporal, Spatial and Spatio-Temporal Data Mining, Lyon, France Sept. 12.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Zhang, B. (2001), "Generalized K-Harmonic Means-Dynamic Weighting of Data in Unsupervised Learning,", the First SIAM International Conference on Data Mining (SDM'2001), Chicago, USA, April 5-7.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1760905</ref_obj_id>
				<ref_obj_pid>1760894</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Zhang, B. (2003), "Comparison of the Performance of Center-based Clustering Algorithms", the proceedings of PAKDD-03, Seoul, South Korea, April.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952161</article_id>
		<sort_key>459</sort_key>
		<display_label></display_label>
		<pages>459</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>64</seq_no>
		<title><![CDATA[Model-based Clustering with Soft Balancing]]></title>
		<page_from>459</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952161</url>
		<abstract>
			<par><![CDATA[Balanced clustering algorithms can be useful in a varietyof applications and have recently attracted increasing researchinterest. Most recent work, however, addressed onlyhard balancing by constraining each cluster to have equalor a certain minimum number of data objects. This paperprovides a soft balancing strategy built upon a soft mixture-of-models clustering framework. This strategy constrains the sum of posterior probabilities of object membership foreach cluster to be equal and thus balances the expectednumber of data objects in each cluster. We first derive softmodel-based clustering from an information-theoretic viewpointand then show that the proposed balanced clusteringcan be parameterized by a temperature parameter that controlsthe softness of clustering as well as that of balancing.As the temperature decreases, the resulting partitioning becomesmore and more balanced. In the limit, when temperaturebecomes zero, the balancing becomes hard and theactual partitioning becomes perfectly balanced. The effectivenessof the proposed soft balanced clustering algorithmis demonstrated on both synthetic and real text data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39024847</person_id>
				<author_profile_id><![CDATA[81100049396]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15036181</person_id>
				<author_profile_id><![CDATA[81100558602]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Joydeep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ghosh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>82732</ref_obj_id>
				<ref_obj_pid>82729</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[S. C. Ahalt, A. K. Krishnamurthy, P. Chen, and D. E. Melton. Competitive learning algorithms for vector quantization. <i>Neural Networks</i>, 3(3):277-290, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Banerjee and J. Ghosh. Frequency sensitive competitive learning for clustering on high-dimensional hyperspheres. In <i>Proc. IEEE Int. Joint Conf. Neural Networks</i>, pages 1590- 1595, May 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Banerjee and J. Ghosh. On scaling up balanced clustering algorithms. In <i>Proc. 2nd SIAM Int. Conf. Data Mining</i>, pages 333-349, April 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. D. Banfield and A. E. Raftery. Model-based Gaussian and non-Gaussian clustering. <i>Biometrics</i>, 49(3):803-821, September 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. A. Blimes. A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models. Technical report, University of California at Berkeley, April 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. S. Bradley, K. P. Bennett, and A. Demiriz. Constrained k-means clustering. Technical Report MSR-TR-2000-65, Microsoft Research, Redmond, WA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347119</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[I. V. Cadez, S. Gaffney, and P. Smyth. A general probabilistic framework for clustering individuals and objects. In <i>Proc. 6th ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining</i>, pages 140-149, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum-likelihood from incomplete data via the EM algorithm. <i>Journal of the Royal Statistical Society B</i>, 39(1):1-38, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502550</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon. Co-clustering documents and words using bipartite spectral graph partitioning. In <i>Proc. 7th ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining</i>, pages 269-274, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. Fraley and A. E. Raftery. How many clusters? Which clustering method? Answers via model-based analysis. <i>The Computer Journal</i>, 41(8):578-588, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326142</ref_obj_id>
				<ref_obj_pid>2325757</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. S. Galanopoulos, R. L. Moses, and S. C. Ahalt. Diffusion approximation of frequency sensitive competitive learning. <i>IEEE Trans. Neural Networks</i>, 8(5):1026-1030, September 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Ghosh. Scalable clustering. In N. Ye, editor, <i>Handbook of Data Mining</i>, pages 341-364. Lawrence Erlbaum Assoc., 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>540298</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. A. Hartigan. <i>Clustering Algorithms</i>. John Wiley & Sons, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>796533</ref_obj_id>
				<ref_obj_pid>795665</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[P. Indyk. A sublinear-time approximation scheme for clustering in metric spaces. In <i>40th Annual IEEE Symp. Foundations of Computer Science</i>, pages 154-159, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[A. K. Jain and R. C. Dubes. <i>Algorithms for Clustering Data</i>. Prentice Hall, New Jersey, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331504</ref_obj_id>
				<ref_obj_pid>331499</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: A review. <i>ACM Computing Surveys</i>, 31(3):264-323, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>796585</ref_obj_id>
				<ref_obj_pid>795666</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[R. Kannan, S. Vempala, and A. Vetta. On clusterings - good, bad and spectral. In <i>41st Annual IEEE Symp. Foundations of Computer Science</i>, pages 367-377, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[G. Karypis. <i>CLUTO - A Clustering Toolkit</i>. Dept. of Computer Science, University of Minnesota, May 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>621303</ref_obj_id>
				<ref_obj_pid>619043</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[G. Karypis, E.-H. Han, and V. Kumar. Chameleon: Hierarchical clustering using dynamic modeling. <i>Computer</i>, 32(8):68-75, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[S. P. Lloyd. Least squares quantization in PCM. <i>IEEE Trans. Information Theory</i>, IT-28:129-137, March 1982.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. MacQueen. Some methods for classification and analysis of multivariate observations. In <i>Proc. 5th Berkeley Symp. Math. Statistics and Probability</i>, pages 281-297, 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[G. McLachlan and K. Basford. <i>Mixture Models: Inference and Applications to Clustering</i>. Marcel Dekker, New York, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral clustering: analysis and an algorithm. In T. G. Dietterich, S. Becker, and Z. Ghahramani, editors, <i>Advances in Neural Information Processing Systems</i>, volume 14, pages 849-856. MIT Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[K. Rose. Deterministic annealing for clustering, compression, classification, regression, and related optimization problems. <i>Proceedings of IEEE</i>, 86(11):2210-2239, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944935</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[A. Strehl and J. Ghosh. Cluster ensembles -- a knowledge reuse framework for combining partitions. <i>Journal of Machine Learning Research</i>, 3:583-617, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>970797</ref_obj_id>
				<ref_obj_pid>970781</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[A. Strehl and J. Ghosh. Relationship-based clustering and visualization for high-dimensional data mining. <i>INFORMS Journal on Computing: Special Issue on Web Mining</i>, 15(2):208-230, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[A. Strehl, J. Ghosh, and R. J. Mooney. Impact of similarity measures on web-page clustering. In <i>AAAI Workshop on AI for Web Search</i>, pages 58-64, July 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656273</ref_obj_id>
				<ref_obj_pid>645504</ref_obj_pid>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[A. K. H. Tung, R. T. Ng, L. V. D. Lakshmanan, and J. Han. Constraint-based clustering in large databases. In <i>Proc. 8th Int. Conf. Database Theory</i>, pages 405-419, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik. <i>Statistical Learning Theory</i>. John Wiley, New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Y. Zhao and G. Karypis. Criterion functions for document clustering: experiments and analysis. Technical Report #01- 40, Department of Computer Science, University of Minnesota, November 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[S. Zhong and J. Ghosh. A comparative study of generative models for document clustering. In <i>SIAM Int. Conf. Data Mining Workshop on Clustering High Dimensional Data and Its Applications</i>, San Francisco, CA, May 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952161</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[S. Zhong and J. Ghosh. Scalable, balanced model-based clustering. In <i>Proc. 3rd SIAM Int. Conf. Data Mining</i>, pages 71-82, San Francisco, CA, May 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952116</article_id>
		<sort_key>469</sort_key>
		<display_label></display_label>
		<pages>469</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>65</seq_no>
		<title><![CDATA[Integrating Fuzziness into OLAP for Multidimensional Fuzzy Association Rules Mining]]></title>
		<page_from>469</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952116</url>
		<abstract>
			<par><![CDATA[This paper contributes to the ongoing research onmultidimensional online association rules mining byproposing a general architecture that utilizes a fuzzy datacube for knowledge discovery. Three different methods areintroduced to mine fuzzy association rules in the constructedfuzzy data cube, namely single dimension, multidimensionaland hybrid association rules mining. Experimental resultsobtained for each of the three methods on the adult data ofthe United States census in 2000 show their effectiveness andapplicability.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Knowledge acquisition</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Fuzzy set</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010282</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning settings</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14211269</person_id>
				<author_profile_id><![CDATA[81100613277]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Reda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alhajj]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45027187</person_id>
				<author_profile_id><![CDATA[81336490511]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mehmet]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>628147</ref_obj_id>
				<ref_obj_pid>627335</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C.C. Agarwal and P.S. Yu, "A new approach to online generation of association rules," <i>IEEE TKDE</i>, Vol.13, No.4, pp.527-540, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>653299</ref_obj_id>
				<ref_obj_pid>645482</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, A. Gupta, S. Sarawagi, "Modeling Multidimensional Databases," <i>Proc. of IEEE ICDE</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>266898</ref_obj_id>
				<ref_obj_pid>266714</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K.C.C. Chan and W.H. Au, "Mining Fuzzy Association Rules," <i>Proc. of ACM CIKM</i>, pp.209-215, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628022</ref_obj_id>
				<ref_obj_pid>627324</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Han and Y. Fu, "Mining multiple-level association rules in large databases," <i>IEEE TKDE</i>, Vol.11, pp.798-804, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304195</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Hidber, "Online Association Rule Mining," <i>Proc. of ACM SIGMOD</i>, pp. 145-156, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Kamber, J. Han and J.Y. Chiang, "Meta-rule guided mining of multidimensional association rules using data cubes," <i>Proc. of ACM KDD</i>, pp.207-210, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>756199</ref_obj_id>
				<ref_obj_pid>648315</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Kaya, R. Alhajj, F. Polat and A. Arslan, "Efficient Automated Mining of Fuzzy Association Rules," <i>Proc. of DEXA</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>758382</ref_obj_id>
				<ref_obj_pid>645927</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. Margaritis, C. Faloutsos and S. Thrun, "NetCube: A Scalable Tool for Fast Data Mining and Compression," <i>Proc. of VLDB</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>853682</ref_obj_id>
				<ref_obj_pid>850950</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[W. Zhang, "Mining Fuzzy Quantitative Association Rules," <i>Proc. of IEEE ICTAI</i>, pp.99-102, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952112</article_id>
		<sort_key>473</sort_key>
		<display_label></display_label>
		<pages>473</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>66</seq_no>
		<title><![CDATA[Analyzing High-Dimensional Data by Subspace Validity]]></title>
		<page_from>473</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952112</url>
		<abstract>
			<par><![CDATA[We are proposing a novel method that makes it possibleto analyze high dimensional data with arbitrary shapedprojected clusters and high noise levels. At the core of ourmethod lies the idea of subspace validity. We map the datain a way that allows us to test the quality of subspaces usingstatistical tests. Experimental results, both on synthetic andreal data sets, demonstrate the potential of our method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Statistical</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Statistical databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010442</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Mathematics and statistics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003244</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Data analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP309470300</person_id>
				<author_profile_id><![CDATA[81539552656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Amihood]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Amir]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P240932</person_id>
				<author_profile_id><![CDATA[81100651151]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Reuven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kashi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P207616</person_id>
				<author_profile_id><![CDATA[81100457395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Nathan]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Netanyahu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP17000393</person_id>
				<author_profile_id><![CDATA[81100126311]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Keim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P380994</person_id>
				<author_profile_id><![CDATA[81100347796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Markus]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wawryniuk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>304188</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal, C. M. Procopiuc, J. L. Wolf, P. S. Yu, and J. S. Park. Fast algorithms for projected clustering. In <i>Proc. ACM SIGMOD International Conference on Management of Data, June 1-3, 1999, Philadephia, Pennsylvania, USA</i>, pages 61-72. ACM Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335383</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal and P. S. Yu. Finding generalized projected clusters in high dimensional spaces. In <i>Proc. of the 2000 ACM SIGMOD International Conference on Management of Data, May 16-18, 2000, Dallas, Texas, USA</i>, pages 70-81. ACM, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276314</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Aggrawal, J. Gehrke, D. Gunopulos, and P. Raghavan. Automatic subspace clustering of high dimensional data for data mining applications. In <i>Proc. ACM SIGMOD International Conference on Management of Data, June 2-4, 1998, Seattle, Washington, USA</i>, pages 94-105. ACM Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672215</ref_obj_id>
				<ref_obj_pid>645927</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Amir, R. Kashi, and N. S. Netanyahu. Analyzing quantitative databases: Image is everything. In <i>VLDB 2001, Proc. of 27th International Conference on Very Large Data Bases</i>, pages 89-98, Roma, Italy, September 11-14 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. P. Dempster, N. Laird, and D. Rubin. Maximum likelihood for incomplete data via the EM algorithm. <i>J. of the Royal Statistical Society, ser. B</i>, 39:1-38, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618646</ref_obj_id>
				<ref_obj_pid>616060</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Hinneburg, M. Wawryniuk, and D. A. Keim. Hd-eye: Visual mining of high-dimensional data. <i>IEEE Computer Graphics & Applications Journal</i>, 19(5):22-31, September 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614508</ref_obj_id>
				<ref_obj_pid>614285</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. A. Keim. Information visualization and visual data mining. <i>IEEE Transactions on Visualization and Computer Graphics (TVCG)</i>, 8(1):1-8, January-March 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312189</ref_obj_id>
				<ref_obj_pid>312179</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. A. Keim and A. Hinneburg. Clustering techniques for large data sets - from the past to the future. In <i>Tutorial Notes for ACM SIGKDD 1999 International Conference on Knowledge Discovery and Data Mining</i>, pages 141-181, San Diego, CA, 1999. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564739</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. M. Procopiuc, M. Jones, P. K. Agarwal, and T. M. Murali. A monte carlo algorithm for fast projective clustering. In <i>Proc. of the ACM SIGMOD international conference on Management of data</i>, pages 418-427. ACM Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952077</article_id>
		<sort_key>477</sort_key>
		<display_label></display_label>
		<pages>477</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>67</seq_no>
		<title><![CDATA[Objective and Subjective Algorithms for Grouping Association Rules]]></title>
		<page_from>477</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952077</url>
		<abstract>
			<par><![CDATA[We propose two algorithms for grouping and summarizingassociation rules. The first algorithm recursively groupsrules according to the structure of the rules and generatesa tree of clusters as a result. The second algorithm groupsthe rules according to the semantic distance between therules by making use of an autometically tagged semantictree-structured network of items. We provide a case study inwhich the proposed algorithms are evaluated. The resultsshow that our grouping methods are effective and producegood grouping results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.1</cat_node>
				<descriptor>Schema and subschema</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10010820</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Data model extensions</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15029280</person_id>
				<author_profile_id><![CDATA[81100329796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Aijun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[An]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14123754</person_id>
				<author_profile_id><![CDATA[81100344618]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shakil]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Khan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15021365</person_id>
				<author_profile_id><![CDATA[81100080207]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xiangji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>593507</ref_obj_id>
				<ref_obj_pid>593429</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adomavicius, G. and Tuzhilin, A. "Expert-driven validation of rule-based user models in personalization applications", <i>Data Mining and Knowledge Discovery</i>, vol.5, nos. 1/2, January/April 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844823</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Huang, X., An, A.. Cercone. N and Promhouse, G. "Discovery of Interesting Association Rules from Livelink Web Log data", <i>Proc. of the IEEE Int. Conf. on Data Mining (ICDM'02)</i>, Maebashi City, Japan, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>653287</ref_obj_id>
				<ref_obj_pid>645482</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Lent, B., Swami, A.N., and Widom, J. "Clustering Association Rules", <i>Proc. of ICDE</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312272</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Sahar, S., "Interestingness via What is not Interesting", <i>Proceedings of KDD '99</i>, 1999, pp.332-336.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Toivonen, H., Klemettinen, M., Ronkainen, P. Hatonen, K. and Mannila, H. "Pruning and grouping discovered association rules", <i>Proc. of KDD'95</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Wang, K., Tay, S.H.W. and Liu, B. "Interestingness based interval merger for numeric association rules", <i>Proc. of KDD'98</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952126</article_id>
		<sort_key>481</sort_key>
		<display_label></display_label>
		<pages>481</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>68</seq_no>
		<title><![CDATA[Efficient Subsequence Matching in Time Series Databases Under Time and Amplitude Transformations]]></title>
		<page_from>481</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952126</url>
		<abstract>
			<par><![CDATA[Subsequence matching in large time series databases hasattracted a lot of interest and many methods have been proposedthat cope with this problem in an adequate extend.However, locating subsequence matches of arbitrary length,under time and amplitude transformations, has received farless attention and is still an open problem. In this paperwe present an efficient algorithm for variable-length subsequencematching under transformations that guaranteesno false dismissals. Further, this algorithm uses a novelsimilarity criterion for determining similarity under amplitudetransformations in a most efficient way. Finally, ouralgorithm has been tested in various experiments on realdata, resulting in a running time improvement of one orderof magnitude compared to the naive approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Pattern matching</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Statistical databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010432.10010442</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Mathematics and statistics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003244</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Data analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010031.10010032</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Data structures design and analysis->Pattern matching</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645573</person_id>
				<author_profile_id><![CDATA[81100112764]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tassos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Argyros]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645260</person_id>
				<author_profile_id><![CDATA[81100323539]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Charis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ermopoulos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>652239</ref_obj_id>
				<ref_obj_pid>645415</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, C. Faloutsos, and A. Swami. Efficient similarity search in sequence databases. In <i>Proceedings of the 4th Int'l Conf. on Foundations of Data Organization and Algorithms</i>, pages 69-84, Chicago, IL, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[T. Argyros and C. Ermopoulos. Efficient subsequence matching in time series databases under time and amplitude transformations (extended version). In http://ieee.ntua.gr/~targyros/transform03.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304000</ref_obj_id>
				<ref_obj_pid>303976</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K. Chu and M. Wong. Fast time-series searching with scaling and shifting. In <i>Proceedings of ACM Principles on Database Systems</i>, pages 237-248, Philadelphia, PA, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669017</ref_obj_id>
				<ref_obj_pid>645801</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. Das, D. Gunopulos, and H. Mannila. Finding similar time series. In <i>1st European Symposium on Principles of Data Mining and Knowledge Discovery</i>, pages 88-100, Trondheim, Norway, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>191925</ref_obj_id>
				<ref_obj_pid>191839</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. Fast subsequence matching in time-series databases. In <i>Proceedings of ACM SIGMOD Int'l Conf. on Managment of Data</i>, pages 419-429, Minneapolis, MN, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>695935</ref_obj_id>
				<ref_obj_pid>646500</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Kahveci, A. Singh, and A. Gurel. Similarity searching for multi-attribute sequences. In <i>Proceedings of 14th Int'l Conf. on Scientific and Statistical Database Management</i>, pages 175-186, Edinburgh, Scotland.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>880107</ref_obj_id>
				<ref_obj_pid>876886</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Keogh. A fast and robust method for pattern matching in time series databases. In <i>Proceedings of Ninth Int'l Conf. on Tools with Artificial Intelligence</i>, pages 578-584, Newport Beach, CA, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287405</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[E. Keogh. Exact indexing of dynamic time warping. In <i>Proceedings of the 28th Int'l Conf. on Very Large Data Bases</i>, pages 406-417, Hong Kong, China, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>375680</ref_obj_id>
				<ref_obj_pid>375663</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, K. Chakrabarti, S. Mehrotra, and M. Pazzani. Locally adaptive dimensionality reduction for indexing large time series databases. In <i>Proceedings of ACM SIGMOD Conf. on Managment of Data</i>, pages 151-162, Santa Barbara, CA, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E. Keogh, K. Chakrabarti, M. Pazzani, and S. Mehrotra. Dimensionality reduction for fast similarity search in large time series databases. <i>Journal of Knowledge and Information Systems</i>, 3(3):263-286, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669511</ref_obj_id>
				<ref_obj_pid>645803</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[E. Keogh and M. Pazzani. Scaling up dynamic time warping to massive datasets. In <i>Proceedings of the 3rd European Conf. on Principles and Practice of Knowledge Discovery in Databases</i>, pages 1-11, Prague, Czech Republic, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>693335</ref_obj_id>
				<ref_obj_pid>646418</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[E. Keogh and M. Pazzani. A simple dimensionality reduction technique for fast similarity search in large time series databases. In <i>Proceedings of 4th Pacific- Asia Conf. on Knowledge Discovery and Data Mining</i>, pages 122-133, Kyoto, Japan, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[E. Keogh and P. Smyth. A probabilistic approach to fast pattern matching in time series databases. In <i>Proceedings of 3rd Int'l Conf. on Knowledge Discovery and Data Mining</i>, pages 24-30, Menlo Park, CA, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1965357</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[B. Mandelbrot. <i>Fractals and Scaling in Finance: Discontinuity, Concentration, Risk</i>. Springer-Verlag, NY, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[P. Maragos, A. Dimakis, and I. Kokkinos. Some advances in nonlinear speech modeling using modulations, fractals and chaos. In <i>Proceedings of IEEE Int'l Conf. on Digital Signal Processing</i>, pages 325-332, Santorini, Greece, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847378</ref_obj_id>
				<ref_obj_pid>846219</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[C. Perng, H. Wang, S. Zhang, and S. Parker. Landmarks: a new model for similarity-based pattern querying in time series databases. In <i>Proceedings of 16th Int'l Conf. on Data Engineering</i>, pages 33-42, San Diego, CA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>653609</ref_obj_id>
				<ref_obj_pid>645483</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[B. Yi, V. Jagadish, and C. Faloutsos. Efficient retrieval of similar time sequences under time warping. In <i>Proceedings of the 14th Int'l Conf. on Data Engineering</i>, pages 201-208, Orlando, FL, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952091</article_id>
		<sort_key>485</sort_key>
		<display_label></display_label>
		<pages>485</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>69</seq_no>
		<title><![CDATA[A Fast Algorithm for Computing Hypergraph Transversals and its Application in Mining Emerging Patterns]]></title>
		<page_from>485</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952091</url>
		<abstract>
			<par><![CDATA[Computing the minimal transversals of a hypergraph isan important problem in computer science that has significantapplications in data mining. In this paper, we present anew algorithm for computing hypergraph transversals andhighlight their close connection to an important class ofpatterns known as emerging patterns. We evaluate our techniqueon a number of large datasets and show that it out-performsprevious approaches by a factor of 9-29 times.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Hypergraphs</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.2.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003624</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010432.10010442</concept_id>
				<concept_desc>CCS->Applied computing->Physical sciences and engineering->Mathematics and statistics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003637</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Hypergraphs</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15037710</person_id>
				<author_profile_id><![CDATA[81100616144]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bailey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P498108</person_id>
				<author_profile_id><![CDATA[81100285740]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Manoukian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15035326</person_id>
				<author_profile_id><![CDATA[81100532239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kotagiri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ramamohanarao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Berge. <i>Hypergraphs, North Holland Mathematical Library</i>, volume 45. Elsevier, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>696307</ref_obj_id>
				<ref_obj_pid>646516</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[E. Boros, V. Gurvich, L. Khachiyan, and K. Makino. On the Complexity of Generating Maximal Frequent and Minimal Infrequent Sets. In <i>Proceedings of STACS 2002</i>, pages 133-141, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312191</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[G. Dong and J. Li. Efficient Mining of Emerging Patterns: Discovering Trends and Differences. In <i>Proceedings of KDD'99</i>, pages 43-52, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>219403</ref_obj_id>
				<ref_obj_pid>219375</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Eiter and G. Gottlob. Identifying the Minimal Transversals of a Hypergraph and Related Problems. <i>SIAM Journal on Computing</i>, 24(6):1278-1304, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245833</ref_obj_id>
				<ref_obj_pid>245808</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. L. Fredman and L. Khachiyan. On the Complexity of Dualization of Monotone Disjunctive Normal Forms. <i>Journal of Algorithms</i>, 21(3):618-628, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>263684</ref_obj_id>
				<ref_obj_pid>263661</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Gunopulos, R. Khardon, H. Mannila, and H. Toivonen. Data Mining, Hypergraph Transversals, and Machine Learning. In <i>Proceedings of PODS'97</i>, pages 209-216, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>720631</ref_obj_id>
				<ref_obj_pid>647256</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Kavvadias and E. C. Stavropoulos. Evaluation of an Algorithm for the Transversal Hypergraph Problem. In <i>Proceedings of WAE'99</i>, pages 72-84, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>693198</ref_obj_id>
				<ref_obj_pid>646418</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Li, G. Dong, and K. Ramamohanarao. Making use of the most Expressive Jumping Emerging Patterns for Classification. In <i>Proceedings of PAKDD'00</i>, pages 220-232, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593448</ref_obj_id>
				<ref_obj_pid>593416</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[H. Mannila and H. Toivonen. Levelwise Search and Borders of Theories in Knowledge Discovery. <i>Data Mining and Knowledge Discovery</i>, 3(1):241- 258, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>25669</ref_obj_id>
				<ref_obj_pid>25667</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R. Reiter. A Theory of Diagnosis from First Principles. <i>Artificial Intelligence</i>, 32(1):57-95, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R. Rymon. An SE-Tree-Based Prime Implicant Generation Algorithm. <i>Annals of Mathematics and Artificial Intelligence</i>, 11(1-4):351-366, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952118</article_id>
		<sort_key>489</sort_key>
		<display_label></display_label>
		<pages>489</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>70</seq_no>
		<title><![CDATA[Mining Relevant Text from Unlabelled Documents]]></title>
		<page_from>489</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952118</url>
		<abstract>
			<par><![CDATA[Automatic classification of documents is an importantarea of research with many applications in the fields of documentsearching, forensics and others. Methods to performclassification of text rely on the existence of a sample of documentswhose class labels are known. However, in manysituations, obtaining this sample may not be an easy (oreven possible) task. In this paper we focus on the classificationof unlabelled documents into two classes: relevant andirrelevant, given a topic of interest. By dividing the set ofdocuments into buckets (for instance, answers returned bydifferent search engines), and using association rule miningto find common sets of words among the buckets, we can efficientlyobtain a sample of documents that has a large percentageof relevant ones. This sample can be used to trainmodels to classify the entire set of documents. We prove, viaexperimentation, that our method is capable of filtering relevantdocuments even in adverse conditions where the percentageof irrelevant documents in the buckets is relativelyhigh.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Textual databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.7.5</cat_node>
				<descriptor>Document analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010505</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P426639</person_id>
				<author_profile_id><![CDATA[81100273432]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Barbar&#225;]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15020877</person_id>
				<author_profile_id><![CDATA[81100062921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Carlotta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Domeniconi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP309471400</person_id>
				<author_profile_id><![CDATA[81541192156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>279962</ref_obj_id>
				<ref_obj_pid>279943</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blum, A., Mitchell T. (1998). Combining Labelled and Unlabelled Data with Co-Training. <i>Proceedings of the 1998 Conference on Computational Learning Theory</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Chen, Y., Zhou, X. S., Huang, T. S. (2001). One-class SVM for learning in image retrieval. <i>Proceedings of the International Conference on Image Processing</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Dumais, S. T., Letsche, T. A., Littman, M. L., & Landauer, T. K. (1997). Automatic cross-language retrieval using latent semantic indexing. <i>AAAI Spring Symposium on Cross-Language Text and Speech Retrieval</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fung, B. C. M., Wang, K., & Ester M. (2003). Hierarchical Document Clustering Using Frequent Itemsets. <i>Proceedings of the SIAM International Conference on Data Mining</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649721</ref_obj_id>
				<ref_obj_pid>645326</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Joachims, T. (1998). Text categorization with support vector machines. <i>Proceedings of the European Conference on Machine Learning</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kandola, J., Shawe-Taylor, J., & Cristianini, N. (2002). Learning Semantic Similarity. <i>Neural Information Processing Systems (NIPS)</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>599670</ref_obj_id>
				<ref_obj_pid>599613</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Leopold, E., & Kindermann, J. (2002). Text categorization with support vector machines, how to represent texts in input space? <i>Machine Learning</i>, &#60;b&#62;46&#60;/b&#62;:423-444.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lewis, D., Reuters-21578 Text Categorization Test Collection Distribution 1.0. http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Porter, M. (1980). An algorithm for suffix stripping, Program, &#60;b&#62;14&#60;/b&#62;(3):130-137 http://www.tartarus.org/~martin/PorterStemmer]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Zhou, X. S., & Huang, T. S. (2001). Small sample learning during multimedia retrieval using BiasMap. <i>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952121</article_id>
		<sort_key>493</sort_key>
		<display_label></display_label>
		<pages>493</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>71</seq_no>
		<title><![CDATA[A User-driven and Quality-oriented Visualization for Mining Association Rules]]></title>
		<page_from>493</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952121</url>
		<abstract>
			<par><![CDATA[On account of the enormous amounts of rules that canbe produced by data mining algorithms, knowledgevalidation is one of the most problematic steps in anassociation rule discovery process.In order to findrelevant knowledge for decision-making, the user needs toreally rummage through the rules.Visualization can bevery beneficial to support him/her in this task byimproving the intelligibility of the large rule sets andenabling the user to navigate inside them.In this article,we propose to answer the association rule validationproblem by designing a human-centered visualizationmethod for the rule rummaging task.This new approachbased on a specific rummaging model relies on ruleinterestingness measures and on interactive rule subsetfocusing and mining.We have implemented ourrepresentation by developing a first experimentalprototype called ARVis.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Visual</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Relevance feedback</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10010365</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Visual analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359.10003361</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results->Relevance assessment</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40023353</person_id>
				<author_profile_id><![CDATA[81309503666]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Julien]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Blanchard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15019599</person_id>
				<author_profile_id><![CDATA[81100011886]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fabrice]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Guillet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15026491</person_id>
				<author_profile_id><![CDATA[81100224767]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Henri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Briand]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>257975</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agrawal, R., Mannila, H., Srikant, R., Toivonen, H., and Verkamo, A.I., "Fast discovery of association rules", <i>Advances in Knowledge Discovery and Data Mining</i>, AAAI/MIT Press, U.M. Fayyad, G. Piatetsky-Shapiro, and P. Smyth (Eds.), 1996, 307-328.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>196241</ref_obj_id>
				<ref_obj_pid>196234</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bandhari, I., "Attribute focusing: machine-assisted knowledge discovery applied to software production process control", <i>Knowledge acquisition 6</i>, 1994, 271-294.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blanchard, J., Kuntz, P., Guillet, F., and Gras, R., "Implication intensity: from the basic statistical definition to the entropic version", <i>Statistical Data Mining and Knowledge Discovery</i>, CRC Press, H. Bozdogan (Ed.), 2003, 473-485.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>257944</ref_obj_id>
				<ref_obj_pid>257938</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brachman, J.R., and Anand, T., "The process of knowledge discovery in databases: a human-centered approach", <i>Advances in Knowledge Discovery and Data Mining</i>, AAAI/MIT Press, U.M. Fayyad, G. Piatetsky-Shapiro, and P. Smyth (Eds.), 1996, 37-58.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669329</ref_obj_id>
				<ref_obj_pid>645802</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Guillaume, S., Guillet, F., and Philippe, J., "Improving the discovery of association rules with intensity of implication", <i>Proc. of the 2nd European Conference of Principles of Data Mining and Knowledge Discovery</i>, Springer, L.N.A.I. 1510, 1998, 318-327.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>782018</ref_obj_id>
				<ref_obj_pid>782010</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Han, J., Chiang, J., Chee, S., Chen, J., Cheng, S., Gong, W., Kamber, M., Koperski, K., Liu, G., Lu, Y., Stefanovic, N., Winstone, L., Xia, B., Zaiane, O.R., Zhang, S., and Zhu, H., "DBMiner: a system for data mining in relational databases and data warehouses", <i>Proc. of CASCON'97</i>, 1997, 249-260.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>240472</ref_obj_id>
				<ref_obj_pid>240455</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Imielinski, T., and Mannila, H., "A database perspective on knowledge discovery", <i>Communications of the ACM 39(11)</i>, 1996, 58-64.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593489</ref_obj_id>
				<ref_obj_pid>593425</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Imielinski, T., and Virmani, A., "MSQL: a query language for database mining", <i>Journal of data mining and knowledge discovery 3(4)</i>, 1999, 373-408.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Klemettinen, M., Mannila, H., and Toivonen, H., <i>Interactive exploration of discovered knowledge: a methodology for interaction, and usability studies</i>, Technical report C-1996-3, University of Helsinki, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669662</ref_obj_id>
				<ref_obj_pid>645804</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Kuntz, P., Guillet, F., Lehn, R., and Briand, H., "A userdriven process for mining association rules", <i>Proc. of the 4th European Conference of Principles of Data Mining and Knowledge Discovery</i>, Springer, L.N.A.I. 1910, 2000, 160-168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347128</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Liu, B., Hu, M., and Hsu, W., "Multi-level organization and summarization of the discovered rules", &#60;i&gt;Proc. of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, 2000, 208-217.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Montgomery, H., "Decision rules and the search for dominance structure: toward a process model of decision-making", <i>Analyzing and Aiding Decision Processes</i>, P.C. Humphreys, O. Svenson, and A. Vari (Eds.), 1983, 471-483.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775053</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Tan, P., Kumar, V., and Srivastava, J., "Selecting the right interestingness measure for association patterns", <i>Proc. of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i>, 2000, 32-41.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>857670</ref_obj_id>
				<ref_obj_pid>857189</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Wong, P.C., Whitney, P., and Thomas, J., "Visualizing association rules for text mining", <i>Proc. of the IEEE Symposium on Information Visualization InfoVis'99</i>, 1999, 120-123.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952096</article_id>
		<sort_key>497</sort_key>
		<display_label></display_label>
		<pages>497</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>72</seq_no>
		<title><![CDATA[Towards Simple, Easy-to-Understand, yet Accurate Classifiers]]></title>
		<page_from>497</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952096</url>
		<abstract>
			<par><![CDATA[We design a method for weighting linear support vectormachine classifiers or random hyperplanes, to obtain classifierswhose accuracy is comparable to the accuracy of anon-linear support vector machine classifier, and whose resultscan be readily visualized. We conduct a simulationstudy to examine how our weighted linear classifiers behavein the presence of known structure. The results show thatthe weighted linear classifiers might perform well comparedto the non-linear support vector machine classifiers, whilethey are more readily interpretable than the non-linear classifiers.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Visual</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10010365</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Visual analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14097901</person_id>
				<author_profile_id><![CDATA[81100256663]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Doina]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Caragea]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP17000332</person_id>
				<author_profile_id><![CDATA[81317492882]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dianne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cook]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P290152</person_id>
				<author_profile_id><![CDATA[81100409481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Vasant]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Honavar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>2906</ref_obj_id>
				<ref_obj_pid>2812</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Asimov. The Grand Tour: A Tool for Viewing Multidimensional Data. <i>SIAM Journal of Scientific and Statistical Computing</i>, 6(1):128-143, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging Predictors, In Machine Learning, Vol. 24, No. 2, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502547</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. Caragea, D. Cook and V. Honavar. Gaining Insights into Support Vector Machine Pattern Classifiers Using Projection-Based Tour Methods, In Proceedings of the KDD Conference, San Francisco, CA, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Cook and A. Buja. Manual Controls For High-Dimensional Data Projections. <i>Journal of Computational and Graphical Statistics</i>, 6(4):464-480, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Cook, A. Buja, J. Cabrera, and C. Hurley. Grand Tour and Projection Pursuit. <i>Journal of Comp. and Graphical Statistics</i>, 4(3):155-172, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Drish. Obtaining Calibrated Probability Estimates from Support Vector Machines. San Diego, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>743935</ref_obj_id>
				<ref_obj_pid>648054</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Dietterich. Ensemble Methods in Machine Learning. In: <i>Lecture Notes in Computer Science</i>, Vol. 1857, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. <i>Making Large-Scale SVM Learning Practical</i>. MIT Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik. <i>The Nature of Statistical Learning Theory</i>. Springer-Verlag, New York, NY, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952105</article_id>
		<sort_key>501</sort_key>
		<display_label></display_label>
		<pages>501</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>73</seq_no>
		<title><![CDATA[Validating and Refining Clusters via Visual Rendering]]></title>
		<page_from>501</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952105</url>
		<abstract>
			<par><![CDATA[The automatic clustering algorithms are known towork well in dealing with clusters of regular shapes, e.g.compact spherical/elongated shapes, but may incur highererror rates when dealing with arbitrarily shaped clusters.Although some efforts have been devoted to addressingthe problem of skewed datasets, the problem of handlingclusters with irregular shapes is still in its infancy,especially in terms of dimensionality of the datasets andthe precision of the clustering results considered. Notsurprisingly, the statistical indices works ineffective invalidating clusters of irregular shapes, too. In this paper,we address the problem of clustering and validatingarbitrarily shaped clusters with a visual framework(VISTA). The main idea of the VISTA approach is tocapitalize on the power of visualization and interactivefeedbacks to encourage domain experts to participate inthe clustering revision and clustering validation process.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Visual</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10010365</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Visual analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15022176</person_id>
				<author_profile_id><![CDATA[81100107380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Keke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39047013</person_id>
				<author_profile_id><![CDATA[81350573402]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ling]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>952712</ref_obj_id>
				<ref_obj_pid>952532</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Keke Chen and Ling Liu: "Cluster Rendering of Skewed Datasets via Visualization". ACM Symposium on Applied Computing 2003, Melborne, FL.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276312</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[G. Guha, R. Rastogi, and K. Shim. "CURE: An efficient clustering algorithm for large databases", in Proc. of the 1998 ACM SIGMOD.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cook, D.R, Buja, A., Cabrea, J., and Hurley, H. "Grand tour and projection pursuit", Journal of Computational and Graphical Statistics, V23, pp. 225-250.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347134</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Li Yang. "Interactive Exploration of Very Large Relational Datasets through 3D Dynamic Projections", in Proc. of SIGKDD2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502530</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E. Kandogan. "Visualizing Multi-dimensional Clusters, Trends, and Outliers using Star Coordinates", in Proc. of SIGKDD2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>42779</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Jain and R. Dubes. "Algorithms for Clustering Data", Prentice hall, Englewood Cliffs, NJ, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Grinstein G., Ankerst M., Keim D.A.: Visual Data Mining: Background, Applications, and Drug Discovery Applications", Tutorial at ACM SIGKDD2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>331504</ref_obj_id>
				<ref_obj_pid>331499</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Jain, A.K., Murty, M.N. and Flynn, P.J.: Data Clustering: A Review. ACM Computing Surveys, 31(3), P264-323.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Ester, M., Kriegel, H., Sander, J. and Xu, X. "A Density-based Algorithm for Discovering Clusters in Large Spatial Databases with Noise".]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hinneburg, A. and Keim, D. "An Efficient Approach to Clustering in Large Multimedia Databases with Noise", in Proc. of KDD-98, pp. 58-65.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>565124</ref_obj_id>
				<ref_obj_pid>565117</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Maria Halkidi, Yannis Batistakis, Michalis Vazirgiannis: "Cluster Validity Methods: Part I&II", SIGMOD Record, Vol31, No.2 & 3, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671342</ref_obj_id>
				<ref_obj_pid>645924</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[G. Sheikholeslami, S. Chatterjee, and A. Zhang. "Wavecluster: A multi-resolution clustering approach for very large spatial databases", In Proc. VLDB98', 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>355007</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Jean Gallier: "Geometric methods and applications: for computer science and engineering", Springer-Verlag, NY, c2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618646</ref_obj_id>
				<ref_obj_pid>616060</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[A. Hinneburg, D. Keim, and M. Wawryniuk: "Visual Mining of High-dimensional data", IEEE Computer Graphics and Applications. V19, No 5, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>304187</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. Ankerst, M. Breunig, H. Kriegel and J. Sander: "OPTICS: Ordering Points To Identify the Clustering Structure", in proc. of SIGMOD1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952099</article_id>
		<sort_key>505</sort_key>
		<display_label></display_label>
		<pages>505</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>74</seq_no>
		<title><![CDATA[Icon-based Visualization of Large High-Dimensional Datasets]]></title>
		<page_from>505</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952099</url>
		<abstract>
			<par><![CDATA[High dimensional data visualization is critical todata analysts since it gives a direct view of originaldata. We present a method to visualize large amount ofhigh dimensional data. We divide dimensions of datainto several groups. Then, we use one icon to represent each group, and associate visual properties of eachicon with dimensions in each group. A high dimensional data record will be represented by multiple different types of icons located in the same position. Furthermore, we use summary icons to display local detailsof viewer's interests and the whole data set at meantime. We show its effectiveness and efficiency through a case study on a real large data set.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.1</cat_node>
				<descriptor>Data models</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.1</cat_node>
				<descriptor>Normal forms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Visual</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10010365</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Visual analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP48023114</person_id>
				<author_profile_id><![CDATA[81100107312]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14097125</person_id>
				<author_profile_id><![CDATA[81414601631]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chenyi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77032339</person_id>
				<author_profile_id><![CDATA[81540800556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ding]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645339</person_id>
				<author_profile_id><![CDATA[81414616609]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Heloise]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lynn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645624</person_id>
				<author_profile_id><![CDATA[81414617753]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Yves]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Simon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bruckner, L.A., On chernoff faces. In Graphical Representation of Multivariate Data, P.C.C. Wang, Ed. Academic Press, New York, New York, pages 93-121, 1978.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614428</ref_obj_id>
				<ref_obj_pid>614274</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Christopher, G. Healey, James T. Enns, Large Datasets at a Glance: Combining Textures and Colors in Scientific Visualization. IEEE Transactions on Visualization and Computer Graphics, Volume 5, Issue 2, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Chernoff, H. The use of facesto represent points in k-dimensional space graphically. Journal of the American Statistical Association 68, 342, pages 361-367, 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Foley, J., and Ribarsky, W. Next-generation data visualization tools. Scientific Visualization: Advances and Challenges, L. Rosenblum, Ed. Academic Press, San Diego, California, pages 103-127, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>949634</ref_obj_id>
				<ref_obj_pid>949607</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Levkowitz, H. Color Icons: Merging Color and Texture Perception for Integrated Visualization of Multiple Parameter, Proceedings of IEEE Visualization'91 Conference, San Diego, CA, Oct. 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288234</ref_obj_id>
				<ref_obj_pid>288216</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Laidlaw, D. H., Ahrens, E.T., Kremers, D., Avalos, M.J., Jacobs, R.E., and Readhead, C. Visualizing diffusion tensor images of the mouse spinal cord. Proceedings of Visualization '98, pages 127- 134, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Pickett, R. M. and Grinstein, G. G., Iconographics Displays for Visualizing Multidimensional Data. Proceedings of the 1988 IEEE Conference on Systems, Man and Cybernetics. Beijing and Shenyang, People's Republic of China, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Grinstein, G. G., Pickett, R. M. and Williams, M., EXVIS: An Exploratory Data Visualization Environment. Proceedings of Graphics Interface '89 pages 254-261, London, Canada, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>267038</ref_obj_id>
				<ref_obj_pid>266989</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Wegenkittl, R., Lffelmann, H., Grller, E., Visualizing the behavior of higher dimensional dynamical systems. Proceedings of the conference on Visualization '97, 1997, Phoenix, Arizona, United States.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952084</article_id>
		<sort_key>509</sort_key>
		<display_label></display_label>
		<pages>509</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>75</seq_no>
		<title><![CDATA[Indexing and Mining Free Trees]]></title>
		<page_from>509</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952084</url>
		<abstract>
			<par><![CDATA[Tree structures are used extensively in domains such ascomputational biology, pattern recognition, computer networks,and so on. In this paper, we present an indexing techniquefor free trees and apply this indexing technique to theproblem of mining frequent subtrees. We first define a novelrepresentation, the canonical form, for rooted trees and extendthe definition to free trees. We also introduce anotherconcept, the canonical string, as a simpler representationfor free trees in their canonical forms. We then apply ourtree indexing technique to the frequent subtree mining problemand present FreeTreeMiner, a computationally efficientalgorithm that discovers all frequently occurring subtreesin a database of free trees. We study the performance andthe scalability of our algorithms through extensive experimentsbased on both synthetic data and datasets from tworeal applications: a dataset of chemical compounds and adataset of Internet multicast trees.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.1</cat_node>
				<descriptor>Indexing methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003365.10003366</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Search engine architectures and scalability->Search engine indexing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003318</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Document representation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645622</person_id>
				<author_profile_id><![CDATA[81350577988]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14128274</person_id>
				<author_profile_id><![CDATA[81540199556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yirong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42049806</person_id>
				<author_profile_id><![CDATA[81332517207]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Muntz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>VLDB 94</i>, September 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>578775</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. V. Aho, J. E. Hopcroft, and J. E. Ullman. <i>The Design and Analysis of Computer Algorithms</i>. Addison-Wesley, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952084</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Y. Chi, Y. Yang, and R. R. Muntz. Indexing and mining free trees. In <i>ICDM 2003</i>, November 2003. Full version available as Technical Report CSD-TR No. 030041 at ftp://ftp.cs.ucla.edu/tech-report/2003-reports/030041.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>32802</ref_obj_id>
				<ref_obj_pid>32795</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. J. Chung. <i>O</i>(<i>n</i><sup>2.5</sup>) time algorithm for subgraph homeomorphism problem on trees. <i>Journal of Algorithms</i>, 8:106- 112, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775058</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Efficiently mining frequent trees in a forest. In <i>8th ACM SIGKDD</i>, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952129</article_id>
		<sort_key>513</sort_key>
		<display_label></display_label>
		<pages>513</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>76</seq_no>
		<title><![CDATA[T-Trees, Vertical Partitioning and Distributed Association Rule Mining]]></title>
		<page_from>513</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952129</url>
		<abstract>
			<par><![CDATA[In this paper we consider a technique (DATA-VP) fordistributed (and parallel) Association Rule Mining thatmakes use of a vertical partitioning technique to distributethe input data amongst processors. The proposed verticalpartitioning is facilitated by a novel compressed set enumerationtree data structure (the T-tree), and an associatedmining algorithm (Apriori-T), that allows for computationallyeffective distributed/parallel ARM when compared withexisting approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.0</cat_node>
				<descriptor>Parallel algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010170</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Parallel algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010169.10010170</concept_id>
				<concept_desc>CCS->Computing methodologies->Parallel computing methodologies->Parallel algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P86339</person_id>
				<author_profile_id><![CDATA[81100499892]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Frans]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Coenen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37026780</person_id>
				<author_profile_id><![CDATA[81100359326]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP17016733</person_id>
				<author_profile_id><![CDATA[81318497754]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shakil]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ahmed]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>627803</ref_obj_id>
				<ref_obj_pid>627307</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Agrawal, R, and Shafer, J.C. (1996). Parallel Mining of Association Rules. IEEE Transactions on Knowledge and Data Engineering, Vol 8, No 6, pp 962-969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Agrawal, R. and Srikant, R. (1994). <i>Fast algorithms for mining association rules</i>. Proc. 20th VLDB Conference, Morgan Kaufman, pp 487-499.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>554058</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Arnold, K., Freeman, E. and Hupfer, S. (1999). <i>JavaSpaces: Principles, Patterns and Practice</i>. Addison Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Chattratichat, J., Darlington, J., Ghanem, M., Guo, Y., Hning, H., Khler, M., Sutiwaraphun, J., To H. W., Yang, D. (1997). <i>Large Scale Data Mining: Challenges and Responses</i>. Proc. 3rd Int. Conf. on Knowledge Discovery and Data mining (KDD'97), pp 143-146.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Coenen, F. and Leng, P. (2001). <i>Optimising Association Rule Algorithms Using Itemset Ordering</i>. Research and Development in Intelligent Systems XVIII: Proc ES2001 Conference, eds M Bramer, F Coenen and A Preece, Springer, pp 53-66.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>954524</ref_obj_id>
				<ref_obj_pid>954514</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Coenen, F., Goulbourne, G. and Leng, P., (2003). <i>Tree Structures for Mining association Rules</i>. To appear in the journal of Data Mining and Knowledge Discovery.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Goulbourne, G., Coenen, F. and Leng, P. (2000). <i>Algorithms for Computing Association Rules Using a Partial-Support Tree</i>. Journal of Knowledge-Based Systems, Vol (13), pp 141-149.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952094</article_id>
		<sort_key>517</sort_key>
		<display_label></display_label>
		<pages>517</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>77</seq_no>
		<title><![CDATA[Information Theoretic Clustering of Sparse Co-Occurrence Data]]></title>
		<page_from>517</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952094</url>
		<abstract>
			<par><![CDATA[A novel approach to clustering co-occurrence data posesit as an optimization problem in information theory whichminimizes the resulting loss in mutual information. A divisiveclustering algorithm that monotonically reduces thisloss function was recently proposed. In this paper we showthat sparse high-dimensional data presents special challengeswhich can result in the algorithm getting stuck atpoor local minima. We propose two solutions to this problem:(a) a "prior" to overcome infinite relative entropy valuesas in the supervised Naive Bayes algorithm, and (b)local search to escape local minima. Finally, we combinethese solutions to get a robust algorithm that is computationallyefficient. We present experimental results to showthat the proposed method is effective in clustering documentcollections and outperforms previous information-theoreticclustering approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.1.1</cat_node>
				<descriptor>Information theory</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Sorting and searching</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010031.10010033</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Data structures design and analysis->Sorting and searching</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003712</concept_id>
				<concept_desc>CCS->Mathematics of computing->Information theory</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40023634</person_id>
				<author_profile_id><![CDATA[81100098715]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Inderjit]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Dhillon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P439029</person_id>
				<author_profile_id><![CDATA[81100084481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yuqiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Guan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>129837</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Cover and J. Thomas. <i>Elements of Information Theory</i>. John Wiley & Sons, New York, USA, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon and Y. Guan. Information theoretic clustering of sparse co-occurrence data. Technical Report TR-03-39, Dept. of Computer Sciences, University of Texas, Sept 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844769</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon, Y. Guan, and J. Kogan. Iterative clustering of high dimensional text data augmented by local search. In <i>Proc. of IEEE International Conf. on Data Mining</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944973</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[I. S. Dhillon, S. Mallela, and R. Kumar. A divisive information-theoretic feature clustering algorithm for text classification. <i>J. of Mach. Learning Res.</i>, 3:1265-1287, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>954544</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. O. Duda, P. E. Hart, and D. G. Stork. <i>Pattern Classification</i>. John Wiley & Sons, 2nd edition, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[K. Lang. News Weeder: Learning to filter netnews. In <i>Proc. 12th Int'l Conf. Machine Learning</i>, pages 331-339, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[K. Rose. Deterministic annealing for clustering, compression, classification, regression, and related optimization problems. <i>Proc. IEEE</i>, 86(11):2210-2239, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564401</ref_obj_id>
				<ref_obj_pid>564376</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[N. Slonim, N. Friedman, and N. Tishby. Unsupervised document classification using sequential information maximization. In <i>ACM SIGIR</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345578</ref_obj_id>
				<ref_obj_pid>345508</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[N. Slonim and N. Tishby. Document clustering using word clusters via the information bottleneck method. In <i>ACM SIGIR</i>, pages 208-215, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952097</article_id>
		<sort_key>521</sort_key>
		<display_label></display_label>
		<pages>521</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>78</seq_no>
		<title><![CDATA[Links Between Kleinberg's Hubs and Authorities, Correspondence Analysis, and Markov Chains]]></title>
		<page_from>521</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952097</url>
		<abstract>
			<par><![CDATA[In this work, we show that Kleinberg's hubs and authoritiesmodel is closely related to both correspondence analysis,a well-known multivariate statistical technique, and aparticular Markov chain model of navigation through theweb. The only difference between correspondence analysisand Kleinberg's method is the use of the average value ofthe hubs (authorities) scores for computing the authorities(hubs) scores, instead of the sum for Kleinberg's method.We also show that correspondence analysis and our Markovmodel are related to SALSA, a variant of Kleinberg's model.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Network problems</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Multivariate statistics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Markov processes</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003649.10003651</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic representations->Markov networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003704</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Multivariate statistics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003700.10003701</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Stochastic processes->Markov processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003644</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Network flows</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003635.10003644</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Graph algorithms analysis->Network flows</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645311</person_id>
				<author_profile_id><![CDATA[81100242971]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Francois]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fouss]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P188036</person_id>
				<author_profile_id><![CDATA[81100445630]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Marco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Saerens]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43117807</person_id>
				<author_profile_id><![CDATA[83458695457]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jean-Michel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Renders]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[P. Bremaud. <i>Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues</i>. Springer-Verlag New York, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>248979</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[G. H. Golub and C. F. V. Loan. <i>Matrix Computations, 3th Ed</i>. The Johns Hopkins University Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. J. Greenacre. <i>Theory and Applications of Correspondence Analysis</i>. Academic Press, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>324140</ref_obj_id>
				<ref_obj_pid>324133</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. M. Kleinberg. Authoritative sources in a hyperlinked environment. <i>Journal of the ACM</i>, 46(5):604-632, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383041</ref_obj_id>
				<ref_obj_pid>382979</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Lempel and S. Moran. Salsa: The stochastic approach for link-structure analysis. <i>ACM Transactions on Information Systems</i>, 19(2):131-160, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642215</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Y. Ng, A. X. Zheng, and M. I. Jordan. Link analysis, eigenvectors and stability. <i>International Joint Conference on Artificial Intelligence (IJCAI-01)</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation ranking: Bringing order to the web. <i>Technical Report, Computer System Laboratory, Stanford University</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Papoulis and S. U. Pillai. <i>Probability, Random Variables and Stochastic Processes</i>. McGraw-Hill, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[W. J. Stewart. <i>Introduction to the Numerical Solution of Markov Chains</i>. Princeton University Press, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952120</article_id>
		<sort_key>525</sort_key>
		<display_label></display_label>
		<pages>525</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>79</seq_no>
		<title><![CDATA[Fast PNN-based Clustering Using K-nearest Neighbor Graph]]></title>
		<page_from>525</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952120</url>
		<abstract>
			<par><![CDATA[Search for nearest neighbor is the main source ofcomputation in most clustering algorithms. We proposethe use of nearest neighbor graph for reducing thenumber of candidates. The number of distancecalculations per search can be reduced from O(N) to O(k)where N is the number of clusters, and k is the number ofneighbors in the graph. We apply the proposed schemewithin agglomerative clustering algorithm known as thePNN algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Path and circuit problems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003640</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Paths and connectivity problems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P525345</person_id>
				<author_profile_id><![CDATA[81100165787]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pasi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fr&#228;nti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P484482</person_id>
				<author_profile_id><![CDATA[81100561691]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Olli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Virmajoki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645591</person_id>
				<author_profile_id><![CDATA[81100289956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ville]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hautam&#228;ki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J.H. Ward, "Hierarchical grouping to optimize an objective function," <i>J. Amer. Statist. Assoc.</i>, 58, 236-244, 1963.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[W.H. Equitz, "A new vector quantization clustering algorithm," <i>IEEE-ASSP</i>, 37(10), 1568-1575, Oct. 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2319890</ref_obj_id>
				<ref_obj_pid>2318983</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Fr&#228;nti, T. Kaukoranta, D.-F. Shen and K.-S. Chang, "Fast and memory efficient implementation of the exact PNN," <i>IEEE-IP</i>, 9(5), 773-777, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J.C. Cover and G.J.S. Ross, "Minimum spanning trees and simple-linkage cluster analysis," <i>Applied Statistics</i>, 18, 54- 64, 1969.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S.-W. Ra and J.K. Kim, "A fast mean-distance-ordered partial codebook search algorithm for image vector quantization," <i>IEEE-CS</i>, 40(9), 576-579, September 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Arya and D.M. Mount, "Algorithm for fast vector quantization," <i>IEEE Data Compresion Conference</i>, Snowbird Utah, 381-390, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A.D. Constantinou, R.D. Bull and C.N. Canagarajah, "A new class of VQ codebook design algorithms using adjacency maps," <i>SPIE Electronics Imaging 2000</i>, San Jose, 3974, 625-634, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[O. Virmajoki, P. Fr&#228;nti, T. Kaukoranta, "Practical methods for speeding-up the pairwise nearest neighbor method", <i>Optical Engineering</i>, 40(11), 2495-2504, November 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Y. Linde, A. Buzo and R.M. Gray, "An Algorithm for Vector Quantizer Design," <i>IEEE-COM</i>, 28(1), 84-95, Jan. 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2319964</ref_obj_id>
				<ref_obj_pid>2318987</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Kaukoranta, P. Fr&#228;nti and O. Nevalainen, "A fast exact GLA based on code vector activity detection", <i>IEEE-IP</i>, 9(8), 1337-1342, Aug. 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952130</article_id>
		<sort_key>529</sort_key>
		<display_label></display_label>
		<pages>529</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>80</seq_no>
		<title><![CDATA[The Rough Set Approach to Association Rule Mining]]></title>
		<page_from>529</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952130</url>
		<abstract>
			<par><![CDATA[In transaction processing, an association is said to existbetween two sets of items when a transaction containingone set is likely to also contain the other. In informationretrieval, an association between two sets of keywords occurswhen they co-occur in a document. Similarly, in datamining, an association occurs when one attribute set occurstogether with another. As the number of such associationsmay be large, maximal association rules are sought, e.g.,Feldman et al (1997, 1998).Rough set theory is a successful tool for data mining. Byusing this theory, rules similar to maximal associations canbe found. However, we show that the rough set approach todiscovering knowledge is much simpler than the maximalassociation method.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Rough Set, Data Mining, Knowledge Discoveryin Databases]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Transaction processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003193</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Database transaction processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP31026508</person_id>
				<author_profile_id><![CDATA[81100084930]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Guan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39041387</person_id>
				<author_profile_id><![CDATA[81406600041]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Bell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP25004509</person_id>
				<author_profile_id><![CDATA[81339514152]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[Y.]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>275011</ref_obj_id>
				<ref_obj_pid>275008</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bell, D.A.; Guan, J. W. 1998, Computational methods for rough classification and discovery, <i>Journal of the American Society for Information Science, Special Topic Issue on Data Mining</i>, Vol.49(1998), No.5, 403- 414.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Feldman, R.; Aumann, Y.; Amir, A.; Zilberstain, A.; Kloesgen, W. Ben-Yehuda, Y. 1997, Maximal association rules: a new tool for mining for keyword cooccurrences in document collection, in <i>Proceedings of the 3rd International Conference on Knowledge Discovery (KDD 1997)</i>, 167-170.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669185</ref_obj_id>
				<ref_obj_pid>645802</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Feldman, R.; Fresko, M.; Kinar, Y.; Lindell, Y.; Liphstat, O.; Rajman, M.; Schler, Y.; Zamir, O. 1998, Text mining at the term level, in <i>Proceedings of the 2nd European Symposium on Knowledge Discovery in Databases, PKDD'98, Nantes, France, 23-26 September 1998; Lecture Notes in Artificial Intelligence 1510: Principles of Data Mining and Knowledge Discovery</i>, Jan M. Zytkow Mohamed Quafafou eds.; Springer, 65- 73.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>291148</ref_obj_id>
				<ref_obj_pid>291144</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Guan, J. W.; Bell, D. A. 1998, Rough computational methods for information systems, <i>Artificial Intelligence -- An International Journal</i>, Vol.105(1998), 77-104.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>531580</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Pawlak, Z. (1991). Rough sets: theoretical aspects of reasoning about data. Kluwer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952110</article_id>
		<sort_key>533</sort_key>
		<display_label></display_label>
		<pages>533</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>81</seq_no>
		<title><![CDATA[Comparing Pure Parallel Ensemble Creation Techniques Against Bagging]]></title>
		<page_from>533</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952110</url>
		<abstract>
			<par><![CDATA[We experimentally evaluate randomization-based approachesto creating an ensemble of decision-tree classifiers.Unlike methods related to boosting, all of the eightapproaches considered here create each classifier in an ensembleindependently of the other classifiers. Experimentswere performed on 28 publicly available datasets, usingC4.5 release 8 as the base classifier. While each of the otherseven approaches has some strengths, we find that none ofthem is consistently more accurate than standard baggingwhen tested for statistical significance.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Statistical computing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.0</cat_node>
				<descriptor>Parallel algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010169.10010170</concept_id>
				<concept_desc>CCS->Computing methodologies->Parallel computing methodologies->Parallel algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010170</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Parallel algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003698</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Statistical graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15019596</person_id>
				<author_profile_id><![CDATA[81407593306]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lawrence]]></first_name>
				<middle_name><![CDATA[O.]]></middle_name>
				<last_name><![CDATA[Hall]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15037024</person_id>
				<author_profile_id><![CDATA[81100590967]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Bowyer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645519</person_id>
				<author_profile_id><![CDATA[81100466201]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Banfield]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645297</person_id>
				<author_profile_id><![CDATA[81100480291]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Divya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bhadoria]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P437818</person_id>
				<author_profile_id><![CDATA[81100620573]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[Philip]]></middle_name>
				<last_name><![CDATA[Kegelmeyer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P495687</person_id>
				<author_profile_id><![CDATA[81100037554]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Eschrich]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>599607</ref_obj_id>
				<ref_obj_pid>599591</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Bauer and R. Kohavi. An empirical comparison of voting classification algorithms: Bagging, boosting, and variants. <i>Machine Learning</i>, 36(1,2):105-139, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[K. Bowyer, N. Chawla, J. T.E. Moore, L. Hall, and W. Kegelmeyer. A parallel decision tree builder for mining very large visualization datasets. In <i>IEEE Systems, Man, and Cybernetics Conference</i>, pages 1888-1893, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Brazdil and J. Gama. The statlog project- evaluation / characterization of classification algorithms. Technical report, The STATLOG Project- Evaluation / Characterization of Classification Algorithms, http://www.ncc.up.pt/liacc/ML/statlog/, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging predictors. <i>Machine Learning</i>, 24:123- 140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>570182</ref_obj_id>
				<ref_obj_pid>570181</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Random forests. <i>Machine Learning</i>, 45(1):5-32, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[L. Breiman, J. Friedman, R. Olshen, and P. Stone. <i>Classification and Regression Trees</i>. Wadsworth International Group, Belmont, CA., 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>641722</ref_obj_id>
				<ref_obj_pid>641681</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[N. Chawla, T. Moore, L. Hall, K. Bowyer, W. Kegelmeyer, and C. Springer. Distributed learning with bagging-like performance. <i>Pattern Recognition Letters</i>, 24:455-471, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>755187</ref_obj_id>
				<ref_obj_pid>648299</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Collins, R. Schapire, and Y. Singer. Logistic regression, AdaBoost and Bregman distances. In <i>Proceedings of the Thirteenth Annual Conference on Computational Learning Theory</i>, pages 158-169, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>350131</ref_obj_id>
				<ref_obj_pid>350128</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. Dietterich. An experimental comparison of three methods for constructing ensembles of decision trees: bagging, boosting, and randomization. <i>Machine Learning</i>, 40(2):139-157, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>284986</ref_obj_id>
				<ref_obj_pid>284980</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Ho. The random subspace method for constructing decision forests. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 20(8):832-844, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[G. Hulten and P. Domingos. Learning from infinite data in finite time. In <i>Advances in Neural Information Processing Systems 14</i>, pages 673-680, Cambridge, MA, 2002. MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[C. Merz and P. Murphy. <i>UCI Repository of Machine Learning Databases</i>. Univ. of CA., Dept. of CIS, Irvine, CA. http://www.ics.uci.edu/~mlearn/MLRepository.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Quinlan. <i>C4.5: Programs for Machine Learning</i>. Morgan Kaufmann, 1992. San Mateo, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>83645</ref_obj_id>
				<ref_obj_pid>83637</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. Schapire. The strength of weak learnability. <i>Machine Learning</i>, 5(2):197-227, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323651</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[I. H. Witten and E. Frank. <i>Data Mining: Practical machine learning tools with Java implementations</i>. Morgan Kaufmann, San Francisco, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952078</article_id>
		<sort_key>537</sort_key>
		<display_label></display_label>
		<pages>537</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>82</seq_no>
		<title><![CDATA[Improving Home Automation by Discovering Regularly Occurring Device Usage Patterns]]></title>
		<page_from>537</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952078</url>
		<abstract>
			<par><![CDATA[The data stream captured by recording inhabitant-deviceinteractions in an environment can be mined todiscover significant patterns, which an intelligent agentcould use to automate device interactions. However, thisknowledge discovery problem is complicated by severalchallenges, such as excessive noise in the data, data thatdoes not naturally exist as transactions, a need tooperate in real time, and a domain where frequency maynot be the best discriminator. In this paper, we propose anovel data mining technique that addresses thesechallenges and discovers regularly-occurringinteractions with a smart home. We also discuss a casestudy that shows the data mining technique can improvethe accuracy of two prediction algorithms, thusdemonstrating multiple uses for a home automationsystem. Finally, we present an analysis of the algorithmand results obtained using inhabitant interactions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Heuristic methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>K.4.3</cat_node>
				<descriptor>Automation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003567.10003569</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing and business->Automation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010206</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Heuristic function construction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P543935</person_id>
				<author_profile_id><![CDATA[81100193289]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Edwin]]></first_name>
				<middle_name><![CDATA[O.]]></middle_name>
				<last_name><![CDATA[Heierman]]></last_name>
				<suffix><![CDATA[III]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14049362</person_id>
				<author_profile_id><![CDATA[81100111814]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Diane]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Cook]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>655281</ref_obj_id>
				<ref_obj_pid>645480</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant, "Mining sequential patterns," <i>Proc. 11th International Conference Data Engineering (ICDE 1995)</i>, Taipei, Taiwan, pp. 3-14, March 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>295733</ref_obj_id>
				<ref_obj_pid>295240</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Coen. Design principles for Intelligent Environments. <i>AAAI Spring Symposium</i>, Stanford, pp. 36-43, March 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2213068</ref_obj_id>
				<ref_obj_pid>2212967</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Das, D. Cook, A. Bhattacharaya, E. Heierman, and T. Lin. The Role of Prediction Algorithms in the MavHome Smart Home Architecture. <i>IEEE Wireless Communications</i>, vol. 9, no. 6, pp. 77-84, December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[B. Davison and H. Hirsh. Predicting Sequences of User Actions. In <i>Technical Report</i>, Rutgers, The State University of New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Mannila, H. Toivonen, and A. Verkamo, "Discovering frequent episodes in sequences," <i>Proc. 1st International Conference on Knowledge Discovery and Data Mining (KDD'95)</i>, Montreal, Canada, pp. 210-215, August 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Mozer. An intelligent environment must be adaptive. <i>IEEE Intelligent Systems</i>, vol. 14, no. 2, pp. 11-13, March/April 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952117</article_id>
		<sort_key>541</sort_key>
		<display_label></display_label>
		<pages>541</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>83</seq_no>
		<title><![CDATA[Ontologies Improve Text Document Clustering]]></title>
		<page_from>541</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952117</url>
		<abstract>
			<par><![CDATA[Text document clustering plays an important role in providingintuitive navigation and browsing mechanisms by organizinglarge sets of documents into a small number ofmeaningful clusters. The bag of words representation usedfor these clustering methods is often unsatisfactory as it ignoresrelationships between important terms that do not co-occurliterally. In order to deal with the problem, we integratecore ontologies as background knowledge into theprocess of clustering text documents. Our experimentalevaluations compare clustering techniques based on pre-categorizationsof texts from Reuters newsfeeds and on asmaller domain of an eLearning course about Java. In theexperiments, improvements of results by background knowledgecompared to a baseline without background knowledgecan be shown in many interesting combinations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Textual databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P443307</person_id>
				<author_profile_id><![CDATA[81100539734]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andreas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hotho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39038162</person_id>
				<author_profile_id><![CDATA[81409593685]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Steffen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Staab]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP48023404</person_id>
				<author_profile_id><![CDATA[81100171609]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Gerd]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stumme]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>992635</ref_obj_id>
				<ref_obj_pid>992628</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Agirre and G. Rigau. Word sense disambiguation using conceptual density. In <i>Proc. of COLING'96</i>, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Gutschke. Kategorisierung von textuellen lernobjekten mit methoden des maschinellen lernens. Studienarbeit, Universit&#228;t Hannover, Hannover, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[N. Henze. Towards open adaptive hypermedia. In <i>9. ABIS-Workshop 2001, im Rahmen der Workshopwoche "Lernen - Lehren - Wissen - Adaptivit&#228;t" (LLWA 01)</i>, Dortmund, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Hotho, S. Staab, and G. Stumme. Text clustering based on background knowledge. Technical Report 425, University of Karlsruhe, Institute AIFB, 2003. 36 pages.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>972721</ref_obj_id>
				<ref_obj_pid>972719</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[N. Ide and J. V&#233;ronis. Introduction to the special issue on word sense disambiguation: The state of the art. <i>Computational Linguistics</i>, 24(1):1-40, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Lewis. Reuters-21578 text categorization test collection, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>219748</ref_obj_id>
				<ref_obj_pid>219717</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[G. Miller. WordNet: A lexical database for english. <i>CACM</i>, 38(11):39-41, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Steinbach, G. Karypis, and V. Kumar. A comparison of document clustering techniques. In <i>KDD Workshop on Text Mining</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952095</article_id>
		<sort_key>545</sort_key>
		<display_label></display_label>
		<pages>545</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>84</seq_no>
		<title><![CDATA[The Hybrid Poisson Aspect Model for Personalized Shopping Recommendation]]></title>
		<page_from>545</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952095</url>
		<abstract>
			<par><![CDATA[Predicting an individual customer's likelihood of purchasinga specific item forms the basis of many marketingactivities, such as personalized shopping recommendation.Collaborative filtering and association rule miningcan be applied to this problem, but in retail supermarkets,the problem becomes particularly challenging because ofthe sparsity and skewness of transaction data. This paperpresents HyPAM(Hybrid Poisson Aspect Model), a newprobabilistic graphical model that combines a Poisson mixturewith a latent aspect class model to model customers'shopping behavior. We empirically compare HyPAM withtwo well-known recommenders, GroupLens (a correlation-basedmethod), and IBM SmartPad (association rules andcosine similarity). Experimental results show that HyPAMoutperforms the other recommenders by a large margin fortwo real-world retail supermarkets, ranking most of actualpurchases in the top ten percent of the most likely purchaseditems. We also present a new visualization method, rankplot, to evaluate the quality of recommendations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.1</cat_node>
				<descriptor>Marketing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.7</cat_node>
				<descriptor>Consumer products</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Visual</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010481.10003558</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Consumer products</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010481.10010488</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Marketing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010406</concept_id>
				<concept_desc>CCS->Applied computing->Enterprise computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10010365</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Visual analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15029042</person_id>
				<author_profile_id><![CDATA[81350597365]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chun-Nan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hsu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645337</person_id>
				<author_profile_id><![CDATA[81430618234]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hao-Hsiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP25000623</person_id>
				<author_profile_id><![CDATA[81423595791]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Han-Shen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proceedings of the 20th International Conference on Very Large Data Bases</i>, pages 487-499, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657311</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Billsus and M. J. Pazzani. Learning collaborative information filters. In <i>Proceedings of the Fifteenth International Conference on Machine Learning</i>, pages 46-54, Jul 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2074100</ref_obj_id>
				<ref_obj_pid>2074094</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. S. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In <i>Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence</i>, pages 43-52, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502523</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[I. V. Cadez, P. Smyth, and H. Mannila. Probabilistic modeling of transaction data with applications to profiling, visualization, and prediction. In <i>Proceedings of the 7th ACM International Conference on Knowledge Discovery and Data Mining</i>, pages 37-46, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Dempster, N. Laird, and D. Rubin. Maximum likelihood from incomplete data via the em algorithm. <i>Joulnal of the Royal statistical Society</i>, B39: 1-37, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>138867</ref_obj_id>
				<ref_obj_pid>138859</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Goldberg, D. Nichols, B. M. Oki, and D. Terry. Using collaborative filtering to weave an information tapestry. <i>Communications of the ACM</i>, 35(12):61-70, Dec 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2073829</ref_obj_id>
				<ref_obj_pid>2073796</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Hofmann. Probabilistic latent semantic analysis. In <i>Proceedings of the 15th Conference on Uncertainty in Artificial Intelligence</i>, pages 289-296, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593506</ref_obj_id>
				<ref_obj_pid>593429</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. D. Lawrence, G. S. Almasi, V. Kotlyar, M. S. Viveros, and S. Duri. Personalization of supermarket product recommendations. <i>Data Mining and Knowledge Discovery</i> 5: 11-32, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. Ling and C. Li. Data mining for direct marketing: Problems and solutions. In <i>Proceedings of the 4th International Conference on Knowledge Discovery and nata Mining</i>, pages 73-79, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1011974</ref_obj_id>
				<ref_obj_pid>1011951</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. Hsu, H. Chung, and H. Huang. Data Mining Skewed and Sparse Transaction Data for Personalized Shopping Recommendation. Submitted for publication, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>720088</ref_obj_id>
				<ref_obj_pid>647235</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Popescul, L. Ungar, D. Pennock, and S. Lawrellce. Probabilistic models for unified collaborative and content-based recommendation in sparse-data environments. In <i>Proceedings of the Seventeenth Conference on Uncertaintv in Artificia I Intelligence</i>, pages 437-444, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192905</ref_obj_id>
				<ref_obj_pid>192844</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[P. Resnick, N. Iacovou, M. Suchak, P. Bergsiorm, and J. Riedl. GroupLens: An Open Architecture for Collaborative Filtering of Netnews. In <i>Proceedings of ACM Conference on Computer Supported Cooperative Work</i>, pages 175-186, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952101</article_id>
		<sort_key>549</sort_key>
		<display_label></display_label>
		<pages>549</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>85</seq_no>
		<title><![CDATA[Efficient Mining of Frequent Subgraphs in the Presence of Isomorphism]]></title>
		<page_from>549</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952101</url>
		<abstract>
			<par><![CDATA[Frequent subgraph mining is an active research topic inthe data mining community. A graph is a general modelto represent data and has been used in many domains likecheminformatics and bioinformatics. Mining patterns fromgraph databases is challenging since graph related operations,such as subgraph testing, generally have higher timecomplexity than the corresponding operations on itemsets,sequences, and trees, which have been studied extensively.In this paper, we propose a novel frequent subgraph miningalgorithm: FFSM, which employs a vertical search schemewithin an algebraic graph framework we have developedto reduce the number of redundant candidates proposed.Our empirical study on synthetic and real datasets demonstratesthat FFSM achieves a substantial performance gainover the current start-of-the-art subgraph mining algorithmgSpan.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Search process</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003325</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Information retrieval query processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43129592</person_id>
				<author_profile_id><![CDATA[81342497864]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43144916</person_id>
				<author_profile_id><![CDATA[81452601906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43142756</person_id>
				<author_profile_id><![CDATA[81407592542]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Prins]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>844706</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Borgelt and M. R. Berhold. Mining molecular fragments: Finding relevant substructures of molecules. <i>In ICDM'02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671008</ref_obj_id>
				<ref_obj_pid>645923</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Goldman and J. Widom. Dataguides: Enabling query formulation and optimization in semistructured databases. <i>In VLDB'97</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Huan, W. Wang, and J. Prins. Efficient mining of frequent subgraph in the presence of isomorphism. <i>UNC computer science technique report TR03-021</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>669817</ref_obj_id>
				<ref_obj_pid>645804</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Inokuchi, T. Washio, and H. Motoda. An apriori-based algorithm for mining frequent substructures from graph data. <i>In PKDD'00</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658027</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Kuramochi and G. Karypis. Frequent subgraph discovery. <i>In ICDM'01</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[K. Shearer, H. Bunks, and S. Venkatesh. Video indexing and similarity retrieval by largest common subgraph detection using decision trees. <i>Pattern Recognition</i>, 34(5):1075-91, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1624163</ref_obj_id>
				<ref_obj_pid>1624162</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. Srinivasan, R. D. King, S. H. Muggleton, and M. Sternberg. The predictive toxicology evaluation challenge. <i>In Proc. of the 15th International Joint Conferrence on Artificial Intelligence (IJCAI)</i>, pages 1-6, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844749</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[N. Vanetik, E. Gudes, and E. Shimony. Computing frequent graph patterns from semi-structured data. <i>ICDM'02</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844811</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[X. Yan and J. Han. gspan: Graph-based substructure pattern mining. <i>In ICDM'02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775058</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki. Efficiently mining frequent trees in a forest. <i>In SIGKDD'02</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. New algorithms for fast discovery of association rules. <i>In SIGKDD'97</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952115</article_id>
		<sort_key>553</sort_key>
		<display_label></display_label>
		<pages>553</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>86</seq_no>
		<title><![CDATA[Comparing Naive Bayes, Decision Trees, and SVM with AUC and Accuracy]]></title>
		<page_from>553</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952115</url>
		<abstract>
			<par><![CDATA[Predictive accuracy has often been used as the mainand often only evaluation criterion for the predictive performanceof classification or data mining algorithms. Inrecent years, the area under the ROC (Receiver OperatingCharacteristics) curve, or simply AUC, has been proposedas an alternative single-number measure for evaluating performanceof learning algorithms. In our previous work, weproved that AUC is, in general, a better measure (definedprecisely) than accuracy. Many popular data mining algorithmsshould then be re-evaluated in terms of AUC. Forexample, it is well accepted that Naive Bayes and decisiontrees are very similar in accuracy. How do they compare inAUC? Also, how does the recently developed SVM (SupportVector Machine) compare to traditional learning algorithmsin accuracy and AUC? We will answer these questions inthis paper. Our conclusions will provide important guide-linesin data mining applications on real-world datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Parameter learning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010316</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010316</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Markov decision processes</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15021530</person_id>
				<author_profile_id><![CDATA[81100084313]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645376</person_id>
				<author_profile_id><![CDATA[81100053478]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jingjing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030222</person_id>
				<author_profile_id><![CDATA[81100159332]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[X.]]></middle_name>
				<last_name><![CDATA[Ling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz. UCI repository of machine learning databases. http://www.ics.uci.edu/~mlearn/MLRepository.html, 1998. University of California, Irvine, Dept. of Information and Computer Sciences.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1746434</ref_obj_id>
				<ref_obj_pid>1746432</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. P. Bradley. The use of the area under the ROC curve in the evaluation of machine learning algorithms. <i>Pattern Recognition</i>, 30:1145-1159, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Brown, W. Grundy, D. Lin, and N. C. et al. Knowledge-based analysis of microarray gene expression data using support vector machines. In <i>Proceedings of the National Academy of Sciences</i>, pages 262-267, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1961199</ref_obj_id>
				<ref_obj_pid>1961189</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. C. Chang and C. Lin. Libsvm: A library for support vector machines (version 2.4), 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>61950</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C. W. Therrien. <i>Decision Estimation and Classification: An Introduction to Pattern Recognition and Related Topics</i>. Wiley, New York, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. Domingos and M. Pazzani. Beyond independence: conditions for the optimality of the simple Bayesian classifier. In <i>Proceedings of the Thirteenth International Conference on Machine Learning</i>, pages 105-112, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[U. Fayyad and K. Irani. Multi-interval discretization of continuous-valued attributes for classification learning. In <i>Proceedings of Thirteenth International Joint Conference on Artificial Intelligence</i>, pages 1022-1027. Morgan Kaufmann, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655987</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. Ferri, P. A. Flach, and J. Hernandez-Orallo. Learning decision trees using the area under the ROC curve. In <i>Proceedings of the Nineteenth International Conference on Machine Learning (ICML 2002)</i>, pages 139-146, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>92131</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[K. Fukunaga. <i>Introduction to Statistical Pattern Recognition</i>. Academic Press, second edition, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. Hsu and C. Lin. A comparison on methods for multiclass support vector machines. Technical report, Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[I. Kononenko. Comparison of inductive and naive Bayesian learning approaches to automatic knowledge acquisition. In B. Wielinga, editor, <i>Current Trends in Knowledge Acquisition</i>. IOS Press, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[P. Langley, W. Iba, and K. Thomas. An analysis of Bayesian classifiers. In <i>Proceedings of the Tenth National Conference of Artificial Intelligence</i>, pages 223-228. AAAI Press, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593531</ref_obj_id>
				<ref_obj_pid>593434</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Y. Lin. Support vector machines and the bayes rule in classification. <i>Data Mining and Knowledge Discovery</i>, 6(3):259- 275, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1630736</ref_obj_id>
				<ref_obj_pid>1630659</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[C. X. Ling, J. Huang, and H. Zhang. AUC: a statistically consistent and more discriminating measure than accuracy. In <i>Proceedingsof 18th International Conferenceon Artificial Intelligence (IJCAI-2003)</i>, pages 329-341, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>759119</ref_obj_id>
				<ref_obj_pid>646420</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[C. X. Ling and H. Zhang. Toward Bayesian classifiers with accurate probabilities. In <i>Proceedings of the Sixth Pacific-Asia Conference on KDD</i>, pages 123-134. Springer, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593535</ref_obj_id>
				<ref_obj_pid>593435</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[H. Liu, F. Hussain, C. L. Tan, and M. Dash. Discretization: An enabling technique. <i>Data Mining and Knowledge Discovery</i>, 6(4):393-423, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[D. Meyer, F. Leisch, and K. Hornik. Benchmarking support vector machines. Technical report, Vienna University of Economics and Business Administration, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>779926</ref_obj_id>
				<ref_obj_pid>779909</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[F. Provost and P. Domingos. Tree induction for probability based ranking. <i>Machine Learning</i>, 2003. To appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[F. Provost and T. Fawcett. Analysis and visualization of classifier performance: comparison under imprecise class and cost distribution. In <i>Proceedings of the Third International Conference on Knowledge Discovery and Data Mining</i>, pages 43-48. AAAI Press, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657469</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[F. Provost, T. Fawcett, and R.Kohavi. The case against accuracy estimation for comparing induction algorithms. In <i>Proceedings of the Fifteenth International Conference on Machine Learning</i>, pages 445-453. Morgan Kaufmann, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[J. Quinlan. <i>C4.5: Programs for Machine Learning</i>. Morgan Kaufmann: San Mateo, CA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[P. Smyth, A. Gray, and U. Fayyad. Retrofitting decision tree classifiers using kernel density estimation. In <i>Proceedings of the 12th International Conference on machine Learning</i>, pages 506-514, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>326408</ref_obj_id>
				<ref_obj_pid>326394</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[J. A. K. Suykens and J. Vandewalle. Multiclass least squares support vector machines. In <i>IJCNN'99 International Joint Conference on Neural Networks</i>, Washington, DC, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952076</article_id>
		<sort_key>557</sort_key>
		<display_label></display_label>
		<pages>557</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>87</seq_no>
		<title><![CDATA[SVM Based Models for Predicting Foreign Currency Exchange Rates]]></title>
		<page_from>557</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952076</url>
		<abstract>
			<par><![CDATA[Support vector machine (SVM) has appeared as a powerfultool for forecasting forex market and demonstrated betterperformance over other methods, e.g., neural network orARIMA based model. SVM-based forecasting modelnecessitates the selection of appropriate kernel function andvalues of free parameters: regularization parameter and \varepsilon-insensitive loss function. In this paper, we investigate the effectof different kernel functions, namely, linear, polynomial, radialbasis and spline on prediction error measured by several widelyused performance metrics. The effect of regularizationparameter is also studied. The prediction of six different foreigncurrency exchange rates against Australian dollar has beenperformed and analyzed. Some interesting results are presented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.1.0</cat_node>
				<descriptor>Numerical algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.1</cat_node>
				<descriptor>Computations on polynomials</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.4</cat_node>
				<descriptor>Economics</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010455.10010460</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences->Economics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003720</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on polynomials</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003724</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Numerical differentiation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Economics</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP24022018</person_id>
				<author_profile_id><![CDATA[81100621016]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Joarder]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kamruzzaman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P250236</person_id>
				<author_profile_id><![CDATA[81100482079]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ruhul]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Sarker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645355</person_id>
				<author_profile_id><![CDATA[81100195245]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Iftekhar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ahmad]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[G. E. P. Box and G. M. Jenkins, <i>Time Series Analysis: Forecasting and Control</i>, Holden-Day, San Francosco, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Cao and F. Tay, "Financial forecasting using support vector machines," <i>Neural Comput & Applic</i>, vol. 10, pp.184-192, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326753</ref_obj_id>
				<ref_obj_pid>2325780</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Gestel <i>et. al.</i>, "Financial time series prediction using least squares support vector machines within the evidence framework," <i>IEEE trans. Neural Network</i>, vol. 12, no.4, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>239551</ref_obj_id>
				<ref_obj_pid>239524</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Hill, M. O'Connor and W. Remus, "Neural network models for time series forecasts," <i>Management Science</i>, vol. 42, pp 1082-1092, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>155154</ref_obj_id>
				<ref_obj_pid>155150</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[W. C. Jhee and J. K. Lee, "Performance of neural networks in managerial forecasting," <i>Intelligent Systems in Accounting, Finance and Management</i>, vol. 2, pp 55-71, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. kamruzzaman and R. Sarker, "Forecasting of currency exchange rate: a case study," to appear in <i>Proc. IEEE International Conference on Neural Networks & Signal Processing (ICNNSP'03)</i>, Nanjing, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. kamruzzaman and R. Sarker, "Application of support vector machine to Forex monitoring," <i>submitted to 3rd Int. Conf. on Hybrid Intelligent Systems HIS03, Melbourne, 2003</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326749</ref_obj_id>
				<ref_obj_pid>2325780</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. Medeiros, A. Veiga and C. Pedreira, "Modeling exchange rates: smooth transitions, neural networks, and linear models," <i>IEEE Trans. Neural Networks</i>, vol. 12, no. 4, pp. 755-764, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Z. Tang and P. A. Fishwich, "Back-Propagation neural nets as models for time series forecasting," <i>ORSA Journal on Computing</i>, vol. 5(4), pp 374-385, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik, <i>Statistical Learning Theory</i>. New York: Wiley, 198.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. H. Wang and J. Y. Leu, "Stock market trend prediction using ARIMA-based neural networks," <i>Proc. of IEEE Int. Conf. on Neural Networks</i>, vol. 4, pp. 2160-2165, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Yao and C.L. Tan, "A case study on using neural networks to perform technical forecasting of forex," <i>Neurocomputing</i>, vol. 34, pp. 79-98, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326747</ref_obj_id>
				<ref_obj_pid>2325780</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[H. Zimmermann, R. Neuneier and R. Grothmann, "Multi-agent modeling of multiple FX-markets by neural networks," <i>IEEE Trans. Neural Networks</i>, vol. 12, no. 4, pp. 735-743, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[G. Zhang and M. Y. Hu, "Neural network forecasting of the British Pound/US Dollar exchange rate," <i>OMEGA: Int. Journal of Management Science</i>, 26, pp 495-506, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952088</article_id>
		<sort_key>561</sort_key>
		<display_label></display_label>
		<pages>561</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>88</seq_no>
		<title><![CDATA[Facilitating Fuzzy Association Rules Mining by Using Multi-Objective Genetic Algorithms for Automated Clustering]]></title>
		<page_from>561</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952088</url>
		<abstract>
			<par><![CDATA[In this paper, we propose an automated clustering methodbased on multi-objective genetic algorithms (GA); the aim ofthis method is to automatically cluster values of a givenquantitative attribute to obtain large number of largeitemsets in low duration (time). We compare the proposedmulti-objective GA-based approach with CURE-basedapproach. In addition to the autonomous specification offuzzy sets, experimental results showed that the proposedautomated clustering exhibits good performance overCURE-based approach in terms of runtime as well as thenumber of large itemsets and interesting association rules.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.1</cat_node>
				<descriptor>Fuzzy set</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP45027187</person_id>
				<author_profile_id><![CDATA[81336490511]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mehmet]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14211269</person_id>
				<author_profile_id><![CDATA[81100613277]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Reda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alhajj]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>266898</ref_obj_id>
				<ref_obj_pid>266714</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[K.C.C. Chan and W.H. Au, "Mining Fuzzy Association Rules," <i>Proc. of ACM CIKM</i>, pp.209-215, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>371624</ref_obj_id>
				<ref_obj_pid>371621</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. Guha, R. Rastogi and K. Shim, "CURE: An Efficient Clustering Algorithm for Large Databases," <i>Information Systems</i>, Vol.26, No.1, pp.35-58, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>129194</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J.H. Holland, Adaptation in Natural and Artificial Systems, The MIT Press, Cambridge, MA, MIT Press edition, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T.P. Hong, C.S. Kuo and S.C. Chi, "Mining Association Rules from Quantitative Data," <i>Intelligent Data Analysis</i>, Vol.3, pp.363-376, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>653287</ref_obj_id>
				<ref_obj_pid>645482</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[B. Lent, A. Swami and J. Widom, "Clustering Association Rules," <i>Proc. of IEEE ICDE</i>, pp.220-231, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253361</ref_obj_id>
				<ref_obj_pid>253260</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R.J. Miller and Y. Yang, "Association Rules over Interval Data," <i>Proc. of the ACM SIGMOD</i>, pp.452-461, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672827</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. Ng and J. Han. "Efficient and effective clustering methods for spatial data mining," <i>Proc. of VLDB</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>233311</ref_obj_id>
				<ref_obj_pid>233269</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Srikant and R. Agrawal. "Mining Quantitative Association Rules in Large Relational Tables," <i>Proc. of ACM SIGMOD</i>, pp.1-12, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791635</ref_obj_id>
				<ref_obj_pid>791219</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[R.R. Yager, "Fuzzy Summaries in Database Mining," <i>Proc. of Artificial Intelligence for Application</i>, pp.265-269, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>853682</ref_obj_id>
				<ref_obj_pid>850950</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[W. Zhang, "Mining Fuzzy Quantitative Association Rules," <i>Proc. of IEEE ICTAI</i>, pp.99-102, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2221470</ref_obj_id>
				<ref_obj_pid>2221347</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[E. Zitzler and L. Thiele, "Multi-objective Evolutionary Algorithms: A Comparative Case Study and the Strength Pareto Approach ," <i>IEEE TEC</i>, Vol.3, pp.257-271, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>756199</ref_obj_id>
				<ref_obj_pid>648315</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. Kaya, R. Alhajj, F. Polat and A. Arslan, "Efficient Automated Mining of Fuzzy Association Rules," <i>Proc. of DEXA</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952100</article_id>
		<sort_key>565</sort_key>
		<display_label></display_label>
		<pages>565</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>89</seq_no>
		<title><![CDATA[PixelMaps]]></title>
		<subtitle><![CDATA[A New Visual Data Mining Approach for Analyzing Large Spatial Data Sets]]></subtitle>
		<page_from>565</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952100</url>
		<abstract>
			<par><![CDATA[PixelMaps are a new pixel-oriented visual data miningtechnique for large spatial datasets. They combine kernel-density-based clustering with pixel-oriented displays to emphasizeclusters while avoiding overlap in locally densepoint sets on maps. Because a full evaluation of densityfunctions is prohibitively expensive, we also propose an efficientapproximation, Fast-PixelMap, based on a synthesisof the quadtree and gridfile data structures.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Visual</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10010365</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Visual analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15023414</person_id>
				<author_profile_id><![CDATA[81100126311]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Keim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP30025088</person_id>
				<author_profile_id><![CDATA[81100148704]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Panse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40029143</person_id>
				<author_profile_id><![CDATA[81100622998]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sips]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43116724</person_id>
				<author_profile_id><![CDATA[81452611984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[North]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[I. Advizor Solutions. Visual insight in3d. http://www. advizorsolutions.com/, Aug 26 15:19 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[ESRI. An esri white paper: Arcview 3d analyst features, 1998. http://www.esri.com/library/ whitepapers/pdfs/3danalys.pdf, Aug 26 15:13 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076797</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Han and M. Kamber. <i>Data Mining: Concepts and Techniques</i>. Morgan Kaufmann Publishers, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Hinneburg and D. A. Keim. An efficient approach to clustering in large multimedia databases with noise. In <i>Knowledge Discovery and Data Mining</i>, pages 58-65, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. M. Homepage. Sgi mineset. http://www.sgi.com/ software/mineset.html, Aug 26 15:13 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>833498</ref_obj_id>
				<ref_obj_pid>554868</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Keim, E. Koutsofios, and S. C. North. Visual exploration of large telecommunication data sets. In <i>Proc. Workshop on User Interfaces In Data Intensive Systems (Invited Talk), Edinburgh, UK</i>, pages 12-20, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288245</ref_obj_id>
				<ref_obj_pid>288216</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. A. Keim and A. Herrmann. The gridfit algorithm: An efficient and effective approach to visualizing large amounts of spatial data. pages 181-188, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>668610</ref_obj_id>
				<ref_obj_pid>645824</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[E. Zitzler and L. Thiele. Multiobjective optimization using evolutionary algorithms - a comparative case study. parallel problem solving from nature. In <i>PPSN-V</i>, pages 292-301, September 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952074</article_id>
		<sort_key>569</sort_key>
		<display_label></display_label>
		<pages>569</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>90</seq_no>
		<title><![CDATA[Effectiveness of Information Extraction, Multi-Relational, and Semi-Supervised Learning for Predicting Functional Properties of Genes]]></title>
		<page_from>569</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952074</url>
		<abstract>
			<par><![CDATA[We focus on the problem of predicting functional propertiesof the proteins corresponding to genes in the yeastgenome. Our goal is to study the effectiveness of approachesthat utilize all data sources that are availablein this problem setting, including unlabeled and relationaldata, and abstracts of research papers. We study transductionand co-training for using unlabeled data. We investigatea propositionalization approach which uses relationalgene interaction data. We study the benefit of informationextraction for utilizing a collection of scientific abstracts.The studied tasks are KDD Cup tasks of 2001 and 2002.The solutions which we describe achieved the highest scorefor task 2 in 2001, the fourth rank for task 3 in 2001, thehighest score for one of the two subtasks and the third placefor the overall task 2 in 2002.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Scientific databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010364</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Scientific visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P345452</person_id>
				<author_profile_id><![CDATA[81100564058]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark-A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Krogel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37024781</person_id>
				<author_profile_id><![CDATA[81100180901]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tobias]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scheffer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>279962</ref_obj_id>
				<ref_obj_pid>279943</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. In <i>Proceedings of the Workshop on Computational Learning Theory</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1746434</ref_obj_id>
				<ref_obj_pid>1746432</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Bradley. The use of the area under the ROC curve in the evaluation of machine learning algorithms. <i>Pattern Recognition</i>, 30(7):1145-1159, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507523</ref_obj_id>
				<ref_obj_pid>507515</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Cheng, C. Hatzis, H. Hayashi, M.-A. Krogel, S. Morishita, D. Page, and J. Sese. KDD Cup 2001 Report. <i>SIGKDD Explorations</i>, 3(2):47-64, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Craven. The 2002 KDD Cup competition results for gene regulation prediction. <i>SIGKDD Explorations</i>, 4(2), 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[K. Fukuda, T. Tsunoda, A. Tamura, and T. Takagi. Towards information extraction: Identifying protein names from biological papers. In <i>Proceedings of the Pacific Symposium on Biocomputing</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657646</ref_obj_id>
				<ref_obj_pid>645528</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. Transductive inference for text classification using support vector machines. In <i>Proceedings of the International Conference on Machine Learning</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>567236</ref_obj_id>
				<ref_obj_pid>567222</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Kramer, N. Lavra, and P. A. Flach. Propositionalization Approaches to Relational Data Mining. In <i>Relational Data Mining</i>. Springer, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952074</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M.-A. Krogel and T. Scheffer. Effectiveness of information extraction, multi-relational and multi-view learning for predicting gene deletion experiments. In <i>BIOKDD</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>742951</ref_obj_id>
				<ref_obj_pid>648001</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M.-A. Krogel and S. Wrobel. Transformation-Based Learning Using Multirelational Aggregation. In <i>Proceedings of the Eleventh International Conference on Inductive Logic Programming (ILP)</i>. Springer, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Leek. Information extraction using hidden Markov models. Master's thesis, UCSD, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952107</article_id>
		<sort_key>573</sort_key>
		<display_label></display_label>
		<pages>573</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>91</seq_no>
		<title><![CDATA[Tractable Group Detection on Large Link Data Sets]]></title>
		<page_from>573</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952107</url>
		<abstract>
			<par><![CDATA[Discovering underlying structure from co-occurrencedata is an important task in a variety of fields, including:insurance, intelligence, criminal investigation, epidemiology,human resources, and marketing.Previously Kubicaet. al. presented the group detection algorithm (GDA) - analgorithm for finding underlying groupings of entities fromco-occurrence data.This algorithm is based on a probabilisticgenerative model and produces coherent groups thatare consistent with prior knowledge.Unfortunately, the optimizationused in GDA is slow, potentially making it infeasiblefor many large data sets.To this end, we present k-groups - an algorithm that uses an approach similar tothat of k-means to significantly acclerate the discovery ofgroups while retaining GDA's probabilistic model.We comparethe performance of GDA and k-groups on a variety ofdata, showing that k-groups' sacrifice in solution quality issignificantly offset by its increase in speed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Concurrency</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003753.10003761</concept_id>
				<concept_desc>CCS->Theory of computation->Models of computation->Concurrency</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10011777</concept_id>
				<concept_desc>CCS->Computing methodologies->Concurrent computing methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P467939</person_id>
				<author_profile_id><![CDATA[81100580238]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jeremy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kubica]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39024558</person_id>
				<author_profile_id><![CDATA[81100042782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moore]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14064299</person_id>
				<author_profile_id><![CDATA[81100155456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jeff]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schneider]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>944937</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. <i>Journal of Machine Learning Research</i>, 3, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Gersho and R. M. Gray. <i>Vector Quantization and Signal Compression</i>. Communications and Information Theory. Kluwer Academic Publishers, Norwell, MA, USA, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>351745</ref_obj_id>
				<ref_obj_pid>351743</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Guha, R. Rastogi, and K. Shim. ROCK: A robust clustering algorithm for categorical attributes. <i>Information Systems</i>, 25(5):345-366, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Kubica, A. Moore, and J. Schneider. K-groups: Tractable group detection on large link data sets. In <i>CMU Tech. Report 03-32</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>777215</ref_obj_id>
				<ref_obj_pid>777092</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Kubica, A. Moore, J. Schneider. and Y. Yang. Stochastic link and group detection. In <i>AAAI</i>, pages 798-804. ACM Press, Jul 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347724</ref_obj_id>
				<ref_obj_pid>347709</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[K. Nigam, A. K. McCallum, S. Thrun, and T. M. Mitchell. Text classification from labeled and unlabeled documents using EM. <i>Machine Learning</i>, 39 (2/3): 103-134, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246405</ref_obj_id>
				<ref_obj_pid>1246398</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[N. Ueda, R. Nakano, Z. Ghahramani, and G. E. Hinton. SMEM algorithm for mixture models. <i>Neural Computation</i>, 12(9):2109-2128, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952092</article_id>
		<sort_key>577</sort_key>
		<display_label></display_label>
		<pages>577</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>92</seq_no>
		<title><![CDATA[Tree-structured Partitioning Based on Splitting Histograms of Distances]]></title>
		<page_from>577</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952092</url>
		<abstract>
			<par><![CDATA[We propose a novel clustering algorithm that is similar in spiritto classification trees. The data is recursively split using a criterionthat applies a discrete curve evolution method to the histogramof distances. The algorithm can be depicted throughtree diagrams with triple splits. Leaf nodes represent eitherclusters or sets of observations that can not yet be clearly assignedto a cluster. After constructing the tree, unclassified datapoints are mapped to their closest clusters. The algorithm hasseveral advantages. First, it deals effectively with observationsthat can not be unambiguously assigned to a cluster by allowinga "margin of error". Second, it automatically determinesthe number of clusters; apart from the margin of error the useronly needs to specify the minimal cluster size but not the numberof clusters. Third, it is linear with respect to the number ofdata points and thus suitable for very large data sets. Experimentsinvolving both simulated and real data from differentdomains show that the proposed method is effective and efficient.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15037115</person_id>
				<author_profile_id><![CDATA[81100594681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Longin]]></first_name>
				<middle_name><![CDATA[Jan]]></middle_name>
				<last_name><![CDATA[Latecki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645510</person_id>
				<author_profile_id><![CDATA[81100139081]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rajagopal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Venugopal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645442</person_id>
				<author_profile_id><![CDATA[81100299796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sobel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP27004325</person_id>
				<author_profile_id><![CDATA[81350574638]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Steve]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Horvath]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Breiman, Leo, Friedman, J.H., Olshen, R.A., and Stone, C.J. <i>Classification and Regression Tree's</i>. Wadsworth, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B.S. Everitt Cluster analysis <i>Heinemann, London</i> 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Hennig and L. J. Latecki. The choice of vantage objects for image retrieval <i>Pattern Recognition</i> 36, pp. 2187-2196, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hand, D.J. <i>Discrimination and Classification</i>. Wiley, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hand, D.J. <i>Construction and Assessment of Classification Rules</i>, Wiley, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>540298</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hartigan, J. <i>Clustering Algorithms</i>. Wiley, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[L. Kaufman and P.J. Rousseeu. <i>Finding Groups in Data</i>. Wiley, New York, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>526829</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kohonen, T. <i>Self-Organizing Maps</i>. Springer, Berlin, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[L. J. Latecki and D. de Wildt. Automatic Recognition of Unpredictable Events in Videos <i>Proc. ICPR</i>, Vol. 2, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>354193</ref_obj_id>
				<ref_obj_pid>354167</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[L. J. Latecki and R. Lakamper Shape Similarity Measure Based on Correspondence of Visual Parts <i>IEEE Trans. Pattern Analysis and Machine Intelligence (PAMI)</i> 22, pp. 1185-1190, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Bing Liu, Yiyuan Xia and Philip S. Yu. CLTree - Clustering through decision tree construction <i>IBM Research Report</i> RC21695, 20/3/2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[B. Pavel. Survey of clustering data mining techniques. <i>Accrue Software Inc</i> 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. R. Quinlan. C4.5: program for machine learning <i>Morgan Kaufmann</i> 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[W.M. Rand. Objective criteria for the evaluation of clustering methods. <i>J. of the American Statistical As</i>. 66, 846-850, 1971.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[D. T. Ross, U. Scherf, M. B. Eisen, C. M. Perou, P. Spellman, V. Iyer, S.S. Jeffrey, M. V de Rijn, M. Waltham, A. Pergamenschikov. Systematic variation in gene expression patterns in human cancer cell lines. <i>Nat Genet</i> 24, 227-234, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Classification Trees <i>Electronic Statistic Textbook, Statsoft Inc.</i> "http://www.statsoftinc.com/textbook/stathome.html"]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Classification Trees: Slide notes "http://medg.lcs.mit.edu/hamish/6872LECT/sld001.htm"]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952125</article_id>
		<sort_key>581</sort_key>
		<display_label></display_label>
		<pages>581</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>93</seq_no>
		<title><![CDATA[CoMine]]></title>
		<subtitle><![CDATA[Efficient Mining of Correlated Patterns]]></subtitle>
		<page_from>581</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952125</url>
		<abstract>
			<par><![CDATA[Association rule mining often generates a huge numberof rules, but a majority of them either are redundantor don not reflect the tue correlation relationship amongdata objects.In this paper, we re-examine this problemand show that two interesting measures, all_confidence(denoted as \alpha) and coherence (denoted as \gamma), both disclosegenuine correlation relationships and can be computedefficiently.Moreover, we propose two interestingalgorithms, CoMine(\alpha) and CoMine(\gamma), based onextensions of a pattern-growth methodology.Our performancestudy shows that the CoMine algorithms havehigh performance in comparison with their Apriori-basedcounterpart algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Relevance feedback</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003359.10003361</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results->Relevance assessment</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP309753100</person_id>
				<author_profile_id><![CDATA[81542611356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Young-Koo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP92029010</person_id>
				<author_profile_id><![CDATA[81543627856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Won-Young]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP48030560</person_id>
				<author_profile_id><![CDATA[81100430507]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Y.]]></first_name>
				<middle_name><![CDATA[Dora]]></middle_name>
				<last_name><![CDATA[Cai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95039082</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proc. VLDB</i>, Sept. 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>253327</ref_obj_id>
				<ref_obj_pid>253260</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. Brin, R. Motwani, and C. Silverstein. Beyond market basket: Generalizing association rules to correlations. In <i>Proc. SIGMOD</i>, May 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>Proc. SIGMOD</i>, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L. Kaufman and P. J. Rousseeuw. <i>Finding Groups in Data: an Introduction to Cluster Analysis</i>. John Wiley & Sons, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657859</ref_obj_id>
				<ref_obj_pid>645496</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Ma and J. L. Hellerstein. Mining mutually dependent patterns. In <i>Proc. ICDM</i>, Nov. 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335226</ref_obj_id>
				<ref_obj_pid>335168</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Morishita and J. Sese. Traversing itemset lattice with statistical metric pruning. In <i>Proc. PODS</i>, May 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642922</ref_obj_id>
				<ref_obj_pid>642913</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Omiecinski. Alternative interest measures for mining associations. <i>IEEE Trans. Knowledge and Data Engineering</i>, 15:57-69, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[H. Xiong, P.-N. Tan: and V. Kumar. Mining hyperclique patterns with confidence pruning. In <i>Tech. Report</i>, Univ. of Minnesota, Minneapolis, March 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952089</article_id>
		<sort_key>585</sort_key>
		<display_label></display_label>
		<pages>585</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>94</seq_no>
		<title><![CDATA[Ensembles of Cascading Trees]]></title>
		<page_from>585</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952089</url>
		<abstract>
			<par><![CDATA[We introduce a new method, called CS4, to constructcommittees of decision trees for classification. The methodconsiders different top-ranked features as the root nodes ofmember trees. This idea is particularly suitable for dealingwith high-dimensional bio-medical data as top-ranked featuresin this type of data usually possess similar merits forclassification. To make a decision, the committee combinesthe power of individual trees in a weighted manner. UnlikeBagging or Boosting which uses bootstrapped trainingdata, our method builds all the member trees of a committeeusing exactly the same set of training data. We have testedthese ideas on UCI data sets as well as recent bio-medicaldata sets of gene expression or proteomic profiles that areusually described by more than 10,000 features. All the experimentalresults show that our method is efficient and thatthe classification performance are superior to C4.5 familyalgorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Medical information systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010447</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health care information systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP309504600</person_id>
				<author_profile_id><![CDATA[81537800956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jinyan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95034893</person_id>
				<author_profile_id><![CDATA[81452593691]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Huiqing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>599607</ref_obj_id>
				<ref_obj_pid>599591</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Bauer and R. Kohavi. An empirical comparison of voting classification algorithms: Bagging, boosting, and variants. <i>Machine Learning</i>, 36:105-139, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging predictors. <i>Machine Learning</i>, 24:123-140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>570182</ref_obj_id>
				<ref_obj_pid>570181</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Random forest. <i>Machine Learning</i>, 45:5-32, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>350131</ref_obj_id>
				<ref_obj_pid>350128</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. G. Dietterich. An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization. <i>Machine Learning</i>, 40:139- 158, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. E. Schapire. Experiments with a new boosting algorithm. In L. Saitta, editor, <i>Machine Learning: Proceedings of the Thirteenth International Conference</i>, pages 148-156, Bari, Italy, July 1996. Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952089</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Li and H. Liu. CS4: Ensembles of cascading trees. In http://sdmc.i2r.a-star.edu.sg/jinyan, pages 1-15, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Li, H. Liu, J. R. Downing, A. E.-J. Yeoh, and L. Wong. Simple rules underlying gene expression profiles of more than six subtypes of acute lymphoblastic leukemia (ALL) patients. <i>Bioinformatics</i>, 19:71-78, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Li, H. Liu, S.-K. Ng, and L. Wong. Discovery of significant rules for classifying cancer diagnosis data. <i>Bioinformatics</i>, 19:To appear, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Li and L. Wong. Identifying good diagnostic gene groups from gene expression profiles using the concept of emerging patterns. <i>Bioinformatics</i>, 18:725-734, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. R. Quinlan. <i>C4.5: Programs for Machine Learning</i>. Morgan Kaufmann, San Mateo, CA, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[E.-J. Yeoh, M. E. Ross, S. A. Shurtleff, W. K. Williams, D. Patel, R. Mahfouz, F. G. Behm, S. C. Raimondi, M. V. Relling, A. Patel, C. Cheng, D. Campana, D. Wilkins, X. Zhou, J. Li, H. Liu, C.-H. Pui, W. E. Evans, C. Naeve, L. Wong, and J. R. Downing. Classification, subtype discovery, and prediction of outcome in pediatric acute lymphoblastic leukemia by gene expression profiling. <i>Cancer Cell</i>, 1:133-143, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952082</article_id>
		<sort_key>589</sort_key>
		<display_label></display_label>
		<pages>589</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>95</seq_no>
		<title><![CDATA[Using Discriminant Analysis for Multi-class Classification]]></title>
		<page_from>589</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952082</url>
		<abstract>
			<par><![CDATA[Discriminant analysis is known to learn discriminativefeature transformations. This paper studies its use in multi-classclassification problems. The performance is tested ona large collection of benchmark datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40027682</person_id>
				<author_profile_id><![CDATA[81100475528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37027291</person_id>
				<author_profile_id><![CDATA[81100413890]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shenghuo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43135765</person_id>
				<author_profile_id><![CDATA[81335495822]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mitsunori]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ogihara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>944737</ref_obj_id>
				<ref_obj_pid>944733</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. L. Allwein, R. E. Schapire, and Y. Singer. Reducing multiclass to binary: A unifying approach for margin classifiers. <i>JMLR</i>, 1:113-141, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz. UCI repository of machine learning databases, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622834</ref_obj_id>
				<ref_obj_pid>1622826</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. G. Dietterich and G. Bakiri. Solving multiclass learning problems via error-correcting output codes. <i>Journal of Artificial Intelligence Research</i>, 2:263-286, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>744115</ref_obj_id>
				<ref_obj_pid>648056</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Dzeroski and B. Zenko. Stacking with multiresponse model trees. In <i>Proceedings of The Third International Workshop on Multiple Classifier Systems, MCS</i>, pages 201- 211. Springer-Verlag, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>92131</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[K. Fukunaga. <i>Introduction to statistical pattern recognition</i>. Academic Press, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>302744</ref_obj_id>
				<ref_obj_pid>302528</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Hastie and R. Tibshirani. Classification by pairwise coupling. In M. I. Jordan, M. J. Kearns, and S. A. Solla, editors, <i>Advances in Neural Information Processing Systems</i>, volume 10. The MIT Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>299104</ref_obj_id>
				<ref_obj_pid>299094</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. Making large-scale support vector machine learning practical. In <i>Advances in Kernel Methods: Support Vector Machines</i>. 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>59551</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. A. Johnson and D. W. Wichern. <i>Applied Multivariate Statistical Analysis</i>. Prentice Hall, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564402</ref_obj_id>
				<ref_obj_pid>564376</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. Kawatani. Topic difference factor extraction between two document sets of its application to text categorization. In <i>SIGIR 2002</i>, pages 137-144, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956924</ref_obj_id>
				<ref_obj_pid>956863</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Li, S. Zhu, and M. Ogihara. Efficient multi-way text categorization via generalized discriminant analysis. In <i>CIKM'03</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>501951</ref_obj_id>
				<ref_obj_pid>501945</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Loog, R. Duin, and R. Haeb-Umbach. Multiclass linear dimension reduction by weighted pairwise fisher criteria. <i>IEEE Transaction on Pattern Analysis and Machine Intelligence</i>, 23(7):762-766, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>364294</ref_obj_id>
				<ref_obj_pid>364267</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[A. M. Martinez and A. C. Kak. PCA versus LDA. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 23(2):228-233, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[G. J. McLachlan. <i>Discriminant Analysis and Statistical Pattern Recognition</i>. John Wiley & Sons, Inc., 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S. Mika, G. R&#228;tsch, J. Weston, B. Sch&#246;lkopf, and K.-R. M&#252;ller. Fisher discriminant analysis with kernels. In Y.- H. Hu, J. Larsen, E. Wilson, and S. Douglas, editors, <i>Neural Networks for Signal Processing IX</i>, pages 41-48. IEEE, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>118936</ref_obj_id>
				<ref_obj_pid>118850</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[M. O. Noordewier, G. G. Towell, and J. B. Shavlik. Training knowledge-based neural networks to recognize genes. In <i>Advances in Neural Information Processing Systems</i>, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[D. Roth, M. Yang, and N. Ahuja. Learning to recognize objects. In <i>CVPR</i>, pages 724-731, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[SGI. MLC++: Datasets from UCI. http://www.sgi.com/tech/mlc/db/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>607838</ref_obj_id>
				<ref_obj_pid>607787</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[A. Shashua. On the equivalence between the support vector machine for classification and sparsified fisher's linear discriminant. <i>Neural Processing Letters</i>, 9(2):129-139, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>236271</ref_obj_id>
				<ref_obj_pid>236262</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[D. L. Swets and J. Weng. Using discriminant eigenfeatures for image retrieval. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 18(8):831-836, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[V. N. Vapnik. <i>Statistical Learning Theory</i>. Wiley, New York, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[W. Zhao, R. Chellappa, and P. Phillips. Subspace linear discriminant analysis for face recognition. Technical Report CAR-TR-914., University of Maryland, College Park, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952081</article_id>
		<sort_key>593</sort_key>
		<display_label></display_label>
		<pages>593</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>96</seq_no>
		<title><![CDATA[Interpretations of Association Rules by Granular Computing]]></title>
		<page_from>593</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952081</url>
		<abstract>
			<par><![CDATA[This paper presents interpretations for associationrules. It first introduces Pawlak's method, and thecorresponding algorithm of finding decision rules (a kindof association rules). It then uses extended random sets topresent a new algorithm of finding interesting rules. Itproves that the new algorithm is faster than Pawlak'salgorithm. The extended random sets are easily to includemore than one criterion for determining interesting rules.They also provide two measures for dealing withuncertainties in association rules.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Relevance feedback</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317.10003359.10003361</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Evaluation of retrieval results->Relevance assessment</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP77040645</person_id>
				<author_profile_id><![CDATA[81409597966]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yuefeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79026544</person_id>
				<author_profile_id><![CDATA[81414597990]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>628111</ref_obj_id>
				<ref_obj_pid>627332</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Cohen, et al., Finding interesting associations without support pruning, <i>IEEE Transactions on Knowledge and Data Engineering</i>, 2001, 13(1): 64-78.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>113136</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Kruse, E. Schwecke and J. Heinsoln, <i>Uncertainty and vagueness in knowledge based systems (Numerical Methods)</i>, Springer-Verlag, New York, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1783668</ref_obj_id>
				<ref_obj_pid>1783574</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Y. Li, Extended random sets for knowledge discovery in information system, in Proc. <i>the 9th International Conference on Rough Sets, Fuzzy Sets, Data Mining and Granular Computing</i>, China, 2003, 524-532.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Y. Lin, The lattice structure of database and mining multiple level rules, <i>Bulletin of International Rough Set Society</i>, 2002, 6(1/2): 11-16.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Liu and Y. Li, The interpretation of generalized evidence theory, <i>Chinese Journal of Computers</i>, 1997, 20(2): 158-164.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>692980</ref_obj_id>
				<ref_obj_pid>646473</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Z. Pawlak, In pursuit of patterns in data reasoning from data, the rough set way, <i>3rd International Conference on Rough Sets and Current Trends in Computing</i>, USA, 2002, 1-9.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628189</ref_obj_id>
				<ref_obj_pid>627338</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. Rastogi and K. Shim, Mining optimized association rules with categorical and numeric attributes, <i>IEEE Transactions on Knowledge and Data Engineering</i>, 2002, 14(1): 29-50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952103</article_id>
		<sort_key>597</sort_key>
		<display_label></display_label>
		<pages>597</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>97</seq_no>
		<title><![CDATA[Algorithms for Spatial Outlier Detection]]></title>
		<page_from>597</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952103</url>
		<abstract>
			<par><![CDATA[A spatial outlier is a spatially referenced object whosenon-spatial attribute values are significantly different fromthe values of its neighborhood. Identification of spatial outlierscan lead to the discovery of unexpected, interesting,and useful spatial patterns for further analysis. One drawbackof existing methods is that normal objects tend to befalsely detected as spatial outliers when their neighborhoodcontains true spatial outliers. In this paper, we proposea suite of spatial outlier detection algorithms to overcomethis disadvantage. We formulate the spatial outlier detectionproblem in a general way and design algorithms whichcan accurately detect spatial outliers. In addition, usinga real-world census data set, we demonstrate that our approachescan not only avoid detecting false spatial outliersbut also find true spatial outliers ignored by existing methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Statistical computing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Distribution functions</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003703</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Distribution functions</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003698</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Statistical graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P339915</person_id>
				<author_profile_id><![CDATA[81100053980]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chang-Tien]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45023360</person_id>
				<author_profile_id><![CDATA[81100110060]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dechang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645621</person_id>
				<author_profile_id><![CDATA[81100599385]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yufeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[V. Barnett and T. Lewis. <i>Outliers in Statistical Data</i>. John Wiley, New York, 3rd edition, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Haining. <i>Spatial Data Analysis in the Social and Environmental Sciences</i>. Cambridge University Press, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Haslett, R. Brandley, P. Craig, A. Unwin, and G. Wills. Dynamic Graphics for Exploring Spatial Data With Application to Locating Global and Local Anomalies. <i>The American Statistician</i>, 45:234-242, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Hawkins. <i>Identification of Outliers</i>. Chapman and Hall, 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>59551</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Johnson. <i>Applied Multivariate Statistical Analysis</i>. Prentice Hall, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671334</ref_obj_id>
				<ref_obj_pid>645924</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[E. Knorr and R. Ng. Algorithms for Mining Distance-Based Outliers in Large Datasets. In <i>Proc. 24th VLDB Conference</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C.-T. Lu, H. Wang, and Y. Kou. http://europa.nvc.cs.vt.edu/~ctlu/Project/MapView/index.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Luc. Exploratory Spatial Data Analysis and Geographic Information Systems. In M. Painho, editor, <i>New Tools for Spatial Analysis</i>, pages 45-54, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Luc. Local Indicators of Spatial Association: LISA. <i>Geographical Analysis</i>, 27(2):93-115, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Y. Panatier. <i>Variowin. Software For Spatial Data Analysis in 2D</i>. New York: Springer-Verlag, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>255825</ref_obj_id>
				<ref_obj_pid>255810</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[I. Ruts and P. Rousseeuw. Computing Depth Contours of Bivariate Point Clouds. In <i>Computational Statistics and Data Analysis, 23:153-168</i>, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[S. Shekhar and S. Chawla. <i>A Tour of Spatial Databases</i>. Prentice Hall, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502567</ref_obj_id>
				<ref_obj_pid>502512</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. Shekhar, C.-T. Lu, and P. Zhang. Detecting Graph-Based Spatial Outlier: Algorithms and Applications(A Summary of Results). In <i>Proc. of the Seventh ACM-SIGKDD Int'l Conference on Knowledge Discovery and Data Mining</i>, Aug 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1293955</ref_obj_id>
				<ref_obj_pid>1293951</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S. Shekhar, C.-T. Lu, and P. Zhang. Detecting Graph-Based Spatial Outlier. <i>Intelligent Data Analysis: An International Journal</i>, 6(5):451-468, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>769723</ref_obj_id>
				<ref_obj_pid>769713</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. Shekhar, C.-T. Lu, and P. Zhang. A Unified Approach to Spatial Outliers Detection. <i>GeoInformatica, An International Journal on Advances of Computer Science for Geographic Information System</i>, 7(2), June 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. Johnson and I. Kwok and R. Ng. Fast Computation of 2-Dimensional Depth Contours. In <i>Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining</i>, pages 224-228. AAAI Press, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[U.S. Census Burean, United Stated Department of Commence. http://www.census.gov/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952127</article_id>
		<sort_key>601</sort_key>
		<display_label></display_label>
		<pages>601</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>98</seq_no>
		<title><![CDATA[Learning Rules for Anomaly Detection of Hostile Network Traffic]]></title>
		<page_from>601</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952127</url>
		<abstract>
			<par><![CDATA[We introduce an algorithm called LERAD that learnsrules for finding rare events in nominal time-series datawith long range dependencies. We use LERAD to findanomalies in network packets and TCP sessions to detectnovel intrusions. We evaluated LERAD on the 1999DARPA/Lincoln Laboratory intrusion detection evaluationdata set and on traffic collected in a universitydepartmental server environment.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>G.3</cat_node>
				<descriptor>Time series analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>C.2.1</cat_node>
				<descriptor>Packet-switching networks</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>C.2.2</cat_node>
				<descriptor>TCP/IP</descriptor>
				<type>P</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003033.10003039</concept_id>
				<concept_desc>CCS->Networks->Network protocols</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003033.10003106.10011705</concept_id>
				<concept_desc>CCS->Networks->Network types->Packet-switching networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003693</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Time series analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15026744</person_id>
				<author_profile_id><![CDATA[81100230827]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Mahoney]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77044558</person_id>
				<author_profile_id><![CDATA[81408600551]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Chan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal & R. Srikant, "Fast Algorithms for Mining Association Rules", <i>Proc. 20th Intl. Conf. Very Large Data Bases</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Barbara, J. Couto, S. Jajodia, L. Popyack, & N. Wu, "ADAM: Detecting Intrusions by Data Mining", <i>Proc. IEEE Workshop on Information Assurance and Security</i>, 2001, pp. 11-16.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Hoagland, SPADE, Silicon Defense, http://www.silicondefense.com/software/spice/, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166255</ref_obj_id>
				<ref_obj_pid>166237</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[W. E. Leland, M. S. Taqqu, W. Willinger, & D. W. Wilson, "On the Self-Similar Nature of Ethernet Traffic", <i>Proc. ACM SIGComm</i>, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361124</ref_obj_id>
				<ref_obj_pid>361116</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Lippmann, J. W. Haines, D. J. Fried, J. Korba, & K. Das (2000), "The 1999 DARPA Off-Line Intrusion Detection Evaluation", <i>Computer Networks 34(4)</i>, 2000, pp. 579-595.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Mahoney. Source code for PHAD, ALAD, LERAD, NETAD, SAD, EVAL3, EVAL4, EVAL and AFIL.PL is available at http://cs.fit.edu/~mmahoney/dist/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952127</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Mahoney & P. K. Chan, "Learning Rules for Anomaly Detection of Hostile Network Traffic", Florida Tech. technical report CS-2003-16, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1267552</ref_obj_id>
				<ref_obj_pid>1267549</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[V. Paxson, "Bro: A System for Detecting Network Intruders in Real-Time", <i>Proc. 7'th USENIX Security Symposium</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>208390</ref_obj_id>
				<ref_obj_pid>208389</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[V. Paxson, S. Floyd, "The Failure of Poisson Modeling", IEEE/ACM Transactions on Networking (3), 1995, pp. 226-244.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1039864</ref_obj_id>
				<ref_obj_pid>1039834</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M. Roesch, "Snort - Lightweight Intrusion Detection for Networks", <i>Proc. USENIX Lisa</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>670720</ref_obj_id>
				<ref_obj_pid>645838</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Valdes & K. Skinner, "Adaptive, Model-based Monitoring for Cyber Attack Detection", <i>Proc. RAID</i>, 2000, pp. 80-92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952098</article_id>
		<sort_key>605</sort_key>
		<display_label></display_label>
		<pages>605</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>99</seq_no>
		<title><![CDATA[An Algorithm for the Exact Computation of the Centroid of Higher Dimensional Polyhedra and its Application to Kernel Machines]]></title>
		<page_from>605</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952098</url>
		<abstract>
			<par><![CDATA[The Support Vector Machine (SVM) solution correspondsto the centre of the largest sphere inscribed in versionspace. Alternative approaches like Bayesian PointMachines (BPM) and Analytic Centre Machines have suggestedthat the generalization performance can be furtherenhanced by considering other possible centres of versionspace like the centroid (centre of mass) or the analytic centre.We present an algorithm to compute exactly the centroidof higher dimensional polyhedra, then derive approximationalgorithms to build a new learning machine whoseperformance is comparable to BPM. We also show that forregular kernel matrices (Gaussian kernels for example), theSVM solution can be obtained by solving a linear system ofequalities.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Geometrical problems and computations</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.1</cat_node>
				<descriptor>Computations on matrices</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.1.3</cat_node>
				<descriptor>Linear systems (direct and iterative methods)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003719</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on matrices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010148.10010149.10010158</concept_id>
				<concept_desc>CCS->Computing methodologies->Symbolic and algebraic manipulation->Symbolic and algebraic algorithms->Linear algebra algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003719</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computations on matrices</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061.10010063</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures->Computational geometry</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010061</concept_id>
				<concept_desc>CCS->Theory of computation->Randomness, geometry and discrete structures</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43117499</person_id>
				<author_profile_id><![CDATA[81541162956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Frederic]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Maire]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Graepel, R. Herbrich, and C. Campbell. Bayes point machines: Estimating the bayes point in kernel space. In <i>in Proc. of IJCAI Workshop Support Vector Machines</i>, pages 23-27, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Herbrich and T. Graepel. Large scale bayes point machines. In <i>in Advances in Neural Information System Processing 13</i>, pages 528-534, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944742</ref_obj_id>
				<ref_obj_pid>944733</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Herbrich, T. Graepel, and C. Campbell. Bayes point machines. <i>Journal of Machine Learning Research, 1</i>, pages 245-279, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Lasserre. An analytical expression and an algorithm for the volume of a convex polyhedron in <i>r&#60;sup&#62;n&#60;/sup&#62;. Journal of Optimization Theory and Applications</i>, Vol 39, No 3, pages 363-377, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326688</ref_obj_id>
				<ref_obj_pid>2325778</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[K. Muller, S. Mika, G. Ratch, K. Tsuda, and B. Scholkopf. An introduction to kernel-based learning algorithmss. <i>IEEE Trans. on NN, vol 12, no 2</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Opper and D. Haussler. Generalization performance of bayes optimal classification algorithm for learning a perceptron. <i>Phys. Rev. Lett. vol. 66</i>, pages 26-77, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258062</ref_obj_id>
				<ref_obj_pid>258006</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[P. Rujn. Playing billiard in version space. <i>Neural Comput., vol. 9</i>, pages 197-238, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. Scholkopft and A. Smola. <i>Learning with Kernels</i>. The MIT Press, Cambridge, Massachusetts, London, England, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Shawe-Taylor and R. C. Williamson. A pac analysis of a bayesian estimator. Technical report, Royal Holloway, Univ. London, 1997. R Tech. Rep. NC2-TR-1997-013.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Watkin. Optimal learning with a neural network. <i>Europhys. Lett., vol. 21</i>, pages 871-877, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952090</article_id>
		<sort_key>609</sort_key>
		<display_label></display_label>
		<pages>609</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>100</seq_no>
		<title><![CDATA[Simple Estimators for Relational Bayesian Classifiers]]></title>
		<page_from>609</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952090</url>
		<abstract>
			<par><![CDATA[In this paper we present the Relational BayesianClassifier (RBC), a modification of the Simple BayesianClassifier (SBC) for relational data. There exist severalBayesian classifiers that learn predictive models ofrelational data, but each uses a different estimationtechnique for modeling heterogeneous sets of attributevalues. The effects of data characteristics on estimationhave not been explored. We consider four simpleestimation techniques and evaluate them on three real-worlddata sets. The estimator that assumes each multisetvalue is independently drawn from the same distribution(INDEPVAL) achieves the best empirical results. Weexamine bias and variance tradeoffs over a range of datasets and show that INDEPVAL's ability to model moremultiset information results in lower bias estimates andcontributes to its superior performance.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Statistical computing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003698</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Statistical graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15036288</person_id>
				<author_profile_id><![CDATA[81100563777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jennifer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Neville]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15038225</person_id>
				<author_profile_id><![CDATA[81100640362]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45023023</person_id>
				<author_profile_id><![CDATA[81335490719]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gallagher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>721421</ref_obj_id>
				<ref_obj_pid>647288</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Domingos, P. A Unified Bias-Variance Decomposition for Zero-One and Squared Loss. <i>Proceedings of the 17th National Conference on Artificial Intelligence</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274160</ref_obj_id>
				<ref_obj_pid>274158</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Domingos, P. and M. Pazzani. On the optimality of the simple Bayesian classifier under zero-one loss. <i>Machine Learning</i>, 29:103-130, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655682</ref_obj_id>
				<ref_obj_pid>645530</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Getoor, L., N. Friedman, D. Koller, and A. Pfeffer. Learning probabilistic relational models. <i>Relational Data Mining</i>, Dzeroski and Lavrac, Eds., Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kersting, K. and L. De Raedt. Basic principles of learning Bayesian logic programs. Tech Report 174, University of Freiburg, Germany, June 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Jensen, D., J. Neville and M. Hay. Avoiding bias when aggregating relational data with degree disparity. <i>Proc. of the 20th International Conf. on Machine Learning</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1765345</ref_obj_id>
				<ref_obj_pid>1765335</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Lachiche, N. and P. Flach 1BC2: a true first-order Bayesian Classifier. <i>Proceedings of the 12th International Conference on Inductive Logic Programming</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[McCallum, A. and K. Nigam. A comparison of Event Models for Naive Bayes Text Classification. In <i>AAAI-98 Workshop on Learning for Text Categorization</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1624313</ref_obj_id>
				<ref_obj_pid>1624312</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[McCallum, A., K. Nigam, J. Rennie and K. Seymore. A Machine Learning Approach to Building Domain-specific Search Engines. <i>Proceedings of the 19th International Joint Conference on Artificial Intelligence</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Neville, J., D. Jensen and B. Gallagher. Simple Estimators for Relational Bayesian Classifiers. University of Massachusetts, Technical Report 03-04.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642210</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Taskar, B., E. Segal, and D. Koller. Probabilistic Classification and Clustering in Relational Data. <i>Proceedings of the 17th Intl Joint Conference on Artificial Intelligence</i>, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952071</article_id>
		<sort_key>613</sort_key>
		<display_label></display_label>
		<pages>613</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>101</seq_no>
		<title><![CDATA[Protecting Sensitive Knowledge By Data Sanitization]]></title>
		<page_from>613</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952071</url>
		<abstract>
			<par><![CDATA[In this paper, we address the problem of protecting somesensitive knowledge in transactional databases. The challengeis on protecting actionable knowledge for strategicdecisions, but at the same time not losing the great benefitof association rule mining. To accomplish that, we introducea new, efficient one-scan algorithm that meets privacyprotection and accuracy in association rule mining, withoutputting at risk the effectiveness of the data mining per se.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Security, integrity, and protection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Transaction processing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Relational databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10002953.10002955</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database design and models->Relational database model</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003197.10010822</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Query languages->Relational database query languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003193</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Database transaction processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003018</concept_id>
				<concept_desc>CCS->Security and privacy->Database and storage security</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011735</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Theory of database privacy and security</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645553</person_id>
				<author_profile_id><![CDATA[81100516428]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Stanley]]></first_name>
				<middle_name><![CDATA[R.  M.]]></middle_name>
				<last_name><![CDATA[Oliveira]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P525288</person_id>
				<author_profile_id><![CDATA[81100104421]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Osmar]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Za&#239;ane]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>788219</ref_obj_id>
				<ref_obj_pid>519168</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim, and V. Verykios. Disclosure Limitation of Sensitive Rules. In <i>Proc. of IEEE Knowledge and Data Engineering Workshop</i>, pages 45-52, Chicago, Illinois, November 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>731877</ref_obj_id>
				<ref_obj_pid>647597</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[E. Dasseni, V. S. Verykios, A. K. Elmagarmid, and E. Bertino. Hiding Association Rules by Using Confidence and Support. In <i>Proc. of the 4th Information Hiding Workshop</i>, pages 369- 383, Pittsburg, PA, April 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>850789</ref_obj_id>
				<ref_obj_pid>850782</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. R. M. Oliveira and O. R. Za&#239;ane. Privacy Preserving Frequent Itemset Mining. In <i>Proc. of the IEEE ICDM Workshop on Privacy, Security, and Data Mining</i>, pages 43-54, Maebashi City, Japan, December 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. R. M. Oliveira and O. R. Za&#239;ane. Algorithms for Balancing Privacy and Knowledge Discovery in Association Rule Mining. In <i>Proc. of the 7th International Database Engineering and Applications Symposium (IDEAS'03)</i>, Hong Kong, China, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. R. M. Oliveira and O. R. Za&#239;ane. An Efficient One-Scan Sanitization For Improving The Balance Between Privacy And Knowledge Discovery. Technical report, TR03-15, Computer Science Department, University of Alberta, Canada, June 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>604271</ref_obj_id>
				<ref_obj_pid>604264</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Saygin, V. S. Verykios, and C. Clifton. Using Unknowns to Prevent Discovery of Association Rules. <i>SIGMOD Record</i>, 30(4):45-54, December 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952102</article_id>
		<sort_key>617</sort_key>
		<display_label></display_label>
		<pages>617</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>102</seq_no>
		<title><![CDATA[Mining Frequent Itemsets in Distributed and Dynamic Databases]]></title>
		<page_from>617</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952102</url>
		<abstract>
			<par><![CDATA[Traditional methods for frequent itemset mining typicallyassume that data is centralized and static. Such methods imposeexcessive communication overhead when data is distributed,and they waste computational resources when datais dynamic. In this paper we present what we believe to bethe first unified approach that overcomes these assumptions.Our approach makes use of parallel and incremental techniquesto generate frequent itemsets in the presence of dataupdates without examining the entire database, and imposesminimal communication overhead when mining distributeddatabases. Further, our approach is able to generate bothlocal and global frequent itemsets. This ability permits ourapproach to identify high-contrast frequent itemsets, whichallows one to examine how the data is skewed over differentsites.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.1.0</cat_node>
				<descriptor>Parallel algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Distributed databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003195</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Parallel and distributed DBMSs</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010170</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Parallel algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010169.10010170</concept_id>
				<concept_desc>CCS->Computing methodologies->Parallel computing methodologies->Parallel algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645433</person_id>
				<author_profile_id><![CDATA[81100546102]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Otey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43134877</person_id>
				<author_profile_id><![CDATA[81502735559]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43132319</person_id>
				<author_profile_id><![CDATA[81100375834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Parthasarathy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31024020</person_id>
				<author_profile_id><![CDATA[81100030758]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Veloso]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43131522</person_id>
				<author_profile_id><![CDATA[81342504174]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Meira]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>627803</ref_obj_id>
				<ref_obj_pid>627307</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and J. Shafer. Parallel mining of association rules. In <i>IEEE Trans. on Knowledge and Data Engg.</i>, volume 8, pages 962-969, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655582</ref_obj_id>
				<ref_obj_pid>645481</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Cheung, J. Han, and et al. Maintenance of discovered associations in large databases: An incremental updating technique. In <i>Proc. of the Int'l. Conf. on Data Engineering</i>, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Cierniak, M. Zaki, and W. Li. Compile-time scheduling algorithms for a heterogeneous network of workstations. In <i>The Computer Journal</i>, volume 40, pages 356-372.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847320</ref_obj_id>
				<ref_obj_pid>846219</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[V. Ganti and J. G. et al. Demon: Mining and monitoring evolving data. In <i>Proc. of the 16th Int'l Conf. on Data Engineering</i>, pages 439-448, San Diego, USA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Lee and D. Cheung. Maintenance of discovered associations: When to update? In <i>Research Issues on Data Mining and Knowledge Discovery</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952102</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. E. Otey, A. Veloso, C. Wang, S. Parthasarathy, and W. Meira. Mining frequent itemsets in distributed and dynamic databases. In <i>OSU-CISRC-9/03-TR48</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Thomas, S. Bodagala, K. Alsabti, and S. Ranka. An efficient algorithm for the incremental updation of association rules. In <i>Proc. of the 3rd Int'l Conf. on Knowledge Discovery and Data Mining</i>, August 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[A. Veloso and W. M. J. et al. Mining frequent itemsets in evolving databases. In <i>Proc. of the Int'l Conf. on Data Mining</i>, Arlington, USA, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593453</ref_obj_id>
				<ref_obj_pid>593417</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Zaki and S. P. et al. New parallel algorithms for fast discovery of association rules. <i>Data Mining and Knowledge Discovery: An International Journal</i>, 4(1):343-373, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952106</article_id>
		<sort_key>621</sort_key>
		<display_label></display_label>
		<pages>621</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>103</seq_no>
		<title><![CDATA[Structure Search and Stability Enhancement of Bayesian Networks]]></title>
		<page_from>621</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952106</url>
		<abstract>
			<par><![CDATA[Learning Bayesian network structure from large-scale datasets, without any expert-specified ordering of variables, remainsa difficult problem. We propose systematic improvements toautomatically learn Bayesian network structure from data. (1)We propose a linear parent search method to generate candidategraph. (2) We propose a comprehensive approach to eliminatecycles using minimal likelihood loss, a short cycle first heuristic,and a cut-edge repairing. (3) We propose structure perturbationto assess the stability of the network and a stability-improvementmethod to refine the network structure. The algorithms are easyto implement and efficient for large networks. Experimental resultson two data sets show that our new approach outperformsexisting methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Network problems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Heuristic methods</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10003809.10003635.10003644</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Graph algorithms analysis->Network flows</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010206</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Heuristic function construction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10003644</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Network flows</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP36023233</person_id>
				<author_profile_id><![CDATA[81100050273]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hanchuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43116647</person_id>
				<author_profile_id><![CDATA[81100136610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ding]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>627737</ref_obj_id>
				<ref_obj_pid>627303</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Buntine, W., "A guide to the literature on learning probabilistic networks from data," <i>IEEE Trans KDE</i>, 8(2): 195-210, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>266920</ref_obj_id>
				<ref_obj_pid>266714</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cheng, J., Bell, DA, Liu, W., "Learning belief networks from data: an information theory based approach," <i>6th ACM Int Conf on Information and Knowledge Management</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Chickering, D., Geiger, D., and Heckerman, D., "Learning Bayesian Networks is NP-Hard," <i>MSR-TR-94-17</i>, Microsoft Research, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Chickering, D.M., "The WinMine toolkit," <i>MSR-TR-2002-103</i>, Microsoft Research, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2073810</ref_obj_id>
				<ref_obj_pid>2073796</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cooper, G.F., and Yoo, C., "Causal discovery from a mixture of experimental and observational data," <i>UAI-1999</i>: 116-125, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>145259</ref_obj_id>
				<ref_obj_pid>145254</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cooper, G.F., and Herskovits, E., "A Bayesian method for the induction of probabilistic networks from data," <i>Machine Learning, 9</i>: 309-347, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2073971</ref_obj_id>
				<ref_obj_pid>2073946</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Friedman, N., and Koller, D., "Being Bayesian about network structure: a Bayesian approach to structure discovery in Bayesian networks," <i>Machine Learning</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>308676</ref_obj_id>
				<ref_obj_pid>308574</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Heckerman, D., "A tutorial on learning with Bayesian networks," in M.I. Jordan (Ed.) <i>Learning in Graphical Models</i>: 301-354, MIT Press, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944735</ref_obj_id>
				<ref_obj_pid>944733</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Heckerman, D., Chickering, D.M., Meek, C., Rounthwaite, R., and Kadie, C. "Dependency networks for inference, collaborative filtering, and data visualization," <i>J. Machine Learning Research, 1</i>: 49-75, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Hughe, T.R., et al. "Functional discovery via a compendium of expression profiles," <i>Cell, 102</i>: 109-126, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hulten, G., Chickering, D.M., and Heckerman, D., "Learning Bayesian networks from dependency networks: a preliminary study," <i>AI & Statistics 2003</i>: 54-61, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>236283</ref_obj_id>
				<ref_obj_pid>236275</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Larranaga, P., Poza, M., Yurramendi, Y., Murga, R.H., and Kuijpers, C.M., "Structural learning of Bayesian networks by genetic algorithms: a performance analysis of control parameters," <i>IEEE Trans. PAMI, 18</i>: 912-926, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>52121</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pearl, J., <i>Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</i>, San Mateo, CA: Morgan Kaufmann, 1988.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Pe'er, D., Regev, A., Elidan, G., and Friedman, N., "Inferring subnetworks from perturbed expression profiles," <i>Bioinformatics, 17</i>: 215S-224S, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Peng, H.C., Herskovits E, and Davatzikos C. "Bayesian clustering methods for morphological analysis of MR images," IEEE Int'l Symp on Medical Imaging: Macro to Nano: 875-878, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Peng, H.C., and Ding, C., "An efficient algorithm for detecting modular regulatory networks using Bayesian subnets of co-regulated genes," LBNL Technical Report 53734, Aug 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952122</article_id>
		<sort_key>625</sort_key>
		<display_label></display_label>
		<pages>625</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>104</seq_no>
		<title><![CDATA[Privacy-Preserving Collaborative Filtering Using Randomized Perturbation Techniques]]></title>
		<page_from>625</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952122</url>
		<abstract>
			<par><![CDATA[Collaborative Filtering (CF) techniques are becomingincreasingly popular with the evolution of the Internet. Toconduct collaborative filtering, data from customers areneeded. However, collecting high quality data from customersis not an easy task because many customers areso concerned about their privacy that they might decide togive false information. We propose a randomized perturbation(RP) technique to protect users' privacy while stillproducing accurate recommendations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Information filtering</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Probabilistic algorithms (including Monte Carlo)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.7</cat_node>
				<descriptor>Security, integrity, and protection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.3</cat_node>
				<descriptor>Collaborative computing</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011735</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Theory of database privacy and security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003671</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003130</concept_id>
				<concept_desc>CCS->Human-centered computing->Collaborative and social computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002978.10003018</concept_id>
				<concept_desc>CCS->Security and privacy->Database and storage security</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003349</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Document filtering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003352</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Information extraction</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645352</person_id>
				<author_profile_id><![CDATA[81100183166]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Huseyin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Polat]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95031721</person_id>
				<author_profile_id><![CDATA[81451597756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wenliang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Du]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anonymizer.com: http://www.anonymizer.com.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335438</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Privacy-preserving data mining. In <i>Proceedings of the 2000 ACM SIGMOD on Management of Data</i>, pages 439-450, Dallas, TX USA, May 15-18 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2074100</ref_obj_id>
				<ref_obj_pid>2074094</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In <i>Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence</i>, pages 43-52, Madison, WI, July 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>830525</ref_obj_id>
				<ref_obj_pid>829514</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Canny. Collaborative filtering with privacy. In <i>IEEE Symposium on Security and Privacy</i>, pages 45-57, Oakland, CA, May 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564419</ref_obj_id>
				<ref_obj_pid>564376</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Canny. Collaborative filtering with privacy via factor analysis. In <i>Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval</i>, pages 238-245, Tampere, Finland, August 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312682</ref_obj_id>
				<ref_obj_pid>312624</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Herlocker, J. Konstan, A. Borchers, and J. Riedl. An algorithmic framework for performing collaborative filtering. In <i>Proceedings of the 1999 Conference on Research and Development in Information Retrieval</i>, August 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>245126</ref_obj_id>
				<ref_obj_pid>245108</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl. Grouplens: Applying collaborative filtering to usenet news. In <i>Communications of the ACM</i>, pages 77-87, March 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>290168</ref_obj_id>
				<ref_obj_pid>290163</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. K. Reiter and A. D. Rubin. Crowds: anonymity for web transaction. <i>ACM Transactions on Information and System Security</i>, 1(1):Pages 66-92, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192905</ref_obj_id>
				<ref_obj_pid>192844</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl. Grouplens: An open architecture for collaborative filtering of netnews. In <i>Proceedings of the ACM Conference on Computer Supported Cooperative Work</i>, pages 175-186, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952080</article_id>
		<sort_key>629</sort_key>
		<display_label></display_label>
		<pages>629</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>105</seq_no>
		<title><![CDATA[Semantic Role Parsing]]></title>
		<subtitle><![CDATA[Adding Semantic Structure to Unstructured Text]]></subtitle>
		<page_from>629</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952080</url>
		<abstract>
			<par><![CDATA[There is a ever-growing need to add structure in the formof semantic markup to the huge amounts of unstructured textdata now available. We present the technique of shallow semanticparsing, the process of assigning a simple WHO didWHAT to WHOM, etc., structure to sentences in text, as auseful tool in achieving this goal. We formulate the semanticparsing problem as a classification problem using SupportVector Machines. Using a hand-labeled training setand a set of features drawn from earlier work together withsome feature enhancements, we demonstrate a system thatperforms better than all other published results on shallowsemantic parsing.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Language parsing and understanding</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP79027071</person_id>
				<author_profile_id><![CDATA[81100191940]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sameer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pradhan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36023075</person_id>
				<author_profile_id><![CDATA[81100037780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kadri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hacioglu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79027478</person_id>
				<author_profile_id><![CDATA[81100632913]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wayne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ward]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77032424</person_id>
				<author_profile_id><![CDATA[81406597036]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Martin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14119401</person_id>
				<author_profile_id><![CDATA[81100330420]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jurafsky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>980860</ref_obj_id>
				<ref_obj_pid>980451</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. F. Baker, C. J. Fillmore, and J. B. Lowe. The Berkeley FrameNet project. In <i>COLING/ACL-98</i>, Montreal, 1998. ACL.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>309508</ref_obj_id>
				<ref_obj_pid>309497</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. M. Bikel, R. Schwartz, and R. M. Weischedel. An algorithm that learns what's in a name. <i>Machine Learning</i>, 34:211-231, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073029</ref_obj_id>
				<ref_obj_pid>1073012</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[E. Chaniak. Immediate-head parsing for language models. In <i>Proceedings of the 39th ACL</i>, Toulouse, France, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1119361</ref_obj_id>
				<ref_obj_pid>1119355</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Chen and O. Rambow. Use of deep linguistics features for the recognition and labeling of semantic arguments. In <i>Proceedings of the EMNLP</i>, Sapporo, Japan, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1119363</ref_obj_id>
				<ref_obj_pid>1119355</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Gildea and J. Hockenmaier. Identifying semantic roles using combinatory categorial grammar. In <i>Proceedings of the EMNLP</i>, Sapporo, Japan, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>643093</ref_obj_id>
				<ref_obj_pid>643092</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Gildea and D. Jurafsky. Automatic labeling of semantic roles. <i>Computational Linguistics</i>, 28(3):245-288, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073124</ref_obj_id>
				<ref_obj_pid>1073083</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Gildea and M. Palmer. The necessity of syntactic parsing for predicate argument recognition. In <i>Proceedings of the 40th ACL</i>, Philadelphia, PA, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[K. Hacioglu, S. Pradhan, W. Ward, J. Martin, and D. Jurafsky. Shallow semantic parsing using support vector machines. Technical Report TR-CSLR-2003-1, Center for Spoken Language Research, Boulder, Colorado, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073492</ref_obj_id>
				<ref_obj_pid>1073483</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[K. Hacioglu and W. Ward. Target word detection and semantic role chunking using support vector machines. In <i>Proceedings of the Human Language Technology Conference</i>, Edmonton, Canada, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>888741</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[T. Hofmann and J. Puzicha. Statistical models for co-occurrence data. Memo, Massachussetts Institute of Technology Artificial Intelligence Laboratory, Feb. 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[P. Kingsbury and M. Palmer. From Treebank to PropBank. In <i>Proceedings of the LREC</i>, Las Palmas, Canary Islands, Spain, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>980696</ref_obj_id>
				<ref_obj_pid>980432</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[D. Lin. Automatic retrieval and clustering of similar words. In <i>Proceedings of the COLING-ACL</i>, Montreal, Canada, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[M. Marcus, G. Kim, M. A. Marcinkiewicz, R. MacIntyre, A. Bies, M. Ferguson, K. Katz, and B. Schasberger. The penn treebank: Annotating predicate argument structure, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. Platt. Probabilities for support vector machines. In A. Smola, P. Bartlett, B. Scolkopf, and D. Schuurmans, editors, <i>Advances in Large Margin Classifiers</i>. MIT press, Cambridge, MA, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593518</ref_obj_id>
				<ref_obj_pid>593431</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[G. N. Sean Wallis. Knowledge discovery in grammatically analysed corpora. <i>Data Mining and Knowledge Discovery</i>, 5(4):305-335, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1075098</ref_obj_id>
				<ref_obj_pid>1075096</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[M. Surdeanu, S. Harabagiu, J. Williams, and P. Aarseth. Using predicate-argument structures for information extraction. In <i>Proceedings of the ACL</i>, Sapporo, Japan, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik. <i>The Nature of Statistical Learning Theory</i>. Springer-Verlag, New York, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952070</article_id>
		<sort_key>633</sort_key>
		<display_label></display_label>
		<pages>633</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>106</seq_no>
		<title><![CDATA[Mining Semantic Networks for Knowledge Discovery]]></title>
		<page_from>633</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952070</url>
		<abstract>
			<par><![CDATA[This paper addresses the problem of mining a class ofsemantic networks, called Concept Frame Graphs (CFG's),for knowledge discovery from text. This new representationis motivated by the need to capture richer text content sothat non-trivial mining tasks can be performed. We firstdefine the CFG representation and then describe a rule-basedalgorithm for constructing a CFG from text documents.Treating the CFG as a networked knowledge base,we propose new methods for text mining. On a specific taskof discovering the top companies in an area, we observe thatour approach leads to simpler content mining algorithms,once the CFG has been constructed. Moreover, exploitingthe network structure of CFG results in significant improvementsin precision and recall.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Semantic networks</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Knowledge acquisition</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010282</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning settings</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010188</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Semantic networks</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645396</person_id>
				<author_profile_id><![CDATA[81100140027]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rajaraman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15027554</person_id>
				<author_profile_id><![CDATA[81100255697]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ah-Hwee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>125311</ref_obj_id>
				<ref_obj_pid>125301</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[G. A. Carpenter, G. Grossberg, and D. B. Rosen. Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system. <i>Neural Networks</i>, 4:759-771, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Feldman and I. Dagan. Knowledge discovery in textual databases. In <i>Proceedings, KDD</i>, pages 112-117, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>318728</ref_obj_id>
				<ref_obj_pid>318723</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[M. Lesk. Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In <i>Proceedings, SIGDOC</i>, pages 24-26, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[K. Rajaraman. I2R TM corpus. URL: http://textmining.i2r.astar. edu.sg/people/kanagasa/tmcorpus, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>4569</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. F. Sowa. <i>Conceptual Structures: Information Processing in Mind and Machine</i>. Addison-Wesley, MA, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073163</ref_obj_id>
				<ref_obj_pid>1073083</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G. Zhou and J. Su. Named entity recognition using a HMM-based chunk tagger. In <i>Proceedings, ACL</i>, pages 473-480, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952123</article_id>
		<sort_key>637</sort_key>
		<display_label></display_label>
		<pages>637</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>107</seq_no>
		<title><![CDATA[Impact Studies and Sensitivity Analysis in Medical Data Mining with ROC-based Genetic Learning]]></title>
		<page_from>637</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952123</url>
		<abstract>
			<par><![CDATA[ROC curves have been used for a fair comparison of machinelearning algorithms since the late 90's. Accordingly,the area under the ROC curve (AUC) is nowadays considereda relevant learning criterion, accommodating imbalanceddata, misclassification costs and noisy data.This paper shows how a genetic algorithm-based optimizationof the AUC criterion can be exploited for impactstudies and sensitivity analysis.The approach is illustrated on the Atherosclerosis Identificationproblem, PKDD 2002 Challenge.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Heuristic methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Medical information systems</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010447</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Health care information systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010206</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Heuristic function construction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645457</person_id>
				<author_profile_id><![CDATA[81100614693]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mich&#232;le]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sebag]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645392</person_id>
				<author_profile_id><![CDATA[81453605555]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J&#233;r&#244;me]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Az&#233;]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645477</person_id>
				<author_profile_id><![CDATA[81100597224]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[No&#235;l]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lucas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>229867</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. B&#228;eck. <i>Evolutionary Algorithms in theory and practice</i>. New-York: Oxford University Press, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1746434</ref_obj_id>
				<ref_obj_pid>1746432</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Bradley. The use of the area under the ROC curve in the evaluation of machine learning algorithms. <i>Pattern Recognition</i>, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Arcing classifiers. <i>Annals of Statistics</i>, 26(3):801-845, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655987</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[P. Flach, C. Ferri and J. Hern&#225;ndez-Orallo. Learning decision trees using the area under the ROC curve. In <i>Proc. of the 19th Int. Conf. on Machine Learning</i>, pages 179-186, Morgan Kaufmann, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>300679</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. K. Card, J. D. Mackinlay, and B. Shneiderman. <i>Information Visualization: Using vision to think</i>. Morgan Kaufmann, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312220</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. Domingos. Meta-cost: A general method for making classifiers cost sensitive. In <i>Knowledge Discovery from Databases</i>, pages 155-164. Morgan Kaufmann, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. B. Fogel, E. C. Wasson, E. M. Boughton, V. W. Porto, and P. J. Angeline. Linear and neural models for classifying breast cancer. <i>IEEE Trans. Medical Imaging</i>, 17(3):485- 488, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>513543</ref_obj_id>
				<ref_obj_pid>513540</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. Hand and R. Till. A simple generalisation of the area under the ROC curve for multiple class classification problems. <i>Machine Learning</i>, 45(2):171-186, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1760367</ref_obj_id>
				<ref_obj_pid>1760335</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. Ling, J. Hunag, and H. Zhang. Auc: a better measure than accuracy in comparing learning algorithms. In <i>Proc. of 16th Canadian Conference on AI 2003</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[N. Lucas, J. Az&#233;, and M. Sebag. Atherosclerosis risk identification and visual analysis. In <i>Discovery Challenge ECML-PKDD </i>. http://lisp.vse.cz/challenge/ecmlpkdd2002/, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657469</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[F. Provost, T. Fawcett, and R. Kohavi. The case against accuracy estimation for comparing classifiers. In <i>Proc. of the 15th Int. Conf. on Machine Learning</i>, pages 445-553. Morgan Kaufmann, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. Sebag, J. Az&#233;, and N. Lucas. Roc-based evolutionary learning. Application to medical data mining. In P. Liardet et al., editors, <i>Artificial Evolution'03</i>. Springer Verlag, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657129</ref_obj_id>
				<ref_obj_pid>645526</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[R. Shapire, Y. Freund, P. Bartlett, and W. Lee. Boosting the margin: a new explanation for the effectiveness of voting methods. In <i>Proc. of the 14th Int. Conf. on Machine Learning</i>, pages 322-330. Morgan Kaufmann, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[V. N. Vapnik. <i>Statistical Learning Theory</i>. Wiley, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952079</article_id>
		<sort_key>641</sort_key>
		<display_label></display_label>
		<pages>641</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>108</seq_no>
		<title><![CDATA[K-D Decision Tree]]></title>
		<subtitle><![CDATA[An Accelerated and Memory Efficient Nearest Neighbor Classifier]]></subtitle>
		<page_from>641</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952079</url>
		<abstract>
			<par><![CDATA[Most nearest neighbor (NN) classifiers employ NN searchalgorithms for the acceleration. However, NNclassification does not always require the NN search.Based on this idea, we propose a novel algorithm namedk-d decision tree (KDDT). Since KDDT uses Voronoicondensed prototypes, it is less memory consuming thannaive NN classifiers. We have confirmed that KDDT ismuch faster than NN search based classifiers through thecomparative experiment (from 9 to 369 times faster).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645583</person_id>
				<author_profile_id><![CDATA[81542019056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tomoyuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shibata]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14119601</person_id>
				<author_profile_id><![CDATA[81100331065]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Takekazu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kato]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P284770</person_id>
				<author_profile_id><![CDATA[81100186757]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Toshikazu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wada]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B.K.B T.M. Cover and P.E. Hart: Nearest neighbor pattern classification, IEEE Transactions on Information Theory, Vol. IT-13, No. 1, pp. 21-27, (1967).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P.E. Hart: The condensed nearest-neighbor rule, IEEE Transactions on Information Theory, Vol. IT-4, No. 5, pp. 515-516, (1968).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[G. W. Gates: The Reduced Nearest Neighbor Rule, IEEE Trans. on Information Theory, Vol. IT-18, No. 3, pp. 431-433, 1972.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. L. Ritter, H. B. Woodruff, S. R. Lowry, and T. L. Isenhour: An algorithm for a selective nearest neighbor decision rule, IEEE Trans. on Information Theory, Vol. 21, pp. 665-669, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[I. Tomek: A generalization of the k-nn rule, IEEE Trans. on Systems, Man and Cybernetics, Vol. 6, pp. 121-126, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1623881</ref_obj_id>
				<ref_obj_pid>1623755</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. W. Aha and D. Kibler: Noise-Tolerant Instance-Based Learning Algorithms, Proc. of 11th IJCAI, pp. 794-799, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>104717</ref_obj_id>
				<ref_obj_pid>104713</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. W. Aha, D. Kibler and M. Albert: Instance-Based Learning Algorithms, Machine Learning, Vol. 6, pp. 37-66, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Bhattacharya, R. S. Poulsen, G. T. Toussaint: Application of Proximity Graphs to Editing Nearest Neighbor Decision Rule, International Symposium on Information Theory, Santa Monica, (1981).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[B.V. Dasarathy: Minimal consistent set (MCS) identification for optimal nearest neighbor decision systems design, IEEE Transactions on Systems, Man and Cybernetics, Vol. 24, No. 3, pp. 511-517, (1994).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[B.V. Dasarathy, J. S. Sanchez and S. Townsend: Nearest Neighbour Editing and Condensing Tools-Synergy Exploitation, Pattern Analysis & Applications, Vol. 3, pp. 19-30, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[V. N. Vapnik: The Nature of Statistical Learning Theory, Splinger, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261549</ref_obj_id>
				<ref_obj_pid>261540</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. E. Schapire: A decision-theoretic generalization of on-line learning and an application to boosting, Journal of Computer and System Sciences, Vol. 55, No. 1, pp. 119-139, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361007</ref_obj_id>
				<ref_obj_pid>361002</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. L. Bentley: Multidimensional binary search trees used for associative searching, Communications of the ACM, Vol. 18, No. 9, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>293348</ref_obj_id>
				<ref_obj_pid>293347</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[S. Arya, D. M. Mount, N. S. Netanyahu, R. Silverman, and A. Y. Wu, "An optimal algorithm for approximate nearest neighbor searching," <i>Journal of the ACM</i>, Vol. 45, pp. 891-923, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[ANN: Library for Approximate Nearest Neighbor Searching (http://www.cs.umd.edu/~mount/ANN/)]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952072</article_id>
		<sort_key>645</sort_key>
		<display_label></display_label>
		<pages>645</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>109</seq_no>
		<title><![CDATA[Mining the Web to Discover the Meanings of an Ambiguous Word]]></title>
		<page_from>645</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952072</url>
		<abstract>
			<par><![CDATA[In information retrieval and text mining, informationon word senses is usually taken from dictionaries or lexicaldatabases that have been prepared by lexicographers.In this paper we propose an automatic method for wordsense induction, i.e. for the discovery of a set of sensedescriptors to a given ambiguous word. The approach isbased on the statistics of word co-occurrence as derivedfrom web pages. The underlying assumption is that thesenses of an ambiguous word are best described by termsthat, although bearing a strong association to this word,are mutually exclusive, i.e. whose association strengthwithin the retrieved web pages is as weak as possible.Measuring association strength is based upon a novelConfidence Gain approach that relates the observed co-occurrencefrequency for two sense descriptor candidatesto an average co-occurrence frequency for pairs of arbitrarywords. The proposed approach is fully unsupervisedand takes into account the contemporary meanings ofwords, as reflected in texts from the internet. Our resultsare evaluated using a list of ambiguous words commonlyreferred to in the literature.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Textual databases</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>World Wide Web (WWW)</descriptor>
				<type>P</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003152</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15037410</person_id>
				<author_profile_id><![CDATA[81316491070]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Raz]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tamir]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP28026675</person_id>
				<author_profile_id><![CDATA[81100583257]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Reinhard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rapp]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Kilgarrif and M. Palmer, <i>International Journal of Computers and the Humanities. Special Issue on SENSEVAL</i>, 34(1- 2), 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[U. Arns, <i>Sprachstatistische Analysen lexikalischer Mehrdeutigkeiten</i>. Diplomarbeit an der Universit&#228;t-GH Paderborn, Germany, Fachbereich Psychologie, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311445</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C.D. Manning and H. Sch&#252;tze, <i>Foundations of Statistical Natural Language Processing</i>. Cambridge, MA: MIT Press, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D.B. Neill, <i>Fully Automatic Word Sense Induction by Semantic Clustering</i>. Cambridge University, Master's Thesis, M.Phil. in Computer Speech, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775138</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Pantel and D. Lin, Discovering Word Senses from Text. In: <i>Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining</i>, Edmonton, 613-619, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[K.W. Church and W.A. Gale, Poisson Mixtures. In: <i>Natural Language Engineering</i> 1, 163-190, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[R. Tamir, <i>Association Generation Using Confidence Gain over Internet Pages</i>. Manuscript of doctoral dissertation, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. Rapp, <i>Die Berechnung von Assoziationen</i>. Hildesheim: Olms, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>981684</ref_obj_id>
				<ref_obj_pid>981658</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Yarowsky, Unsupervised word sense disambiguation rivaling supervised methods. In: <i>Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics</i>, Cambridge, MA, 189-196, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D.L. Nelson, C.L. McEvoy, J.R. Walling, and J.W. Wheeler, The University of South Florida homograph norms. <i>Behavior Research Methods and Instrumentation</i>, 12, 16-37, 1980.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952093</article_id>
		<sort_key>649</sort_key>
		<display_label></display_label>
		<pages>649</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>110</seq_no>
		<title><![CDATA[A Hybrid Data-Mining Approach in Genomics and Text Structures]]></title>
		<page_from>649</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952093</url>
		<abstract>
			<par><![CDATA[We introduce a genetic sequence identifier based on ahierarchical system using fuzzy and classic (crisp) neuralnetworks. The system is based on a set of predictors andon a decision network. The prediction of the structure ofthe genes is addressed using a new method and tools,involving the sequence of distances between bases andneuro-fuzzy predictors. The method and system have beensuccessful in predicting genomic sequences and textstructures.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Heuristic methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Connectionism and neural nets</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010294</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Neural networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010206</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Heuristic function construction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P111899</person_id>
				<author_profile_id><![CDATA[81405594245]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Horia-Nicolai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Teodorescu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645426</person_id>
				<author_profile_id><![CDATA[81350591938]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lucian]]></first_name>
				<middle_name><![CDATA[Iulian]]></middle_name>
				<last_name><![CDATA[Fira]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Uberbacher, <i>Computing the Genome</i>, http://www.ornl.gov/ORNLReview/v30n3-4/genome.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. Tomida, T. Hanai, H. Honda, T. Kobayashi, "Gene Expression Analysis Using Fuzzy ART", <i>Genome Informatics</i>, 12: 245-246 (2001) 245.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A.P. Gasch, B. M. Eisen, "Exploring the conditional coregulation of yeast gene expression through fuzzy k-means clustering", <i>Genome Biol.</i> 2002; 3 (11): research0059.1- research0059.22. http://www.pubmedcentral.nih.gov/ articlerender.fcgi?tool=pubmed&pubmedid=12429058.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Hugheygif, A. Kroghgif, "Hidden Markov models for sequence analysis: extension and analysis of the basic method". <i>CABIOS</i> 12(2):95-107, 1996. Reprint: http://www.cse.ucsc.edu /research/compbio/html_format_papers/hughkrogh96/cabios.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H.N. Teodorescu, <i>The Dynamics of the Words</i>. Invited Plenary Lecture, The 11th Conference on Applied and Industrial Mathematics (CAIM 2003): 29-31 May, 2003. University of Oradea, Romania, http://caim2003.rdsor.ro/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[H.N. Teodorescu, L.I. Fira, "Predicting the Genome Bases Sequences by means of distance sequences and a Neuro-Fuzzy Predictor", <i>Fuzzy Systems & A.I. - Reports and Letters</i>, vol. 7 (2003) (to appear).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[L.I. Fira, H.N. Teodorescu, "Genome Bases Sequences Characterization by a Neuro-Fuzzy Predictor", <i>Proceedings IEEE-EMBS 2003 Conference</i>, 17-21 September, Cancun, Mexico.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M.A. Marty-Renom, A.C. Stuart, A. Fiser, R. Sanchez, F. Melo, A. Ali, "Comparative Protein Structure modeling of Genes and Genomes", <i>Annu. Rev. Biophys. Biomol. Struct.</i> 2000. 29:291-325.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>242217</ref_obj_id>
				<ref_obj_pid>242204</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. Yamakawa, H.N. Teodorescu, "Neuro-Fuzzy Systems: Hybrid configurations". In vol. M.J. Patyra, D. Mlynek (Eds.): <i>Fuzzy Logic. Implementation and applications</i>. Wiley & Teubner, 1996, pp. 267-298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E. Kononov, Visual Recurrence Analysis - version 4.2, http://home.netcom.com/~eugenek/download.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952083</article_id>
		<sort_key>653</sort_key>
		<display_label></display_label>
		<pages>653</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>111</seq_no>
		<title><![CDATA[Model Stability]]></title>
		<subtitle><![CDATA[A key factor in determining whether an algorithm produces an optimal model from a matching distribution]]></subtitle>
		<page_from>653</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952083</url>
		<abstract>
			<par><![CDATA[This paper investigates the factors leading to producingsuboptimal models when training and test class distributions(or misclassification costs) are matched. Our resultshows that model stability plays a key role in determiningwhether the algorithm produces an optimal modelfrom a matching distribution (cost). The performance differencebetween a model trained from the matching distribution(cost) and the optimal model generally increases asthe degree of model stability decreases. The practical implicationof our result is that one should only follow theconventional wisdom of using a training class distribution(cost) that matches the test class distribution (cost) to traina classifier if the learning algorithm is known to be stable.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.5</cat_node>
				<descriptor>Modeling methodologies</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010342.10010343</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis->Modeling methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43119427</person_id>
				<author_profile_id><![CDATA[81100367824]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kai]]></first_name>
				<middle_name><![CDATA[Ming]]></middle_name>
				<last_name><![CDATA[Ting]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645514</person_id>
				<author_profile_id><![CDATA[81100361645]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Regina]]></first_name>
				<middle_name><![CDATA[Jing Ying]]></middle_name>
				<last_name><![CDATA[Quek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Blake, C. & Merz, C.J. <i>UCI Repository of machine learning databases</i>. {http://www.ics.uci.edu/~mlearn/MLRepository.html}. Irvine, CA: University of California. 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658143</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Drummond C. & Holte R. Exploiting the Cost (In)sensitivity of Decision Tree Splitting Criteria. <i>Proceedings of The 17th International Conference on Machine Learning</i>. Morgan Kaufmann. San Francisco. 2000. pp. 239-246.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>373425</ref_obj_id>
				<ref_obj_pid>373423</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Provost, F. & Fawcett, T. Robust Classification for Imprecise Environments. <i>Machine Learning</i> 42, 2001. pp. 203-231.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Quinlan, J.R. <i>C4.5: Program for Machine Learning</i>. Morgan Kaufmann. 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655851</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Ting, K.M. Issues in Classifier Evaluation using Optimal Cost Curves. <i>Proceedings of The 19th International Conference on Machine Learning</i>. Morgan Kaufmann. San Francisco. 2002. pp. 642-649.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628237</ref_obj_id>
				<ref_obj_pid>627340</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Ting, K.M. An Instance-Weighting Method to Induce Cost-Sensitive Trees. <i>IEEE Transactions on Knowledge and Data Engineering</i>. Vol. 14, No. 3. 2002. pp. 659-665.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952083</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ting, K.M. & Quek, R.J.Y. Model Stability: A key factor in determining whether an algorithm produces an optimal model from a matching distribution. <i>TR-2003/3</i>. GSCIT, Monash University. http://www.gscit.monash.edu.au/~kmting/. 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Weiss, G. & Provost, F. The Effect of Class Distribution on Classifier Learning: An Empirical Study. <i>TR ML-TR-44</i>, Dept of Computer Sc., Rutgers University. 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952104</article_id>
		<sort_key>657</sort_key>
		<display_label></display_label>
		<pages>657</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>112</seq_no>
		<title><![CDATA[Enhancing Techniques for Efficient Topic Hierarchy Integration]]></title>
		<page_from>657</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952104</url>
		<abstract>
			<par><![CDATA[In this paper, we study the problem of integrating documentsfrom different sources into a comprehensive topic hierarchy.Our objective is to develop efficient techniques thatimprove the accuracy of traditional categorization methodsby incorporating categorization information providedby data sources into categorization process. Notice thatin the World-Wide Web, categorization information is oftenavailable from information sources. We present severalenhancing techniques that use categorization informationto enhance traditional methods such as naive Bayes andsupport vector machines. Experiment on collections fromOpenfind and Yam, and Google and Yahoo!, well-knownpopular web sites in Taiwan and USA, respectively, showsthat our techniques significantly improve the classificationaccuracy from, for example, 55% to 66% for Naive Bayes,and from 57% to 67% for SVM for the data set collectedfrom Yam and Openfind.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Textual databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.7.5</cat_node>
				<descriptor>Document analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010505</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Document analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39045158</person_id>
				<author_profile_id><![CDATA[81452593857]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jyh-Jong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsay]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645348</person_id>
				<author_profile_id><![CDATA[81100114591]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hsuan-Yu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645264</person_id>
				<author_profile_id><![CDATA[81100255096]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chi-Feng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645266</person_id>
				<author_profile_id><![CDATA[81100227393]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ching-Han]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>372163</ref_obj_id>
				<ref_obj_pid>371920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Rakesh Agrawal, Ramakrishnan Srikant. <i>On Integrating Catalogs</i>. Int'l World Wide Web Conference, Hong Kong, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280408</ref_obj_id>
				<ref_obj_pid>280397</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Apte, F. Damerau, S. Weiss. <i>Text mining with decision rules and decision trees</i>. Proc. of Automated Learning and Discovery, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[V. Boyapati <i>Towards a Comprehensive Topic Hierarchy for News</i>. Master Thesis, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>765533</ref_obj_id>
				<ref_obj_pid>765529</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Chakrabarti, B. Dom, R. Agrawal, P. Raghavan. <i>Scalable feature selection, classification and signature generation for organizing large text databases into hierarchical topic taxonomies</i>. VLDB'98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>649721</ref_obj_id>
				<ref_obj_pid>645326</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. Joachims. <i>Text Categorization with Support Vector Machines: Learning with Many Relevant Features</i>. ECML'98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>243277</ref_obj_id>
				<ref_obj_pid>243199</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Lewis, R. Schapire, J. Callan, R. Papka. <i>Training Algorithms for Linear Text Classifiers</i>. SIGIR'96.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657461</ref_obj_id>
				<ref_obj_pid>645527</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[A. McCallum, R. Rosenfeld, T. Mitchell, A. Ng. <i>Improving Text Classification by Shrinkage in a Hierarchy of Classes</i>. ICML'98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>541177</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Mitchell. <i>Machine Learning</i>. McGraw-Hill, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258537</ref_obj_id>
				<ref_obj_pid>258525</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[H.T. Ng, W.B. Goh, K.L. Low. <i>Feature selection, perceptron learning, and a usability case study for text categorization</i>. SIGIR'97.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347732</ref_obj_id>
				<ref_obj_pid>347709</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[R.E. Schapire, Y. Singer. <i>BoosTexter: A Boosting-based System for Text Categorization</i>. Machine Learning, 39(2/3):135- 168, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345593</ref_obj_id>
				<ref_obj_pid>345508</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[D. Susan, C. Hao. <i>Hierarchical Classification of Web Content</i>. SIGIR'00.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J.-J. Tsay, J.-D. Wang. <i>Design and Evaluation of Approaches for Automatic Chinese Text Categorization</i>, Journal of Computational Linguistics and Chinese Language Processing, Vol. 5, No. 2, pp. 43-58, August, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J.-J. Tsay, K.-J. Wu. <i>Learning Between Class Hierarchies for Text Categorization</i>. Technical Report, Dept of CSIE, National Chung Cheng University, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671360</ref_obj_id>
				<ref_obj_pid>645925</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[K. Wang, S. Zhou, C. C. Liew. <i>Building hierarchical classifier using class proximity</i>. VLDB'99.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357383</ref_obj_id>
				<ref_obj_pid>357367</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Y. Yang <i>An evaluation of statistical approaches to text categorization</i>. Journal of Information Retrieval, 1(1/2):67-88, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952113</article_id>
		<sort_key>661</sort_key>
		<display_label></display_label>
		<pages>661</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>113</seq_no>
		<title><![CDATA[Pattern Discovery based on Rule Induction and Taxonomy Generation]]></title>
		<page_from>661</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952113</url>
		<abstract>
			<par><![CDATA[One of the most important problems with rule inductionmethods is that they cannot extract rules, which plausiblyrepresent experts' decision processes. In this paper,the characteristics of experts' rules are closely examinedand a new approach to extract plausible rules is introduced,which consists of the following three procedures. First, thecharacterization of decision attributes (given classes) is extractedfrom databases and the concept hierarchy for givenclasses is calculated. Second, based on the hierarchy, rulesfor each hierarchical level are induced from data. Then, foreach given class, rules for all the hierarchical levels are integratedinto one rule.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Induction</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010297.10010298</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Logical and relational learning->Inductive logic learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP40025004</person_id>
				<author_profile_id><![CDATA[81100219997]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shusaku]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsumoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P432865</person_id>
				<author_profile_id><![CDATA[81100281744]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shoji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hirano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T. Cox and M. Cox. <i>Multidimensional Scaling</i>. Chapman & Hall/CRC, Boca Raton, 2nd edition, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1538772</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. Everitt. <i>Cluster Analysis</i>. John Wiley & Son, London, 3rd edition, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Z. Pawlak. <i>Rough Sets</i>. Kluwer Academic Publishers, Dordrecht, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Quinlan, editor. <i>C4.5 - Programs for Machine Learning</i>. Morgan Kaufmann, Palo Alto, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>574489</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. Shavlik and T. Dietterich, editors. <i>Readings in Machine Learning</i>. Morgan Kaufmann, Palo Alto, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>187235</ref_obj_id>
				<ref_obj_pid>186965</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Skowron and J. Grzymala-Busse. From rough set theory to evidence theory. In R. Yager, M. Fedrizzi, and J. Kacprzyk, editors, <i>Advances in the Dempster-Shafer Theory of Evidence</i>, pages 193-236. John Wiley & Sons, New York, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>305768</ref_obj_id>
				<ref_obj_pid>305762</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Tsumoto. Automated induction of medical expert system rules from clinical databases based on rough set theory. <i>Information Sciences</i>, 112:67-84, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Tsumoto. Extraction of experts' decision rules from clinical databases using rough set model. <i>Intelligent Data Analysis</i>, 2(3), 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. Tsumoto. Extraction of hierarchical decision rules from clinical databases using rough sets. <i>Information Sciences</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952087</article_id>
		<sort_key>665</sort_key>
		<display_label></display_label>
		<pages>665</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>114</seq_no>
		<title><![CDATA[Active Sampling for Feature Selection]]></title>
		<page_from>665</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952087</url>
		<abstract>
			<par><![CDATA[In knowledge discovery applications, where new featuresare to be added, an acquisition policy can help select thefeatures to be acquired based on their relevance and thecost of extraction. This can be posed as a feature selectionproblem where the feature values are not known in advance.We propose a technique to actively sample the featurevalues with the ultimate goal of choosing between alternativecandidate features with minimum sampling cost.Our heuristic algorithm is based on extracting candidatefeatures in a region of the instance space where the featurevalue is likely to alter our knowledge the most. An experimentalevaluation on a standard database shows that it ispossible outperform a random subsampling policy in termsof the accuracy in feature selection.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Knowledge acquisition</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Heuristic methods</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010206</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Heuristic function construction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010282</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning settings</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P266509</person_id>
				<author_profile_id><![CDATA[81100522049]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sriharsha]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Veeramachaneni]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14109645</person_id>
				<author_profile_id><![CDATA[81100296767]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Paolo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Avesani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>270626</ref_obj_id>
				<ref_obj_pid>270613</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Blum and P. Langley. Selection of Relevant Features and Examples in Machine Learning. <i>Artificial Intelligence</i>, 97(1-2):245-271, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>189489</ref_obj_id>
				<ref_obj_pid>189256</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D.A. Cohn, L. Atlas, and R.E. Ladner. Improving Generalization with Active Learning. <i>Machine Learning</i>, 15(2):201- 221, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[G. Hughes. Sampling for Decision Making in Crop Loss Assessment and Pest Management: Introduction. In <i>Symposium on Sampling for Decision Making in Crop Loss Assessment and Pest Management</i>, pages 1080-1083, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>944968</ref_obj_id>
				<ref_obj_pid>944919</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[I. Guyon and A. Elisseefi. An Introduction to Variable and Feature Selection. <i>Journal of Machine Learning Research</i>, 3:1157-1182, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J.P. Nyrop, M.R. Binns, and W. der Werf. Sampling for IPM Decision Making: Where Should We Invest Time and Resources. In <i>Symposium on Sampling for Decision Making in Crop Loss Assessment and Pest Management</i>, pages 1104- 1111, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[L.V. Madden and G. Hughes. Sampling for Plant Disease Incidence. In <i>Symposium on Sampling for Decision Making in Crop Loss Assessment and Pest Management</i>, pages 1088- 1103, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1642216</ref_obj_id>
				<ref_obj_pid>1642194</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Saar-Tsechansky and F. Provost. Active Sampling for Class Probability Estimation and Ranking. In <i>Proc. 7th International Joint Conference on Artificial Intelligence</i>, pages 911-920, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>312220</ref_obj_id>
				<ref_obj_pid>312129</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[P. Domingos. MetaCost: A General Method for Making Classifiers Cost-Sensitive. In <i>Knowledge Discovery and Data Mining</i>, pages 155-164, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1622838</ref_obj_id>
				<ref_obj_pid>1622826</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[P.D. Turney. Cost-sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Induction Algorithm. <i>Journal of Artificial Intelligence Research</i>, 2:369- 409, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>655646</ref_obj_id>
				<ref_obj_pid>645530</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[N. Roy and A. McCallum. Toward optimal active learning through sampling estimation of error reduction. In <i>Proc. 18th International Conf. on Machine Learning</i>, pages 441- 448. Morgan Kaufmann, San Francisco, CA, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>658272</ref_obj_id>
				<ref_obj_pid>645529</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. Tong and D. Koller. Support vector machine active learning with applications to text classification. In <i>Proceedings of the International Conference on Machine Learning</i>, pages 999-1006, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844719</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Z. Zheng and B. Padmanabhan. On active learning for data acquisition. In <i>Proceedings of the International Conference on Datamining</i>, pages 562-570, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952111</article_id>
		<sort_key>669</sort_key>
		<display_label></display_label>
		<pages>669</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>115</seq_no>
		<title><![CDATA[Combining the web content and usage mining to understand the visitor behavior in a web site]]></title>
		<page_from>669</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952111</url>
		<abstract>
			<par><![CDATA[A web site is a semi structured collection of differentkinds of data, whose motivation is show relevant informationto visitor and by this way capture her/his attention.Understand the specifics preferences that define the visitorbehavior in a web site, is a complex task. An approximationis suppose that it depend the content, navigationsequence and time spent in each page visited. These variablescan be extracted from the web log files and the website itself, using web usage and content mining respectively.Combining the describe variables, a similarity measureamong visitor sessions is introduced and used in a clusteringalgorithm, which identifies groups of similar sessions,allowing the analysis of visitors behavior.In order to prove the methodology's effectiveness, it wasapplied in a certain web site, showing the benefits of thedescribed approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Prototyping</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>World Wide Web (WWW)</descriptor>
				<type>P</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003152</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003123.10010860.10011694</concept_id>
				<concept_desc>CCS->Human-centered computing->Interaction design->Interaction design process and methods->Interface design prototyping</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645386</person_id>
				<author_profile_id><![CDATA[81100191715]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Juan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vel&#225;squez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36030605</person_id>
				<author_profile_id><![CDATA[81100610717]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hiroshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yasuda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P279448</person_id>
				<author_profile_id><![CDATA[81100590293]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Terumasa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aoki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>553876</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Baeza-Yates, B. Ribeiro-Neto, Modern Information Retrieval, chapter 2. <i>Addison-Wesley</i> 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>711414</ref_obj_id>
				<ref_obj_pid>646996</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[B. Berendt, A. Hotho and G. Stumme, Towards Semantic Web Mining, <i>Procs. in First Int. Semantic Web Conf.</i>, pages 264-278, Sardinia, Italy, June 9-12, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Cooley, B. Mobasher, J. Srivastava. Data Preparation for Mining World Wide Web Browsing Patterns. <i>Journal of Knowlegde and Information Systems</i> Vol. 1, pages 5-32, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[V.I. Levenshtein, Binary codes capable of correcting deletions, insertions and reversals, <i>Sov. Phys. Dokl.</i>, pages 705-710, 1966.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>680169</ref_obj_id>
				<ref_obj_pid>646160</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[B. Mobasher, T. Luo, Y. Sung, and J. Zhu, Integrating Web Usage and Content Mining for More Effective Personalization, <i>In Procs. of the Int. Conf. on E-Commerce and Web Technologies</i>, September, Greenwich, UK, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T.A. Runkler and J.C. Bezdek, Web mining with Relational Clustering December, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Vel&#225;squez, H. Yasuda, T. Aoki and Richard Weber, Acquiring Knowledge About User's Preferences in a Web Site, <i>In Procs. of the IEEE Int. Conf. on Information Technology: Research and Education</i>, pages 375-379, Newark, New Jersey, USA, August 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Vel&#225;squez, H. Yasuda, T. Aoki and Richard Weber, Using Self Organizing Feature Maps to Acquire Knowledge About Visitor Behavior in a Web Site, <i>In Procs. of the Knowledge-Based Intelligent Information & Engineering Systems</i>, to appear, University of Oxford, UK, September, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952086</article_id>
		<sort_key>673</sort_key>
		<display_label></display_label>
		<pages>673</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>116</seq_no>
		<title><![CDATA[Class Decomposition via Clustering]]></title>
		<subtitle><![CDATA[A New Framework for Low-Variance Classifiers]]></subtitle>
		<page_from>673</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952086</url>
		<abstract>
			<par><![CDATA[We propose a pre-processing step to classification thatapplies a clustering algorithm to the training set to discoverlocal patterns in the attribute or input space. Wedemonstrate how this knowledge can be exploited to enhancethe predictive accuracy of simple classifiers. Our focusis mainly on classifiers characterized by high bias butlow variance (e.g., linear classifiers); these classifiers experiencedifficulty in delineating class boundaries over theinput space when a class distributes in complex ways. Decomposingclasses into clusters makes the new class distributioneasier to approximate and provides a viable way toreduce bias while limiting the growth in variance. Experimentalresults on real-world domains show an advantagein predictive accuracy when clustering is used as a pre-processingstep to classification.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP42051180</person_id>
				<author_profile_id><![CDATA[81339533935]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ricardo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vilalta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645467</person_id>
				<author_profile_id><![CDATA[81342487619]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Murali-Krishna]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Achari]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43126261</person_id>
				<author_profile_id><![CDATA[81339498116]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Christoph]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Eick]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. Blake and M. C. J. UCI, Repository of machine learning databases. <i>University of California, Irvine, Dept. of Information and Computer Sciences</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Breiman. Bagging predictors. <i>Machine Learning Journal</i>, 24:123-140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Y. Freund and R. E. Schapire. Experiments with a new boosting algorithm. pages 148-156, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>148062</ref_obj_id>
				<ref_obj_pid>148061</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Geman, E. Bienenstock, and R. Doursat. Neural networks and the bias/variance dilemma. <i>Neural Computation</i>, pages 1-58, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. Hastie, R. Tibshirani, and J. Friedman. <i>The elements of statistical learning; data mining, inference, and prediction</i>. Springer-Verlag, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. Vilalta and I. Rish. A decomposition of classes via clustering to explain and improve naive bayes. <i>14th European Conference on Machine Learning</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952075</article_id>
		<sort_key>677</sort_key>
		<display_label></display_label>
		<pages>677</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>117</seq_no>
		<title><![CDATA[Bootstrapping Rule Induction]]></title>
		<page_from>677</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952075</url>
		<abstract>
			<par><![CDATA[Most rule learning systems posit hard decision boundariesfor continuous attributes and point estimates of ruleaccuracy, with no measures of variance, which may seemarbitrary to a domain expert. These hard boundaries/pointschange with small perturbations to the training data. Moreover,rule induction typically produces a large number ofrules that must be filtered and interpreted by an analyst.This paper describes a method of combining rules over multiplebootstrap replications of rule induction so as to reducethe total number of rules presented to an analyst and to providemeasures of variance to continuous attribute decisionboundaries and accuracy-point estimates. The method isillustrated with perioperative data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Induction</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Heuristic methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Rule-based databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010206</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Heuristic function construction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003201</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Triggers and rules</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010297.10010298</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Logical and relational learning->Inductive logic learning</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645411</person_id>
				<author_profile_id><![CDATA[81100186335]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lemuel]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Waitman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39048209</person_id>
				<author_profile_id><![CDATA[81100550958]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Douglas]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Fisher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39031851</person_id>
				<author_profile_id><![CDATA[81339509816]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[King]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Van Den Eijkel, G.C. 1999. Rule Induction. In Intelligent Data Analysis: An Introduction. Springer-Verlag, Berlin. pp. 195-216.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Forrest, J.B., Rehder, K., Cahalan, M.K., and Goldsmith, C.H. 1992. Multicenter Study of General Anesthesia III. Predictors of Severe Perioperative Adverse Outcomes. Anesthesiology 76: 3-15.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Riddle, P., Segal, R., and Etzioni, O. 1994. Representation Design and Brute-force Induction in a Boeing Manufacturing Domain. Applied Artificial Intelligence 8: 125-147.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288812</ref_obj_id>
				<ref_obj_pid>288808</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kubat, M., Holte, R.C., and Matwin, S. 1998. Machine learning for the detection of oil spills in satellite radar images. Machine Learning 30: 195-215.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>287565</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Segal, R.B. Machine learning as massive search. 1997. University of Washington. Ref Type: Thesis/Dissertation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Good, I. J. The Estimation of Probabilities: An Essay on Modern Bayesian Methods. Research monograph 30. MIT Press, 1965.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Efron, B. and Tibshirani, R.J. 1993. An Introduction to the Bootstrap. Chapman and Hall, New York, NY.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>231989</ref_obj_id>
				<ref_obj_pid>231986</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Breiman, L. 1996. Bagging Predictors. Machine Learning 24: 123-140.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199346</ref_obj_id>
				<ref_obj_pid>199288</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Segal, R. and Etzioni, O. 1994. Learning Decision Lists Using Homogeneous Rules. In AAAI-94.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Waitman, L. R., Fisher, D., & King, P. (2001) http://www.vuse.vanderbilt.edu/dfisher/waitman2001.doc]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952119</article_id>
		<sort_key>681</sort_key>
		<display_label></display_label>
		<pages>681</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>118</seq_no>
		<title><![CDATA[Center-Based Indexing for Nearest Neighbors Search]]></title>
		<page_from>681</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952119</url>
		<abstract>
			<par><![CDATA[The paper addresses the problem of indexing data forthe k nearest neighbors (k-nn) search. It presents a tree-basedtop-down indexing method that uses an iterative k-meansalgorithm for tree node splitting and combines threedifferent search pruning criteria from BST, GHT and GNATinto one. The experiments show that the presented indexingtree accelerates the k-nn searching up to several thousandstimes in case of large data sets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.1</cat_node>
				<descriptor>Indexing methods</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>G.2.2</cat_node>
				<descriptor>Graph algorithms</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003633.10010917</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Graph theory->Graph algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003365.10003366</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Search engine architectures and scalability->Search engine indexing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003318</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Document representation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P21497</person_id>
				<author_profile_id><![CDATA[81100061548]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Arkadiusz]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wojna]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>361007</ref_obj_id>
				<ref_obj_pid>361002</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. L. Bentley. Multidimensional binary search trees used for associative searching. <i>Communications of the ACM</i>, 18(9):509-517, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. L. Blake and C. J. Merz. UCI repository of machine learning databases. http://www.ics.uci.edu/~mlearn/MLRepository.html, Department of Information and Computer Science, University of California, Irvine, CA, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673006</ref_obj_id>
				<ref_obj_pid>645921</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. Brin. Near neighbor search in large metric spaces. In <i>Proceedings of the Twenty First International Conference on Very Large Databases</i>, pages 574-584, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Finkel and J. Bentley. Quad-trees: a data structure for retrieval and composite keys. <i>ACTA Informatica</i>, 4(1):1-9, 1974.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1311121</ref_obj_id>
				<ref_obj_pid>1311063</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[K. Fukunaga and P. M. Narendra. A branch and bound algorithm for computing k-nearest neighbors. <i>IEEE Transactions on Computers</i>, 24(7):750-753, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>280279</ref_obj_id>
				<ref_obj_pid>280277</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[V. Gaede and O. Gunther. Multidimensional access methods. <i>ACM Computing Surveys</i>, 30(2):170-231, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1220718</ref_obj_id>
				<ref_obj_pid>1220715</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[G. G&#243;ra and A. G. Wojna. RIONA: a new classification system combining rule induction and instance-based learning. <i>Fundamenta Informaticae</i>, 51(4):369-390, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1313699</ref_obj_id>
				<ref_obj_pid>1313332</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[I. Kalantari and G. McDonald. A data structure and an algorithm for the nearest point problem. <i>IEEE Transactions on Software Engineering</i>, 9(5):631-634, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S. M. Savaresi and D. L. Boley. On the performance of bisecting K-means and PDDP. In <i>Proceedings of the First SIAM International Conference on Data Mining</i>, pages 1- 14, Chicago, USA, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Uhlmann. Satisfying general proximity/similarity queries with metric trees. <i>Information Processing Letters</i>, 40(4):175-179, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952108</article_id>
		<sort_key>685</sort_key>
		<display_label></display_label>
		<pages>685</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>119</seq_no>
		<title><![CDATA[Postprocessing Decision Trees to Extract Actionable Knowledge]]></title>
		<page_from>685</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952108</url>
		<abstract>
			<par><![CDATA[Most data mining algorithms and tools stop at discoveredcustomer models, producing distribution informationon customer profiles. Such techniques, when applied to industrialproblems such as customer relationship management(CRM), are useful in pointing out customers who arelikely attritors and customers who are loyal, but they requirehuman experts to postprocess the mined information manually.Most of the postprocessing techniques have been limitedto producing visualization results and interestingnessranking, but they do not directly suggest actions that wouldlead to an increase the objective function such as profit. Inthis paper, we present a novel algorithm that suggest actionsto change customers from an undesired status (suchas attritors) to a desired one (such as loyal) while maximizingobjective function: the expected net profit. We developthese algorithms under resource constraints that areabound in reality. The contribution of the work is in takingthe output from an existing mature technique (decisiontrees, for example), and producing novel, actionable knowledgethrough automatic postprocessing.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.1</cat_node>
				<descriptor>Business</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Information filtering</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010406</concept_id>
				<concept_desc>CCS->Applied computing->Enterprise computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010406.10010412</concept_id>
				<concept_desc>CCS->Applied computing->Enterprise computing->Business process management</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003349</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Document filtering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003352</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Information extraction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP77037737</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15031571</person_id>
				<author_profile_id><![CDATA[81100408980]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030222</person_id>
				<author_profile_id><![CDATA[81100159332]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[X.]]></middle_name>
				<last_name><![CDATA[Ling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P560445</person_id>
				<author_profile_id><![CDATA[81414595580]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Tielin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In <i>Proceedings of 20th International Conference on Very Large Data Bases(VLDB'94)</i>, pages 487-499. Morgan Kaufmann, September 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>265442</ref_obj_id>
				<ref_obj_pid>265394</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Keim and H. Kriegel. Issues in visualizing large databases, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627798</ref_obj_id>
				<ref_obj_pid>627307</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. A. Keim and H.-P. Kriegel. Visualization techniques for mining large databases: A comparison. <i>Transactions on Knowledge and Data Engineering, Special Issue on Data Mining</i>, 8(6):923-938, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. X. Ling and C. Li. Data mining for direct marketing - specific problems and solutions. In <i>Proceedings of Fourth International Conference on Knowledge Discovery and Data Mining (KDD-98)</i>, pages 73-79. 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>628025</ref_obj_id>
				<ref_obj_pid>627325</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[B. Liu, W. Hsu, L.-F. Mun, and H.-Y. Lee. Finding interesting patterns using user expectations. <i>Knowledge and Data Engineering</i>, 11(6):817-832, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>240463</ref_obj_id>
				<ref_obj_pid>240455</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. S. Usama Fayyad, Gregory Piatetsky-Shapiro. From data mining to knowledge discovery in databases. <i>AI Magazine</i>, 17(11), Fall 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952124</article_id>
		<sort_key>689</sort_key>
		<display_label></display_label>
		<pages>689</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>120</seq_no>
		<title><![CDATA[Frequent-Pattern based Iterative Projected Clustering]]></title>
		<page_from>689</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952124</url>
		<abstract>
			<par><![CDATA[Irrelevant attributes add noise to high dimensional clustersand make traditional clustering techniques inappropriate.Projected clustering algorithms have been proposed to findthe clusters in hidden subspaces. We realize the analogy betweenmining frequent itemsets and discovering the relevantsubspace for a given cluster. We propose a methodology forfinding projected clusters by mining frequent itemsets andpresent heuristics that improve its quality. Our techniquesare evaluated with synthetic and real data; they are scalableand discover projected clusters accurately.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Pattern analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645438</person_id>
				<author_profile_id><![CDATA[81100069377]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Man]]></first_name>
				<middle_name><![CDATA[Lung]]></middle_name>
				<last_name><![CDATA[Yiu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P209328</person_id>
				<author_profile_id><![CDATA[81100130062]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nikos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mamoulis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>304188</ref_obj_id>
				<ref_obj_pid>304182</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal, J. L. Wolf, P. S. Yu, C. Procopiuc, and J. S. Park. Fast algorithms for projected clustering. In <i>ACM SIGMOD</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335383</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. C. Aggarwal and P. S. Yu. Finding generalized projected clusters in high dimensional spaces. In <i>ACM SIGMOD</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>276314</ref_obj_id>
				<ref_obj_pid>276304</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, J. Gehrke, D. Gunopulos, and P. Raghavan. Automatic subspace clustering of high dimensional data for data mining applications. In <i>ACM SIGMOD</i>, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In <i>VLDB</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>656271</ref_obj_id>
				<ref_obj_pid>645503</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[K. S. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft. When is "nearest neighbor" meaningful? In <i>ICDT</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[C. Blake and C. Merz. UCI repository of machine learning databases, www.ics.uci.edu/~mlearn/mlrepository.html, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223812</ref_obj_id>
				<ref_obj_pid>223784</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Faloutsos and K.-I. Lin. Fastmap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets. In <i>ACM SIGMOD</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>351745</ref_obj_id>
				<ref_obj_pid>351743</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Guha, R. Rastogi, and K. Shim. Rock: A robust clustering algorithm for categorical attributes. In <i>IEEE ICDE</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>335372</ref_obj_id>
				<ref_obj_pid>342009</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In <i>ACM SIGMOD</i>, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>564739</ref_obj_id>
				<ref_obj_pid>564691</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. M. Procopiuc, M. Jones, P. K. Agarwal, and T. M. Murali. A monte carlo algorithm for fast projective clustering. In <i>ACM SIGMOD</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952085</article_id>
		<sort_key>693</sort_key>
		<display_label></display_label>
		<pages>693</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>121</seq_no>
		<title><![CDATA[General MC]]></title>
		<subtitle><![CDATA[Estimating Boundary of Positive Class from Small Positive Data]]></subtitle>
		<page_from>693</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952085</url>
		<abstract>
			<par><![CDATA[Single-Class Classification (SCC) seeks to distinguishone class of data from the universal set of multiple classes.We propose a SCC method called General MC that estimatesan accurate classification boundary of positive classfrom small positive data using the distribution of unlabeleddata. Our theoretical and empirical analyses show that,as long as the distribution of unlabeled data is not highlyskewed in the feature space, General MC significantly outperformsother recent SCC methods when the positive dataset is highly under-sampled.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Distribution functions</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003703</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Distribution functions</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP45026040</person_id>
				<author_profile_id><![CDATA[81452596114]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hwanjo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>656022</ref_obj_id>
				<ref_obj_pid>645531</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Liu, W. S. Lee, P. S. Yu, and X. Li. Partially supervised classification of text documents. In <i>Proc. 19th Int. Conf. Machine Learning (ICML'02)</i>, pages 387-394, Sydney, Australia, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1630743</ref_obj_id>
				<ref_obj_pid>1630659</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H. Yu. SVMC: Single-class classification with support vector machines. In <i>Proc. Int. Joint Conf. on Articial Intelligence (IJCAI-03)</i>, Acapulco, Maxico, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>775083</ref_obj_id>
				<ref_obj_pid>775047</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[H. Yu, J. Han, and K. C. Chang. PEBL: Positive-example based learning for Web page classification using SVM. In <i>Proc. 8th Int. Conf. Knowledge Discovery and Data Mining (KDD'02)</i>, pages 239-248, Edmonton, Canada, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>956406</ref_obj_id>
				<ref_obj_pid>956382</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[H. Yu, J. Han, and K. C.-C. Chang. PEBL: Web page classification without negative examples. <i>to appear IEEE Transactions on Knowledge and Data Engineering</i>, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952128</article_id>
		<sort_key>697</sort_key>
		<display_label></display_label>
		<pages>697</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>122</seq_no>
		<title><![CDATA[Clustering Item Data Sets with Association-Taxonomy Similarity]]></title>
		<page_from>697</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952128</url>
		<abstract>
			<par><![CDATA[We explore in this paper the efficient clustering of itemdata. Different from those of the traditional data, the featuresof item data are known to be of high dimensionalityand sparsity. In view of the features of item data, we devisein this paper a novel measurement, called the association-taxonomysimilarity, and utilize this measurement to performthe clustering. With this association-taxonomy similaritymeasurement, we develop an efficient clustering algorithm,called algorithm AT (standing for Association-Taxonomy),for item data. Two validation indexes basedon association and taxonomy properties are also devised toassess the quality of clustering for item data. As validatedby the real dataset, it is shown by our experimental resultsthat algorithm AT devised in this paper significantly outperformsthe prior works in the clustering quality as measuredby the validation indexes, indicating the usefulness ofassociation-taxonomy similarity in item data clustering.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.3</cat_node>
				<descriptor>Similarity measures</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Clustering</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003356</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Clustering and classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351.10003444</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining->Clustering</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010260.10003697</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Unsupervised learning->Cluster analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Measurement</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P449048</person_id>
				<author_profile_id><![CDATA[81100541223]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ching-Huang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15038174</person_id>
				<author_profile_id><![CDATA[81100637068]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kun-Ta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chuang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP94030680</person_id>
				<author_profile_id><![CDATA[81450594725]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ming-Syan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules in Large Databases. <i>Proceedings of the 20th International Conference on Very Large Data Bases</i>, pages 478-499, September 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>847264</ref_obj_id>
				<ref_obj_pid>846218</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[S. Guha, R. Rastogi, and K. Shim. ROCK: A Robust Clustering Algorithm for Categorical Attributes. <i>Proceedings of the 15th International Conference on Data Engineering</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593469</ref_obj_id>
				<ref_obj_pid>593420</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Z. Huang. Extensions to the k-Means Algorithm for Clustering Large Data Sets with Categorical Values. <i>Data Mining and Knowledge Discovery</i>, 2(3):283-304, September 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>320054</ref_obj_id>
				<ref_obj_pid>319950</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[K. Wang, C. Xu, and B. Liu. Clustering Transactions Using Large Items. <i>Proceedings of ACM CIKM International Conference on Information and Knowledge Management</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844741</ref_obj_id>
				<ref_obj_pid>844380</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[C.-H. Yun, K.-T. Chuang, and M.-S. Chen. Using Category-Based Adherence to Cluster Market-Basket Data. <i>Proceedings of the 2nd IEEE International Conference on Data Mining (ICDM 2002)</i>, Dec. 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952114</article_id>
		<sort_key>701</sort_key>
		<display_label></display_label>
		<pages>701</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>123</seq_no>
		<title><![CDATA[Dimensionality Reduction Using Kernel Pooled Local Discriminant Information]]></title>
		<page_from>701</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952114</url>
		<abstract>
			<par><![CDATA[We study the use of kernel subspace methods for learninglow-dimensional representations for classification. We proposea kernel pooled local discriminant subspace methodand compare it against several competing techniques: generalizedFisher discriminant analysis (GDA) and kernelprincipal components analysis (KPCA) in classificationproblems. We evaluate the classification performance ofthe nearest-neighbor rule with each subspace representation.The experimental results demonstrate the efficacy ofthe kernel pooled local subspace method and the potentialfor substantial improvements over competing methods suchas KPCA in some classification problems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.1</cat_node>
				<descriptor>Computation of transforms (e.g., fast Fourier transform)</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.4</cat_node>
				<descriptor>Representations (procedural and rule-based)</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010314</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Rule learning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003714.10003715.10003717</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical analysis->Numerical analysis->Computation of transforms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP15042622</person_id>
				<author_profile_id><![CDATA[81100114269]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP27000194</person_id>
				<author_profile_id><![CDATA[81100023197]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15020877</person_id>
				<author_profile_id><![CDATA[81100062921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Carlotta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Domeniconi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1121922</ref_obj_id>
				<ref_obj_pid>1121912</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[G. Baudat and F. Anouar. Generalized discriminant analysis using akernel approach. <i>Neural Computation</i>, 12:2385- 2404, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Chen and et al. A new lda-based face recognition system which can solve the small samplesize problem. <i>Pattern Recognition</i>, 33:1713-1726, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. Courant and D. Hilbert, editors. <i>Methods of Mathematical Physiacs, vol. 1</i>. Interscience, New York, 1953.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>345662</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[N. Cristianini and J. Shawe-Taylor. <i>An Introduction to Support Vector Machines and other kernel-based learning methods</i>. Cambridge University Press, Cambridge, UK, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Dash and H. Liu. Feature selection methods for classification. <i>Intelligent Data Analysis: An International Journal</i>, 1, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[R. O. Duda and P. E. Hart. <i>Pattern Classification and Scene Analysis</i>. John Wiley & Sons, Inc., 1973.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>677295</ref_obj_id>
				<ref_obj_pid>646072</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[K. Etemad and R. Chellappa. Discriminant analysis for recognition of human faces. In <i>Proc. Int'l Conf. Acoustics, Speech, and Signal Processing</i>, pages 2148-2151, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Hastie and R. Tibshirani. Discriminant adaptive nearest neighbor classification and regression. In D. S. Touretzky, M. C. Mozer, and M. E. Hasselmo, editors, <i>Advances in Neural Information Processing Systems</i>, volume 8, pages 409-415. The MIT Press, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[I. Jolliffe. <i>Principal Component Analysis</i>. New York: Springer-Verlag, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Neter, M. Kutner, C. Nachtsheim, and L. Wasserman. <i>Applied Linear Statistical Models, 4th Edition</i>. Irwin, Chicago, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[S. T. Roweis and L. K. Saul. Nonlinear dimensionality reduction bylocally linear embedding. <i>Science</i>, 290:2323- 2326, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>295960</ref_obj_id>
				<ref_obj_pid>295919</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[B. Scholkopf, A. Smola, and K.-R. Muller. Nonlinear component analysis as a kernel eigenvalue problem. <i>Neural Computation</i>, 10:1299-1319, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952073</article_id>
		<sort_key>705</sort_key>
		<display_label></display_label>
		<pages>705</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>124</seq_no>
		<title><![CDATA[A Feature Selection Framework for Text Filtering]]></title>
		<page_from>705</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952073</url>
		<abstract>
			<par><![CDATA[This paper presents a new framework for local featureselection in text filtering. In this framework, a feature setis constructed per category by first selecting a set of termshighly indicative of membership (positive set) and anotherset of terms highly indicative of non-membership (negativeset), and then combining these two sets. This feature selectionframework not only unifies several standard featureselection methods, but also facilitates the proposal of a newmethod that optimally combines the positive and negativesets. The experimental comparison between the proposedmethod and standard methods was conducted on six featureselection metrics: chi-square, correlation coefficient, oddsratio, GSS coefficient and two proposed variants of odds ratioand GSS coefficient: OR-square and GSS-square respectively.The results show that the proposed feature selectionmethod improves text filtering performance.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Correlation and regression analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003691</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Regression analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010309.10010313</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Factorization methods->Canonical correlation analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP309701900</person_id>
				<author_profile_id><![CDATA[81537865856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zhaohui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zheng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14093749</person_id>
				<author_profile_id><![CDATA[81100243324]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rohini]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Srihari]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43117998</person_id>
				<author_profile_id><![CDATA[81100243670]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Sargur]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Srihari]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>699638</ref_obj_id>
				<ref_obj_pid>646633</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[F. Galavotti, L. Sebastiani and M. Simi. Experiments on the use of feature selection and negative evidence in automated text categorization. <i>Proceedings of ECDL-00, 4th European Conference on Research and Advanced Technology for Digital Libraries</i>, pages 59-68, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Mladeni. <i>Machine Learning on non-homogeneous, distributed text data</i>. PhD Dissertation, University of Ljubljana, Slovenia, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258537</ref_obj_id>
				<ref_obj_pid>258525</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W. Ng, H. Goh and K. Low. Feature selection, perceptron learning, and a usability case study for text categorization. <i>ACM SIGIR Conference on Research and Developement in Information Retrieval</i>, pages 67-73, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>539927</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[V. Rijsbergen. <i>Information Retrieval</i>. Butterworths, London, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>505283</ref_obj_id>
				<ref_obj_pid>505282</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[F. Sebastiani. Machine learning in automated text categorization. <i>ACM Computing Surveys</i>, 34(1):1-47, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>357383</ref_obj_id>
				<ref_obj_pid>357367</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Y. Yang. An evaluation of statistical approaches to text categorization. <i>Journal of Information Retrieval</i>, 1(1/2):67-88, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657137</ref_obj_id>
				<ref_obj_pid>645526</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Y. Yang and J. Pedersen. A comparative study on feature selection in text categorization. <i>The Fourteenth International Conference on Machine Learning</i>, pages 412-420, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Z. Zheng and R. Srihari. Optimally combining positive and negative features for text categorization. <i>Learning from Imbalanced Data Sets II workshop at The Twentieth International Conference on Machine Learning</i>, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952109</article_id>
		<sort_key>709</sort_key>
		<display_label></display_label>
		<pages>709</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>125</seq_no>
		<title><![CDATA[A K-NN Associated Fuzzy Evidential Reasoning Classifier with Adaptive Neighbor Selection]]></title>
		<page_from>709</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952109</url>
		<abstract>
			<par><![CDATA[The paper presents a fuzzy evidential reasoning algorithmin light of the Dempster-Shafer evidence theory andthe K-nearest neighbor algorithm for pattern classification.Given an input pattern to be classified, each of its K nearestneighbors is viewed as an evidence source, in terms ofa fuzzy evidence structure. The distance between the inputpattern and each of its K nearest neighbors is usedfor mass determination while the contextual information ofthe nearest neighbor in the training sample space is formulatedby a fuzzy set in determining a fuzzy focal element.Therefore, pooling evidence provided by neighbors is realizedby a fuzzy evidential reasoning, where feature selectionis further considered through ranking and adaptive combinationof neighbors. A fast implementation scheme of thefuzzy evidential reasoning is also developed. Experimentalresults of classifying multi-channel remote sensing imageshave shown that the proposed approach outperforms the K-nearestneighbor (K-NN) algorithm [1], the fuzzy K-nearestneighbor (F-KNN) algorithm [2], the evidence-theoretic K-nearestneighbor (E-KNN) algorithm [3], and the fuzzy ex-tendedversion of E-KNN (FE-KNN) [4], in terms of theclassification accuracy and insensitivity to the number Kof nearest neighbors.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Feature evaluation and selection</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.3</cat_node>
				<descriptor>Uncertainty, "fuzzy," and probabilistic reasoning</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Graph and tree search strategies</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010210</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Game tree search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010207</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Discrete space search</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010190</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Probabilistic reasoning</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010187.10010191</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Knowledge representation and reasoning->Vagueness and fuzzy logic</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010321.10010336</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning algorithms->Feature selection</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP36028049</person_id>
				<author_profile_id><![CDATA[81100414159]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hongwei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39037854</person_id>
				<author_profile_id><![CDATA[81100327206]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Otman]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Basir]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[T.M. Cover, P. E. Hart. Nearest neighbor pattern classification. <i>IEEE Trans. Information Theory</i>, 12:21-27, 1967.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J.M. Keller, M.R. Gray, J.A. Givens. A fuzzy <i>K</i>-nearest neighbor algorithm. <i>IEEE Trans. Syst. Man, Cybern.</i>, SMC-15 (4):580-585, July 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[T. Denoex. A k-nearest neighbor classification rule based on Dempster-Shafer theory. <i>IEEE Trans. Syst. Man, Cybern.</i>, 25(5):804-813, May 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[L.M. Zouhal, T. Denoeux. Generalizing the evidence-theoretic k-NN rule to fuzzy pattern recognition. In <i>Proc. of 2nd Int. ICSC Symposium on Fuzzy Logic and Applications</i>, pages 294-300, Zurich, Switzerland, Feb. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Shafer. <i>A Mathematic Theory of Evidence</i>. Princeton University Press, Priceton, NJ, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>346905</ref_obj_id>
				<ref_obj_pid>346898</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[G. Giacinto, F. Roli, L. Bruzzone. Combination of neural and statistical algorithms for supervised classification of remote-sensing images. <i>Pattern Recognit. Lett.</i>, 21(5):385-397, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[H. Zhu, O. Basir. A scheme for constructing evidence structures in Dempster-Shafer evidence theory for data fusion. In <i>Proc. of 5th IEEE Int. Symposium on Computational intelligence in Robotics and Automation</i>, Japan, July 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952060</article_id>
		<sort_key>715</sort_key>
		<display_label></display_label>
		<pages>715</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>126</seq_no>
		<title><![CDATA[Findings from a Practical Project Concerning Web Usage Mining]]></title>
		<page_from>715</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952060</url>
		<abstract>
			<par><![CDATA[In a practical project a statistical analysis of the Weblog files of the domain www.volkswagen.de was carriedout by using the CRISP-DM procedure. For the preprocessingphase, more profound findings could be gainedthan are usually described in many studies. Since the aimwas to deduce significant statements while measuring theeffect, tests of significance for e-metrics were used inaddition to the commonly described procedure.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Prototyping</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.3.4</cat_node>
				<descriptor>World Wide Web (WWW)</descriptor>
				<type>P</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003152</concept_id>
				<concept_desc>CCS->Information systems->Information storage systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003123.10010860.10011694</concept_id>
				<concept_desc>CCS->Human-centered computing->Interaction design->Interaction design process and methods->Interface design prototyping</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645312</person_id>
				<author_profile_id><![CDATA[81548036568]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Frank]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dellmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645344</person_id>
				<author_profile_id><![CDATA[81100142292]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Holger]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wulff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14138962</person_id>
				<author_profile_id><![CDATA[81100392367]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schmitz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Chapman et al. (2000): Chapman, P.; Clinton, J.; Kerber, R.; Khabaza, T.; Reinartz, T.; Shearer, C.; Wirth, R.: CRISPDM 1.0: Step-by-step data mining guide. http://www.crisp-dm.org/ CRISPWP-0800.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>931653</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cooley (2000): Cooley, R.: Web Usage Mining: Discovery and Application of Usage Patterns from Web Data. Diss., University of Minnesota, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593521</ref_obj_id>
				<ref_obj_pid>593432</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Tan/Kumar (2002): Tan, P.-N.; Kumar, V.: Discovery of Web Robot Sessions Based on their Navigational Patterns. In: Data Mining and Knowledge Discovery, Vol. 6, Issue 1, 2002, p. 9-35.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593509</ref_obj_id>
				<ref_obj_pid>593429</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Spiliopoulou/Pohle (2001): Spiliopoulou, M.; Pohle, C.: Data Mining for Measuring and Improving the Success of Web Sites. In: Data Mining and Knowledge Discovery, Vol. 5, No. 1/2, 2001, p. 85-114.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>593522</ref_obj_id>
				<ref_obj_pid>593432</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Berendt (2002): Berendt, B.: Using Site Semantics to Analyze, Visualize, and Support Navigation. In: Data Mining and Knowledge Discovery, Vol. 6, Issue 1, 2002, p. 37-59.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Dellmann (2001): Dellmann, F.: An&#225;lisis de la utilizaci&#243;n de sitios web con m&#233;todos de estad&#237;stica inferencial en la pr&#225;ctica. 36&#176; Asamblea Anual del Consejo Latinoamericano de Escuelas de Administraci&#243;n CLADEA: Los nuevos modelos de negocios ante la globalizaci&#243;n. Mexico City, 25.-28.9.2001. http://www. fh-muenster.de/FB9/person/dellmann/articulocladea.pdf (german version: http://www.fh-muenster.de/FB9/person/dellmann/ artikelcladea.pdf).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cooley et al. (1999): Cooley, R.; Mobasher, B.; Srivastan, J.: Data Preparation for Mining World Wide Web Browsing Patterns. In: Knowledge and Information Systems, Vol. 1, No. 1, 1999, p. 5-32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>283441</ref_obj_id>
				<ref_obj_pid>283554</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Pitkow (1997): Pitkow, J.: In Search of Reliable Usage Data on the WWW. In: Sixth International World Wide Web Conference, Santa Clara, CA, 1997, p. 451-463. http://www.scope. gmd.de/info/www6/technical/paper126/paper126.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mann/Whitney (1947): Mann, H. B.; Whitney, D. R. (1947): On a test of whether one of two random variables is stochastically larger than the other. In: Annals of Mathematical Statistics, Vol. 18, p. 50-60.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Breiman et al. (1984): Breiman, L.; Friedman, J. H.; Olshen, R. A.; Stone, C. J.: Classification and Regression Trees. Wadsworth International Group, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952069</article_id>
		<sort_key>719</sort_key>
		<display_label></display_label>
		<pages>719</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>127</seq_no>
		<title><![CDATA[Predicting distribution of a new forest disease using one-class SVMs]]></title>
		<page_from>719</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952069</url>
		<abstract>
			<par><![CDATA[In California, a newly discovered virulent pathogen(Phytophthora ramorum) has killed thousands of nativeoak trees. Mapping the potential distribution of thepathogen is essential for decision makers to assess therisk of the pathogen and aid in preventing its furtherspread. Most methods used to map potential ranges ofspecies (e.g. multivariate or logistic regression) requireboth presence and absence data, the latter of which is notalways feasibly collected. In this study, we present theone-class Support Vector Machine (SVM) to predict thepotential distribution of Sudden Oak Death in California.The model was developed using presence data collectedthroughout the state, and tested for accuracy using a 5-fold cross-validation approach. The model performedwell, and provided 91% predicted accuracy. We believeone-class SVM when coupled with GeographicalInformation Systems (GIS) will become a very usefulmethod to deal with presence-only data in ecologicalanalysis over a range of scales.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Combined</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Distribution functions</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Spatial databases and GIS</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003703</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Distribution functions</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003236</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Spatial-temporal systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010887</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Geographic visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP38023096</person_id>
				<author_profile_id><![CDATA[81430674908]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Qinghua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Guo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645436</person_id>
				<author_profile_id><![CDATA[81100523881]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Maggi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kelly]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14173177</person_id>
				<author_profile_id><![CDATA[81537115456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Catherine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Graham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D. Rizzo, M. Garbelotto, J.M. Davidson, G.W. Slaughter, and S.T. Koike, "<i>Phytophthora ramorum</i> as the cause of extensive mortality of <i>Quercus spp. and Lithocarpus deniflorus</i> in California", <i>Plant Disease</i>, 2002, pp. 205-213.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A.T. Peterson, and D. A. Vieglais, "Predicting species invasions using ecological niche modeling: new approaches from bioinformatics attack a pressing problem", <i>Bioscience</i>, 2001, pp. 363-371.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[E. Welk, K. Schubert, and M.H. Hoffmann, "Present and potential distribution of invasive garlic mustard (Alliaria petiolata) in North America", <i>Diversity and Distributions</i>, 2002, pp. 219-233.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[R. Dettmers, and J. Bart, "A GIS modeling method applied to predicting forest songbird habitat", <i>Ecological Applications</i>, 1999, pp. 152-163.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[M. Garbelotto, P. Svihra, and D. Rizzo, "Sudden oak death syndrome fells three oak species", <i>California Agriculture</i>, 2001, pp. 9-19.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[V. Vapnik, <i>The Nature of Statistical Learning Theory</i>, Springer-Verlag, New York, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>765585</ref_obj_id>
				<ref_obj_pid>765580</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[N. Cristianini, and B. Scholkopf, "Support vector machines and kernel methods - The new generation of learning machines". <i>Ai Magazine</i>, 2002, pp. 31-41.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1119749</ref_obj_id>
				<ref_obj_pid>1119748</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. Scholkopf, J.C. Platt, J. Shawe-Taylor, AJ. Smola, and R.C. Williamson, "Estimation the support of a high-dimensional distribution", <i>Neural Computation</i>, 2001, pp. 1443-1471.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>337890</ref_obj_id>
				<ref_obj_pid>337830</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[D. Tax, and E. Duin, "Support vector domain description", <i>Pattern Recognition Letters</i>, 1999, pp. 1191-1199.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1961199</ref_obj_id>
				<ref_obj_pid>1961189</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. Chang, and C. Lin, <i>LIBSVM: a library for support vector machines</i>, Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[M. Kelly, and R.K. Meentemeyer, "Landscape dynamics of the spread of Sudden Oak Death", <i>Photogrammetric Engineering & Remote Sensing</i>, 2002, pp. 1001-1009.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952064</article_id>
		<sort_key>723</sort_key>
		<display_label></display_label>
		<pages>723</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>128</seq_no>
		<title><![CDATA[Understanding Helicoverpa armigera Pest Population Dynamics related to Chickpea Crop Using Neural Networks]]></title>
		<page_from>723</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952064</url>
		<abstract>
			<par><![CDATA[Insect pests are a major cause of crop loss globally. Pestmanagement will be effective and efficient if we canpredict the occurrence of peak activities of a given pest.Research efforts are going on to understand the pestdynamics by applying analytical and other techniques onpest surveillance data sets. In this study we make an effortto understand pest population dynamics using NeuralNetworks by analyzing pest surveillance data set ofHelicoverpa armigera or Pod borer on chickpea (Cicerarietinum L.) crop. The results show that neural networkmethod successfully predicts the pest attack incidences forone week in advance.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Connectionism and neural nets</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.8</cat_node>
				<descriptor>Heuristic methods</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010205.10010206</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Search methodologies->Heuristic function construction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010294</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Neural networks</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14022471</person_id>
				<author_profile_id><![CDATA[81100027721]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rajat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645237</person_id>
				<author_profile_id><![CDATA[81100268383]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[V. L.]]></middle_name>
				<last_name><![CDATA[Narayana]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP30025176</person_id>
				<author_profile_id><![CDATA[81100154247]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[Krishna]]></middle_name>
				<last_name><![CDATA[Reddy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645316</person_id>
				<author_profile_id><![CDATA[81100590982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[V.  Ranga]]></middle_name>
				<last_name><![CDATA[Rao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645253</person_id>
				<author_profile_id><![CDATA[81100288502]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[L. L.]]></middle_name>
				<last_name><![CDATA[Gowda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645614</person_id>
				<author_profile_id><![CDATA[81100154225]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Y.]]></first_name>
				<middle_name><![CDATA[V. R.]]></middle_name>
				<last_name><![CDATA[Reddy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645315</person_id>
				<author_profile_id><![CDATA[81100642050]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[Rama]]></middle_name>
				<last_name><![CDATA[Murthy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[D.K. Das, T.P. Trivedi and C.P. Srivastava. 2001. Simple rules to predict attack of <i>Helicoverpa armigera</i> on crops growing in Andhra Pradesh, Indian Journal of Agricultural Sciences 71: 421-423.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Dean W. Wichern and Richard Arnold Johnson, Applied Multivariat Statistical Analysis, Prentice Hall, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[International Crop Research Institute for Semi-Arid tropics: ICRISAT, URL: www.icrisat.org, April 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076797</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Jiawei Han and Micheline Kamber, Data Mining Concepts and Techniques, Morgan Kaufmann, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T.M. Manjunath, V.S. Bhatnagar, C.S. Pawar, and S. Sithnantham. 1989. Economic importance of <i>Helicoverpa</i> spp. In India and an assessment of their natural enemies and host plants. In King EG, Jackson RD, eds. Proceeding of the workshop on Biological Control of <i>Helicoverpa</i>: Increasing the Effectiveness of natural Enemies, Far Eastern Regional Research Office, United States Department Agriculture, New Delhi. pp. 197-228.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M.P. Pimbert, C.P. Srivastava. 1991. The influence of rainfall deficits on the abundance of <i>Helicoverpa armegira</i> in Andhra Pradesh, India. Biological Agriculture and Horticulture, 8:153- 176.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>521706</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Simon Haykin, Neural Networks: A Comprehensive Foundation, Pearson Education, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T.P. Trivedi, D.K. Das, A. Dhandapani, and A.K. Kanojia, 2002. Models for Pests and Disease Forecasting, Resources Management in Plant Protection, Volume I, Plant Protection Association of India, Hyderabad, India, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Zhongua Zhao, Zuorui Shen. Theories and their applications of Stochastic Simulation Models for Insect population Dynamics. Department of Entomology, The China Agricultural University, Feb. 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952063</article_id>
		<sort_key>727</sort_key>
		<display_label></display_label>
		<pages>727</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>129</seq_no>
		<title><![CDATA[Text Mining for a Clear Picture of Defect Reports]]></title>
		<subtitle><![CDATA[A Praxis Report]]></subtitle>
		<page_from>727</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952063</url>
		<abstract>
			<par><![CDATA[We applied the text mining categorization technology,in the publicly available, IBM Enterprise InformationPortal V8.1 to more than 15,000 customer reported,product problem records. We used a proven softwarequality category set to categorize these problem recordsinto different areas of interest. Our intent was to developa clear picture of potential areas for quality improvementin each of the software products reviewed, and to providethis information to development's management.The paper presents the benefits that can be gained fromcategorizing problem records, as well as the limitations.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Textual databases</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.7</cat_node>
				<descriptor>Text analysis</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010179.10010186</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing->Language resources</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645391</person_id>
				<author_profile_id><![CDATA[81100129284]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jutta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kreyss]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645557</person_id>
				<author_profile_id><![CDATA[81100460711]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Steve]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Selvaggio]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14212643</person_id>
				<author_profile_id><![CDATA[81406598983]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[White]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645625</person_id>
				<author_profile_id><![CDATA[81100205504]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Zach]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zakharian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Chulani, S., P. Santhanam, D. Moore, B. Leszkowicz, & G. Davidson: Deriving a Software Quality View from Customer Satisfaction and Service Data. European Software Control and Metrics conference, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[http://www.escom.co.uk/conference2001/index.shtml]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Enterprise Information Portal V8.1:. http://www.ibm.com/software/data/eip]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1662329</ref_obj_id>
				<ref_obj_pid>1662321</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Johnson, D. E., F. J. Oles, T. Zhang & T. Goetz: A decision-tree-based symbolic rule induction system for text categorization. IBM Systems Journal 41:3 (March 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Venkataraman, B. K. & W. A. Ward, Jr: An Introduction to Software Quality, June 1999, TR ITL-99-4, http://www.wes.army.mil/ITL/itlpubl.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952061</article_id>
		<sort_key>731</sort_key>
		<display_label></display_label>
		<pages>731</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>130</seq_no>
		<title><![CDATA[Mining Production Data with Neural Network & CART]]></title>
		<page_from>731</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952061</url>
		<abstract>
			<par><![CDATA[This paper presents the preliminary results of a datamining study of a production line involving hundreds ofvariables related to mechanical, chemical, electrical andmagnetic processes involved in manufacturing coatedglass. The study was performed using two nonlinear,nonparametric approaches, namely neural network andCART, to model the relationship between the qualities ofthe coating and machine readings. Furthermore, neuralnetwork sensitivity analysis and CART variable rankingswere used to gain insight into the coating process. Ourinitial results show the promise of data mining techniquesto improve the production.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.6</cat_node>
				<descriptor>Computer-aided manufacturing (CAM)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.6</cat_node>
				<descriptor>Connectionism and neural nets</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Data mining</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010294</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Neural networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003351</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Data mining</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010481.10010483</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Computer-aided manufacturing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14167162</person_id>
				<author_profile_id><![CDATA[81381602704]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mingkun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645547</person_id>
				<author_profile_id><![CDATA[81546088556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shuo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Feng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39039089</person_id>
				<author_profile_id><![CDATA[81100354352]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ishwar]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Sethi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645363</person_id>
				<author_profile_id><![CDATA[81100175027]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jason]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Luciow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645402</person_id>
				<author_profile_id><![CDATA[81100167410]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Keith]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wagner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1076797</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Han and M. Kamber, <i>Data Mining: Concepts and Techniques</i>, Morgan Kaufmann Publishers, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. J. Hill and S. J. Nadel, <i>Coated Glass Applications and Markets, BOC Coating Technology</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>954544</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R. O. Duda, P. E. Hart, and D. G. Stork, <i>Pattern Classification</i>, 2nd, John Wiley & Sons, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>541500</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Haykin, <i>Neural Networks: A Comprehensive Foundation</i>, Macmillan, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>211359</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[V. N. Vapnik, <i>The Nature of Statistical Learning Theory</i>, 2nd, Springer, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[L. Breiman, J. Friedman, R. Olshen, and C.J. Stone, <i>Classification and Regression Trees</i>, Wadsworth Int. l Group, Belmont, CA, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326515</ref_obj_id>
				<ref_obj_pid>2325770</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Q. g. Ali and Y. Chen, "Design Quality and Robustness with Neural Networks", <i>IEEE Transactions on Neural Networks</i>, pp 1518-1527, Vol. 10, No. 6, November 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2326583</ref_obj_id>
				<ref_obj_pid>2325773</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[R. H. Kewley, M. J. Embrechts, and C. Breneman, "Data Strip Mining for the Virtual Design of Pharmaceuticals with Neural Networks", <i>IEEE Transactions on Neural Networks</i>, pp 668-769, Vol. 11, No. 3, May 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>347188</ref_obj_id>
				<ref_obj_pid>347090</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[A. Dhond, A. Gupta, and S. Vadhavkar, "Data Mining Techniques for Optimizing Inventories for Electronic Commerce", pp 480-486, KDD 2000, Boston.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[L. M. Belue, and K. W. Bauer, "Determining input features for multilayer perceptrons", <i>Neurocomputing</i>, 7 (1995) 111-121.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[T. Pyzdek, "Six Sigma, Data Mining and Dead Customer Accounts", <i>Quality Digest</i>, Apr. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. Li, S. Feng, I. K. Sethi, Data Mining on Guardian Glass Coating Process, Technical Report, Science and Technology Center of Guardian Industries Corp, March, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952068</article_id>
		<sort_key>735</sort_key>
		<display_label></display_label>
		<pages>735</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>131</seq_no>
		<title><![CDATA[Inference of Protein-Protein Interactions by Unlikely Profile Pair]]></title>
		<page_from>735</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952068</url>
		<abstract>
			<par><![CDATA[We note that a set of statistically "unusual" protein-profilepairs in experimentally determined database ofprotein-protein interactions can typify protein-proteininteractions, and propose a novel method calledPICUPP that sifts such protein-profile pairs using astatistical simulation. It is demonstrated that unusualPfam and InterPro profile pairs can be extracted fromthe DIP database using a bootstrapping approach. Weparticularly illustrate that such protein-profile pairs canbe used for predicting putative pairs of interactingproteins. Their prediction accuracies are around 86%and 90% when InterPro and Pfam profiles are used,respectively at 75% confidence level.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Monte Carlo</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.2.8</cat_node>
				<descriptor>Scientific databases</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010349</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003677</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Markov-chain Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003145.10003147.10010364</concept_id>
				<concept_desc>CCS->Human-centered computing->Visualization->Visualization application domains->Scientific visualization</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003670.10003682</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Probabilistic reasoning algorithms->Sequential Monte Carlo methods</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P345445</person_id>
				<author_profile_id><![CDATA[81100157919]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Byung-Hoon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39039246</person_id>
				<author_profile_id><![CDATA[81100357770]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ostrouchov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P634501</person_id>
				<author_profile_id><![CDATA[81100471850]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Gong-Xin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14081665</person_id>
				<author_profile_id><![CDATA[81100207530]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Al]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Geist]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP309434200</person_id>
				<author_profile_id><![CDATA[81541191356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Andrey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gorin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P312011</person_id>
				<author_profile_id><![CDATA[81100293623]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Nagiza]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Samatova]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Y. a. X. D. Chen, "Computational Analyses of High-Throughput Protein-Protein Interaction Data," <i>Current Protein and Peptide Science</i>, vol. 4, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Valencia and F. Pazos, "Computational methods for the prediction of protein interactions," <i>Current Opinion in Structural Biology</i>, vol. 12, pp. 368-373, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. J. Enright, et al., "Protein interaction maps for complete genomes based on gene fusion events," <i>Nature</i>, vol. 402, pp. 86-90, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[E. M. Marcotte, et al., "Detecting protein function and protein-protein interactions from genome sequences," <i>Science</i>, vol. 285, pp. 751-3, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[R. Overbeek, Fonstein, M., D'Souza, M., Pusch, G.D., Maltsev, N., "Use of contiguity on the chromosome to predict functional coupling," <i>In Silico Biol.</i>, vol. 1, pp. 93-108, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Dandekar, et al., "Conservation of gene order: a fingerprint of proteins that physically interact," <i>Trends in Biochemical Sciences</i>, vol. 23, pp. 324-328, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Pellegrini, et al., "Assigning protein functions by comparative genome analysis: protein phylogenetic profiles," <i>Proc Natl Acad Sci USA</i>, vol. 96, pp. 4285-8, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[M. Huynen, et al., "Predicting protein function by genomic context: Quantitative evaluation and qualitative inferences," <i>Genome Research</i>, vol. 10, pp. 1204-1210, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. R. Bock and D. A. Gough, "Predicting protein--protein interactions from primary structure," <i>Bioinformatics</i>, vol. 17, pp. 455-60., 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[E. Sprinzak and H. Margalit, "Correlated sequence-signatures as markers of protein-protein interaction," <i>J Mol Biol</i>, vol. 311, pp. 681-92, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[A. Bateman, et al., "The Pfam protein families database," <i>Nucleic Acids Res</i>, vol. 30, pp. 276-80, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[N. J. Mulder, et al., "The InterPro Database, 2003 brings increased coverage and new features," <i>Nucleic Acids Research</i>, vol. 31, pp. 315-318, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. G. Henikoff, et al., "Blocks-based methods for detecting protein homology," <i>Electrophoresis</i>, vol. 21, pp. 1700-6. {pii}, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[I. Xenarios, et al., "DIP, the Database of Interacting Proteins: a research tool for studying cellular networks of protein interactions," <i>Nucleic Acids Research</i>, vol. 30, pp. 303- 305, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. E. Fienberg, "Analysis of Cross-Classified Categorical Data," <i>Notices of the American Mathematical Society</i>, vol. 23, pp. A619-A619, 1976.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[T. Pawson and J. Schlessinger, "Sh2 and Sh3 Domains," <i>Current Biology</i>, vol. 3, pp. 434-442, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[D. G. Drubin, et al., "Homology of a Yeast Actin-Binding Protein to Signal Transduction Proteins and Myosin-I," <i>Nature</i>, vol. 343, pp. 288-290, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[T. Achsel, et al., "The human U5-220kD protein (hPrp8) forms a stable RNA-free complex with several US-specific proteins, including an RNA unwindase, a homologue of ribosomal elongation factor EF-2, and a novel WD-40 protein," <i>Molecular and Cellular Biology</i>, vol. 18, pp. 6756-6766, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[E. Nishida, et al., "Cofilin, a Protein in Porcine Brain That Binds to Actin-Filaments and Inhibits Their Interactions with Myosin and Tropomyosin," <i>Biochemistry</i>, vol. 23, pp. 5307- 5313, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[F. Taniguchi, et al., "Activation of mitogen-activated protein kinase pathway by keratinocyte growth factor or fibroblast growth factor-10 promotes cell proliferation in human endometrial carcinoma cells," <i>Journal of Clinical Endocrinology and Metabolism</i>, vol. 88, pp. 773-780, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[N. Messer and J. Kendrickjones, "Chimeric Myosin Regulatory Light-Chains - Subdomain Switching Experiments to Analyze the Function of the N-Terminal Ef Hand," <i>Journal of Molecular Biology</i>, vol. 218, pp. 825-835, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952066</article_id>
		<sort_key>739</sort_key>
		<display_label></display_label>
		<pages>739</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>132</seq_no>
		<title><![CDATA[Regulatory Element Discovery Using Tree-structured Models]]></title>
		<page_from>739</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952066</url>
		<abstract>
			<par><![CDATA[Computational discovery of transcriptional regulatoryregions in DNA sequences provides an efficient way tobroaden our understanding of how cellular processes arecontrolled. In this paper, we formulate the regulatoryelement discovery problem in the regression frameworkwith regulatory regions treated as predictor variables andgene expression levels as responses. We use regressiontree models to identify structural relationships betweenpredictors and responses. The regression treemethodology is extended to handle multiple responsesfrom different experiments by modifying the split function.We apply this method to two data sets of the yeastSaccharomyces cerevisiae. The method successfullyidentifies most of regulatory motifs that are known tocontrol gene transcription under the given experimentalconditions. Our method also suggests several putativemotifs that can present novel regulatory motifs.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>F.2.2</cat_node>
				<descriptor>Sequencing and scheduling</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.3</cat_node>
				<descriptor>Correlation and regression analysis</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10010309.10010313</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Factorization methods->Canonical correlation analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10010047.10010048.10003808</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Online algorithms->Online learning algorithms->Scheduling algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10003809.10003636.10003808</concept_id>
				<concept_desc>CCS->Theory of computation->Design and analysis of algorithms->Approximation algorithms analysis->Scheduling algorithms</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010071.10010261.10010272</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Machine learning theory->Reinforcement learning->Sequential decision making</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003648.10003688.10003691</concept_id>
				<concept_desc>CCS->Mathematics of computing->Probability and statistics->Statistical paradigms->Regression analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P645585</person_id>
				<author_profile_id><![CDATA[81100292509]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tu]]></first_name>
				<middle_name><![CDATA[Minh]]></middle_name>
				<last_name><![CDATA[Phuong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77042684</person_id>
				<author_profile_id><![CDATA[81384594768]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Doheon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77046447</person_id>
				<author_profile_id><![CDATA[81409592803]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kwang]]></first_name>
				<middle_name><![CDATA[Hyung]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[L. Breiman, J.H. Friedman, R.A. Olshen, C.J. Stone. <i>Classification and regression tree</i>. Wadsworth, 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>369174</ref_obj_id>
				<ref_obj_pid>369133</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H.M. Bussemaker, H. Li, E.R. Siggia, "Regulatory element detection using correlation with expression", <i>Nature genetics</i>, 2001, 27, pp 167-171.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R.J. Cho, <i>et al</i>. "A genome-wide transcription analysis of the mitotic cell cycle", <i>Molecular Cell</i>, 1998 2, pp 65-73.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. Chu, <i>et al.</i>, "The Transcriptional Program of Sporulation in Budding Yeast", <i>Science</i>, 1998, 282, pp 699-705.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[E.M. Conlon, X.S. Liu, J.D. Lieb, J.S. Liu, "Integrating regulatory motif discovery and genome-wide expression analysis", <i>Proceedings of National Academy of USA</i>, 2003, 100(6), pp 3339-3344.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M.B. Eisen, P.T. Spellman, P.O. Brown, D. Botstein. "Cluster analysis and display of genome-wide expression patterns", <i>Proceedings of National Academy of USA</i>, 1998, 95, pp 14863-14868.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J.D. Hughes, P.W. Estep, S. Tavazoie, G.M. Church. "Computational identification of cis-regulatory elements associated with groups of functionally related genes in S. Cerevisiae". <i>Journal of Molecular Biology</i>, 2000, Vol 296, p 1205-1214.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Keles, M. van der Laan, M. Eisen, "Identification of regulatory elements using a feature selection method", <i>Bioinformatics</i>, Oxford press, 2002, 18(9), pp 1167-1175.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[H.W. Mewes et al. "MIPS: a database for genomes and protein sequences", <i>Nucleic acids research</i>, 2000, 28, pp 37-40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[U. Ohler, H. Niemann, "Identification and analysis of eukaryotic promoters: recent computational approaches". <i>Trends Genetics</i> 2001, &#60;b&#62;17&#60;/b&#62;, pp 56-60.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Y. Pilpel <i>et al.</i>, "Identifying regulatory networks by combinatorial analysis of promoter elements", <i>Nature Genetics</i>, 2001, 29(2), pp 153-159.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M.R. Segal, "Tree-structured methods for longitudinal data". <i>Journal of American Statistical Association</i>, 1992, 87(418), pp 407-418.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[S. Tavazoie <i>et al.</i>, "Systematic determination of genetic network architecture". <i>Nature Genetics</i>, 1999, 22, pp 281-285.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[H. Zhang, "Classification trees for multiple binary responses", <i>Journal of American Statistical Association</i>, 1998, 93(441), pp 180-193.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[http://genetics.med.harvard.edu/~tpilpel/MotComb.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952065</article_id>
		<sort_key>743</sort_key>
		<display_label></display_label>
		<pages>743</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>133</seq_no>
		<title><![CDATA[Applying Noise Handling Techniques to Genomic Data]]></title>
		<subtitle><![CDATA[A Case Study]]></subtitle>
		<page_from>743</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952065</url>
		<abstract>
			<par><![CDATA[Osteogenesis Imperfecta (OI) is a genetic collagenousdisease associated with mutations in one or both of thegenes COLIA1 and COLIA2. There are at least four knownphenotypes of OI, of which type II is the severest and oftenlethal. We identified three approaches to noise handling,namely, robust algorithms, filtering, and polishing,and evaluated their effectiveness when applied to the problemof classifying the disease OI based on a data set ofamino acid sequences and associated information of pointmutations of COLIA1. Preliminary results suggest that eachnoise handling mechanism can be useful under different circumstances.Filtering is stable across all cases. Pruningwith robust c4.5 increased the classification accuracy insome cases, and polishing gave rise to some additional improvementin classifying the lethal OI phenotype.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>H.3.3</cat_node>
				<descriptor>Information filtering</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.2</cat_node>
				<descriptor>Classifier design and evaluation</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>J.3</cat_node>
				<descriptor>Biology and genetics</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010444.10010087</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Computational biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010293.10003660</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Machine learning approaches->Classification and regression trees</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010095</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Systems biology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010257.10010258.10010259.10010263</concept_id>
				<concept_desc>CCS->Computing methodologies->Machine learning->Learning paradigms->Supervised learning->Supervised learning by classification</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010444.10010935</concept_id>
				<concept_desc>CCS->Applied computing->Life and medical sciences->Genetics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003349</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Document filtering</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003317.10003347.10003352</concept_id>
				<concept_desc>CCS->Information systems->Information retrieval->Retrieval tasks and goals->Information extraction</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP39041159</person_id>
				<author_profile_id><![CDATA[81100401310]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Choh]]></first_name>
				<middle_name><![CDATA[Man]]></middle_name>
				<last_name><![CDATA[Teng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>637942</ref_obj_id>
				<ref_obj_pid>637913</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[P. Clark and T. Niblett. The CN2 induction algorithm. <i>Machine Learning</i>, 3(4):261-283, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>735444</ref_obj_id>
				<ref_obj_pid>647714</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. Gamberger, N. Lavra and S. Deroski. Noise elimination in inductive concept learning: A case study in medical diagnosis. In <i>Proceedings of the Seventh International Workshop on Algorithmic Learning Theory</i>, pages 199-212, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>662730</ref_obj_id>
				<ref_obj_pid>645630</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[L. Hunter and T. E. Klein. Finding relevant biomolecular features. In <i>Proceedings of the International Conference on Intelligent Systems for Molecular Biology</i>, pages 190-197, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[G. H. John. Robust decision trees: Removing outliers from databases. In <i>Proceedings of the First International Conference on Knowledge Discovery and Data Mining</i>, pages 174-179, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>551944</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Liu and H. Motoda, editors. <i>Feature Selection for Knowledge Discovery and Data Mining</i>. Kluwer Academic Publishers, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. D. Mooney, C. C. Huang, P. A. Kollman, and T. E. Klein. Computed free energy differences between point mutations in a collagen-like peptide. <i>Biopolymers</i>, 58:347-353, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. R. Quinlan. <i>C4.5: Programs for Machine Learning</i>. Morgan Kaufmann, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>657619</ref_obj_id>
				<ref_obj_pid>645528</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. M. Teng. Correcting noisy data. In <i>Proceedings of the Sixteenth International Conference on Machine Learning</i>, pages 239-248, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>707972</ref_obj_id>
				<ref_obj_pid>646814</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[C. M. Teng. A comparison of noise handling techniques. In <i>Proceedings of the Fourteenth International Florida Artificial Intelligence Research Society Conference</i>, pages 269- 273, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. M. Teng. Noise correction in genomic data. In <i>International Conference on Intelligent Data Engineering and Automated Learning</i>. Springer-Verlag, 2003. Forthcoming.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952062</article_id>
		<sort_key>747</sort_key>
		<display_label></display_label>
		<pages>747</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>134</seq_no>
		<title><![CDATA[Detecting Patterns of Change Using Enhanced Parallel Coordinates Visualization]]></title>
		<page_from>747</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952062</url>
		<abstract>
			<par><![CDATA[Analyzing data to find trends, correlations, and stablepatterns is an important problem for many industrialapplications. In this paper, we propose a new techniquebased on parallel coordinates visualization. Previous workon parallel coordinates methods has shown that they areeffective only when variables that are correlated and/orshow similar patterns are displayed adjacently. Althoughcurrent parallel coordinates tools allow the user tomanually rearrange the order of variables, this process isvery time-consuming when the number of variables islarge. Automated assistance is needed. This paperproposes an edit-distance based technique to rearrangevariables so that interesting patterns can be easilydetected. Our system, V-Miner, includes both automatedmethods for visualizing common patterns and a query toolthat enables the user to describe specific target patterns tobe mined/displayed by the system. Following an overviewof the system, a case study is presented to explain howMotorola engineers have used V-Miner to identifysignificant patterns in their product test and design data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[change patterns, parallel coordinate visualization]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.2.4</cat_node>
				<descriptor>Query processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.7</cat_node>
				<descriptor>Industrial control</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.6.8</cat_node>
				<descriptor>Visual</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010481.10010482.10010486</concept_id>
				<concept_desc>CCS->Applied computing->Operations research->Industry and manufacturing->Command and control</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010349.10010365</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation types and techniques->Visual analytics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10002952.10003190.10003192</concept_id>
				<concept_desc>CCS->Information systems->Data management systems->Database management system engines->Database query processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010111.10011711</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Database theory->Database query processing and optimization (theory)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP28016971</person_id>
				<author_profile_id><![CDATA[81100535537]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kaidi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95031931</person_id>
				<author_profile_id><![CDATA[81414615435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15035890</person_id>
				<author_profile_id><![CDATA[81100547163]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Tirpak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P645228</person_id>
				<author_profile_id><![CDATA[81392596660]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Andreas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schaller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>672836</ref_obj_id>
				<ref_obj_pid>645920</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal and R. Srikant. "Fast algorithm for mining association rules" <i>VLDB-94</i>, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>673157</ref_obj_id>
				<ref_obj_pid>645921</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. Agrawal, Giuseppe Psaila, Edward L. Wimmers, Mohamed Zait. "Querying Shapes of Histories". <i>VLDB-95</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>74700</ref_obj_id>
				<ref_obj_pid>74697</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[R.A. Baeza-Yates. "Algorithms for string matching: A survey". <i>ACM SIGIR Forum</i>, 23(3-4):34-58, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>319445</ref_obj_id>
				<ref_obj_pid>319351</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Goel, C. Baker, C. Shaffer, B. Grossman, R. Haftka, W. Mason, and L. Watson. "VizCraft: A Multidimensional Visualization Tool for Aircraft Configuration Design". <i>IEEE Visualization'99</i>, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>30303</ref_obj_id>
				<ref_obj_pid>30300</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Inselberg, B. Dimsdale. "Parallel Coordinates for Visualizing Multi-Dimensional Geometry". <i>In Proceedings of the Computer Graphics Intl. Conf.</i> 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>617913</ref_obj_id>
				<ref_obj_pid>616032</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Keim and H.-P. Kriegel. "VisDB: Database Exploration using Multidimensional Visualization". <i>IEEE Computer Graphics and Applications</i>, 14(5):40-49, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Ma, J. Hellerstein. "Ordering Categorical Data to Improve Visualization". <i>Info Vis99</i>. 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>152181</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Quinlan. "C4.5: program for machine learning". <i>Morgan Kaufmann</i>, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>952062</ref_obj_id>
				<ref_obj_pid>951949</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[K. Zhao, B. Liu, T. Tirpak, and A. Schaller. "Detecting patterns of change using enhanced parallel coordinates visualization". <i>UIC-CS technical report, 2003</i>.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
	</article_rec>
	<article_rec>
		<article_id>952196</article_id>
		<sort_key>751</sort_key>
		<display_label></display_label>
		<pages>751</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>135</seq_no>
		<title><![CDATA[Invited Talks]]></title>
		<page_from>751</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952196</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>952197</article_id>
		<sort_key>752</sort_key>
		<display_label></display_label>
		<pages>752</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>136</seq_no>
		<title><![CDATA[Tutorials]]></title>
		<page_from>752</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952197</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>952189</article_id>
		<sort_key>753</sort_key>
		<display_label></display_label>
		<pages>753</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>137</seq_no>
		<title><![CDATA[Workshops]]></title>
		<page_from>753</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952189</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>952067</article_id>
		<sort_key>754</sort_key>
		<display_label></display_label>
		<pages>754</pages>
		<article_publication_date>11-19-2003</article_publication_date>
		<seq_no>138</seq_no>
		<title><![CDATA[Author Index]]></title>
		<page_from>754</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=952067</url>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
</content>
</proceeding>

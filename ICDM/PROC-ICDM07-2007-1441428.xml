<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>10-28-2007</start_date>
		<end_date>10-31-2007</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url>http://computer.org/proceedings/icdm/2007/3018</conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES11036</series_id>
		<series_title><![CDATA[ICDM]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1441428</proc_id>
	<acronym>ICDM '07</acronym>
	<proc_desc>Proceedings of the 2007 Seventh IEEE International Conference on Data Mining</proc_desc>
	<conference_number></conference_number>
	<proc_class>conference</proc_class>
	<proc_title></proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-7695-3018-4</isbn>
	<issn>1550-4786</issn>
	<eissn></eissn>
	<copyright_year>2007</copyright_year>
	<publication_date>10-28-2007</publication_date>
	<pages></pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB769</publisher_id>
		<publisher_code>IEEEW</publisher_code>
		<publisher_name>IEEE Computer Society</publisher_name>
		<publisher_address>1730 Massachusetts Ave., NW             Washington, DC</publisher_address>
		<publisher_city></publisher_city>
		<publisher_state></publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>20036-1992</publisher_zip_code>
		<publisher_contact></publisher_contact>
		<publisher_phone></publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url></publisher_url>
	</publisher>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>1442148</article_id>
		<sort_key>60</sort_key>
		<display_label>Page</display_label>
		<pages>xii</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Welcome Message from the Conference Chairs]]></title>
		<page_from>xii</page_from>
		<doi_number>10.1109/ICDM.2007.4</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442148</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442149</article_id>
		<sort_key>70</sort_key>
		<display_label>Page</display_label>
		<pages>xiii</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Preface]]></title>
		<page_from>xiii</page_from>
		<doi_number>10.1109/ICDM.2007.111</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442149</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442150</article_id>
		<sort_key>80</sort_key>
		<display_label>Pages</display_label>
		<pages>xiv-xv</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Conference Organization]]></title>
		<page_from>xiv</page_from>
		<page_to>xv</page_to>
		<doi_number>10.1109/ICDM.2007.5</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442150</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442151</article_id>
		<sort_key>90</sort_key>
		<display_label>Pages</display_label>
		<pages>xvi-xix</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Program Committee]]></title>
		<page_from>xvi</page_from>
		<page_to>xix</page_to>
		<doi_number>10.1109/ICDM.2007.6</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442151</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442152</article_id>
		<sort_key>100</sort_key>
		<display_label>Pages</display_label>
		<pages>xx-xxi</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Non-PC Reviewers]]></title>
		<page_from>xx</page_from>
		<page_to>xxi</page_to>
		<doi_number>10.1109/ICDM.2007.112</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442152</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442153</article_id>
		<sort_key>110</sort_key>
		<display_label>Pages</display_label>
		<pages>xxii-xxiii</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Corporate Sponsors]]></title>
		<page_from>xxii</page_from>
		<page_to>xxiii</page_to>
		<doi_number>10.1109/ICDM.2007.113</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442153</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442154</article_id>
		<sort_key>120</sort_key>
		<display_label>Pages</display_label>
		<pages>xxiv-xxvi</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Invited Speakers and Their Talk Descriptions]]></title>
		<page_from>xxiv</page_from>
		<page_to>xxvi</page_to>
		<doi_number>10.1109/ICDM.2007.114</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442154</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442155</article_id>
		<sort_key>130</sort_key>
		<display_label>Pages</display_label>
		<pages>xxvii-xxviii</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Tutorials and Their Descriptions]]></title>
		<page_from>xxvii</page_from>
		<page_to>xxviii</page_to>
		<doi_number>10.1109/ICDM.2007.115</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442155</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442156</article_id>
		<sort_key>140</sort_key>
		<display_label>Pages</display_label>
		<pages>3-12</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[How Much Noise Is Too Much]]></title>
		<subtitle><![CDATA[A Study in Automatic Text Classification]]></subtitle>
		<page_from>3</page_from>
		<page_to>12</page_to>
		<doi_number>10.1109/ICDM.2007.21</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442156</url>
		<abstract>
			<par><![CDATA[Noise is a stark reality in real life data. Especially in the domain of text analytics, it has a significant impact as data cleaning forms a very large part of the data processing cycle. Noisy unstructured text is common in informal settings such as on-line chat, SMS, email, newsgroups and blogs, automatically transcribed text from speech, and automatically recognized text from printed or handwritten material. Gigabytes of such data is being generated everyday on the Internet, in contact centers, and on mobile phones. Researchers have looked at various text mining issues such as pre-processing and cleaning noisy text, information extraction, rule learning, and classification for noisy text. This paper focuses on the issues faced by automatic text classifiers in analyzing noisy documents coming from various sources. The goal of this paper is to bring out and study the effect of different kinds of noise on automatic text classification. Does the nature of such text warrant moving beyond traditional text classification techniques? We present detailed experimental results with simulated noise on the Reuters21578 and 20-newsgroups benchmark datasets. We present interesting results on real-life noisy datasets from various CRM domains.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200448</person_id>
				<author_profile_id><![CDATA[81375592046]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sumeet]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Agarwal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200449</person_id>
				<author_profile_id><![CDATA[81336489465]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shantanu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Godbole]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200450</person_id>
				<author_profile_id><![CDATA[81375591077]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Diwakar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Punjani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200451</person_id>
				<author_profile_id><![CDATA[81418592570]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Shourya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Roy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442157</article_id>
		<sort_key>150</sort_key>
		<display_label>Pages</display_label>
		<pages>13-22</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Clustering Needles in a Haystack]]></title>
		<subtitle><![CDATA[An Information Theoretic Analysis of Minority and Outlier Detection]]></subtitle>
		<page_from>13</page_from>
		<page_to>22</page_to>
		<doi_number>10.1109/ICDM.2007.53</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442157</url>
		<abstract>
			<par><![CDATA[Identifying atypical objects is one of the traditional topics in machine learning. Recently, novel approaches, e.g., Minority Detection and One-class clustering, have explored further to identify clusters of atypical objects which strongly contrast from the rest of the data in terms of their distribution or density. This paper analyzes such tasks from an information theoretic perspective. Based on Information Bottleneck formalization, these tasks interpret to increasing the averaged atypicalness of the clusters while reducing the complexity of the clustering. This formalization yields a unifying view of the new approaches as well as the classic outlier detection. We also present a scalable minimization algorithm which exploits the localized form of the cost function over individual clusters. The proposed algorithm is evaluated using simulated datasets and a text classification benchmark, in comparison with an existing method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201406</person_id>
				<author_profile_id><![CDATA[81100486044]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ando]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442048</article_id>
		<sort_key>160</sort_key>
		<display_label>Pages</display_label>
		<pages>23-32</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Efficient Data Sampling in Heterogeneous Peer-to-Peer Networks]]></title>
		<page_from>23</page_from>
		<page_to>32</page_to>
		<doi_number>10.1109/ICDM.2007.71</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442048</url>
		<abstract>
			<par><![CDATA[Performing data-mining tasks such as clustering, classification, and prediction on large datasets is an arduous task and, many times, it is an infeasible task given current hardware limitations. The distributed nature of peer-to-peer databases further complicates this issue by introducing an access overhead cost in addition to the cost of sending individual tuples over the network. We propose a two-level sampling approach focusing on peer-to-peer databases for maximizing sample quality given a user-defined communication budget. Given that individual peers may have varying cardinality we propose an algorithm for determining the optimal sample rate (the percentage of tuples to sample from a peer) for each peer. We do this by analyzing the variance of individual peers, ultimately minimizing the total variance of the entire sample. By performing local optimization of individual peer sample rates we maximize approximation accuracy of the samples. We also offer several techniques for sampling in peer-to-peer databases given various amounts of known and unknown information about the network and its peers.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200120</person_id>
				<author_profile_id><![CDATA[81408595268]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Benjamin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Arai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200121</person_id>
				<author_profile_id><![CDATA[81100221381]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Song]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200122</person_id>
				<author_profile_id><![CDATA[81100515024]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dimitrios]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gunopulos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442049</article_id>
		<sort_key>170</sort_key>
		<display_label>Pages</display_label>
		<pages>33-42</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Temporal Analysis of Semantic Graphs Using ASALSAN]]></title>
		<page_from>33</page_from>
		<page_to>42</page_to>
		<doi_number>10.1109/ICDM.2007.54</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442049</url>
		<abstract>
			<par><![CDATA[ASALSAN is a new algorithm for computing three-way DEDICOM, which is a linear algebra model for analyzing intrinsically asymmetric relationships, such as trade among nations or the exchange of emails among individuals, that incorporates a third mode of the data, such as time. ASALSAN is unique because it enables computing the three-way DEDICOM model on large, sparse data. A nonnegative version of ASALSAN is described as well. When we apply these techniques to adjacency arrays arising from directed graphs with edges labeled by time, we obtain a smaller graph on latent semantic dimensions and gain additional information about their changing relationships over time. We demonstrate these techniques on international trade data and the Enron email corpus to uncover latent components and their transient behavior. The mixture of roles assigned to individuals by ASALSAN showed strong correspondence with known job classifications and revealed the patterns of communication between these roles. Changes in the communication pattern over time, e.g., between top executives and the legal department, were also apparent in the solutions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201547</person_id>
				<author_profile_id><![CDATA[81100165342]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Brett]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Bader]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201548</person_id>
				<author_profile_id><![CDATA[81332503177]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Harshman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201549</person_id>
				<author_profile_id><![CDATA[81100225962]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tamara]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Kolda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442050</article_id>
		<sort_key>180</sort_key>
		<display_label>Pages</display_label>
		<pages>43-52</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Scalable Collaborative Filtering with Jointly Derived Neighborhood Interpolation Weights]]></title>
		<page_from>43</page_from>
		<page_to>52</page_to>
		<doi_number>10.1109/ICDM.2007.90</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442050</url>
		<abstract>
			<par><![CDATA[Recommender systems based on collaborative filtering predict user preferences for products or services by learning past user-item relationships. A predominant approach to collaborative filtering is neighborhood based (" k-nearest neighbors"), where a user-item preference rating is interpolated from ratings of similar items and/or users. We enhance the neighborhood-based approach leading to substantial improvement of prediction accuracy, without a meaningful increase in running time. First, we remove certain so-called "global effects" from the data to make the ratings more comparable, thereby improving interpolation accuracy. Second, we show how to simultaneously derive interpolation weights for all nearest neighbors, unlike previous approaches where each weight is computed separately. By globally solving a suitable optimization problem, this simultaneous interpolation accounts for the many interactions between neighbors leading to improved accuracy. Our method is very fast in practice, generating a prediction in about 0.2 milliseconds. Importantly, it does not require training many parameters or a lengthy preprocessing, making it very practical for large scale applications. Finally, we show how to apply these methods to the perceivably much slower user-oriented approach. To this end, we suggest a novel scheme for low dimensional embedding of the users. We evaluate these methods on the Netflix dataset, where they deliver significantly better results than the commercial Netflix Cinematch recommender system.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200123</person_id>
				<author_profile_id><![CDATA[81100405995]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Bell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200124</person_id>
				<author_profile_id><![CDATA[81100202295]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yehuda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Koren]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442051</article_id>
		<sort_key>190</sort_key>
		<display_label>Pages</display_label>
		<pages>53-62</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Rule Cubes for Causal Investigations]]></title>
		<page_from>53</page_from>
		<page_to>62</page_to>
		<doi_number>10.1109/ICDM.2007.29</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442051</url>
		<abstract>
			<par><![CDATA[With the complexity of modern vehicles tremendously increasing, quality engineers play a key role within today's automotive industry. Field data analysis supports corrective actions in development, production and after sales support. We decompose the requirements and show that association rules, being a popular approach to generating explanative models, still exhibit shortcomings. Recently proposed interactive rule cubes are a promising alternative. We extend this work by introducing a way of intuitively visualizing and meaningfully ranking them. Moreover, we present methods to interactively factorize a problem and validate hypotheses by ranking patterns based on expectations, and by browsing a cube-based network of related influences. All this is currently in use as an interactive tool for warranty data analysis in the automotive industry. A real-world case study shows how engineers successfully use it in identifying root causes of quality issues.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202490</person_id>
				<author_profile_id><![CDATA[81416601244]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Axel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Blumenstock]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202491</person_id>
				<author_profile_id><![CDATA[81100285213]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Franz]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schweiggert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202492</person_id>
				<author_profile_id><![CDATA[81375600700]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Markus]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Muller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442052</article_id>
		<sort_key>200</sort_key>
		<display_label>Pages</display_label>
		<pages>63-72</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[The Chosen Few]]></title>
		<subtitle><![CDATA[On Identifying Valuable Patterns]]></subtitle>
		<page_from>63</page_from>
		<page_to>72</page_to>
		<doi_number>10.1109/ICDM.2007.85</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442052</url>
		<abstract>
			<par><![CDATA[Constrained pattern mining extracts patterns based on their individual merit. Usually this results in far more patterns than a human expert or a machine learning technique could make use of. Often different patterns or combinations of patterns cover a similar subset of the examples, thus being redundant and not carrying any new information. To remove the redundant information contained in such pattern sets, we propose a general heuristic approach for selecting a small subset of patterns. We identify several selection techniques for use in this general algorithm and evaluate those on several data sets. The results show that the technique succeeds in severely reducing the number of patterns, while at the same time apparently retaining much of the original information. Additionally the experiments show that reducing the pattern set indeed improves the quality of classification results. Both results show that the approach is very well suited for the goals we aim at.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201550</person_id>
				<author_profile_id><![CDATA[81100467326]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bjorn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bringmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201551</person_id>
				<author_profile_id><![CDATA[81309502970]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Albrecht]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zimmermann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442059</article_id>
		<sort_key>210</sort_key>
		<display_label>Pages</display_label>
		<pages>73-82</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Spectral Regression]]></title>
		<subtitle><![CDATA[A Unified Approach for Sparse Subspace Learning]]></subtitle>
		<page_from>73</page_from>
		<page_to>82</page_to>
		<doi_number>10.1109/ICDM.2007.89</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442059</url>
		<abstract>
			<par><![CDATA[Recently the problem of dimensionality reduction (or, subspace learning) has received a lot of interests in many fields of information processing, including data mining, information retrieval, and pattern recognition. Some popular methods include Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA) and Locality Preserving Projection (LPP). However, a disadvantage of all these approaches is that the learned projective functions are linear combinations of all the original features, thus it is often difficult to interpret the results. In this paper, we propose a novel dimensionality reduction framework, called Unified Sparse Subspace Learning (USSL), for learning sparse projections. USSL casts the problem of learning the projective functions into a regression framework, which facilitates the use of different kinds of regularizers. By using a L1-norm regularizer (lasso), the sparse projections can be efficiently computed. Experimental results on real world classification and clustering problems demonstrate the effectiveness of our method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200148</person_id>
				<author_profile_id><![CDATA[81100430245]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Deng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200149</person_id>
				<author_profile_id><![CDATA[81418598002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xiaofei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200150</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442060</article_id>
		<sort_key>220</sort_key>
		<display_label>Pages</display_label>
		<pages>83-92</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Mining Frequent Itemsets in a Stream]]></title>
		<page_from>83</page_from>
		<page_to>92</page_to>
		<doi_number>10.1109/ICDM.2007.66</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442060</url>
		<abstract>
			<par><![CDATA[We study the problem of finding frequent itemsets in a continuous stream of transactions. The current frequency of an itemset in a stream is defined as its maximal frequency over all possible windows in the stream from any point in the past until the current state that satisfy a minimal length constraint. Properties of this new measure are studied and an incremental algorithm that allows, at any time, to immediately produce the current frequencies of all frequent itemsets is proposed. Experimental and theoretical analysis show that the space requirements for the algorithm are extremely small for many realistic data distributions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202880</person_id>
				<author_profile_id><![CDATA[81100650328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Toon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Calders]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202881</person_id>
				<author_profile_id><![CDATA[81314493548]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nele]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dexters]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202882</person_id>
				<author_profile_id><![CDATA[81100529915]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bart]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goethals]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442061</article_id>
		<sort_key>230</sort_key>
		<display_label>Pages</display_label>
		<pages>93-102</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[A Cascaded Approach to Biomedical Named Entity Recognition Using a Unified Model]]></title>
		<page_from>93</page_from>
		<page_to>102</page_to>
		<doi_number>10.1109/ICDM.2007.20</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442061</url>
		<abstract>
			<par><![CDATA[We propose a cascaded approach for extracting biomedical named entities from text documents using a unified model. Previous works often ignore the high computational cost incurred by a single-phase approach. We alleviate this problem by dividing the named entity extraction task into a segmentation task and a classification task, reducing the computational cost by an order of magnitude. A unified model, which we term "maximum-entropy margin-based" (MEMB), is used in both tasks. The MEMB model considers the error between a correct and an incorrect output during training and helps improve the performance of extracting sparse entity types that occur in biomedical literature. We report experimental evaluations on the GENIA corpus available from the BioNLP/NLPBA (2004) shared task, which demonstrate the state-of-the-art performance achieved by the proposed approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202518</person_id>
				<author_profile_id><![CDATA[81324488510]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shing-Kit]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202519</person_id>
				<author_profile_id><![CDATA[81423592360]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lam]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202520</person_id>
				<author_profile_id><![CDATA[81384618663]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xiaofeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442062</article_id>
		<sort_key>240</sort_key>
		<display_label>Pages</display_label>
		<pages>103-112</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Incorporating User Provided Constraints into Document Clustering]]></title>
		<page_from>103</page_from>
		<page_to>112</page_to>
		<doi_number>10.1109/ICDM.2007.67</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442062</url>
		<abstract>
			<par><![CDATA[Document clustering without any prior knowledge or background information is a challenging problem. In this paper, we propose SS-NMF: a semi-supervised nonnegative matrix factorization framework for document clustering. In SS-NMF, users are able to provide supervision for document clustering in terms of pairwise constraints on a few documents specifying whether they "must" or "cannot" be clustered together. Through an iterative algorithm, we perform symmetric tri-factorization of the documentdocument similarity matrix to infer the document clusters. Theoretically, we show that SS-NMF provides a general framework for semi-supervised clustering and that existing approaches can be considered as special cases of SS-NMF. Through extensive experiments conducted on publicly available data sets, we demonstrate the superior performance of SS-NMF for clustering documents.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202024</person_id>
				<author_profile_id><![CDATA[81337488441]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yanhua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202025</person_id>
				<author_profile_id><![CDATA[81337492554]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Manjeet]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rege]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202026</person_id>
				<author_profile_id><![CDATA[81408594180]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202027</person_id>
				<author_profile_id><![CDATA[81410592467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hua]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442063</article_id>
		<sort_key>250</sort_key>
		<display_label>Pages</display_label>
		<pages>113-122</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Depth-Based Novelty Detection and Its Application to Taxonomic Research]]></title>
		<page_from>113</page_from>
		<page_to>122</page_to>
		<doi_number>10.1109/ICDM.2007.10</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442063</url>
		<abstract>
			<par><![CDATA[It is estimated that less than 10 percent of the world's species have been described, yet species are being lost daily due to human destruction of natural habitats. The job of describing the earth's remaining species is exacerbated by the shrinking number of practicing taxonomists and the very slow pace of traditional taxonomic research. In this article, we tackle, from a novelty detection perspective, one of the most important and challenging research objectives in taxonomy  new species identification. We propose a unique and efficient novelty detection framework based on statistical depth functions. Statistical depth functions provide from the "deepest" point a "center-outward ordering" of multidimensional data. In this sense, they can detect observations that appear extreme relative to the rest of the observations, i.e., novelty. Of the various statistical depths, the spatial depth is especially appealing because of its computational efficiency and mathematical tractability. We propose a novel statistical depth, the kernelized spatial depth (KSD) that generalizes the spatial depth via positive definite kernels. By choosing a proper kernel, the KSD can capture the local structure of a data set while the spatial depth fails. Observations with depth values less than a threshold are declared as novel. The proposed algorithm is simple in structure: the threshold is the only one parameter for a given kernel. We give an upper bound on the false alarm probability of a depth-based detector, which can be used to determine the threshold. Experimental study demonstrates its excellent potential in new species discovery.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200151</person_id>
				<author_profile_id><![CDATA[81375605903]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yixin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200152</person_id>
				<author_profile_id><![CDATA[81375620652]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[L.  Bart]]></middle_name>
				<last_name><![CDATA[Jr.]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200153</person_id>
				<author_profile_id><![CDATA[81416599498]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200154</person_id>
				<author_profile_id><![CDATA[81375599780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hanxiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442065</article_id>
		<sort_key>260</sort_key>
		<display_label>Pages</display_label>
		<pages>123-132</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Detecting Fractures in Classifier Performance]]></title>
		<page_from>123</page_from>
		<page_to>132</page_to>
		<doi_number>10.1109/ICDM.2007.106</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442065</url>
		<abstract>
			<par><![CDATA[A fundamental tenet assumed by many classification algorithms is the presumption that both training and testing samples are drawn from the same distribution of data  this is the stationary distribution assumption. This entails that the past is strongly indicative of the future. However, in real world applications, many factors may alter the One True Model responsible for generating the data distribution both significantly and subtly. In circumstances violating the stationary distribution assumption, traditional validation schemes such as ten-folds and hold-out become poor performance predictors and classifier rankers. Thus, it becomes critical to discover the fracture points in classifier performance by discovering the divergence between populations. In this paper, we implement a comprehensive evaluation framework to identify bias, enabling selection of a "correct" classifier given the sample bias. To thoroughly evaluate the performance of classifiers within biased distributions, we consider the following three scenarios: missing completely at random (akin to stationary); missing at random; and missing not at random. The latter reflects the canonical sample selection bias problem.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203373</person_id>
				<author_profile_id><![CDATA[81350572439]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Cieslak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203374</person_id>
				<author_profile_id><![CDATA[81100002770]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nitesh]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Chawla]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442066</article_id>
		<sort_key>270</sort_key>
		<display_label>Pages</display_label>
		<pages>133-142</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Non-redundant Multi-view Clustering via Orthogonalization]]></title>
		<page_from>133</page_from>
		<page_to>142</page_to>
		<doi_number>10.1109/ICDM.2007.94</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442066</url>
		<abstract>
			<par><![CDATA[Typical clustering algorithms output a single clustering of the data. However, in real world applications, data can often be interpreted in many different ways; data can have different groupings that are reasonable and interesting from different perspectives. This is especially true for high-dimensional data, where different feature subspaces may reveal different structures of the data. Why commit to one clustering solution while all these alternative clustering views might be interesting to the user. In this paper, we propose a new clustering paradigm for explorative data analysis: find all non-redundant clustering views of the data, where data points of one cluster can belong to different clusters in other views. We present a framework to solve this problem and suggest two approaches within this framework: (1) orthogonal clustering, and (2) clustering in orthogonal subspaces. In essence, both approaches find alternative ways to partition the data by projecting it to a space that is orthogonal to our current solution. The first approach seeks orthogonality in the cluster space, while the second approach seeks orthogonality in the feature space. We test our framework on both synthetic and high-dimensional benchmark data sets, and the results show that indeed our approaches were able to discover varied solutions that are interesting and meaningful. keywords: multi-view clustering, non-redundant clustering, orthogonalization]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202050</person_id>
				<author_profile_id><![CDATA[81351594984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cui]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202051</person_id>
				<author_profile_id><![CDATA[81100360432]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xiaoli]]></first_name>
				<middle_name><![CDATA[Z.]]></middle_name>
				<last_name><![CDATA[Fern]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202052</person_id>
				<author_profile_id><![CDATA[81100485643]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jennifer]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Dy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442067</article_id>
		<sort_key>280</sort_key>
		<display_label>Pages</display_label>
		<pages>143-152</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[On Appropriate Assumptions to Mine Data Streams]]></title>
		<subtitle><![CDATA[Analysis and Practice]]></subtitle>
		<page_from>143</page_from>
		<page_to>152</page_to>
		<doi_number>10.1109/ICDM.2007.96</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442067</url>
		<abstract>
			<par><![CDATA[Recent years have witnessed an increasing number of studies in stream mining, which aim at building an accurate model for continuously arriving data. Somehow most existing work makes the implicit assumption that the training data and the yet-to-come testing data are always sampled from the "same distribution&#148;, and yet this "same distribution&#148; evolves over time. We demonstrate that this may not be true, and one actually may never know either "how&#148; or "when&#148; the distribution changes. Thus, a model that fits well on the observed distribution can have unsatisfactory accuracy on the incoming data. Practically, one can just assume the bare minimum that learning from observed data is better than both random guessing and always predicting exactly the same class label. Importantly, we formally and experimentally demonstrate the robustness of a model averaging and simple voting-based framework for data streams, particularly when incoming data "continuously follows significantly different&#148; distributions. On a real streaming data, this framework reduces the expected error of baseline models by 60%, and remains the most accurate compared to those baseline models.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201152</person_id>
				<author_profile_id><![CDATA[81314494134]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201153</person_id>
				<author_profile_id><![CDATA[81367591181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201154</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442064</article_id>
		<sort_key>290</sort_key>
		<display_label>Pages</display_label>
		<pages>153-162</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[ORIGAMI]]></title>
		<subtitle><![CDATA[Mining Representative Orthogonal Graph Patterns]]></subtitle>
		<page_from>153</page_from>
		<page_to>162</page_to>
		<doi_number>10.1109/ICDM.2007.45</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442064</url>
		<abstract>
			<par><![CDATA[In this paper, we introduce the concept of -orthogonal patterns to mine a representative set of graph patterns. Intuitively, two graph patterns are -orthogonal if their similarity is bounded above by . Each -orthogonal pattern is also a representative for those patterns that are at least similar to it. Given user defined , [0, 1], the goal is to mine an -orthogonal, -representative set that minimizes the set of unrepresented patterns. We present ORIGAMI, an effective algorithm for mining the set of representative orthogonal patterns. ORIGAMI first uses a randomized algorithm to randomly traverse the pattern space, seeking previously unexplored regions, to return a set of maximal patterns. ORIGAMI then extracts an orthogonal, -representative set from the mined maximal patterns. We show the effectiveness of our algorithm on a number of real and synthetic datasets. In particular, we show that our method is able to extract high quality patterns even in cases where existing enumerative graph mining methods fail to do so.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203343</person_id>
				<author_profile_id><![CDATA[81418593670]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mohammad]]></first_name>
				<middle_name><![CDATA[Al]]></middle_name>
				<last_name><![CDATA[Hasan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203344</person_id>
				<author_profile_id><![CDATA[81361609414]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vineet]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chaoji]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203345</person_id>
				<author_profile_id><![CDATA[81375599301]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Saeed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Salem]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203346</person_id>
				<author_profile_id><![CDATA[81100044456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jeremy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Besson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203347</person_id>
				<author_profile_id><![CDATA[81100229027]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Mohammed]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Zaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442068</article_id>
		<sort_key>300</sort_key>
		<display_label>Pages</display_label>
		<pages>163-172</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Efficient Algorithms for Mining Significant Substructures in Graphs with Quality Guarantees]]></title>
		<page_from>163</page_from>
		<page_to>172</page_to>
		<doi_number>10.1109/ICDM.2007.11</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442068</url>
		<abstract>
			<par><![CDATA[Graphs have become popular for modeling scientific data in recent years. As a result, techniques for mining graphs are extremely important for understanding inherent data and domain characteristics. One such exploratory mining paradigm is the k-MST (minimum spanning tree over k vertices) problem that can be used to discover significant local substructures. In this paper, we present an efficient approximation algorithm for the k-MST problem in large graphs. The algorithm has an O (k) approximation ratio and O (n log n + m log m log k + nk2 log k) running time, where n and m are the number of vertices and edges respectively. Experimental results on synthetic graphs and protein interaction networks show that the algorithm is scalable to large graphs and useful for discovering biological pathways. The highlight of the algorithm is that it offers both analytical guarantees and empirical evidence of good running time and quality.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201592</person_id>
				<author_profile_id><![CDATA[81313484540]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Huahai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201593</person_id>
				<author_profile_id><![CDATA[81408600777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ambuj]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Singh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442069</article_id>
		<sort_key>310</sort_key>
		<display_label>Pages</display_label>
		<pages>173-182</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Dynamic Micro Targeting]]></title>
		<subtitle><![CDATA[Fitness-Based Approach to Predicting Individual Preferences]]></subtitle>
		<page_from>173</page_from>
		<page_to>182</page_to>
		<doi_number>10.1109/ICDM.2007.14</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442069</url>
		<abstract>
			<par><![CDATA[It is crucial to segment customers intelligently in order to offer more targeted and personalized products and services. Traditionally, customer segmentation is achieved using statistics-based methods that compute a set of statistics from the customer data and group customers into segments by applying clustering algorithms. Recent research proposed a direct grouping-based approach that combines customers into segments by optimally combining transactional data of several customers and building a data mining model of customer behavior for each group. This paper proposes a new micro targeting method that builds predictive models of customer behavior not on the segments of customers but rather on the customer-product groups. This micro-targeting method is more general than the previously considered direct grouping method. We empirically show that it significantly outperforms the direct grouping and statistics-based segmentation methods across multiple experimental conditions and that it generates predominately small-sized segments, thus providing additional support for the micro-targeting approach to personalization. Index Terms: Customer segmentation, marketing application, personalization, micro targeting, customer profiles]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201594</person_id>
				<author_profile_id><![CDATA[81100607875]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tianyi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201595</person_id>
				<author_profile_id><![CDATA[81100364633]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tuzhilin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442070</article_id>
		<sort_key>320</sort_key>
		<display_label>Pages</display_label>
		<pages>183-192</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Data Discretization Unification]]></title>
		<page_from>183</page_from>
		<page_to>192</page_to>
		<doi_number>10.1109/ICDM.2007.35</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442070</url>
		<abstract>
			<par><![CDATA[Data discretization is defined as a process of converting continuous data attribute values into a finite set of intervals with minimal loss of information. In this paper, we prove that discretization methods based on informational theoretical complexity and the methods based on statistical measures of data dependency are asymptotically equivalent. Furthermore, we define a notion of generalized entropy and prove that discretization methods based on MDLP, Gini Index, AIC, BIC, and Pearson's X2 and G2 statistics are all derivable from the generalized entropy function. We design a dynamic programming algorithm that guarantees the best discretization based on the generalized entropy notion. Furthermore, we conducted an extensive performance evaluation of our method for several publicly available data sets. Our results show that our method delivers on the average 31% less classification errors than many previously known discretization methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203387</person_id>
				<author_profile_id><![CDATA[81100054574]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ruoming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203388</person_id>
				<author_profile_id><![CDATA[81540398856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yuri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Breitbart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203389</person_id>
				<author_profile_id><![CDATA[81418598534]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chibuike]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Muoh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442071</article_id>
		<sort_key>330</sort_key>
		<display_label>Pages</display_label>
		<pages>193-202</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Improving Knowledge Discovery in Document Collections through Combining Text Retrieval and Link Analysis Techniques]]></title>
		<page_from>193</page_from>
		<page_to>202</page_to>
		<doi_number>10.1109/ICDM.2007.62</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442071</url>
		<abstract>
			<par><![CDATA[In this paper, we present Concept Chain Queries (CCQ), a special case of text mining in document collections focusing on detecting links between two topics across text documents. We interpret such a query as finding the most meaningful evidence trails across documents that connect these two topics. We propose to use link-analysis techniques over the extracted features provided by Information Extraction Engine for finding new knowledge. A graphical text representation and mining model is proposed which combines information retrieval, association mining and link analysis techniques. We present experiments on different datasets that demonstrate the effectiveness of our algorithm. Specifically, the algorithm generates ranked concept chains and evidence trails where the key terms representing significant relationships between topics are ranked high1.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202064</person_id>
				<author_profile_id><![CDATA[81451595985]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202065</person_id>
				<author_profile_id><![CDATA[81100243324]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rohini]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Srihari]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202066</person_id>
				<author_profile_id><![CDATA[81375610304]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hung]]></first_name>
				<middle_name><![CDATA[Hay]]></middle_name>
				<last_name><![CDATA[Ho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202067</person_id>
				<author_profile_id><![CDATA[81438595552]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Xin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442072</article_id>
		<sort_key>340</sort_key>
		<display_label>Pages</display_label>
		<pages>203-212</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Finding Cohesive Clusters for Analyzing Knowledge Communities]]></title>
		<page_from>203</page_from>
		<page_to>212</page_to>
		<doi_number>10.1109/ICDM.2007.22</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442072</url>
		<abstract>
			<par><![CDATA[Documents and authors can be clustered into "knowledge communities" based on the overlap in the papers they cite. We introduce a new clustering algorithm, Streemer, which finds cohesive foreground clusters embedded in a diffuse background, and use it to identify knowledge communities as foreground clusters of papers which share common citations. To analyze the evolution of these communities over time, we build predictive models with features based on the citation structure, the vocabulary of the papers, and the affiliations and prestige of the authors. Findings include that scientific knowledge communities tend to grow more rapidly if their publications build on diverse information and if they use a narrow vocabulary.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202900</person_id>
				<author_profile_id><![CDATA[81387595638]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Vasileios]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kandylas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202901</person_id>
				<author_profile_id><![CDATA[81375616995]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[Phineas]]></middle_name>
				<last_name><![CDATA[Upham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202902</person_id>
				<author_profile_id><![CDATA[81100365076]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Lyle]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Ungar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442073</article_id>
		<sort_key>350</sort_key>
		<display_label>Pages</display_label>
		<pages>213-222</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Succinct Matrix Approximation and Efficient k-NN Classification]]></title>
		<page_from>213</page_from>
		<page_to>222</page_to>
		<doi_number>10.1109/ICDM.2007.41</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442073</url>
		<abstract>
			<par><![CDATA[This work reveals that instead of the polynomial bounds in previous literatures there exists a sharper bound of exponential form for the L2 norm of an arbitrary shaped random matrix. Based on the newly elaborated bound, a nonuniform sampling method is presented to succinctly approximate a matrix with a sparse binary one, and thus relieves the computation loads of k-NN classifier in both time and storage. The method is also pass-efficient because sampling and quantizing are combined together in a single step and the whole process can be completed within one pass over the input matrix. In the evaluations on compression ratio and reconstruction error, the sampling method exhibits impressive capability in providing succinct and tight approximations for the input matrices. The most significant finding in the classification experiment is that the k-NN classifier based on the approximation can even outperform the standard one. This provides another strong evidence for the claim that our method is especially capable in capturing intrinsic characteristics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200681</person_id>
				<author_profile_id><![CDATA[81542421956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200682</person_id>
				<author_profile_id><![CDATA[81543287956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442074</article_id>
		<sort_key>360</sort_key>
		<display_label>Pages</display_label>
		<pages>223-231</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[A Pairwise Covariance-Preserving Projection Method for Dimension Reduction]]></title>
		<page_from>223</page_from>
		<page_to>231</page_to>
		<doi_number>10.1109/ICDM.2007.65</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442074</url>
		<abstract>
			<par><![CDATA[Dimension reduction is critical in many areas of pattern classification and machine learning and many discriminant analysis algorithms have been proposed. In this paper, a Pairwise Covariance-preserving Projection Method (PCPM) is proposed for dimension reduction. PCPM maximizes the class discrimination and also preserves approximately the pairwise class covariances. The optimization involved in PCPM can be solved directly by eigenvalues decomposition. Our theoretical and empirical analysis reveals the relationship between PCPM and Linear Discriminant Analysis (LDA), Sliced Average Variance Estimator (SAVE), Heteroscedastic Discriminant Analysis (HDA) and Covariance preserving Projection Method (CPM). PCPM can utilize class mean and class covariance information at the same time. Furthermore, pairwise weight scheme can be incorporated naturally with the pairwise summarization form. The proposed methods are evaluated by both synthetic and real-world datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201609</person_id>
				<author_profile_id><![CDATA[81100530142]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiaoming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201610</person_id>
				<author_profile_id><![CDATA[81375597283]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zhaohui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201611</person_id>
				<author_profile_id><![CDATA[81442600302]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Zhilin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Feng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201612</person_id>
				<author_profile_id><![CDATA[81442594130]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jinshan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442075</article_id>
		<sort_key>370</sort_key>
		<display_label>Pages</display_label>
		<pages>232-241</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Community Learning by Graph Approximation]]></title>
		<page_from>232</page_from>
		<page_to>241</page_to>
		<doi_number>10.1109/ICDM.2007.42</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442075</url>
		<abstract>
			<par><![CDATA[Learning communities from a graph is an important problem in many domains. Different types of communities can be generalized as link-pattern based communities. In this paper, we propose a general model based on graph approximation to learn link-pattern based community structures from a graph. The model generalizes the traditional graph partitioning approaches and is applicable to learning various community structures. Under this model, we derive a family of algorithms which are flexible to learn various community structures and easy to incorporate the prior knowledge of the community structures. Experimental evaluation and theoretical analysis show the effectiveness and great potential of the proposed model and algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200193</person_id>
				<author_profile_id><![CDATA[81375607652]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Long]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200194</person_id>
				<author_profile_id><![CDATA[81375615030]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xiaoyun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200195</person_id>
				<author_profile_id><![CDATA[81451593853]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Zhongfei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200196</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442076</article_id>
		<sort_key>380</sort_key>
		<display_label>Pages</display_label>
		<pages>242-251</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Parallel Mining of Frequent Closed Patterns]]></title>
		<subtitle><![CDATA[Harnessing Modern Computer Architectures]]></subtitle>
		<page_from>242</page_from>
		<page_to>251</page_to>
		<doi_number>10.1109/ICDM.2007.13</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442076</url>
		<abstract>
			<par><![CDATA[Inspired by emerging multi-core computer architectures, in this paper we present MT CLOSED, a multi-threaded algorithm for frequent closed itemset mining (FCIM). To the best of our knowledge, this is the first FCIM parallel algorithm proposed so far. We studied how different duplicate checking techniques, typical of FCIM algorithms, may affect this parallelization. We showed that only one of them allows to decompose the global FCIM problem into independent tasks that can be executed in any order, and thus in parallel. Finally we show how MT CLOSED efficiently harness modern CPUs. We designed and tested several parallelization paradigms by investigating static/dynamic decomposition and scheduling of tasks, thus showing its scalability w.r.t. to the number of CPUs. We analyzed the cache friendliness of the algorithm. Finally, we provided additional speed-up by introducing SIMD extensions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200207</person_id>
				<author_profile_id><![CDATA[81324491771]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Claudio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lucchese]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200208</person_id>
				<author_profile_id><![CDATA[81100280273]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Salvatore]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Orlando]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200209</person_id>
				<author_profile_id><![CDATA[81100009930]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Raffaele]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perego]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442077</article_id>
		<sort_key>390</sort_key>
		<display_label>Pages</display_label>
		<pages>252-261</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[Supervised Learning by Training on Aggregate Outputs]]></title>
		<page_from>252</page_from>
		<page_to>261</page_to>
		<doi_number>10.1109/ICDM.2007.50</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442077</url>
		<abstract>
			<par><![CDATA[Supervised learning is a classic data mining problem where one wishes to be be able to predict an output value associated with a particular input vector. We present a new twist on this classic problem where, instead of having the training set contain an individual output value for each input vector, the output values in the training set are only given in aggregate over a number of input vectors. This new problem arose from a particular need in learning on mass spectrometry data, but could easily apply to situations when data has been aggregated in order to maintain privacy. We provide a formal description of this new problem for both classification and regression. We then examine how k-nearest neighbor, neural networks, and support vector machines can be adapted for this problem.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202085</person_id>
				<author_profile_id><![CDATA[81100258932]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Musicant]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202086</person_id>
				<author_profile_id><![CDATA[81448592603]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Janara]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Christensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202087</person_id>
				<author_profile_id><![CDATA[81375596043]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jamie]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Olson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442078</article_id>
		<sort_key>400</sort_key>
		<display_label>Pages</display_label>
		<pages>262-271</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Sample Selection for Maximal Diversity]]></title>
		<page_from>262</page_from>
		<page_to>271</page_to>
		<doi_number>10.1109/ICDM.2007.16</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442078</url>
		<abstract>
			<par><![CDATA[The problem of selecting a sample subset sufficient to preserve diversity arises in many applications. One example is in the design of recombinant inbred lines (RIL) for genetic association studies. In this context, genetic diversity is measured by how many alleles are retained in the resulting inbred strains. RIL panels that are derived from more than two parental strains, such as the Collaborative Cross [2, 14], present a particular challenge with regard to which of the many existing lab mouse strains should be included in the initial breeding funnel in order to maximize allele retention. A similar problem occurs in the study of customer reviews when selecting a subset of products with a maximal diversity in reviews. Diversity in this case implies the presence of a set of products having both positive and negative ranks for each customer. In this paper, we demonstrate that selecting an optimal diversity subset is an NP-complete problem via reduction to set cover. This reduction is sufficiently tight that greedy approximations to the set cover problem directly apply to maximizing diversity. We then suggest a slightly modified subset selection problem in which an initial greedy diversity solution is used to effectively prune an exhaustive search for all diversity subsets bounded from below by a specified coverage threshold. Extensive experiments on real datasets are performed to demonstrate the effectiveness and efficiency of our approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200689</person_id>
				<author_profile_id><![CDATA[81100484594]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Feng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200690</person_id>
				<author_profile_id><![CDATA[81375598168]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Adam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Roberts]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200691</person_id>
				<author_profile_id><![CDATA[81100137780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Leonard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McMillan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200692</person_id>
				<author_profile_id><![CDATA[81375614640]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Threadgill]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200693</person_id>
				<author_profile_id><![CDATA[81375595421]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442079</article_id>
		<sort_key>410</sort_key>
		<display_label>Pages</display_label>
		<pages>272-281</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Mining Statistical Information of Frequent Fault-Tolerant Patterns in Transactional Databases]]></title>
		<page_from>272</page_from>
		<page_to>281</page_to>
		<doi_number>10.1109/ICDM.2007.48</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442079</url>
		<abstract>
			<par><![CDATA[Constraints applied on classic frequent patterns are too strict and may cause interesting patterns to be missed. Hence, researchers have proposed to mine a more relaxed version of frequent patterns, where transactions are allowed to miss some items in the itemset they support. Patterns exhibiting such "faults" are called frequent fault-tolerant patterns (FFT-patterns) if they are significant in number. In this paper, the term "pattern" is distinguished from "itemset" as referring to a pair (tidset  itemset). Unlike classical frequent patterns, the number of FFTpatterns grows exponentially not only with the number of items, but also with the number of transactions. Since the latter may reach millions, mining FFT-patterns by enumerating them becomes infeasible. Hence, the challenge is to represent FFT-patterns concisely without losing any useful information. To address this, we draw on the observation that, in transactional databases, the transactions themselves are not important from the data mining point-ofview; i.e. researchers are interested in finding itemsets contained in lots of transactions, rather than in the transactions per se. Therefore, we propose to mine only the frequent itemsets along with the statistical information of the supporting transaction sets, rather than enumerate entire FFTpatterns. Then we present our approach the BIAS framework, consisting of Backtracking algorithm, Integer Linear Programming (ILP) constraints, and aggregation statistics to solve this problem. Algorithms under this framework not only increase the efficiency of the FFT-patterns mining process by more than an order of magnitude, but also provide a more comprehensive analysis of FFT-Patterns.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201180</person_id>
				<author_profile_id><![CDATA[81436593426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ardian]]></first_name>
				<middle_name><![CDATA[Kristanto]]></middle_name>
				<last_name><![CDATA[Poernomo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201181</person_id>
				<author_profile_id><![CDATA[81319492485]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vivekanand]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gopalkrishnan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442080</article_id>
		<sort_key>420</sort_key>
		<display_label>Pages</display_label>
		<pages>282-291</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[Lightweight Distributed Trust Propagation]]></title>
		<page_from>282</page_from>
		<page_to>291</page_to>
		<doi_number>10.1109/ICDM.2007.64</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442080</url>
		<abstract>
			<par><![CDATA[Using mobile devices, such as smart phones, people may create and distribute different types of digital content (e.g., photos, videos). One of the problems is that digital content, being easy to create and replicate, may likely swamp users rather than informing them. To avoid that, users may organize content producers that they know and trust in a web of trust. Users may then reason about this web of trust to form opinions about content producers with whom they have never interacted before. These opinions will then determine whether content is accepted. The process of forming opinions is called trust propagation. We design a mechanism for mobile devices that effectively propagates trust and that is lightweight and distributed (as opposed to previous work that focuses on centralized propagation). This mechanism uses a graph-based learning technique. We evaluate the effectiveness (predictive accuracy) of this mechanism against a large real-world data set. We also evaluate the computational cost of a J2ME implementation on a mobile phone.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202922</person_id>
				<author_profile_id><![CDATA[81100232264]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniele]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Quercia]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202923</person_id>
				<author_profile_id><![CDATA[81100138501]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hailes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202924</person_id>
				<author_profile_id><![CDATA[81100419515]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Licia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Capra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442081</article_id>
		<sort_key>430</sort_key>
		<display_label>Pages</display_label>
		<pages>292-301</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Social Network Extraction of Academic Researchers]]></title>
		<page_from>292</page_from>
		<page_to>301</page_to>
		<doi_number>10.1109/ICDM.2007.30</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442081</url>
		<abstract>
			<par><![CDATA[This paper addresses the issue of extraction of an academic researcher social network. By researcher social network extraction, we are aimed at finding, extracting, and fusing the `semantic'-based profiling information of a researcher from the Web. Previously, social network extraction was often undertaken separately in an ad-hoc fashion. This paper first gives a formalization of the entire problem. Specifically, it identifies the `relevant documents' from the Web by a classifier. It then proposes a unified approach to perform the researcher profiling using Conditional Random Fields (CRF). It integrates publications from the existing bibliography datasets. In the integration, it proposes a constraints-based probabilistic model to name disambiguation. Experimental results on an online system show that the unified approach to researcher profiling significantly outperforms the baseline methods of using rule learning or classification. Experimental results also indicate that our method to name disambiguation performs better than the baseline method using unsupervised learning. The methods have been applied to expert finding. Experiments show that the accuracy of expert finding can be significantly improved by using the proposed methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201645</person_id>
				<author_profile_id><![CDATA[81350588685]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201646</person_id>
				<author_profile_id><![CDATA[81363603541]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Duo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201647</person_id>
				<author_profile_id><![CDATA[81350600057]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Limin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442082</article_id>
		<sort_key>440</sort_key>
		<display_label>Pages</display_label>
		<pages>302-311</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[General Averaged Divergence Analysis]]></title>
		<page_from>302</page_from>
		<page_to>311</page_to>
		<doi_number>10.1109/ICDM.2007.105</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442082</url>
		<abstract>
			<par><![CDATA[Subspace selection is a powerful tool in data mining. An important subspace method is the Fisher Rao linear discriminant analysis (LDA), which has been successfully applied in many fields such as biometrics, bioinformatics, and multimedia retrieval. However, LDA has a critical drawback: the projection to a subspace tends to merge those classes that are close together in the original feature space. If the separated classes are sampled from Gaussian distributions, all with identical covariance matrices, then LDA maximizes the mean value of the Kullback Leibler (KL) divergences between the different classes. We generalize this point of view to obtain a framework for choosing a subspace by 1) generalizing the KL divergence to the Bregman divergence and 2) generalizing the arithmetic mean to a general mean. The framework is named the general averaged divergence analysis (GADA). Under this GADA framework, a geometric mean divergence analysis (GMDA) method based on the geometric mean is studied. A large number of experiments based on synthetic data show that our method significantly outperforms LDA and several representative LDA extensions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201648</person_id>
				<author_profile_id><![CDATA[81100159571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dacheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201649</person_id>
				<author_profile_id><![CDATA[81452599228]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xuelong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201650</person_id>
				<author_profile_id><![CDATA[81452596585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xindong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201651</person_id>
				<author_profile_id><![CDATA[81409593039]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Maybank]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442083</article_id>
		<sort_key>450</sort_key>
		<display_label>Pages</display_label>
		<pages>312-321</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[Maximum Entropy Based Significance of Itemsets]]></title>
		<page_from>312</page_from>
		<page_to>321</page_to>
		<doi_number>10.1109/ICDM.2007.43</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442083</url>
		<abstract>
			<par><![CDATA[We consider the problem of defining the significance of an itemset. We say that the itemset is significant if we are surprised by its frequency when compared to the frequencies of its sub-itemsets. In other words, we estimate the frequency of the itemset from the frequencies of its sub-itemsets and compute the deviation between the real value and the estimate. For the estimation we use Maximum Entropy and for measuring the deviation we use Kullback-Leibler divergence. A major advantage compared to the previous methods is that we are able to use richer models whereas the previous approaches only measure the deviation from the independence model. We show that our measure of significance goes to zero for derivable itemsets and that we can use the rank as a statistical test. Our empirical results demonstrate that for our real datasets the independence assumption is too strong but applying more flexible models leads to good results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202101</person_id>
				<author_profile_id><![CDATA[81363600602]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nikolaj]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tatti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442084</article_id>
		<sort_key>460</sort_key>
		<display_label>Pages</display_label>
		<pages>322-331</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[Local Probabilistic Models for Link Prediction]]></title>
		<page_from>322</page_from>
		<page_to>331</page_to>
		<doi_number>10.1109/ICDM.2007.108</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442084</url>
		<abstract>
			<par><![CDATA[One of the core tasks in social network analysis is to predict the formation of links (i.e. various types of relationships) over time. Previous research has generally represented the social network in the form of a graph and has leveraged topological and semantic measures of similarity between two nodes to evaluate the probability of link formation. Here we introduce a novel local probabilistic graphical model method that can scale to large graphs to estimate the joint co-occurrence probability of two nodes. Such a probability measure captures information that is not captured by either topological measures or measures of semantic similarity, which are the dominant measures used for link prediction. We demonstrate the effectiveness of the co-occurrence probability feature by using it both in isolation and in combination with other topological and semantic features for predicting co-authorship collaborations on three real datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201652</person_id>
				<author_profile_id><![CDATA[81375603454]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201653</person_id>
				<author_profile_id><![CDATA[81375618822]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Venu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Satuluri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201654</person_id>
				<author_profile_id><![CDATA[81375608415]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Srinivasan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Parthasarathy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442085</article_id>
		<sort_key>470</sort_key>
		<display_label>Pages</display_label>
		<pages>332-341</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[Improving Text Classification by Using Encyclopedia Knowledge]]></title>
		<page_from>332</page_from>
		<page_to>341</page_to>
		<doi_number>10.1109/ICDM.2007.77</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442085</url>
		<abstract>
			<par><![CDATA[The exponential growth of text documents available on the Internet has created an urgent need for accurate, fast, and general purpose text classification algorithms. However, the "bag of words" representation used for these classification methods is often unsatisfactory as it ignores relationships between important terms that do not co-occur literally. In order to deal with this problem, we integrate background knowledge in our application: Wikipedia into the process of classifying text documents. The experimental evaluation on Reuters newsfeeds and several other corpus shows that our classification results with encyclopedia knowledge are much better than the baseline "bag of words" methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202597</person_id>
				<author_profile_id><![CDATA[81435603235]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202598</person_id>
				<author_profile_id><![CDATA[81329489404]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202599</person_id>
				<author_profile_id><![CDATA[81100630328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hua-Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zeng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202600</person_id>
				<author_profile_id><![CDATA[81375615696]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Lijun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202601</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442086</article_id>
		<sort_key>480</sort_key>
		<display_label>Pages</display_label>
		<pages>342-350</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[Language-Independent Set Expansion of Named Entities Using the Web]]></title>
		<page_from>342</page_from>
		<page_to>350</page_to>
		<doi_number>10.1109/ICDM.2007.104</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442086</url>
		<abstract>
			<par><![CDATA[Set expansion refers to expanding a given partial set of objects into a more complete set. A well-known example system that does set expansion using the web is Google Sets. In this paper, we propose a novel method for expanding sets of named entities. The approach can be applied to semi-structured documents written in any markup language and in any human language. We present experimental results on 36 benchmark sets in three languages, showing that our system is superior to Google Sets in terms of mean average precision.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202944</person_id>
				<author_profile_id><![CDATA[81100212462]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202945</person_id>
				<author_profile_id><![CDATA[81100145736]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Cohen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442087</article_id>
		<sort_key>490</sort_key>
		<display_label>Pages</display_label>
		<pages>351-360</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>44</seq_no>
		<title><![CDATA[Structure-Based Statistical Features and Multivariate Time Series Clustering]]></title>
		<page_from>351</page_from>
		<page_to>360</page_to>
		<doi_number>10.1109/ICDM.2007.103</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442087</url>
		<abstract>
			<par><![CDATA[We propose a new method for clustering multivariate time series. A univariate time series can be represented by a fixed-length vector whose components are statistical features of the time series, capturing the global structure. These descriptive vectors, one for each component of the multivariate time series, are concatenated, before being clustered using a standard fast clustering algorithm such as k-means or hierarchical clustering. Such statistical feature extraction also serves as a dimension-reduction procedure for multivariate time series. We demonstrate the effectiveness and simplicity of our proposed method by clustering human motion sequences: dynamic and high-dimensional multivariate time series. The proposed method based on univariate time series structure and statistical metrics provides a novel, yet simple and flexible way to cluster multivariate time series data efficiently with promising accuracy. The success of our method on the case study suggests that clustering may be a valuable addition to the tools available for human motion pattern recognition research.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202960</person_id>
				<author_profile_id><![CDATA[81100219052]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiaozhe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202961</person_id>
				<author_profile_id><![CDATA[81100261305]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wirth]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202962</person_id>
				<author_profile_id><![CDATA[81375605744]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Liang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442088</article_id>
		<sort_key>500</sort_key>
		<display_label>Pages</display_label>
		<pages>361-370</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>45</seq_no>
		<title><![CDATA[A Generalization of Proximity Functions for K-Means]]></title>
		<page_from>361</page_from>
		<page_to>370</page_to>
		<doi_number>10.1109/ICDM.2007.59</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442088</url>
		<abstract>
			<par><![CDATA[K-means is a widely used partitional clustering method. A large amount of effort has been made on finding better proximity (distance) functions for K-means. However, the common characteristics of proximity functions remain unknown. To this end, in this paper, we show that all proximity functions that fit K-means clustering can be generalized as K-means distance, which can be derived by a differentiable convex function. A general proof of sufficient and necessary conditions for K-means distance functions is also provided. In addition, we reveal that K-means has a general uniformization effect; that is, K-means tends to produce clusters with relatively balanced cluster sizes. This uniformization effect of K-means exists regardless of proximity functions. Finally, we have conducted extensive experiments on various real-world data sets, and the results show the evidence of the uniformization effect. Also, we observed that external clustering validation measures, such as Entropy and Variance of Information (VI), have difficulty in measuring clustering quality if data have skewed distributions on class sizes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202603</person_id>
				<author_profile_id><![CDATA[81375612119]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Junjie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202604</person_id>
				<author_profile_id><![CDATA[81451596433]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xiong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202605</person_id>
				<author_profile_id><![CDATA[81309495279]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202606</person_id>
				<author_profile_id><![CDATA[81375615165]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wenjun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442089</article_id>
		<sort_key>510</sort_key>
		<display_label>Pages</display_label>
		<pages>371-380</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>46</seq_no>
		<title><![CDATA[Multilevel Belief Propagation for Fast Inference on Markov Random Fields]]></title>
		<page_from>371</page_from>
		<page_to>380</page_to>
		<doi_number>10.1109/ICDM.2007.9</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442089</url>
		<abstract>
			<par><![CDATA[Graph-based inference plays an important role in many mining and learning tasks. Among all the solvers for this problem, belief propagation (BP) provides a general and efficient way to derive approximate solutions. However, for large scale graphs the computational cost of BP is still demanding. In this paper, we propose a multilevel algorithm to accelerate belief propagation on Markov Random Fields (MRF). First, we coarsen the original graph to get a smaller one. Then, BP is applied on the new graph to get a coarse result. Finally the coarse solution is efficiently refined back to derive the original solution. Unlike traditional multiresolution approaches, our method features adaptive coarsening and efficient refinement. The above process can be recursively applied to reduce the computational cost remarkably. We theoretically justify the feasibility of our method on Gaussian MRFs, and empirically show that it is also effectual on discrete MRFs. The effectiveness of our method is verified in experiments on various inference tasks.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202116</person_id>
				<author_profile_id><![CDATA[81375594505]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Liang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xiong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202117</person_id>
				<author_profile_id><![CDATA[81375591936]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202118</person_id>
				<author_profile_id><![CDATA[81375600089]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Changshui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442090</article_id>
		<sort_key>520</sort_key>
		<display_label>Pages</display_label>
		<pages>381-390</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>47</seq_no>
		<title><![CDATA[Disk Aware Discord Discovery]]></title>
		<subtitle><![CDATA[Finding Unusual Time Series in Terabyte Sized Datasets]]></subtitle>
		<page_from>381</page_from>
		<page_to>390</page_to>
		<doi_number>10.1109/ICDM.2007.61</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442090</url>
		<abstract>
			<par><![CDATA[The problem of finding unusual time series has recently attracted much attention, and several promising methods are now in the literature. However, virtually all proposed methods assume that the data reside in main memory. For many real-world problems this is not be the case. For example, in astronomy, multi-terabyte time series datasets are the norm. Most current algorithms faced with data which cannot fit in main memory resort to multiple scans of the disk/tape and are thus intractable. In this work we show how one particular definition of unusual time series, the time series discord, can be discovered with a disk aware algorithm. The proposed algorithm is exact and requires only two linear scans of the disk with a tiny buffer of main memory. Furthermore, it is very simple to implement. We use the algorithm to provide further evidence of the effectiveness of the discord definition in areas as diverse as astronomy, web query mining, video surveillance, etc., and show the efficiency of our method on datasets which are many orders of magnitude larger than anything else attempted in the literature.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201674</person_id>
				<author_profile_id><![CDATA[81309492747]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dragomir]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yankov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201675</person_id>
				<author_profile_id><![CDATA[81100209161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eamonn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Keogh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201676</person_id>
				<author_profile_id><![CDATA[81375619048]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Umaa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rebbapragada]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442091</article_id>
		<sort_key>530</sort_key>
		<display_label>Pages</display_label>
		<pages>391-400</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>48</seq_no>
		<title><![CDATA[Binary Matrix Factorization with Applications]]></title>
		<page_from>391</page_from>
		<page_to>400</page_to>
		<doi_number>10.1109/ICDM.2007.99</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442091</url>
		<abstract>
			<par><![CDATA[An interesting problem in Nonnegative Matrix Factorization (NMF) is to factorize the matrix X which is of some specific class, for example, binary matrix. In this paper, we extend the standard NMF to Binary Matrix Factorization (BMF for short): given a binary matrix X , we want to factorize X into two binary matrices W ,H (thus conserving the most important integer property of the objective matrix X ) satisfying X WH. Two algorithms are studied and compared. These methods rely on a fundamental boundedness property of NMF which we propose and prove. This new property also provides a natural normalization scheme that eliminates the bias of factor matrices. Experiments on both synthetic and real world datasets are conducted to show the competency and effectiveness of BMF.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200248</person_id>
				<author_profile_id><![CDATA[81453627292]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zhongyuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200249</person_id>
				<author_profile_id><![CDATA[81100475528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200250</person_id>
				<author_profile_id><![CDATA[81100136610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ding]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200251</person_id>
				<author_profile_id><![CDATA[81375609870]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Xiangsun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442092</article_id>
		<sort_key>540</sort_key>
		<display_label>Pages</display_label>
		<pages>403-408</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>49</seq_no>
		<title><![CDATA[A Semantic Kernel for Semi-structured DocumentS]]></title>
		<page_from>403</page_from>
		<page_to>408</page_to>
		<doi_number>10.1109/ICDM.2007.23</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442092</url>
		<abstract>
			<par><![CDATA[Natural Language Processing has emerged as an active field of research in the machine learning community. Several methods based on statistical information have been proposed. However, with the linguistic complexity of the texts, semantic-based approaches have been investigated. In this paper, we propose a Semantic Kernel for semistructured biomedical documents. The semantic meanings of words are extracted using the UMLS framework. The kernel, with a SVM classifier, has been applied to a text categorization task on a medical corpus of free text documents. The results have shown that the Semantic Kernel outperforms the Linear Kernel and the Naive Bayes classifier. Moreover, this kernel was ranked in the top ten of the best algorithms among 44 classification methods at the 2007 CMC Medical NLP International Challenge.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201677</person_id>
				<author_profile_id><![CDATA[81321488877]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sujeevan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aseervatham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201678</person_id>
				<author_profile_id><![CDATA[81321499707]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Emmanuel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Viennet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201679</person_id>
				<author_profile_id><![CDATA[81100277578]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Youn&#232;s]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bennani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442093</article_id>
		<sort_key>550</sort_key>
		<display_label>Pages</display_label>
		<pages>409-414</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>50</seq_no>
		<title><![CDATA[DUSC]]></title>
		<subtitle><![CDATA[Dimensionality Unbiased Subspace Clustering]]></subtitle>
		<page_from>409</page_from>
		<page_to>414</page_to>
		<doi_number>10.1109/ICDM.2007.49</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442093</url>
		<abstract>
			<par><![CDATA[To gain insight into today's large data resources, data mining provides automatic aggregation techniques. Clustering aims at grouping data such that objects within groups are similar while objects in different groups are dissimilar. In scenarios with many attributes or with noise, clusters are often hidden in subspaces of the data and do not show up in the full dimensional space. For these applications, subspace clustering methods aim at detecting clusters in any subspace. Existing subspace clustering approaches fall prey to an effect we call dimensionality bias. As dimensionality of subspaces varies, approaches which do not take this effect into account fail to separate clusters from noise. We give a formal definition of dimensionality bias and analyze consequences for subspace clustering. A dimensionality unbiased subspace clustering (DUSC) definition based on statistical foundations is proposed. In thorough experiments on synthetic and real world data, we show that our approach outperforms existing subspace clustering algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202987</person_id>
				<author_profile_id><![CDATA[81100257752]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ira]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Assent]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202988</person_id>
				<author_profile_id><![CDATA[81331496997]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ralph]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Krieger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202989</person_id>
				<author_profile_id><![CDATA[81350600194]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Emmanuel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[M&#252;ller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202990</person_id>
				<author_profile_id><![CDATA[81100145971]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Seidl]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442094</article_id>
		<sort_key>560</sort_key>
		<display_label>Pages</display_label>
		<pages>415-420</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>51</seq_no>
		<title><![CDATA[Finding Predictive Runs with LAPS]]></title>
		<page_from>415</page_from>
		<page_to>420</page_to>
		<doi_number>10.1109/ICDM.2007.84</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442094</url>
		<abstract>
			<par><![CDATA[We present an extension to the Lasso [6] for binary classification problems with ordered attributes. Inspired by the Fused Lasso [5] and the Group Lasso [7, 3] models, we aim to both discover and model runs (contiguous subgroups of the variables) that are highly predictive. We call the extended model LAPS (the Lasso with Attribute Partition Search). Such problems commonly arise in financial and medical domains, where predictors are time series variables, for example. This paper outlines the formulation of the problem, an algorithm to obtain the model coefficients and experiments showing applicability to practical problems of this type.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200264</person_id>
				<author_profile_id><![CDATA[81543403356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Suhrid]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Balakrishnan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200265</person_id>
				<author_profile_id><![CDATA[81100083780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Madigan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442095</article_id>
		<sort_key>570</sort_key>
		<display_label>Pages</display_label>
		<pages>421-426</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>52</seq_no>
		<title><![CDATA[Latent Dirichlet Conditional Naive-Bayes Models]]></title>
		<page_from>421</page_from>
		<page_to>426</page_to>
		<doi_number>10.1109/ICDM.2007.55</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442095</url>
		<abstract>
			<par><![CDATA[In spite of the popularity of probabilistic mixture models for latent structure discovery from data, mixture models do not have a natural mechanism for handling sparsity, where each data point only has a few non-zero observations. In this paper, we introduce conditional naive-Bayes (CNB) models, which generalize naive-Bayes mixture models to naturally handle sparsity by conditioning the model on observed features. Further, we present latent Dirichlet conditional naive-Bayes (LD-CNB) models, which constitute a family of powerful hierarchical Bayesian models for latent structure discovery from sparse data. The proposed family of models are quite general and can work with arbitrary regular exponential family conditional distributions. We present a variational inference based EM algorithm for learning along with special case analyses for Gaussian and discrete distributions. The efficacy of the proposed models are demonstrated by extensive experiments on a wide variety of different datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202991</person_id>
				<author_profile_id><![CDATA[81100144629]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Arindam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Banerjee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202992</person_id>
				<author_profile_id><![CDATA[81375593685]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hanhuai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442096</article_id>
		<sort_key>580</sort_key>
		<display_label>Pages</display_label>
		<pages>427-432</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>53</seq_no>
		<title><![CDATA[Efficient Kernel Discriminant Analysis via Spectral Regression]]></title>
		<page_from>427</page_from>
		<page_to>432</page_to>
		<doi_number>10.1109/ICDM.2007.88</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442096</url>
		<abstract>
			<par><![CDATA[Linear Discriminant Analysis (LDA) has been a popular method for extracting features which preserve class separability. The projection vectors are commonly obtained by maximizing the between class covariance and simultaneously minimizing the within class covariance. LDA can be performed either in the original input space or in the reproducing kernel Hilbert space (RKHS) into which data points are mapped, which leads to Kernel Discriminant Analysis (KDA). When the data are highly nonlinear distributed, KDA can achieve better performance than LDA. However, computing the projective functions in KDA involves eigen-decomposition of kernel matrix, which is very expensive when a large number of training samples exist. In this paper, we present a new algorithm for kernel discriminant analysis, called Spectral Regression Kernel Discriminant Analysis (SRKDA). By using spectral graph analysis, SRKDA casts discriminant analysis into a regression framework which facilitates both efficient computation and the use of regularization techniques. Specifically, SRKDA only needs to solve a set of regularized regression problems and there is no eigenvector computation involved, which is a huge save of computational cost. Our computational analysis shows that SRKDA is 27 times faster than the ordinary KDA. Moreover, the new formulation makes it very easy to develop incremental version of the algorithm which can fully utilize the computational results of the existing training samples. Experiments on face recognition demonstrate the effectiveness and efficiency of the proposed algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202611</person_id>
				<author_profile_id><![CDATA[81100430245]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Deng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202612</person_id>
				<author_profile_id><![CDATA[81418598002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xiaofei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202613</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442097</article_id>
		<sort_key>590</sort_key>
		<display_label>Pages</display_label>
		<pages>433-438</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>54</seq_no>
		<title><![CDATA[Zonal Co-location Pattern Discovery with Dynamic Parameters]]></title>
		<page_from>433</page_from>
		<page_to>438</page_to>
		<doi_number>10.1109/ICDM.2007.102</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442097</url>
		<abstract>
			<par><![CDATA[Zonal co-location patterns represent subsets of featuretypes that are frequently located in a subset of space (i.e., zone). Discovering zonal spatial co-location patterns is an important problem with many applications in areas such as ecology, public health, and homeland defense. However, discovering these patterns with dynamic parameters (i.e., repeated specification of zone and interest measure values according to user preferences) is computationally complex due to the repetitive mining process. Also, the set of candidate patterns is exponential in the number of feature types, and spatial datasets are huge. Previous studies have focused on discovering global spatial co-location patterns with a fixed interest measure threshold. In this paper, we propose an indexing structure for co-location patterns and propose algorithms (Zoloc-Miner) to discover zonal colocation patterns efficiently for dynamic parameters. Extensive experimental evaluation shows our proposed approaches are scalable, efficient, and outperform naive alternatives.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202614</person_id>
				<author_profile_id><![CDATA[81309506932]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mete]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Celik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202615</person_id>
				<author_profile_id><![CDATA[81375616137]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Kang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202616</person_id>
				<author_profile_id><![CDATA[81100610476]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shekhar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442098</article_id>
		<sort_key>600</sort_key>
		<display_label>Pages</display_label>
		<pages>439-444</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>55</seq_no>
		<title><![CDATA[Predicting Blogging Behavior Using Temporal and Social Networks]]></title>
		<page_from>439</page_from>
		<page_to>444</page_to>
		<doi_number>10.1109/ICDM.2007.97</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442098</url>
		<abstract>
			<par><![CDATA[Modeling the behavior of bloggers is an important problem with various applications in recommender systems, targeted advertising, and event detection. In this paper, we propose three models by combining content, temporal, social dimensions: the general blogging-behavior model, the profile-based blogging-behavior model and the socialnetwork and profile-based blogging-behavior model. The models are based on two regression techniques: Extreme Learning Machine (ELM), and Modified General Regression Neural Network (MGRNN). We choose one of the largest blogs, a political blog, DailyKos 1, for our empirical evaluation. Experiments show that the social network and profile-based blogging behavior model with ELM regression techniques produce good results for the most active bloggers and can be used to predict blogging behavior.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200753</person_id>
				<author_profile_id><![CDATA[81443594567]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200754</person_id>
				<author_profile_id><![CDATA[81375594410]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Qiankun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200755</person_id>
				<author_profile_id><![CDATA[81329492258]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bingjun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200756</person_id>
				<author_profile_id><![CDATA[81100106069]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Prasenjit]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mitra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442099</article_id>
		<sort_key>610</sort_key>
		<display_label>Pages</display_label>
		<pages>445-450</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>56</seq_no>
		<title><![CDATA[gApprox]]></title>
		<subtitle><![CDATA[Mining Frequent Approximate Patterns from a Massive Network]]></subtitle>
		<page_from>445</page_from>
		<page_to>450</page_to>
		<doi_number>10.1109/ICDM.2007.36</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442099</url>
		<abstract>
			<par><![CDATA[Recently, there arise a large number of graphs with massive sizes and complex structures in many new applications, such as biological networks, social networks, and the Web, demanding powerful data mining methods. Due to inherent noise or data diversity, it is crucial to address the issue of approximation, if one wants to mine patterns that are potentially interesting with tolerable variations. In this paper, we investigate the problem of mining frequent approximate patterns from a massive network and propose a method called gApprox. gApprox not only finds approximate network patterns, which is the key for many knowledge discovery applications on structural data, but also enriches the library of graph mining methodologies by introducing several novel techniques such as: (1) a complete and redundancy-free strategy to explore the new pattern space faced by gApprox; and (2) transform "frequent in an approximate sense" into an anti-monotonic constraint so that it can be pushed deep into the mining process. Systematic empirical studies on both real and synthetic data sets show that frequent approximate patterns mined from the worm protein-protein interaction network are biologically interesting and gApprox is both effective and efficient.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201229</person_id>
				<author_profile_id><![CDATA[81375599868]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201230</person_id>
				<author_profile_id><![CDATA[81100044779]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xifeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201231</person_id>
				<author_profile_id><![CDATA[81313483490]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Feida]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201232</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442100</article_id>
		<sort_key>620</sort_key>
		<display_label>Pages</display_label>
		<pages>451-456</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>57</seq_no>
		<title><![CDATA[Document Transformation for Multi-label Feature Selection in Text Categorization]]></title>
		<page_from>451</page_from>
		<page_to>456</page_to>
		<doi_number>10.1109/ICDM.2007.18</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442100</url>
		<abstract>
			<par><![CDATA[Feature selection on multi-label documents for automatic text categorization is an under-explored research area. This paper presents a systematic document transformation framework, whereby the multi-label documents are transformed into single-label documents before applying standard feature selection algorithms, to solve the multi-label feature selection problem. Under this framework, we undertake a comparative study on four intuitive document transformation approaches and propose a novel approach called Entropy-based Label Assignment (ELA), which assigns the labels weights to a multi-label document based on label entropy. Three standard feature selection algorithms are utilized for evaluating the document transformation approaches in order to verify its impact on multi-class text categorization problems. Using a SVM classifier and two multi-label evaluation benchmark text collections, we show that the choice of document transformation approaches can significantly influence the performance of multi-class categorization and that our proposed document transformation approach ELA can achieve better performance than all other approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203478</person_id>
				<author_profile_id><![CDATA[81375600014]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Weizhu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203479</person_id>
				<author_profile_id><![CDATA[81375615226]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203480</person_id>
				<author_profile_id><![CDATA[81309512327]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Benyu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203481</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203482</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442101</article_id>
		<sort_key>630</sort_key>
		<display_label>Pages</display_label>
		<pages>457-462</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>58</seq_no>
		<title><![CDATA[Recommendation via Query Centered Random Walk on K-Partite Graph]]></title>
		<page_from>457</page_from>
		<page_to>462</page_to>
		<doi_number>10.1109/ICDM.2007.8</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442101</url>
		<abstract>
			<par><![CDATA[This paper presents an algorithm for recommending items using a diverse set of features. The items are recommended by performing a random walk on the k-partite graph constructed from the heterogenous features. To support personalized recommendation, the random walk must be initiated separately for each user, which is computationally demanding given the massive size of the graph. To overcome this problem, we apply multi-way clustering to group together the highly correlated nodes. A recommendation is then made by traversing the subgraph induced by clusters associated with a user's interest. Our experimental results on real data sets demonstrate the efficacy of the proposed algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201701</person_id>
				<author_profile_id><![CDATA[81375595305]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Haibin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cheng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201702</person_id>
				<author_profile_id><![CDATA[81544724956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pang-Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201703</person_id>
				<author_profile_id><![CDATA[81350595916]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sticklen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201704</person_id>
				<author_profile_id><![CDATA[81100277850]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Punch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442102</article_id>
		<sort_key>640</sort_key>
		<display_label>Pages</display_label>
		<pages>463-468</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>59</seq_no>
		<title><![CDATA[Bandit-Based Algorithms for Budgeted Learning]]></title>
		<page_from>463</page_from>
		<page_to>468</page_to>
		<doi_number>10.1109/ICDM.2007.91</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442102</url>
		<abstract>
			<par><![CDATA[We explore the problem of budgeted machine learning, in which the learning algorithm has free access to the training examples' labels but has to pay for each attribute that is specified. This learning model is appropriate in many areas, including medical applications. We present new algorithms for choosing which attributes to purchase of which examples in the budgeted learning model based on algorithms for the multi-armed bandit problem. All of our approaches outperformed the current state of the art. Furthermore, we present a new means for selecting an example to purchase after the attribute is selected, instead of selecting an example uniformly at random, which is typically done. Our new example selection method improved performance of all the algorithms we tested, both ours and those in the literature.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203005</person_id>
				<author_profile_id><![CDATA[81367591353]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Deng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203006</person_id>
				<author_profile_id><![CDATA[81318492741]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bourke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203007</person_id>
				<author_profile_id><![CDATA[81332526172]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scott]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203008</person_id>
				<author_profile_id><![CDATA[81375620781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Julie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sunderman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203009</person_id>
				<author_profile_id><![CDATA[81375603070]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Yaling]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zheng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442103</article_id>
		<sort_key>650</sort_key>
		<display_label>Pages</display_label>
		<pages>469-474</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>60</seq_no>
		<title><![CDATA[Extracting Product Comparisons from Discussion Boards]]></title>
		<page_from>469</page_from>
		<page_to>474</page_to>
		<doi_number>10.1109/ICDM.2007.27</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442103</url>
		<abstract>
			<par><![CDATA[In recent years, product discussion forums have become a rich environment in which consumers and potential adopters exchange views and information. Researchers and practitioners are starting to extract user sentiment about products from user product reviews. Users often compare different products, stating which they like better and why. Extracting information about product comparisons offers a number of challenges; recognizing and normalizing entities (products) in the informal language of blogs and discussion groups require different techniques than those used for entity extraction in the more formal text of newspapers and scientific articles. We present a case study in extracting information about comparisons between running shoes and between cars, describe an effective methodology, and show how it produces insight into how consumers view the running shoe and car markets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203010</person_id>
				<author_profile_id><![CDATA[81100064489]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ronen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Feldman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203011</person_id>
				<author_profile_id><![CDATA[81375620994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Moshe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fresco]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203012</person_id>
				<author_profile_id><![CDATA[81100496666]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jacob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goldenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203013</person_id>
				<author_profile_id><![CDATA[81375617216]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Oded]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Netzer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203014</person_id>
				<author_profile_id><![CDATA[81100365076]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Lyle]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ungar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442104</article_id>
		<sort_key>660</sort_key>
		<display_label>Pages</display_label>
		<pages>475-480</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>61</seq_no>
		<title><![CDATA[Mining Interpretable Human Strategies]]></title>
		<subtitle><![CDATA[A Case Study]]></subtitle>
		<page_from>475</page_from>
		<page_to>480</page_to>
		<doi_number>10.1109/ICDM.2007.19</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442104</url>
		<abstract>
			<par><![CDATA[This paper focuses on mining human strategies by observing their actions. Our application domain is an HCI study aimed at discovering general strategies used by software users and understanding how such strategies relate to gender and success. We cast this as a sequential pattern discovery problem, where user strategies are manifested as sequential patterns. Problematically, we found that the patterns discovered by standard algorithms were difficult to interpret and provided limited information about high-level strategies. To help interpret the patterns and extract general strategies, we examined multiple ways of clustering the patterns into meaningful groups, which collectively led to interesting findings about user behavior both in terms of gender differences and problem-solving success. As a real-world application of data mining techniques, our work led to the discovery of new strategic patterns that are linked to user success and had not been revealed in more than nine years of manual empirical work. As a case study, our work highlights important research directions for making data mining more accessible to non-experts.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203015</person_id>
				<author_profile_id><![CDATA[81100360432]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiaoli]]></first_name>
				<middle_name><![CDATA[Z.]]></middle_name>
				<last_name><![CDATA[Fern]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203016</person_id>
				<author_profile_id><![CDATA[81323492399]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chaitanya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Komireddy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203017</person_id>
				<author_profile_id><![CDATA[81100337865]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Margaret]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Burnett]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442105</article_id>
		<sort_key>670</sort_key>
		<display_label>Pages</display_label>
		<pages>481-486</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>62</seq_no>
		<title><![CDATA[Cross-Mining Binary and Numerical Attributes]]></title>
		<page_from>481</page_from>
		<page_to>486</page_to>
		<doi_number>10.1109/ICDM.2007.32</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442105</url>
		<abstract>
			<par><![CDATA[We consider the problem of relating itemsets mined on binary attributes of a data set to numerical attributes of the same data. An example is biogeographical data, where the numerical attributes correspond to environmental variables and the binary attributes encode the presence or absence of species in different environments. From the viewpoint of itemset mining, the task is to select a small collection of interesting itemsets using the numerical attributes; from the viewpoint of the numerical attributes, the task is to constrain the search for local patterns (e.g. clusters) using the binary attributes. We give a formal definition of the problem, discuss it theoretically, give a simple constant-factor approximation algorithm, and show by experiments on biogeographical data that the algorithm can capture interesting patterns that would not have been found using either itemset mining or clustering alone.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201255</person_id>
				<author_profile_id><![CDATA[81363590792]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gemma]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Garriga]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201256</person_id>
				<author_profile_id><![CDATA[81335491740]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hannes]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Heikinheimo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201257</person_id>
				<author_profile_id><![CDATA[81100031671]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jouni]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Seppanen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442106</article_id>
		<sort_key>680</sort_key>
		<display_label>Pages</display_label>
		<pages>487-492</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>63</seq_no>
		<title><![CDATA[Prism]]></title>
		<subtitle><![CDATA[A Primal-Encoding Approach for Frequent Sequence Mining]]></subtitle>
		<page_from>487</page_from>
		<page_to>492</page_to>
		<doi_number>10.1109/ICDM.2007.33</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442106</url>
		<abstract>
			<par><![CDATA[Sequence mining is one of the fundamental data mining tasks. In this paper we present a novel approach called PRISM, for mining frequent sequences. PRISM utilizes a vertical approach for enumeration and support counting, based on the novel notion of prime block encoding, which in turn is based on prime factorization theory. Via an extensive evaluation on both synthetic and real datasets, we show that PRISM outperforms popular sequence mining methods like SPADE [10], PrefixSpan [6] and SPAM [2], by an order of magnitude or more.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201714</person_id>
				<author_profile_id><![CDATA[81343493585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Karam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gouda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201715</person_id>
				<author_profile_id><![CDATA[81375620476]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mosab]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hassaan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201716</person_id>
				<author_profile_id><![CDATA[81100229027]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mohammed]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Zaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442107</article_id>
		<sort_key>690</sort_key>
		<display_label>Pages</display_label>
		<pages>493-498</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>64</seq_no>
		<title><![CDATA[Using Burstiness to Improve Clustering of Topics in News Streams]]></title>
		<page_from>493</page_from>
		<page_to>498</page_to>
		<doi_number>10.1109/ICDM.2007.17</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442107</url>
		<abstract>
			<par><![CDATA[Specialists who analyze online news have a hard time separating the wheat from the chaff. Moreover, automatic data-mining techniques like clustering of news streams into topical groups can fully recover the underlying true class labels of data if and only if all classes are well separated. In reality, especially for news streams, this is clearly not the case. The question to ask is thus this: if we cannot recover the full C classes by clustering, what is the largest K \le C clusters we can find that best resemble the K underlying classes? Using the intuition that bursty topics are more likely to correspond to important events that are of interest to analysts, we propose several new bursty vector space models (B-VSM) for representing a news document. B-VSM takes into account the burstiness (across the full corpus and whole duration) of each constituent word in a document at the time of publication. We benchmarked our B-VSM against the classical TFIDF-VSM on the task of clustering a collection of news stream articles with known topic labels. Experimental results show that B-VSM was able to find the burstiest clusters/topics. Further, it also significantly improved the recall and precision for the top K clusters/topics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203049</person_id>
				<author_profile_id><![CDATA[81100331201]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Qi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203050</person_id>
				<author_profile_id><![CDATA[81335488797]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kuiyu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203051</person_id>
				<author_profile_id><![CDATA[81100399142]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ee-Peng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442108</article_id>
		<sort_key>700</sort_key>
		<display_label>Pages</display_label>
		<pages>499-504</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>65</seq_no>
		<title><![CDATA[Bayesian Folding-In with Dirichlet Kernels for PLSI]]></title>
		<page_from>499</page_from>
		<page_to>504</page_to>
		<doi_number>10.1109/ICDM.2007.15</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442108</url>
		<abstract>
			<par><![CDATA[Probabilistic latent semantic indexing (PLSI) represents documents of a collection as mixture proportions of latent topics, which are learned from the collection by an expectation maximization (EM) algorithm. New documents or queries need to be folded into the latent topic space by a simplified version of the EM-algorithm. During PLSIFolding-in of a new document, the topic mixtures of the known documents are ignored. This may lead to a suboptimal model of the extended collection. Our new approach incorporates the topic mixtures of the known documents in a Bayesian way during foldingin. That knowledge is modeled as prior distribution over the topic simplex using a kernel density estimate of Dirichlet kernels. We demonstrate the advantages of the new Bayesian folding-in using real text data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201258</person_id>
				<author_profile_id><![CDATA[81100527521]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hinneburg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201259</person_id>
				<author_profile_id><![CDATA[81453647911]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hans-Henning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gabriel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201260</person_id>
				<author_profile_id><![CDATA[81375602205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Andr&#232;]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gohr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442109</article_id>
		<sort_key>710</sort_key>
		<display_label>Pages</display_label>
		<pages>505-510</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>66</seq_no>
		<title><![CDATA[Confident Identification of Relevant Objects Based on Nonlinear Rescaling Method and Transductive Inference]]></title>
		<page_from>505</page_from>
		<page_to>510</page_to>
		<doi_number>10.1109/ICDM.2007.24</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442109</url>
		<abstract>
			<par><![CDATA[We present a novel machine learning algorithm to identify relevant objects from a large amount of data. This approach is driven by linear discrimination based on Nonlinear Rescaling (NR) method and transductive inference. The NR algorithm for linear discrimination (NRLD) computes both the primal and the dual approximation at each step. The dual variables associated with the given labeled dataset provide important information about the objects in the data-set and play the key role in ordering these objects. A confidence score based on a transductive inference procedure using NRLD is used to rank and identify the relevant objects from a pool of unlabeled data. Experimental results on an unbalanced protein data-set for the drug target prioritization and identification problem are used to illustrate the feasibility of the proposed identification algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201717</person_id>
				<author_profile_id><![CDATA[81309493976]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shen-Shyang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201718</person_id>
				<author_profile_id><![CDATA[81100223525]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Roman]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Polyak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442110</article_id>
		<sort_key>720</sort_key>
		<display_label>Pages</display_label>
		<pages>511-516</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>67</seq_no>
		<title><![CDATA[Training Conditional Random Fields by Periodic Step Size Adaptation for Large-Scale Text Mining]]></title>
		<page_from>511</page_from>
		<page_to>516</page_to>
		<doi_number>10.1109/ICDM.2007.39</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442110</url>
		<abstract>
			<par><![CDATA[For applications with consecutive incoming training examples, on-line learning has the potential to achieve a likelihood as high as off-line learning without scanning all available training examples and usually has a much smaller memory footprint. To train CRFs on-line, this paper presents the Periodic Step size Adaptation (PSA) method to dynamically adjust the learning rates in stochastic gradient descent. We applied our method to three large scale text mining tasks. Experimental results show that PSA outperforms the best off-line algorithm, L-BFGS, by many hundred times, and outperforms the best on-line algorithm, SMD, by an order of magnitude in terms of the number of passes required to scan the training data set.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202186</person_id>
				<author_profile_id><![CDATA[81423595791]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Han-Shen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202187</person_id>
				<author_profile_id><![CDATA[81384591291]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yu-Ming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202188</person_id>
				<author_profile_id><![CDATA[81350597365]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chun-Nan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hsu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442111</article_id>
		<sort_key>730</sort_key>
		<display_label>Pages</display_label>
		<pages>517-522</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>68</seq_no>
		<title><![CDATA[Semi-supervised Document Clustering via Active Learning with Pairwise Constraints]]></title>
		<page_from>517</page_from>
		<page_to>522</page_to>
		<doi_number>10.1109/ICDM.2007.79</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442111</url>
		<abstract>
			<par><![CDATA[This paper investigates a framework that discovers pairwise constraints for semi-supervised text document clustering. An active learning approach is proposed to select informative document pairs for obtaining user feedbacks. A gain directed document pair selection method that measures how much we can learn by revealing the relationships between pairs of documents is designed. Three different models, namely, uncertainty model, generation error model, and objective function model are proposed. Language modeling is investigated for representing clusters in the semi-supervised document clustering approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202218</person_id>
				<author_profile_id><![CDATA[81100079357]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ruizhang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202219</person_id>
				<author_profile_id><![CDATA[81423592360]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lam]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442112</article_id>
		<sort_key>740</sort_key>
		<display_label>Pages</display_label>
		<pages>523-528</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>69</seq_no>
		<title><![CDATA[Computing Correlation Anomaly Scores Using Stochastic Nearest Neighbors]]></title>
		<page_from>523</page_from>
		<page_to>528</page_to>
		<doi_number>10.1109/ICDM.2007.12</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442112</url>
		<abstract>
			<par><![CDATA[This paper addresses the task of change analysis of correlated multi-sensor systems. The goal of change analysis is to compute the anomaly score of each sensor when we know that the system has some potential difference from a reference state. Examples include validating the proper performance of various car sensors in the automobile industry. We solve this problem based on a neighborhood preservation principle -If the system is working normally, the neighborhood graph of each sensor is almost invariant against the fluctuations of experimental conditions. Here a neighborhood graph is defined based on the correlation between sensor signals. With the notion of stochastic neighborhood, our method is capable of robustly computing the anomaly score of each sensor under conditions that are hard to be detected by other naive methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202220</person_id>
				<author_profile_id><![CDATA[81100055426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tsuyoshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Id&#233;]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202221</person_id>
				<author_profile_id><![CDATA[81100631405]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Spiros]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Papadimitriou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202222</person_id>
				<author_profile_id><![CDATA[81100026796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michail]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vlachos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442113</article_id>
		<sort_key>750</sort_key>
		<display_label>Pages</display_label>
		<pages>529-534</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>70</seq_no>
		<title><![CDATA[On Meta-Learning Rule Learning Heuristics]]></title>
		<page_from>529</page_from>
		<page_to>534</page_to>
		<doi_number>10.1109/ICDM.2007.51</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442113</url>
		<abstract>
			<par><![CDATA[The goal of this paper is to investigate to what extent a rule learning heuristic can be learned from experience. To that end, we let a rule learner learn a large number of rules and record their performance on the test set. Subsequently, we train regression algorithms on predicting the test set performance of a rule from its training set characteristics. We investigate several variations of this basic scenario, including the question whether it is better to predict the performance of the candidate rule itself or of the resulting final rule. Our experiments on a number of independent evaluation sets show that the learned heuristics outperform standard rule learning heuristics. We also analyze their behavior in coverage space.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203534</person_id>
				<author_profile_id><![CDATA[81387596151]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Frederik]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Janssen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203535</person_id>
				<author_profile_id><![CDATA[81100142140]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Johannes]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Furnkranz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442114</article_id>
		<sort_key>760</sort_key>
		<display_label>Pages</display_label>
		<pages>535-540</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>71</seq_no>
		<title><![CDATA[Web Site Recommendation Using HTTP Traffic]]></title>
		<page_from>535</page_from>
		<page_to>540</page_to>
		<doi_number>10.1109/ICDM.2007.44</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442114</url>
		<abstract>
			<par><![CDATA[Collaborative Filtering (CF) is widely used in web recommender systems, while most existing CF applications focus on transactions or page views within a single site. In this paper, we build a recommender system prototype, which suggests web sites to users, by collecting browsing events at routers without neither user nor website effort. 100 million HTTP flows, involving 11, 327 websites, are converted to user-site ratings using access frequency as the implicit rating metric. With this rating dataset, we evaluate six CF algorithms including one proposed algorithm based on IP address locality. Our experiments show that the recommendation from K nearest neighbors (RkNN ) performs the best by 50% p@10 (precision of top 10) and 53% p@5 (precision of top 5). Although the precision is far from ideal, our preliminary results suggest the potential value of such a centralized web site recommender system.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201725</person_id>
				<author_profile_id><![CDATA[81547796956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jia]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201726</person_id>
				<author_profile_id><![CDATA[81540926156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shaozhi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ye]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201727</person_id>
				<author_profile_id><![CDATA[81375614680]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201728</person_id>
				<author_profile_id><![CDATA[81100556330]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Julie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dickerson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442115</article_id>
		<sort_key>770</sort_key>
		<display_label>Pages</display_label>
		<pages>541-546</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>72</seq_no>
		<title><![CDATA[Trend Motif]]></title>
		<subtitle><![CDATA[A Graph Mining Approach for Analysis of Dynamic Complex Networks]]></subtitle>
		<page_from>541</page_from>
		<page_to>546</page_to>
		<doi_number>10.1109/ICDM.2007.92</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442115</url>
		<abstract>
			<par><![CDATA[Complex networks have been used successfully in scientific disciplines ranging from sociology to microbiology to describe systems of interacting units. Until recently, studies of complex networks have mainly focused on their network topology. However, in many real world applications, the edges and vertices have associated attributes that are frequently represented as vertex or edge weights. Furthermore, these weights are often not static, instead changing with time and forming a time series. Hence, to fully understand the dynamics of the complex network, we have to consider both network topology and related time series data. In this work, we propose a motif mining approach to identify trend motifs for such purposes. Simply stated, a trend motif describes a recurring subgraph where each of its vertices or edges displays similar dynamics over a userdefined period. Given this, each trend motif occurrence can help reveal significant events in a complex system; frequent trend motifs may aid in uncovering dynamic rules of change for the system, and the distribution of trend motifs may characterize the global dynamics of the system. Here, we have developed efficient mining algorithms to extract trend motifs. Our experimental validation using three disparate empirical datasets, ranging from the stock market, world trade, to a protein interaction network, has demonstrated the efficiency and effectiveness of our approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200808</person_id>
				<author_profile_id><![CDATA[81100054574]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ruoming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200809</person_id>
				<author_profile_id><![CDATA[81375619446]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Scott]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McCallen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200810</person_id>
				<author_profile_id><![CDATA[81375619081]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Eivind]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Almaas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442116</article_id>
		<sort_key>780</sort_key>
		<display_label>Pages</display_label>
		<pages>547-552</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>73</seq_no>
		<title><![CDATA[Analyzing and Detecting Review Spam]]></title>
		<page_from>547</page_from>
		<page_to>552</page_to>
		<doi_number>10.1109/ICDM.2007.68</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442116</url>
		<abstract>
			<par><![CDATA[Mining of opinions from product reviews, forum posts and blogs is an important research topic with many applications. However, existing research has been focused on extraction, classification and summarization of opinions from these sources. An important issue that has not been studied so far is the opinion spam or the trustworthiness of online opinions. In this paper, we study this issue in the context of product reviews. To our knowledge, there is still no published study on this topic, although Web page spam and email spam have been investigated extensively. We will see that review spam is quite different from Web page spam and email spam, and thus requires different detection techniques. Based on the analysis of 5.8 million reviews and 2.14 million reviewers from amazon.com, we show that review spam is widespread. In this paper, we first present a categorization of spam reviews and then propose several techniques to detect them.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203076</person_id>
				<author_profile_id><![CDATA[81339507289]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nitin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jindal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203077</person_id>
				<author_profile_id><![CDATA[81414615435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442117</article_id>
		<sort_key>790</sort_key>
		<display_label>Pages</display_label>
		<pages>553-558</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>74</seq_no>
		<title><![CDATA[A Computational Approach to Style in American Poetry]]></title>
		<page_from>553</page_from>
		<page_to>558</page_to>
		<doi_number>10.1109/ICDM.2007.76</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442117</url>
		<abstract>
			<par><![CDATA[We develop a quantitative method to assess the style of American poems and to visualize a collection of poems in relation to one another. Qualitative poetry criticism helped guide our development of metrics that analyze various orthographic, syntactic, and phonemic features. These features are used to discover comprehensive stylistic information from a poem's multi-layered latent structure, and to compute distances between poems in this space. Visualizations provide ready access to the analytical components. We demonstrate our method on several collections of poetry, showing that it better delineates poetry style than the traditional word-occurrence features that are used in typical text analysis algorithms. Our method has potential applications to academic research of texts, to research of the intuitive personal response to poetry, and to making recommendations to readers based on their favorite poems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200334</person_id>
				<author_profile_id><![CDATA[81406594610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Kaplan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200335</person_id>
				<author_profile_id><![CDATA[81100028344]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Blei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442118</article_id>
		<sort_key>800</sort_key>
		<display_label>Pages</display_label>
		<pages>559-564</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>75</seq_no>
		<title><![CDATA[Change-Point Detection in Time-Series Data Based on Subspace Identification]]></title>
		<page_from>559</page_from>
		<page_to>564</page_to>
		<doi_number>10.1109/ICDM.2007.78</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442118</url>
		<abstract>
			<par><![CDATA[In this paper, we propose series of algorithms for detecting change points in time-series data based on subspace identification, meaning a geometric approach for estimating linear state-space models behind time-series data. Our algorithms are derived from the principle that the subspace spanned by the columns of an observability matrix and the one spanned by the subsequences of time-series data are approximately equivalent. In this paper, we derive an batchtype algorithm applicable to ordinary time-series data, i.e. consisting of only output series, and then introduce the online version of the algorithm and the extension to be available with input-output time-series data. We illustrate the effectiveness of our algorithms with comparative experiments using some artificial and real datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201306</person_id>
				<author_profile_id><![CDATA[81461640434]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yoshinobu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kawahara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201307</person_id>
				<author_profile_id><![CDATA[81100098445]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Takehisa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yairi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201308</person_id>
				<author_profile_id><![CDATA[81100029730]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kazuo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Machida]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442119</article_id>
		<sort_key>810</sort_key>
		<display_label>Pages</display_label>
		<pages>565-570</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>76</seq_no>
		<title><![CDATA[Optimal Subsequence Bijection]]></title>
		<page_from>565</page_from>
		<page_to>570</page_to>
		<doi_number>10.1109/ICDM.2007.47</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442119</url>
		<abstract>
			<par><![CDATA[We consider the problem of elastic matching of sequences of real numbers. Since both a query and a target sequence may be noisy, i.e., contain some outlier elements, it is desirable to exclude the outlier elements from matching in order to obtain a robust matching performance. Moreover, in many applications like shape alignment or stereo correspondence it is also desirable to have a one-to-one and onto correspondence (bijection) between the remaining elements. We propose an algorithm that determines the optimal subsequence bijection (OSB) of a query and target sequence. The OSB is efficiently computed since we map the problem's solution to a cheapest path in a DAG (directed acyclic graph). We obtained excellent results on standard benchmark time series datasets. We compared OSB to Dynamic Time Warping (DTW) with and without warping window. We do not claim that OSB is always superior to DTW. However, our results demonstrate that skipping outlier elements as done by OSB can significantly improve matching results for many real datasets. Moreover, OSB is particularly suitable for partial matching. We applied it to the object recognition problem when only parts of contours are given. We obtained sequences representing shapes by representing object contours as sequences of curvatures.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201309</person_id>
				<author_profile_id><![CDATA[81100594681]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Longin]]></first_name>
				<middle_name><![CDATA[Jan]]></middle_name>
				<last_name><![CDATA[Latecki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201310</person_id>
				<author_profile_id><![CDATA[81100212494]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201311</person_id>
				<author_profile_id><![CDATA[81375619314]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Suzan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Koknar-Tezel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201312</person_id>
				<author_profile_id><![CDATA[81100072429]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Vasileios]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Megalooikonomou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442120</article_id>
		<sort_key>820</sort_key>
		<display_label>Pages</display_label>
		<pages>571-576</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>77</seq_no>
		<title><![CDATA[Connections between Mining Frequent Itemsets and Learning Generative Models]]></title>
		<page_from>571</page_from>
		<page_to>576</page_to>
		<doi_number>10.1109/ICDM.2007.83</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442120</url>
		<abstract>
			<par><![CDATA[Frequent itemsets mining is a popular framework for pattern discovery. In this framework, given a database of customer transactions, the task is to unearth all patterns in the form of sets of items appearing in a sizable number of transactions. We present a class of models called Itemset Generating Models (or IGMs) that can be used to formally connect the process of frequent itemsets discovery with the learning of generative models. IGMs are specified using simple probability mass functions (over the space of transactions), peaked at specific sets of items and uniform everywhere else. Under such a connection, it is possible to rigorously associate higher frequency patterns with generative models that have greater data likelihoods. This enables a generative model-learning interpretation of frequent itemsets mining. More importantly, it facilitates a statistical significance test which prescribes the minimum frequency needed for a pattern to be considered interesting. We illustrate the effectiveness of our analysis through experiments on standard benchmark data sets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202686</person_id>
				<author_profile_id><![CDATA[81100551630]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Srivatsan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Laxman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202687</person_id>
				<author_profile_id><![CDATA[81100178108]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Prasad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Naldurg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202688</person_id>
				<author_profile_id><![CDATA[81375604873]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Raja]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sripada]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202689</person_id>
				<author_profile_id><![CDATA[81100057891]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ramarathnam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Venkatesan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442121</article_id>
		<sort_key>830</sort_key>
		<display_label>Pages</display_label>
		<pages>577-582</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>78</seq_no>
		<title><![CDATA[Solving Consensus and Semi-supervised Clustering Problems Using Nonnegative Matrix Factorization]]></title>
		<page_from>577</page_from>
		<page_to>582</page_to>
		<doi_number>10.1109/ICDM.2007.98</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442121</url>
		<abstract>
			<par><![CDATA[Consensus clustering and semi-supervised clustering are important extensions of the standard clustering paradigm. Consensus clustering (also known as aggregation of clustering) can improve clustering robustness, deal with distributed and heterogeneous data sources and make use of multiple clustering criteria. Semi-supervised clustering can integrate various forms of background knowledge into clustering. In this paper, we show how consensus and semi-supervised clustering can be formulated within the framework of nonnegative matrix factorization (NMF). We show that this framework yields NMF-based algorithms that are: (1) extremely simple to implement; (2) provably correct and provably convergent. We conduct a wide range of comparative experiments that demonstrate the effectiveness of this NMF-based approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203547</person_id>
				<author_profile_id><![CDATA[81100475528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203548</person_id>
				<author_profile_id><![CDATA[81100136610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ding]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203549</person_id>
				<author_profile_id><![CDATA[81339507945]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Jordan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442122</article_id>
		<sort_key>840</sort_key>
		<display_label>Pages</display_label>
		<pages>583-588</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>79</seq_no>
		<title><![CDATA[Failure Prediction in IBM BlueGene/L Event Logs]]></title>
		<page_from>583</page_from>
		<page_to>588</page_to>
		<doi_number>10.1109/ICDM.2007.46</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442122</url>
		<abstract>
			<par><![CDATA[Frequent failures are becoming a serious concern to the community of high-end computing, especially when the applications and the underlying systems rapidly grow in size and complexity. In order to develop effective fault-tolerant strategies, there is a critical need to predict failure events. To this end, we have collected detailed event logs from IBM BlueGene/L, which has 128K processors, and is currently the fastest supercomputer in the world. In this study, we first show how the event records can be converted into a data set that is appropriate for running classification techniques. Then we apply classifiers on the data, including RIPPER (a rule-based classifier), Support Vector Machines (SVMs), a traditional Nearest Neighbor method, and a customized Nearest Neighbor method. We show that the customized nearest neighbor approach can outperform RIPPER and SVMs in terms of both coverage and precision. The results suggest that the customized nearest neighbor approach can be used to alleviate the impact of failures.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201747</person_id>
				<author_profile_id><![CDATA[81100044512]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yinglung]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201748</person_id>
				<author_profile_id><![CDATA[81470649679]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yanyong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201749</person_id>
				<author_profile_id><![CDATA[81451596425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xiong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201750</person_id>
				<author_profile_id><![CDATA[81452610481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ramendra]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sahoo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442123</article_id>
		<sort_key>850</sort_key>
		<display_label>Pages</display_label>
		<pages>589-594</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>80</seq_no>
		<title><![CDATA[A Text Classification Framework with a Local Feature Ranking for Learning Social Networks]]></title>
		<page_from>589</page_from>
		<page_to>594</page_to>
		<doi_number>10.1109/ICDM.2007.26</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442123</url>
		<abstract>
			<par><![CDATA[In this paper, a text classifier framework with a feature ranking scheme is proposed to extract social structures from text data. It is assumed that only a small subset of relations between the individuals in a community is known. With this assumption, the social network extraction is translated into a classification problem. The relations between two individuals are represented by merging their document vectors and the given relations are used as labels of training data. By this transformation, a text classifier such as Rocchio is used for learning the unknown relations. We show that there is a link between the intrinsic sparsity of social networks and class imbalance. Furthermore, we show that feature ranking methods usually fail in problem with unbalanced data. In order to deal with this deficiency and re-balance the unbalanced social data, a local feature ranking method, which is called reverse discrimination, is proposed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203107</person_id>
				<author_profile_id><![CDATA[81330494942]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Masoud]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Makrehchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203108</person_id>
				<author_profile_id><![CDATA[81100436158]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mohamed]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Kamel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442124</article_id>
		<sort_key>860</sort_key>
		<display_label>Pages</display_label>
		<pages>595-600</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>81</seq_no>
		<title><![CDATA[Optimizing Frequency Queries for Data Mining Applications]]></title>
		<page_from>595</page_from>
		<page_to>600</page_to>
		<doi_number>10.1109/ICDM.2007.34</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442124</url>
		<abstract>
			<par><![CDATA[Data mining algorithms use various Trie and bitmap-based representations to optimize the support (i.e., frequency) counting performance. In this paper, we compare the memory requirements and support counting performance of FP Tree, and Compressed Patricia Trie against several novel variants of vertical bit vectors. First, borrowing ideas from the VLDB domain, we compress vertical bit vectors using WAH encoding. Second, we evaluate the Gray code rankbased transaction reordering scheme, and show that in practice, simple lexicographic ordering, obtained by applying LSB Radix sort, outperforms this scheme. Led by these results, we propose HDO, a novel Hamming-distance-based greedy transaction reordering scheme, and aHDO, a linear-time approximation to HDO. We present results of experiments performed on 15 common datasets with varying degrees of sparseness, and show that HDOreordered, WAH encoded bit vectors can take as little as 5% of the uncompressed space, while aHDO achieves similar compression on sparse datasets. Finally, with results from over a billion database and data mining style frequency query executions, we show that bitmap-based approaches result in up to hundreds of times faster support counting, and HDO-WAH encoded bitmaps offer the best space-time tradeoff.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203562</person_id>
				<author_profile_id><![CDATA[81315490626]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hassan]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Malik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203563</person_id>
				<author_profile_id><![CDATA[81100113385]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Kender]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442125</article_id>
		<sort_key>870</sort_key>
		<display_label>Pages</display_label>
		<pages>601-606</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>82</seq_no>
		<title><![CDATA[Detecting Subdimensional Motifs]]></title>
		<subtitle><![CDATA[An Efficient Algorithm for Generalized Multivariate Pattern Discovery]]></subtitle>
		<page_from>601</page_from>
		<page_to>606</page_to>
		<doi_number>10.1109/ICDM.2007.52</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442125</url>
		<abstract>
			<par><![CDATA[Discovering recurring patterns in time series data is a fundamental problem for temporal data mining. This paper addresses the problem of locating subdimensional motifs in real-valued, multivariate time series, which requires the simultaneous discovery of sets of recurring patterns along with the corresponding relevant dimensions. While many approaches to motif discovery have been developed, most are restricted to categorical data, univariate time series, or multivariate data in which the temporal patterns span all of the dimensions. In this paper, we present an expected linear-time algorithm that addresses a generalization of multivariate pattern discovery in which each motif may span only a subset of the dimensions. To validate our algorithm, we discuss its theoretical properties and empirically evaluate it using several data sets including synthetic data and motion capture data collected by an on-body inertial sensor.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203109</person_id>
				<author_profile_id><![CDATA[81100181195]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Minnen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203110</person_id>
				<author_profile_id><![CDATA[81100608549]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Isbell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203111</person_id>
				<author_profile_id><![CDATA[81100313702]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Irfan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Essa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203112</person_id>
				<author_profile_id><![CDATA[81100175439]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Thad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Starner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442126</article_id>
		<sort_key>880</sort_key>
		<display_label>Pages</display_label>
		<pages>607-612</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>83</seq_no>
		<title><![CDATA[Consensus Clusterings]]></title>
		<page_from>607</page_from>
		<page_to>612</page_to>
		<doi_number>10.1109/ICDM.2007.73</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442126</url>
		<abstract>
			<par><![CDATA[In this paper we address the problem of combining multiple clusterings without access to the underlying features of the data. This process is known in the literature as clustering ensembles, clustering aggregation, or consensus clustering. Consensus clustering yields a stable and robust final clustering that is in agreement with multiple clusterings. We find that an iterative EM-like method is remarkably effective for this problem. We present an iterative algorithm and its variations for finding clustering consensus. An extensive empirical study compares our proposed algorithms with eleven other consensus clustering methods on four data sets using three different clustering performance metrics. The experimental results show that the new ensemble clustering methods produce clusterings that are as good as, and often better than, these other methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200349</person_id>
				<author_profile_id><![CDATA[81100511402]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nguyen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200350</person_id>
				<author_profile_id><![CDATA[81100100877]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rich]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Caruana]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442127</article_id>
		<sort_key>890</sort_key>
		<display_label>Pages</display_label>
		<pages>613-618</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>84</seq_no>
		<title><![CDATA[High-Speed Function Approximation]]></title>
		<page_from>613</page_from>
		<page_to>618</page_to>
		<doi_number>10.1109/ICDM.2007.107</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442127</url>
		<abstract>
			<par><![CDATA[We address a new learning problem where the goal is to build a predictive model that minimizes prediction time (the time taken to make a prediction) subject to a constraint on model accuracy. Our solution is a generic framework that leverages existing data mining algorithms without requiring any modifications to these algorithms. We show a first application of our framework to a combustion simulation problem. Our experimental evaluation shows significant improvements over existing methods; prediction time typically is improved by a factor between 2 and 6.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200351</person_id>
				<author_profile_id><![CDATA[81318495296]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Biswanath]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Panda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200352</person_id>
				<author_profile_id><![CDATA[81100207912]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mirek]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Riedewald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200353</person_id>
				<author_profile_id><![CDATA[81452607023]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Johannes]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gehrke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200354</person_id>
				<author_profile_id><![CDATA[81100360517]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[B.]]></middle_name>
				<last_name><![CDATA[Pope]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442128</article_id>
		<sort_key>900</sort_key>
		<display_label>Pages</display_label>
		<pages>619-624</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>85</seq_no>
		<title><![CDATA[Weighted Additive Criterion for Linear Dimension Reduction]]></title>
		<page_from>619</page_from>
		<page_to>624</page_to>
		<doi_number>10.1109/ICDM.2007.81</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442128</url>
		<abstract>
			<par><![CDATA[Linear discriminant analysis (LDA) for dimension reduction has been applied to a wide variety of face recognition tasks. However, it has two major problems. First, it suffers from the small sample size problem when dimensionality is greater than the sample size. Second, it creates subspaces that favor well separated classes over those that are not. In this paper, we propose a simple weighted criterion for linear dimension reduction that addresses the above two problems associated with LDA. In addition, there are well established numerical procedures such as semi-definite programming for efficiently computing the proposed criterion. We demonstrate the efficacy of our proposal and compare it against other competing techniques using a number of examples.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201784</person_id>
				<author_profile_id><![CDATA[81375599742]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201785</person_id>
				<author_profile_id><![CDATA[81100561986]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Robila]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442129</article_id>
		<sort_key>910</sort_key>
		<display_label>Pages</display_label>
		<pages>625-630</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>86</seq_no>
		<title><![CDATA[Local Word Bag Model for Text Categorization]]></title>
		<page_from>625</page_from>
		<page_to>630</page_to>
		<doi_number>10.1109/ICDM.2007.69</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442129</url>
		<abstract>
			<par><![CDATA[Many text processing applications adopted the Bag of Words (BOW) model representation of documents, in which each document is represented as a vector of weighted terms or n-grams, and then cosine distance between two vectors is used as the similarity measurement. Although the great success in information retrieval and text categorization, the conventional BOW model ignores the detailed local text information, i.e. the co-occurrence pattern of words at sentence or paragraph level. In this paper, we propose a novel approach to represent a document as a set of local tf-idf vectors, or what we called local word bags (LWB). By encapsulating local information distributed around a document into multiple LWBs, we can measure the similarity of two documents via the partial match of their corresponding local bags. To perform the matching efficiently, we introduce the Local Word Bag kernel (LWB kernel), a variant of VGPyramid match kernel. The new kernel enables the discriminative machine learning methods like SVM to compute the partial matching between two sets of LWBs in linear time after an one time hierarchical clustering procedure over all local bags at the initialization stage. Experiments on real world datasets demonstrate the effectiveness of our new approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203130</person_id>
				<author_profile_id><![CDATA[81385598740]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203131</person_id>
				<author_profile_id><![CDATA[81321494547]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203132</person_id>
				<author_profile_id><![CDATA[81375613429]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shuicheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203133</person_id>
				<author_profile_id><![CDATA[81375615225]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203134</person_id>
				<author_profile_id><![CDATA[81329493240]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Kunqing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xie]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203135</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442130</article_id>
		<sort_key>920</sort_key>
		<display_label>Pages</display_label>
		<pages>631-636</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>87</seq_no>
		<title><![CDATA[Sampling for Sequential Pattern Mining]]></title>
		<subtitle><![CDATA[From Static Databases to Data Streams]]></subtitle>
		<page_from>631</page_from>
		<page_to>636</page_to>
		<doi_number>10.1109/ICDM.2007.82</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442130</url>
		<abstract>
			<par><![CDATA[Sequential pattern mining is an active field in the domain of knowledge discovery. Recently, with the constant progress in hardware technologies, real-world databases tend to grow larger and the hypothesis that a database can be loaded into main-memory for sequential pattern mining purpose is no longer valid. Furthermore, the new model of data as a continuous and potentially infinite flow, known as data stream model, call for a pre-processing step to ease the mining operations. Since the database size is the most influential factor for mining algorithms we examine the use of sampling over static databases to get approximate mining results with an upper bound on the error rate. Moreover, we extend these sampling analysis and present an algorithm based on reservoir sampling to cope with sequential pattern mining over data streams. We demonstrate with empirical results that our sampling methods are efficient and that sequence mining remains accurate over static databases and data streams.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201338</person_id>
				<author_profile_id><![CDATA[81324493099]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chedy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raissi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201339</person_id>
				<author_profile_id><![CDATA[81100236660]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pascal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Poncelet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442131</article_id>
		<sort_key>930</sort_key>
		<display_label>Pages</display_label>
		<pages>637-642</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>88</seq_no>
		<title><![CDATA[Can the Content of Public News Be Used to Forecast Abnormal Stock Market Behaviour?]]></title>
		<page_from>637</page_from>
		<page_to>642</page_to>
		<doi_number>10.1109/ICDM.2007.74</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442131</url>
		<abstract>
			<par><![CDATA[A popular theory of markets is that they are efficient: all available information is deemed to provide an accurate valuation of an asset at any time. In this paper, we consider how the content of marketrelated news articles contributes to such information. Specifically, we mine news articles for terms of interest, and quantify this degree of interest. We then incorporate this measure into traditional models for market index volatility with a view to forecasting whether the incidence of interesting news is correlated with a shock in the index, and thus if the information can be captured to value the underlying asset. We illustrate the methodology on stock market indices for the USA, the UK, and Australia.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200382</person_id>
				<author_profile_id><![CDATA[81333490598]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Calum]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Robertson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200383</person_id>
				<author_profile_id><![CDATA[81329488866]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shlomo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Geva]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200384</person_id>
				<author_profile_id><![CDATA[81100634921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Rodney]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Wolff]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442132</article_id>
		<sort_key>940</sort_key>
		<display_label>Pages</display_label>
		<pages>643-648</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>89</seq_no>
		<title><![CDATA[An Efficient Spectral Algorithm for Network Community Discovery and Its Applications to Biological and Social Networks]]></title>
		<page_from>643</page_from>
		<page_to>648</page_to>
		<doi_number>10.1109/ICDM.2007.72</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442132</url>
		<abstract>
			<par><![CDATA[Automatic discovery of community structures in complex networks is a fundamental task in many disciplines, including social science, engineering, and biology. Recently, a quantitative measure called modularity (Q) has been proposed to effectively assess the quality of community structures. Several community discovery algorithms have since been developed based on the optimization of Q. However, this optimization problem is NP-hard, and the existing algorithms have a low accuracy or are computationally expensive. In this paper, we present an efficient spectral algorithm for modularity optimization. When tested on a large number of synthetic or real-world networks, and compared to the existing algorithms, our method is efficient and and has a high accuracy. In addition, we have successfully applied our algorithm to detect interesting and meaningful community structures from real-world networks in different domains, including biology, medicine and social science. Due to space limitation, results of these applications are presented in a complete version of the paper available on our website (http://cse.wustl.edu/~jruan/).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202271</person_id>
				<author_profile_id><![CDATA[81100626099]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jianhua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ruan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202272</person_id>
				<author_profile_id><![CDATA[81451597069]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Weixiong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442133</article_id>
		<sort_key>950</sort_key>
		<display_label>Pages</display_label>
		<pages>649-654</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>90</seq_no>
		<title><![CDATA[Exploration of Link Structure and Community-Based Node Roles in Network Analysis]]></title>
		<page_from>649</page_from>
		<page_to>654</page_to>
		<doi_number>10.1109/ICDM.2007.37</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442133</url>
		<abstract>
			<par><![CDATA[Communities are nodes in a network that are grouped together based on a common set of properties. While the communities and link structures are often thought to be in alignment, it may not be the case when the communities are defined using other external criterion. In this paper we provide a new way to measure the alignment. We also provide a new metric that can be used to estimate the number of communities to which a node is attached. This metric, along with degree, is used to assign a communitybased role to nodes. We demonstrate the usefulness of the community-based node roles by applying them to the influence maximization problem.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200888</person_id>
				<author_profile_id><![CDATA[81375600692]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jerry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scripps]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200889</person_id>
				<author_profile_id><![CDATA[81100314838]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pang-Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200890</person_id>
				<author_profile_id><![CDATA[81100008245]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Abdol-Hossein]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Esfahanian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442134</article_id>
		<sort_key>960</sort_key>
		<display_label>Pages</display_label>
		<pages>655-660</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>91</seq_no>
		<title><![CDATA[A Support Vector Approach to Censored Targets]]></title>
		<page_from>655</page_from>
		<page_to>660</page_to>
		<doi_number>10.1109/ICDM.2007.93</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442134</url>
		<abstract>
			<par><![CDATA[Censored targets, such as the time to events in survival analysis, can generally be represented by intervals on the real line. In this paper, we propose a novel support vector technique (named SVCR) for regression on censored targets. SVCR inherits the strengths of support vector methods, such as a globally optimal solution by convex programming, fast training speed and strong generalization capacity. In contrast to ranking approaches to survival analysis, our approach is able not only to achieve superior ordering performance, but also to predict the survival time very well. Experiments show a significant performance improvement when the majority of the training data is censored. Experimental results on several survival analysis datasets demonstrate that SVCR is very competitive against classical survival analysis models.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201806</person_id>
				<author_profile_id><![CDATA[81315491884]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pannagadatta]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Shivaswamy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201807</person_id>
				<author_profile_id><![CDATA[81100142532]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201808</person_id>
				<author_profile_id><![CDATA[81100661686]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jansche]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442135</article_id>
		<sort_key>970</sort_key>
		<display_label>Pages</display_label>
		<pages>661-666</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>92</seq_no>
		<title><![CDATA[Understanding Discrete Classifiers with a Case Study in Gene Prediction]]></title>
		<page_from>661</page_from>
		<page_to>666</page_to>
		<doi_number>10.1109/ICDM.2007.40</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442135</url>
		<abstract>
			<par><![CDATA[The requirement that the models resulting from data mining should be understandable is an uncontroversial requirement. In the data mining literature, however, it plays hardly any role, if at all. In practice, though, understandability is often even more important than, e.g., accuracy. Understandability does not mean that models should be simple. It means that one should be able to understand the predictions of models. In this paper we introduce tools to understand arbitrary classifiers defined on discrete data. More in particular, we introduce Explanations that provide insight at a local level. They explain why a classifier classifies a data point as it does. For global insight, we introduce attribute weights. The higher the weight of an attribute, the more often it is decisive in the classification of a data point. To illustrate our tools, we describe a case study in the prediction of small genes. This is a notoriously hard problem in Bioinformatics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203582</person_id>
				<author_profile_id><![CDATA[81375599484]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Muhammad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Subianto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203583</person_id>
				<author_profile_id><![CDATA[81100532533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Arno]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Siebes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442136</article_id>
		<sort_key>980</sort_key>
		<display_label>Pages</display_label>
		<pages>667-672</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>93</seq_no>
		<title><![CDATA[Statistical Learning Algorithm for Tree Similarity]]></title>
		<page_from>667</page_from>
		<page_to>672</page_to>
		<doi_number>10.1109/ICDM.2007.38</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442136</url>
		<abstract>
			<par><![CDATA[Tree edit distance is one of the most frequently used distance measures for comparing trees. When using the tree edit distance, we need to determine the cost of each operation, but this is a labor-intensive and highly skilled task. This paper proposes an algorithm for learning the costs of tree edit operations from training data consisting of pairs of similar trees. To formalize the cost learning problem, we define a probabilistic model for tree alignment that is a variant of tree edit distance. Then, the parameters of the model are estimated using the expectation maximization (EM) technique. In this paper, we develop an algorithm for parameter learning that is polynomial in time (O(mn2d6)) and space (O(n2d4)) where n, d, and m represent the size of the trees, the maximum degree of trees, and the number of training pairs of trees, respectively.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201365</person_id>
				<author_profile_id><![CDATA[81100489313]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Atsuhiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takasu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201366</person_id>
				<author_profile_id><![CDATA[81100302115]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Daiji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fukagawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201367</person_id>
				<author_profile_id><![CDATA[81100498462]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tatsuya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Akutsu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442137</article_id>
		<sort_key>990</sort_key>
		<display_label>Pages</display_label>
		<pages>673-678</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>94</seq_no>
		<title><![CDATA[A Novel Criterion for Onset Detection]]></title>
		<subtitle><![CDATA[Differential Information Redundancy with Application to Human Movement Initiation]]></subtitle>
		<page_from>673</page_from>
		<page_to>678</page_to>
		<doi_number>10.1109/ICDM.2007.31</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442137</url>
		<abstract>
			<par><![CDATA[A new detection criterion based on the change in the marginal information redundancy is presented. By establishing a link with information theory we are able to give an intuitive interpretation of our criterion. The usefulness of the new criterion is demonstrated for a case study of human movement initiation detection from force and torque signals in activity of daily living tasks. Using the new criterion, we achieve a performance that is more in agreement with expert decisions compared with traditional thresholding techniques and the advanced wavelet-based detector and energy detectors.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201829</person_id>
				<author_profile_id><![CDATA[81435605123]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gert]]></first_name>
				<middle_name><![CDATA[Van]]></middle_name>
				<last_name><![CDATA[Dijck]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201830</person_id>
				<author_profile_id><![CDATA[81409597440]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Marc]]></first_name>
				<middle_name><![CDATA[M.  Van]]></middle_name>
				<last_name><![CDATA[Hulle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201831</person_id>
				<author_profile_id><![CDATA[81435607676]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jo]]></first_name>
				<middle_name><![CDATA[Van]]></middle_name>
				<last_name><![CDATA[Vaerenbergh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442138</article_id>
		<sort_key>1000</sort_key>
		<display_label>Pages</display_label>
		<pages>679-684</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>95</seq_no>
		<title><![CDATA[Using Significant, Positively Associated and Relatively Class Correlated Rules for Associative Classification of Imbalanced Datasets]]></title>
		<page_from>679</page_from>
		<page_to>684</page_to>
		<doi_number>10.1109/ICDM.2007.63</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442138</url>
		<abstract>
			<par><![CDATA[The application of association rule mining to classification has led to a new family of classifiers which are often referred to as "Associative Classifiers (ACs)". An advantage of ACs is that they are rule-based and thus lend themselves to an easier interpretation. Rule-based classifiers can play a very important role in applications such as medical diagnosis and fraud detection where "imbalanced data sets" are the norm and not the exception. The focus of this paper is to extend and modify ACs for classification on imbalanced data sets using only statistical techniques. We combine the use of statistically significant rules with a new measure, the Class Correlation Ratio ( CCR), to build an AC which we call SPARCCC. Experiments show that in terms of classification quality, SPARCCC performs comparably on balanced datasets and outperforms other AC techniques on imbalanced data sets. It also has a significantly smaller rule base and is much more computationally efficient.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200909</person_id>
				<author_profile_id><![CDATA[81321499354]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Florian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Verhein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200910</person_id>
				<author_profile_id><![CDATA[81100002847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sanjay]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chawla]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442139</article_id>
		<sort_key>1010</sort_key>
		<display_label>Pages</display_label>
		<pages>685-690</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>96</seq_no>
		<title><![CDATA[Preserving Privacy through Data Generation]]></title>
		<page_from>685</page_from>
		<page_to>690</page_to>
		<doi_number>10.1109/ICDM.2007.25</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442139</url>
		<abstract>
			<par><![CDATA[Many databases will not or can not be disclosed without strong guarantees that no sensitive information can be extracted. To address this concern several data perturbation techniques have been proposed. However, it has been shown that either sensitive information can still be extracted from the perturbed data with little prior knowledge, or that many patterns are lost. In this paper we show that generating new data is an inherently safer alternative. We present a data generator based on the models obtained by the MDLbased KRIMP [12] algorithm. These are accurate representations of the data distributions and can thus be used to generate data with the same characteristics as the original data. Experimental results show a very large patternsimilarity between the generated and the original data, ensuring that viable conclusions can be drawn from the anonymised data. Furthermore, anonymity is guaranteed for suited databases and the quality privacy trade-off can be balanced explicitly.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202285</person_id>
				<author_profile_id><![CDATA[81335499054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jilles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vreeken]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202286</person_id>
				<author_profile_id><![CDATA[81540779256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Matthijs]]></first_name>
				<middle_name><![CDATA[van]]></middle_name>
				<last_name><![CDATA[Leeuwen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202287</person_id>
				<author_profile_id><![CDATA[81100532533]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Arno]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Siebes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442140</article_id>
		<sort_key>1020</sort_key>
		<display_label>Pages</display_label>
		<pages>691-696</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>97</seq_no>
		<title><![CDATA[Transitional Patterns and Their Significant Milestones]]></title>
		<page_from>691</page_from>
		<page_to>696</page_to>
		<doi_number>10.1109/ICDM.2007.87</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442140</url>
		<abstract>
			<par><![CDATA[Mining frequent patterns in transaction databases has been studied extensively in data mining research. However, most of the existing frequent pattern mining algorithms do not consider the time stamps associated with the transactions. In this paper, we extend the existing frequent pattern mining framework to take into account the time stamp of each transaction and discover patterns whose frequency dramatically changes over time. We define a new type of patterns, called transitional patterns, to capture the dynamic behavior of frequent patterns in a transaction database. Transitional patterns include both positive and negative transitional patterns. Their frequencies increase/decrease dramatically at some time points of a transaction database. We introduce the concept of significant milestones for a transitional pattern, which are time points at which the frequency of the pattern changes most significantly. Moreover, we develop an algorithm to mine from a transaction database the set of transitional patterns along with their significant milestones. Our experimental studies on real-world databases illustrate that mining positive and negative transitional patterns is highly promising as a practical and useful approach to discovering novel and interesting knowledge from large databases.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201832</person_id>
				<author_profile_id><![CDATA[81318496772]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Qian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201833</person_id>
				<author_profile_id><![CDATA[81100329796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Aijun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[An]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442141</article_id>
		<sort_key>1030</sort_key>
		<display_label>Pages</display_label>
		<pages>697-702</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>98</seq_no>
		<title><![CDATA[Topical N-Grams]]></title>
		<subtitle><![CDATA[Phrase and Topic Discovery, with an Application to Information Retrieval]]></subtitle>
		<page_from>697</page_from>
		<page_to>702</page_to>
		<doi_number>10.1109/ICDM.2007.86</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442141</url>
		<abstract>
			<par><![CDATA[Most topic models, such as latent Dirichlet allocation, rely on the bag-of-words assumption. However, word order and phrases are often critical to capturing the meaning of text in many text mining tasks. This paper presents topical n-grams, a topic model that discovers topics as well as topical phrases. The probabilistic model generates words in their textual order by, for each word, first sampling a topic, then sampling its status as a unigram or bigram, and then sampling the word from a topic-specific unigram or bigram distribution. Thus our model can model "white house" as a special meaning phrase in the `politics' topic, but not in the `real estate' topic. Successive bigrams form longer phrases. We present experiments showing meaningful phrases and more interpretable topics from the NIPS data and improved information retrieval performance on a TREC collection.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203177</person_id>
				<author_profile_id><![CDATA[81335499286]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xuerui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203178</person_id>
				<author_profile_id><![CDATA[81100553872]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McCallum]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203179</person_id>
				<author_profile_id><![CDATA[81540450056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442142</article_id>
		<sort_key>1040</sort_key>
		<display_label>Pages</display_label>
		<pages>703-708</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>99</seq_no>
		<title><![CDATA[Mechanism Design for Clustering Aggregation by Selfish Systems]]></title>
		<page_from>703</page_from>
		<page_to>708</page_to>
		<doi_number>10.1109/ICDM.2007.80</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442142</url>
		<abstract>
			<par><![CDATA[We propose a market mechanism that can be implemented on clustering aggregation problem among selfish systems, which tend to lie about their correct clustering during aggregation process. Our study is the preliminary step toward the development of robust distributed data mining among selfish systems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200923</person_id>
				<author_profile_id><![CDATA[81100481286]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pinata]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Winoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200924</person_id>
				<author_profile_id><![CDATA[81536742656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yiu-ming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cheung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200925</person_id>
				<author_profile_id><![CDATA[81375608602]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jiming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442143</article_id>
		<sort_key>1050</sort_key>
		<display_label>Pages</display_label>
		<pages>709-714</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>100</seq_no>
		<title><![CDATA[estMax]]></title>
		<subtitle><![CDATA[Tracing Maximal Frequent Itemsets over Online Data Streams]]></subtitle>
		<page_from>709</page_from>
		<page_to>714</page_to>
		<doi_number>10.1109/ICDM.2007.70</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442143</url>
		<abstract>
			<par><![CDATA[In general, the number of frequent itemsets in a data set is very large. In order to represent them in more compact notation, closed or maximal frequent itemsets (MFIs) are used. However, the characteristics of a data stream make such a task be more difficult. For this purpose, this paper proposes a method called estMax that can trace the set of MFIs over a data stream. The proposed method maintains the set of frequent itemsets by a prefix tree and extracts all of MFIs without any additional superset/subset checking mechanism. Upon processing a newly generated transaction, its longest matched frequent itemsets are marked in a prefix tree as candidates for MFIs. At the same time, if any subset of these newly marked itemsets has been already marked as a candidate MFI, it is cleared as well. By employing this additional step, it is possible to extract the set of MFIs at any moment. The performance of the proposed method is comparatively analyzed by a series of experiments to identify its various characteristics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201847</person_id>
				<author_profile_id><![CDATA[81375605506]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ho]]></first_name>
				<middle_name><![CDATA[Jin]]></middle_name>
				<last_name><![CDATA[Woo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201848</person_id>
				<author_profile_id><![CDATA[81100384662]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Won]]></first_name>
				<middle_name><![CDATA[Suk]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442144</article_id>
		<sort_key>1060</sort_key>
		<display_label>Pages</display_label>
		<pages>715-720</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>101</seq_no>
		<title><![CDATA[Locally Constrained Support Vector Clustering]]></title>
		<page_from>715</page_from>
		<page_to>720</page_to>
		<doi_number>10.1109/ICDM.2007.58</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442144</url>
		<abstract>
			<par><![CDATA[Support vector clustering transforms the data into a high dimensional feature space, where a decision function is computed. In the original space, the function outlines the boundaries of higher density regions, naturally splitting the data into individual clusters. The method, however, though theoretically sound, has certain drawbacks which make it not so appealing to the practitioner. Namely, it is unstable in the presence of outliers and it is hard to control the number of clusters that it identifies. Parametrizing the algorithm incorrectly in noisy settings, can either disguise some objectively present clusters in the data, or can identify a large number of small and nonintuitive clusters. Here, we explore the properties of the data in small regions building a mixture of factor analyzers. The obtained information is used to regularize the complexity of the outlined cluster boundaries, by assigning suitable weighting to each example. The approach is demonstrated to be less susceptible to noise and to outline better interpretable clusters than support vector clustering alone.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200926</person_id>
				<author_profile_id><![CDATA[81309492747]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dragomir]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yankov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200927</person_id>
				<author_profile_id><![CDATA[81100209161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eamonn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Keogh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200928</person_id>
				<author_profile_id><![CDATA[81536937056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kin]]></first_name>
				<middle_name><![CDATA[Fai]]></middle_name>
				<last_name><![CDATA[Kan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442145</article_id>
		<sort_key>1070</sort_key>
		<display_label>Pages</display_label>
		<pages>721-726</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>102</seq_no>
		<title><![CDATA[Cocktail Ensemble for Regression]]></title>
		<page_from>721</page_from>
		<page_to>726</page_to>
		<doi_number>10.1109/ICDM.2007.60</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442145</url>
		<abstract>
			<par><![CDATA[This paper is motivated to improve the performance of individual ensembles using a hybrid mechanism in the regression setting. Based on an error-ambiguity decomposition, we formally analyze the optimal linear combination of two base ensembles, which is then extended to multiple individual ensembles via pairwise combinations. The Cocktail ensemble approach is proposed based on this analysis. Experiments over a broad range of data sets show that the proposed approach outperforms the individual ensembles, two other methods of ensemble combination, and two stateof-the-art regression approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200421</person_id>
				<author_profile_id><![CDATA[81385596195]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200422</person_id>
				<author_profile_id><![CDATA[81451593001]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zhi-Hua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1200423</person_id>
				<author_profile_id><![CDATA[81100367824]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kai]]></first_name>
				<middle_name><![CDATA[Ming]]></middle_name>
				<last_name><![CDATA[Ting]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442146</article_id>
		<sort_key>1080</sort_key>
		<display_label>Pages</display_label>
		<pages>727-732</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>103</seq_no>
		<title><![CDATA[Incremental Subspace Clustering over Multiple Data Streams]]></title>
		<page_from>727</page_from>
		<page_to>732</page_to>
		<doi_number>10.1109/ICDM.2007.100</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442146</url>
		<abstract>
			<par><![CDATA[Data streams are often locally correlated, with a subset of streams exhibiting coherent patterns over a subset of time points. Subspace clustering can discover clusters of objects in different subspaces. However, traditional subspace clustering algorithms for static data sets are not readily used for incremental clustering, and is very expensive for frequent re-clustering over dynamically changing stream data. In this paper, we present an efficient incremental subspace clustering algorithm for multiple streams over sliding windows. Our algorithm detects all the -CC-Clusters, which capture the coherent changing patterns among a set of streams over a set of time points. -CC-Clusters are incrementally generated by traversing a directed acyclic graph pDAG. We propose efficient insertion and deletion operations to update the pDAG dynamically. In addition, effective pruning techniques are applied to reduce the search space. Experiments on real data sets demonstrate the performance of our algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203180</person_id>
				<author_profile_id><![CDATA[81322511304]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Qi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203181</person_id>
				<author_profile_id><![CDATA[81467660181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jinze]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203182</person_id>
				<author_profile_id><![CDATA[81416594540]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442147</article_id>
		<sort_key>1090</sort_key>
		<display_label>Pages</display_label>
		<pages>733-738</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>104</seq_no>
		<title><![CDATA[Noise Modeling with Associative Corruption Rules]]></title>
		<page_from>733</page_from>
		<page_to>738</page_to>
		<doi_number>10.1109/ICDM.2007.28</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442147</url>
		<abstract>
			<par><![CDATA[This paper presents an active learning approach to the problem of systematic noise inference and noise elimination, specifically the inference of Associated Corruption (AC) rules. AC rules are defined to simulate a common noise formation process in real-world data, in which the occurrence of an error on one attribute is dependent on several other attribute values. Our approach consists of two algorithms, Associative Corruption Forward (ACF) and Associative Corruption Backward (ACB). Algorithm ACF is proposed for noise inference, and ACB is designed for noise elimination. The experimental results show that the ACF algorithm can infer the noise formation correctly, and ACB indeed enhances the data quality for supervised learning.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202318</person_id>
				<author_profile_id><![CDATA[81375612992]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202319</person_id>
				<author_profile_id><![CDATA[81375615116]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xindong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442053</article_id>
		<sort_key>1100</sort_key>
		<display_label>Pages</display_label>
		<pages>739-744</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>105</seq_no>
		<title><![CDATA[Co-ranking Authors and Documents in a Heterogeneous Network]]></title>
		<page_from>739</page_from>
		<page_to>744</page_to>
		<doi_number>10.1109/ICDM.2007.57</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442053</url>
		<abstract>
			<par><![CDATA[Recent graph-theoretic approaches have demonstrated remarkable successes for ranking networked entities, but most of their applications are limited to homogeneous networks such as the network of citations between publications. This paper proposes a novel method for co-ranking authors and their publications using several networks: the social network connecting the authors, the citation network connecting the publications, as well as the authorship network that ties the previous two together. The new co-ranking framework is based on coupling two random walks, that separately rank authors and documents following the PageRank paradigm. As a result, improved rankings of documents and their authors depend on each other in a mutually reinforcing way, thus taking advantage of the additional information implicit in the heterogeneous network of authors and documents.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1202011</person_id>
				<author_profile_id><![CDATA[81309500562]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ding]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202012</person_id>
				<author_profile_id><![CDATA[81375617177]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sergey]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Orshanskiy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202013</person_id>
				<author_profile_id><![CDATA[81100528811]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hongyuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1202014</person_id>
				<author_profile_id><![CDATA[81100126614]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[Lee]]></middle_name>
				<last_name><![CDATA[Giles]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442054</article_id>
		<sort_key>1110</sort_key>
		<display_label>Pages</display_label>
		<pages>745-750</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>106</seq_no>
		<title><![CDATA[Discovering Temporal Communities from Social Network Documents]]></title>
		<page_from>745</page_from>
		<page_to>750</page_to>
		<doi_number>10.1109/ICDM.2007.56</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442054</url>
		<abstract>
			<par><![CDATA[This paper studies the discovery of communities from social network documents produced over time, addressing the discovery of temporal trends in community memberships. We first formulate static community discovery at a single time period as a tripartite graph partitioning problem. Then we propose to discover the temporal communities by threading the statically derived communities in different time periods using a new constrained partitioning algorithm, which partitions graphs based on topology as well as prior information regarding vertex membership. We evaluate the proposed approach on synthetic datasets and a real-world dataset prepared from the CiteSeer.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203319</person_id>
				<author_profile_id><![CDATA[81309500562]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ding]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203320</person_id>
				<author_profile_id><![CDATA[81100400797]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Isaac]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Councill]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203321</person_id>
				<author_profile_id><![CDATA[81100528811]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hongyuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203322</person_id>
				<author_profile_id><![CDATA[81100126614]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[C.]]></first_name>
				<middle_name><![CDATA[Lee]]></middle_name>
				<last_name><![CDATA[Giles]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442055</article_id>
		<sort_key>1120</sort_key>
		<display_label>Pages</display_label>
		<pages>751-756</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>107</seq_no>
		<title><![CDATA[Efficient Discovery of Frequent Approximate Sequential Patterns]]></title>
		<page_from>751</page_from>
		<page_to>756</page_to>
		<doi_number>10.1109/ICDM.2007.75</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442055</url>
		<abstract>
			<par><![CDATA[We propose an efficient algorithm for mining frequent approximate sequential patterns under the Hamming distance model. Our algorithm gains its efficiency by adopting a "break-down-and-build-up" methodology. The "breakdown" is based on the observation that all occurrences of a frequent pattern can be classified into groups, which we call strands. We developed efficient algorithms to quickly mine out all strands by iterative growth. In the "build-up" stage, these strands are grouped up to form the support sets from which all approximate patterns would be identified. A salient feature of our algorithm is its ability to grow the frequent patterns by iteratively assembling building blocks of significant sizes in a local search fashion. By avoiding incremental growth and global search, we achieve greater efficiency without losing the completeness of the mining result. Our experimental studies demonstrate that our algorithm is efficient in mining globally repeating approximate sequential patterns that would have been missed by existing methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1201552</person_id>
				<author_profile_id><![CDATA[81313483490]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Feida]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201553</person_id>
				<author_profile_id><![CDATA[81100044779]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xifeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201554</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1201555</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442056</article_id>
		<sort_key>1130</sort_key>
		<display_label>Pages</display_label>
		<pages>757-762</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>108</seq_no>
		<title><![CDATA[Active Learning from Data Streams]]></title>
		<page_from>757</page_from>
		<page_to>762</page_to>
		<doi_number>10.1109/ICDM.2007.101</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442056</url>
		<abstract>
			<par><![CDATA[In this paper, we address a new research problem on active learning from data streams where data volumes grow continuously and labeling all data is considered expensive and impractical. The objective is to label a small portion of stream data from which a model is derived to predict newly arrived instances as accurate as possible. In order to tackle the challenges raised by data streams' dynamic nature, we propose a classifier ensembling based active learning framework which selectively labels instances from data streams to build an accurate classifier. A Minimal Variance principle is introduced to guide instance labeling from data streams. In addition, a weight updating rule is derived to ensure that our instance labeling process can adaptively adjust to dynamic drifting concepts in the data. Experimental results on synthetic and real-world data demonstrate the performances of the proposed efforts in comparison with other simple approaches. *]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1203323</person_id>
				<author_profile_id><![CDATA[81452600756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xingquan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203324</person_id>
				<author_profile_id><![CDATA[81384603947]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203325</person_id>
				<author_profile_id><![CDATA[81375599001]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xiaodong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1203326</person_id>
				<author_profile_id><![CDATA[81409595544]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Yong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442057</article_id>
		<sort_key>1140</sort_key>
		<display_label>Pages</display_label>
		<pages>763-768</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>109</seq_no>
		<title><![CDATA[Lazy Bagging for Classifying Imbalanced Data]]></title>
		<page_from>763</page_from>
		<page_to>768</page_to>
		<doi_number>10.1109/ICDM.2007.95</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442057</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a Lazy Bagging (LB) design, which builds bootstrap replicate bags based on the characteristics of the test instances. Upon receiving a test instance Ik, LB will trim bootstrap bags by taking Ik's nearest neighbors in the training set into consideration. Our hypothesis is that an unlabeled instance's nearest neighbors provide valuable information for learners to refine their local decision boundaries for classifying this instance. By taking full advantage of Ik's nearest neighbors, the base learners are able to receive less bias and variance in classifying Ik. This strategy is beneficial for classifying imbalanced data because refining local decision boundaries can help a learner reduce its inherent bias towards the majority class and improve its performance on minority class examples. Our experimental results will confirm that LB outperforms C4.5 and TB in terms of reducing classification error, and most importantly this error reduction is largely contributed from LB's improvement on minority class examples.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1200125</person_id>
				<author_profile_id><![CDATA[81375599628]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xingquan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1442058</article_id>
		<sort_key>1150</sort_key>
		<display_label>Pages</display_label>
		<pages>769-771</pages>
		<article_publication_date>10-28-2007</article_publication_date>
		<seq_no>110</seq_no>
		<title><![CDATA[Author Index]]></title>
		<page_from>769</page_from>
		<page_to>771</page_to>
		<doi_number>10.1109/ICDM.2007.109</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1442058</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
</content>
</proceeding>

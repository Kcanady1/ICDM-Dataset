<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>11-01-2004</start_date>
		<end_date>11-04-2004</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url>http://computer.org/proceedings/icdm/2004/2142</conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES11036</series_id>
		<series_title><![CDATA[ICDM]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1032649</proc_id>
	<acronym>ICDM '04</acronym>
	<proc_desc>Proceedings of the Fourth IEEE International Conference</proc_desc>
	<conference_number>4</conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Data Mining</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-7695-2142-8</isbn>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2004</copyright_year>
	<publication_date>11-01-2004</publication_date>
	<pages></pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB769</publisher_id>
		<publisher_code>IEEEW</publisher_code>
		<publisher_name>IEEE Computer Society</publisher_name>
		<publisher_address>1730 Massachusetts Ave., NW             Washington, DC</publisher_address>
		<publisher_city></publisher_city>
		<publisher_state></publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>20036-1992</publisher_zip_code>
		<publisher_contact></publisher_contact>
		<publisher_phone></publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url></publisher_url>
	</publisher>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>1033421</article_id>
		<sort_key>.13</sort_key>
		<display_label></display_label>
		<pages>xiii-xiv</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Welcome to ICDM 2004]]></title>
		<page_from>.13</page_from>
		<page_to>xiv</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033421</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033422</article_id>
		<sort_key>.15</sort_key>
		<display_label></display_label>
		<pages>xv-xv</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Conference Organization]]></title>
		<page_from>.15</page_from>
		<page_to>xv</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033422</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033423</article_id>
		<sort_key>.16</sort_key>
		<display_label></display_label>
		<pages>xvi-xvi</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Steering Committee]]></title>
		<page_from>.16</page_from>
		<page_to>xvi</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033423</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033424</article_id>
		<sort_key>.17</sort_key>
		<display_label></display_label>
		<pages>xvii-xix</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Program Committee]]></title>
		<page_from>.17</page_from>
		<page_to>xix</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033424</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033425</article_id>
		<sort_key>.2</sort_key>
		<display_label></display_label>
		<pages>xx-xxi</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Non-PC Reviewers]]></title>
		<page_from>.20</page_from>
		<page_to>xxi</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033425</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033426</article_id>
		<sort_key>.22</sort_key>
		<display_label></display_label>
		<pages>xxii-xxii</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Corporate Sponsors]]></title>
		<page_from>.22</page_from>
		<page_to>xxii</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033426</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033431</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<pages>3-10</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Detection of Significant Sets of Episodes in Event Sequences]]></title>
		<page_from>3</page_from>
		<page_to>10</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033431</url>
		<abstract>
			<par><![CDATA[We present a method for a reliable detection of "unusual" sets of episodes in the form of many pattern sequences, scanned simultaneously for an occurrence as a subsequence in a large event stream within a window of size w. We also investigate the important special case of all permutations of the same sequence, which models the situation where the order of events in an episode does not matter, e.g., when events correspond to purchased market basket items. In order to build a reliable monitoring system we compare obtained measurements to a reference model which in our case is a probabilistic model (Bernoulli or Markov). We first present a precise analysis that leads to a construction of a threshold. The difficulties of carrying out a probabilistic analysis for an arbitrary set of patterns, stems from the possible simultaneous occurrence of many members of the set as subsequences in the same window, the fact that the different patterns typically do have common symbols or common subsequences or possibly common prefixes, and that they may have different lengths. We also report on extensive experimental results, carried out on the Wal-Mart transactions database, that show a remarkable agreement with our theoretical analysis. This paper is an extension of our previous work in [Reliable detection of episodes in event sequences] where we laid out foundation for the problem of the reliable detection of an "unusual" episodes, but did not consider more than one episode scanned simultaneously for an occurrence.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14127532</person_id>
				<author_profile_id><![CDATA[81100355888]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mikhail]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Atallah]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45024052</person_id>
				<author_profile_id><![CDATA[81343493912]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gwadera]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39029192</person_id>
				<author_profile_id><![CDATA[81100136191]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wojciech]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Szpankowski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Purdue University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033430</article_id>
		<sort_key>11</sort_key>
		<display_label></display_label>
		<pages>11-18</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Subspace Selection for Clustering High-Dimensional Data]]></title>
		<page_from>11</page_from>
		<page_to>18</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033430</url>
		<abstract>
			<par><![CDATA[In high-dimensional feature spaces traditional clustering algorithms tend to break down in terms of efficiency and quality. Nevertheless, the data sets often contain clusters which are hidden in various subspaces of the original feature space. In this paper, we present a feature selection technique called SURFING (SUbspaces Relevant For clusterING) that finds all subspaces interesting for clustering and sorts them by relevance. The sorting is based on a quality criterion for the interestingness of a subspace using the k-nearest neighbor distances of the objects. As our method is more or less parameterless, it addresses the unsupervised notion of the data mining task "clustering" in a best possible way. A broad evaluation based on synthetic and real-world data sets demonstrates that SURFING is suitable to find all relevant subspaces in high dimensional, sparse data sets and produces better results than comparative methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P701927</person_id>
				<author_profile_id><![CDATA[81100581578]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Baumgartner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University for Health Sciences, Austria]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP16000355</person_id>
				<author_profile_id><![CDATA[81321496970]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Claudia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Plant]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University for Health Sciences, Austria]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P663559</person_id>
				<author_profile_id><![CDATA[81100207003]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Karin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kailing]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15034628</person_id>
				<author_profile_id><![CDATA[81100512920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kriegel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39032477</person_id>
				<author_profile_id><![CDATA[81332509808]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Peer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kroger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033432</article_id>
		<sort_key>19</sort_key>
		<display_label></display_label>
		<pages>19-26</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Multi-View Clustering]]></title>
		<page_from>19</page_from>
		<page_to>26</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033432</url>
		<abstract>
			<par><![CDATA[We consider clustering problems in which the available attributes can be split into two independent subsets, such that either subset suffices for learning. Example applications of this multi-view setting include clustering of web pages which have an intrinsic view (the pages themselves) and an extrinsic view (e.g., anchor texts of inbound hyperlinks); multi-view learning has so far been studied in the context of classification. We develop and study partitioning and agglomerative, hierarchical multi-view clustering algorithms for text data. We find empirically that the multi-view versions of k-Means and EM greatly improve on their single-view counterparts. By contrast, we obtain negative results for agglomerative hierarchical multi-view clustering. Our analysis explains this surprising phenomenon.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP33025317</person_id>
				<author_profile_id><![CDATA[81333487432]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steffen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bickel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Humboldt-Universit&#228;t zu Berlin, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37024781</person_id>
				<author_profile_id><![CDATA[81100180901]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tobias]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scheffer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Humboldt-Universit&#228;t zu Berlin, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033433</article_id>
		<sort_key>27</sort_key>
		<display_label></display_label>
		<pages>27-34</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Density Connected Clustering with Local Subspace Preferences]]></title>
		<page_from>27</page_from>
		<page_to>34</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033433</url>
		<abstract>
			<par><![CDATA[Many clustering algorithms tend to break down in high-dimensional feature spaces, because the clusters often exist only in specific subspaces (attribute subsets) of the original feature space. Therefore, the task of projected clustering (or subspace clustering) has been defined recently. As a novel solution to tackle this problem, we propose the concept of local subspace preferences, which captures the main directions of high point density. Using this concept we adopt density-based clustering to cope with high-dimensional data. In particular, we achieve the following advantages over existing approaches: Our proposed method has a determinate result, does not depend on the order of processing, is robust against noise, performs only one single scan over the database, and is linear in the number of dimensions. A broad experimental evaluation shows that our approach yields results of significantly better quality than recent work on clustering high-dimensional data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15031232</person_id>
				<author_profile_id><![CDATA[81100395758]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bohm]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P663559</person_id>
				<author_profile_id><![CDATA[81100207003]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Karin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kailing]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15034628</person_id>
				<author_profile_id><![CDATA[81100512920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kriegel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39032477</person_id>
				<author_profile_id><![CDATA[81332509808]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Peer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kroger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033434</article_id>
		<sort_key>35</sort_key>
		<display_label></display_label>
		<pages>35-42</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[On Closed Constrained Frequent Pattern Mining]]></title>
		<page_from>35</page_from>
		<page_to>42</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033434</url>
		<abstract>
			<par><![CDATA[Constrained frequent patterns and closed frequent patterns are two paradigms aimed at reducing the set of extracted patterns to a smaller, more interesting, subset. Although a lot of work has been done with both these paradigms, there is still confusion around the mining problem obtained by joining closed and constrained frequent patterns in a unique framework. In this paper we shed light on this problem by providing a formal definition and a thorough characterization. Wealso study computational issues and show how to combine the most recent results in both paradigms, providing a very efficient algorithm which exploits the two requirements (satisfying constraints and being closed) together at mining time in order to reduce the computation as much as possible.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31036424</person_id>
				<author_profile_id><![CDATA[81100305585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Francesco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bonchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ISTI - CNR, Area della Ricerca di Pisa, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP27004221</person_id>
				<author_profile_id><![CDATA[81324491771]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Claudio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lucchese]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ISTI - CNR, Area della Ricerca di Pisa, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033435</article_id>
		<sort_key>43</sort_key>
		<display_label></display_label>
		<pages>43-50</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Efficient Density-Based Clustering of Complex Objects]]></title>
		<page_from>43</page_from>
		<page_to>50</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033435</url>
		<abstract>
			<par><![CDATA[Nowadays data mining in large databases of complex objects from scientific, engineering or multimedia applications is getting more and more important. In many different application domains complex object representations along with complex distance functions are used for measuring the similarity between objects. Often not only these complex distance measures are available but also simpler distance functions which can be computed much more efficiently. Traditionally, the well known concept of multi-step query processing which is based on exact and lower-bounding approximative distance functions is used independently of data mining algorithms. In this paper, we will demonstrate how the paradigm of multi-step query processing can be integrated into the two density-based clustering algorithms DBSCAN and OPTICS resulting in a considerable efficiency boost. Our approach tries to confine itself to ¿-range queries on the simple distance functions and carries out complex distance computations only at that stage of the clustering algorithm where they are compulsory to compute the correct clustering result. In a broad experimental evaluation based on real-world test data sets, we demonstrate that our approach accelerates the generation of flat and hierarchical density-based clusterings by more than one order of magnitude.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P581310</person_id>
				<author_profile_id><![CDATA[81100589657]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Brecheisen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15034628</person_id>
				<author_profile_id><![CDATA[81100512920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hans-Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kriegel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P479270</person_id>
				<author_profile_id><![CDATA[81100553208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pfeifle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Munich, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033436</article_id>
		<sort_key>51</sort_key>
		<display_label></display_label>
		<pages>51-58</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Test-Cost Sensitive Naive Bayes Classification]]></title>
		<page_from>51</page_from>
		<page_to>58</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033436</url>
		<abstract>
			<par><![CDATA[Inductive learning techniques such as the naive Bayes and decision tree algorithms have been extended in the past to handle different types of costs mainly by distinguishing different costs of classification errors. However, it is an equally important issue to consider how to handle the test costs associated with querying the missing values in a test case. When the value of an attribute is missing in a test case, it may or may not be worthwhile to take the effort to obtain its missing value, depending on how much the value will result in a potential gain in the classification accuracy. In this paper, we show how to obtain a test-cost sensitive naive Bayes classifier (csNB) by including a test strategy which determines how unknown attributes are selected to perform test on in order to minimize the sum of the mis-classification costs and test costs. We propose and evaluate several potential test strategies including one that allows several tests to be done at once. We empirically evaluate the csNB method, and show that it compares favorably with its decision tree counterpart.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P703326</person_id>
				<author_profile_id><![CDATA[81100204879]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiaoyong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15024957</person_id>
				<author_profile_id><![CDATA[81338488235]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Deng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77025006</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030222</person_id>
				<author_profile_id><![CDATA[81100159332]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[X.]]></middle_name>
				<last_name><![CDATA[Ling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Western Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033437</article_id>
		<sort_key>59</sort_key>
		<display_label></display_label>
		<pages>59-66</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Moment]]></title>
		<subtitle><![CDATA[Maintaining Closed Frequent Itemsets over a Stream Sliding Window]]></subtitle>
		<page_from>59</page_from>
		<page_to>66</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033437</url>
		<abstract>
			<par><![CDATA[This paper considers the problem of mining closed frequent itemsets over a sliding window using limited memory space. We design a synopsis data structure to monitor transactions in the sliding window so that we can output the current closed frequent itemsets at any time. Due to time and memory constraints, the synopsis data structure cannot monitor all possible itemsets. However, monitoring only frequent itemsets will make it impossible to detect new itemsets when they become frequent. In this paper, we introduce a compact data structure, the closed enumeration tree (CET), to maintain a dynamically selected set of itemsets over a sliding-window. The selected itemsets consist of a boundary between closed frequent itemsets and the rest of the itemsets. Concept drifts in a data stream are reflected by boundary movements in the CET. In other words, a status change of any itemset (e.g., from non-frequent to frequent) must occur through the boundary. Because the boundary is relatively stable, the cost of mining closed frequent itemsets over a sliding window is dramatically reduced to that of mining transactions that can possibly cause boundary movements in the CET. Our experiments show that our algorithm performs much better than previous approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P645622</person_id>
				<author_profile_id><![CDATA[81350577988]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15026328</person_id>
				<author_profile_id><![CDATA[81455605782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haixun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Thomas J. Watson Research Center, Hawthorne, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Thomas J. Watson Research Center, Hawthorne, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42049806</person_id>
				<author_profile_id><![CDATA[81332517207]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Muntz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033438</article_id>
		<sort_key>67</sort_key>
		<display_label></display_label>
		<pages>67-74</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Communication Efficient Construction of Decision Trees Over Heterogeneously Distributed Data]]></title>
		<page_from>67</page_from>
		<page_to>74</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033438</url>
		<abstract>
			<par><![CDATA[We present an algorithm designed to efficiently construct a decision tree over heterogeneously distributed data without centralizing. We compare our algorithm against a standard centralized decision tree implementation in terms of accuracy as well as the communication complexity. Our experimental results show that by using only 20% of the communication cost necessary to centralize the data we can achieve trees with accuracy at least 80% of the trees produced by the centralized version.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Decision Trees, Distributed Data Mining, Random Projection]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P403466</person_id>
				<author_profile_id><![CDATA[81100182194]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Giannella]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Maryland Baltimore County, Baltimore, MD]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39046951</person_id>
				<author_profile_id><![CDATA[81452593047]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Maryland Baltimore County, Baltimore, MD]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P703212</person_id>
				<author_profile_id><![CDATA[81100587162]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Todd]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Olsen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Maryland Baltimore County, Baltimore, MD]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39029854</person_id>
				<author_profile_id><![CDATA[81100150749]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hillol]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kargupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Maryland Baltimore County, Baltimore, MD]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033439</article_id>
		<sort_key>75</sort_key>
		<display_label></display_label>
		<pages>75-82</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Non-Redundant Data Clustering]]></title>
		<page_from>75</page_from>
		<page_to>82</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033439</url>
		<abstract>
			<par><![CDATA[Data clustering is a popular approach for automatically finding classes, concepts, or groups of patterns. In practice this discovery process should avoid redundancies with existing knowledge about class structures or groupings, and reveal novel, previously unknown aspects of the data. In order to deal with this problem, we present an extension of the information bottleneck framework, called coordinated conditional information bottleneck, which takes negative relevance information into account by maximizing a conditional mutual information score subject to constraints. Algorithmically, one can apply an alternating optimization scheme that can be used in conjunction with different types of numeric and non-numeric attributes. We present experimental results for applications in text mining and computer vision.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P452033</person_id>
				<author_profile_id><![CDATA[81100462360]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gondek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43135961</person_id>
				<author_profile_id><![CDATA[81338489201]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hofmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Brown University, Providence, RI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033440</article_id>
		<sort_key>83</sort_key>
		<display_label></display_label>
		<pages>83-90</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Fast and Exact Out-of-Core K-Means Clustering]]></title>
		<page_from>83</page_from>
		<page_to>90</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033440</url>
		<abstract>
			<par><![CDATA[Clustering has been one of the most widely studied topics in data mining and k-means clustering has been one of the popular clustering algorithms. K-means requires several passes on the entire dataset, which can make it very expensive for large disk-resident datasets. In view of this, a lot of work has been done on various approximate versions of k-means, which require only one or a small number of passes on the entire dataset. In this paper, we present a new algorithm which typically requires only one or a small numberof passes on the entire dataset, and provably produces the same cluster centers as reported by the original k-means algorithm. The algorithm uses sampling to create initial cluster centers, and then takes one or more passes over the entire dataset to adjust these cluster centers. We provide theoretical analysis to show that the cluster centers thus reported are the same as the ones computed by the original k-means algorithm. Experimental results from a number of real and synthetic datasets show speedup between a factor of 2 and 4.5, as compared to k-means.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P701774</person_id>
				<author_profile_id><![CDATA[81100307164]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Anjan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goswami]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P347521</person_id>
				<author_profile_id><![CDATA[81100054574]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ruoming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P93478</person_id>
				<author_profile_id><![CDATA[81100288827]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Gagan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Agrawal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033441</article_id>
		<sort_key>91</sort_key>
		<display_label></display_label>
		<pages>91-98</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Mining Frequent Itemsets from Secondary Memory]]></title>
		<page_from>91</page_from>
		<page_to>98</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033441</url>
		<abstract>
			<par><![CDATA[Mining frequent itemsets is at the core of mining association rules, and is by now quite well understood algorithmically for main memory databases. In this paper, we investigate approaches to mining frequent itemsets when the database or the data structures used in the mining are too large to fit in main memory. Experimental results show that our techniques reduce the required disk accesses by orders of magnitude, and enable truly scalable data mining.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P98929</person_id>
				<author_profile_id><![CDATA[81100137470]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gosta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grahne]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Concordia University, Montreal, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P398491</person_id>
				<author_profile_id><![CDATA[81100415578]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jianfei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Concordia University, Montreal, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033442</article_id>
		<sort_key>99</sort_key>
		<display_label></display_label>
		<pages>99-105</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[A Bayesian Framework for Regularized SVM Parameter Estimation]]></title>
		<page_from>99</page_from>
		<page_to>105</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033442</url>
		<abstract>
			<par><![CDATA[The support vector machine (SVM) is considered here in the context of pattern classification. The emphasis is on the soft margin classifier which uses regularization to handle non-separable learning samples. We present an SVM parameter estimation algorithm that first identifies a subset of the learning samples that we call the support set and then determines not only the weights of the classifier but also the hyperparameter that controls the influence of the regularizing penalty term on basis thereof. We provide numerical results using several data sets from the public domain.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP36026930</person_id>
				<author_profile_id><![CDATA[81339502347]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jens]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gregor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tennessee, Knoxville, TN]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45031065</person_id>
				<author_profile_id><![CDATA[81339514191]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zhenqiu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tennessee, Knoxville, TN]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033443</article_id>
		<sort_key>106</sort_key>
		<display_label></display_label>
		<pages>106-113</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Unimodal Segmentation of Sequences]]></title>
		<page_from>106</page_from>
		<page_to>113</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033443</url>
		<abstract>
			<par><![CDATA[We study the problem of segmenting a sequence into k pieces so that the resulting segmentation satisfies monotonicity or unimodality constraints. Unimodal functions can be used to model phenomena in which a measured variable first increases to a certain level and then decreases. We combine a well-known unimodal regression algorithm with a simple dynamic-programming approach to obtain an optimal quadratic-time algorithm for the problem of unimodal k-segmentation. In addition, we describe a more efficient greedy-merging heuristic that is experimentally shown to give solutions very close to the optimal. As a concrete application of our algorithms, we describe two methods for testing if a sequence behaves unimodally or not. Our experimental evaluation shows that our algorithms and the proposed unimodality tests give very intuitive results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P702818</person_id>
				<author_profile_id><![CDATA[81100266437]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Niina]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Haiminen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Helsinki, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39051588</person_id>
				<author_profile_id><![CDATA[81100631289]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Aristides]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gionis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Helsinki, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033444</article_id>
		<sort_key>114</sort_key>
		<display_label></display_label>
		<pages>114-121</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Dependencies between Transcription Factor Binding Sites]]></title>
		<subtitle><![CDATA[Comparison between ICA, NMF, PLSA and Frequent Sets]]></subtitle>
		<page_from>114</page_from>
		<page_to>121</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033444</url>
		<abstract>
			<par><![CDATA[Gene expression of eucaryotes is regulated through transcription factors, which are molecules able to attach to the binding sites in the DNA sequence. These binding sites are small pieces of DNA usually found upstream from the gene they regulate. As the binding sites play an important role in the gene expression, it is of interest to find out their characteristics. In this paper we look for dependencies and independencies between these binding sites using independent component analysis (ICA), non-negative matrix factorization (NMF), probabilistic latent semantic analysis (PLSA) and the method of frequent sets. The data used are human gene upstream regions and possible binding sites listed in a biological database. Also, results on the baker's yeast (S.Cerevisiae) upstream regions are briefly discussed for comparison. ICA, NMF and PLSA are latent variable methods that decompose the observed data into smaller components. Of these, ICA and NMF were originally aimed for continuous data. We show that these methods can be successfully used on discrete DNA data as well. PLSA and the method of frequent sets were created for discrete data sets. The above methods reveal partially overlapping sets of possible binding sites such that the binding sites within a set are dependent of each other. The methods of frequent sets and NMF give a good overview of the most common data structures, whereas using ICA and PLSA we find large sets that are surprisingly frequent. That is, sets of very frequently occurring possible binding sites can be found near hundreds or thousands of genes; also interesting but less frequent ones co-occur surprisingly often.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P702254</person_id>
				<author_profile_id><![CDATA[81100541512]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Heli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hiisila]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Helsinki University of Technology, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P339930</person_id>
				<author_profile_id><![CDATA[81100555689]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ella]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bingham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Helsinki University of Technology, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033445</article_id>
		<sort_key>122</sort_key>
		<display_label></display_label>
		<pages>122-129</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Mass Spectrum Labeling]]></title>
		<subtitle><![CDATA[Theory and Practice]]></subtitle>
		<page_from>122</page_from>
		<page_to>129</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033445</url>
		<abstract>
			<par><![CDATA[We introduce the problem of labeling a particle's mass spectrum with the substances it contains, and develop several formal representations of the problem, taking into account practical complications such as unknown compounds and noise. This task is currently a bottle-neck in analyzing data from a new generation of instruments for real-time environmental monitoring.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15021383</person_id>
				<author_profile_id><![CDATA[81451598576]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Z.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14048119</person_id>
				<author_profile_id><![CDATA[81408598841]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[L.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702328</person_id>
				<author_profile_id><![CDATA[81100431628]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[J-Y.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14098696</person_id>
				<author_profile_id><![CDATA[81100259679]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gross]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton College]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P701975</person_id>
				<author_profile_id><![CDATA[81100258932]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Musicant]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton College]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43118563</person_id>
				<author_profile_id><![CDATA[81100290062]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ramakrishnan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702349</person_id>
				<author_profile_id><![CDATA[81344497551]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schauer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36031295</person_id>
				<author_profile_id><![CDATA[81100660041]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[S.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Wright]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033446</article_id>
		<sort_key>130</sort_key>
		<display_label></display_label>
		<pages>130-137</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Generation of Attribute Value Taxonomies from Data for Data-Driven Construction of Accurate and Compact Classifiers]]></title>
		<page_from>130</page_from>
		<page_to>137</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033446</url>
		<abstract>
			<par><![CDATA[Attribute Value Taxonomies (AVT) have been shown to be useful in constructing compact, robust, and comprehensible classifiers. However, in many application domains, human-designed AVTs are unavailable. We introduce AVT-Learner, an algorithm for automated construction of attribute value taxonomies from data. AVT-Learner uses Hierarchical Agglomerative Clustering (HAC) to cluster attribute values based on the distribution of classes that co-occur with the values. We describe experiments on UCI data sets that compare the performance of AVT-NBL (an AVT-guided Naive Bayes Learner) with that of the standard Naive Bayes Learner (NBL) applied to the original data set. Our results show that the AVTs generated by AVT-Learner are competitive with human-generated AVTs (in cases where such AVTs are available). AVT-NBL using AVTs generated by AVT-Learner achieves classification accuracies that are comparable to or higher than those obtained by NBL; and the resulting classifiers are significantly more compact than those generated by NBL.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P701980</person_id>
				<author_profile_id><![CDATA[81100492589]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dae-Ki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University, Ames]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15029246</person_id>
				<author_profile_id><![CDATA[81100327674]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Adrian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Silvescu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University, Ames]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14054342</person_id>
				<author_profile_id><![CDATA[81100124134]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University, Ames]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15031604</person_id>
				<author_profile_id><![CDATA[81100409481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Vasant]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Honavar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University, Ames]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033447</article_id>
		<sort_key>138</sort_key>
		<display_label></display_label>
		<pages>138-145</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Semi-Supervised Mixture-of-Experts Classification]]></title>
		<page_from>138</page_from>
		<page_to>145</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033447</url>
		<abstract>
			<par><![CDATA[We introduce a mixture-of-experts technique that is a generalization of mixture modeling techniques previously suggested for semi-supervised learning. We apply the bias-variance decomposition to semi-supervised classification and use the decomposition to study the effects from adding unlabeled data when learning a mixture model. Our empirical results indicate that the biggest gain from adding unlabeled data comes from the reduction of the model variance, whereas the behavior of the bias error term heavily depends on the correctness of the underlying model assumptions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P100064</person_id>
				<author_profile_id><![CDATA[81100377774]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Grigoris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Karakoulas]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Toronto, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702998</person_id>
				<author_profile_id><![CDATA[81100562217]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ruslan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Salakhutdinov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Toronto, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033448</article_id>
		<sort_key>146</sort_key>
		<display_label></display_label>
		<pages>146-153</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Transduction and Typicalness for Quality Assessment of Individual Classifications in Machine Learning and Data Mining]]></title>
		<page_from>146</page_from>
		<page_to>153</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033448</url>
		<abstract>
			<par><![CDATA[In the past machine learning algorithms have been successfully used in many problems, and are emerging as valuable data analysis tools. However, their serious practical use is affected by the fact, that more often than not, they cannot produce reliable and unbiased assessments of their predictions' quality. In last years, several approaches for estimating reliability or confidence of individual classifiers have emerged, many of them building upon the algorithmic theory of randomness, such as (historically ordered) transduction-based confidence estimation, typicalness-based confidence estimation, and transductive reliability estimation. Unfortunately, they all have weaknesses: either they are tightly bound with particular learning algorithms, or the interpretation of reliability estimations is not always consistent with statistical confidence levels. In the paper we propose a joint approach that compensates the mentioned weaknesses by integrating typicalness-based confidence estimation and transductive reliability estimation into joint confidence machine. The resulting confidence machine produces confidence values in the statistical sense (e.g., a confidence level of 95% means that in 95% the predicted class is also a true class), as well as provides us with a general principle that is independent of to the particular underlying classifier We perform a series of tests with several different machine learning algorithms in several problem domains. We compare our results with that of a proprietary TCM-NN method as well as with kernel density estimation. We show that the proposed method significantly outperforms density estimation methods, and how it may be used to improve their performance.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[machine learning, confidence estimation, typicalness, transduction, quality assessment]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P479847</person_id>
				<author_profile_id><![CDATA[81100022199]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Matjaz]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kukar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Ljubljana, Slovenia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033449</article_id>
		<sort_key>154</sort_key>
		<display_label></display_label>
		<pages>154-161</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[Mining Associations by Linear Inequalities]]></title>
		<page_from>154</page_from>
		<page_to>161</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033449</url>
		<abstract>
			<par><![CDATA[The main theorem is: Generalized associations of a relational table can be found by a finite set of linear inequalities within polynomial time. It is derived from the following three results, which were established in ICDM0'02 and are re-developed here. They are (1) Isomorphic Theorem: Isomorphic relations have isomorphic patterns. Such an isomorphism classifies relational tables into isomorphic classes. (2) A variant of the classical bitmaps indexes uniquely exists in each isomorphic class. We take it as the canonical model of the class. (3) All possible attributes/features can be generated by a generalized procedure of the classical AOG (attribute oriented generalization). Then, (4) the main theorem for canonical model is established. By isomorphism theorem, we had the final result (5).]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[association, deduction, feature, granules, bitmaps]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P703235</person_id>
				<author_profile_id><![CDATA[81406596657]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tsay]]></first_name>
				<middle_name><![CDATA[Young]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[San Jose State University, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033450</article_id>
		<sort_key>162</sort_key>
		<display_label></display_label>
		<pages>162-169</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Improving Text Classification using Local Latent Semantic Indexing]]></title>
		<page_from>162</page_from>
		<page_to>169</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033450</url>
		<abstract>
			<par><![CDATA[Latent Semantic Indexing (LSI) has been shown to be extremely useful in information retrieval, but it is not an optimal representation for text classification. It always drops the text classification performance when being applied to the whole training set (global LSI) because this completely unsupervised method ignores class discrimination while only concentrating on representation. Some local LSI methods have been proposed to improve the classification by utilizing class discrimination information. However, their performance improvements over original term vectors are still very limited. In this paper, we propose a new local LSI method called "Local Relevancy Weighted LSI" to improve text classification by performing a separate Single Value Decomposition (SVD) on the transformed local region of each class. Experimental results show that our method is much better than global LSI and traditional local LSI methods on classification within a much smaller LSI dimension.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14182383</person_id>
				<author_profile_id><![CDATA[81452600024]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Nankai University, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15022239</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36024131</person_id>
				<author_profile_id><![CDATA[81309512327]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Benyu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P682354</person_id>
				<author_profile_id><![CDATA[81350592994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wei-ying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39052851</person_id>
				<author_profile_id><![CDATA[81100657847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Gongyi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Nankai University, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033451</article_id>
		<sort_key>170</sort_key>
		<display_label></display_label>
		<pages>170-177</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Dependency Networks for Relational Data]]></title>
		<page_from>170</page_from>
		<page_to>177</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033451</url>
		<abstract>
			<par><![CDATA[Instance independence is a critical assumption of traditional machine learning methods contradicted by many relational datasets. For example, in scientific literature datasets there are dependencies among the references of a paper. Recent work on graphical models for relational data has demonstrated significant performance gains for models that exploit the dependencies among instances. In this paper, we present relational dependency networks (RDNs), a new form of graphical model capable of reasoning with such dependencies in a relational setting. We describe the details of RDN models and outline their strengths, most notably the ability to learn and reason with cyclic relational dependencies. We present RDN models learned on a number of real-world datasets, and evaluate the models in a classification context, showing significant performance improvements. In addition, we use synthetic data to evaluate the quality of model learning and inference procedures.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15036288</person_id>
				<author_profile_id><![CDATA[81100563777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jennifer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Neville]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts Amherst]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15038225</person_id>
				<author_profile_id><![CDATA[81100640362]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts Amherst]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033452</article_id>
		<sort_key>178</sort_key>
		<display_label></display_label>
		<pages>178-185</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Hybrid Pre-Query Term Expansion using Latent Semantic Analysis]]></title>
		<page_from>178</page_from>
		<page_to>185</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033452</url>
		<abstract>
			<par><![CDATA[Latent semantic retrieval methods (unlike vector space methods) take the document and query vectors and map them into a topic space to cluster related terms and documents. This produces a more precise retrieval but also a long query time. We present a new method of document retrieval which allows us to process the latent semantic information into a hybrid Latent Semantic-Vector Space query mapping. This mapping automatically expands the users query based on the latent semantic information in the document set. This expanded query is processed using a fast vector space method. Since we have the latent semantic data in a mapping, we are able to store and retrieve vector information in the same fast manner that the vector space method offers. Multiple mappings are combined to produce hybrid latent semantic retrieval which provide precision results 5% greater than the vector space method and fast query times.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P559893</person_id>
				<author_profile_id><![CDATA[81100157641]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Laurence]]></first_name>
				<middle_name><![CDATA[A.  F.]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Melbourne]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15035326</person_id>
				<author_profile_id><![CDATA[81100532239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kotagiri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ramamohanarao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Melbourne]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033453</article_id>
		<sort_key>186</sort_key>
		<display_label></display_label>
		<pages>186-193</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[SCHISM]]></title>
		<subtitle><![CDATA[A New Approach for Interesting Subspace Mining]]></subtitle>
		<page_from>186</page_from>
		<page_to>193</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033453</url>
		<abstract>
			<par><![CDATA[High-dimensional data pose challenges to traditional clustering algorithms due to their inherent sparsity and data tend to cluster in different and possibly overlapping subspaces of the entire feature space. Finding such subspaces is called subspace mining. We present SCHISM, a new algorithm for mining interesting subspaces, using the notions of support and Chernoff-Hoeffding bounds. We use a vertical representation of the dataset, and use a depth-first search with backtracking to find maximal interesting subspaces. We test our algorithm on a number of high-dimensional synthetic and real datasets to test its effectiveness.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P513765</person_id>
				<author_profile_id><![CDATA[81100325863]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Karlton]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sequeira]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rensselaer Polytechnic Institute, Troy, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15026684</person_id>
				<author_profile_id><![CDATA[81100229027]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mohammed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rensselaer Polytechnic Institute, Troy, New York]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033454</article_id>
		<sort_key>194</sort_key>
		<display_label></display_label>
		<pages>194-201</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[A Transaction-Based Neighbourhood-Driven Approach to Quantifying Interestingness of Association Rules]]></title>
		<page_from>194</page_from>
		<page_to>201</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033454</url>
		<abstract>
			<par><![CDATA[In this paper, we present a data-driven approach for ranking association rules (ARs) based on interestingness. The occurrence of unrelated or weakly related item-pairs in an AR is interesting. In the retail market-basket context, items may be related through various relationships arising due to mutual interaction, 'substitutability' and 'complementarity.' Item-relatedness is a composite of these relationships. We introduce three relatedness measures for capturing relatedness between item-pairs. These measures use the concept of function embedding to appropriately weigh the relatedness contributions due tocomplementarity and substitutability between items. We propose an interestingness coefficient by combining the three relatedness measures. We compare this with two objective measures of interestingness and show the intuitiveness of the proposed interestingness coefficient.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14177445</person_id>
				<author_profile_id><![CDATA[81100509887]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shekar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Indian Institute of Management Bangalore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P489022</person_id>
				<author_profile_id><![CDATA[81100450093]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rajesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Natarajan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Indian Institute of Management Lucknow]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033455</article_id>
		<sort_key>202</sort_key>
		<display_label></display_label>
		<pages>202-208</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Probabilistic Principal Surfaces for Yeast Gene Microarray Data Mining]]></title>
		<page_from>202</page_from>
		<page_to>208</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033455</url>
		<abstract>
			<par><![CDATA[The recent technological advances are producing huge data sets in almost all fields of scientific research, from astronomy to genetics. Although each research field often requires ad-hoc, fine tuned, procedures to properly exploit all the available information inherently present in the data, there is an urgent need for a new generation of general computational theories and tools capable to boost most human activities of data analysis. Here we propose Probabilistic Principal Surfaces (PPS) as an effective high-D data visualization and clustering tool for data mining applications, emphasizing its flexibility and generality of use in data-rich field. In order to better illustrate the potentialities of the method, we also provide a real world case-study by discussing the use of PPS for the analysis of yeast gene expression levels from microarray chips.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P701781</person_id>
				<author_profile_id><![CDATA[81100641601]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Antonino]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Staiano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; di Salerno, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702561</person_id>
				<author_profile_id><![CDATA[81100336749]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lara]]></first_name>
				<middle_name><![CDATA[De]]></middle_name>
				<last_name><![CDATA[Vinco]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; di Salerno, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP24016739</person_id>
				<author_profile_id><![CDATA[81100402679]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Angelo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ciaramella]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; di Salerno, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P637011</person_id>
				<author_profile_id><![CDATA[81100259438]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Giancarlo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raiconi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; di Salerno, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14060584</person_id>
				<author_profile_id><![CDATA[81100143575]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Roberto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tagliaferri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; di Salerno, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702979</person_id>
				<author_profile_id><![CDATA[81100431362]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Roberto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Amato]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; Federico II di Napoli and INFN Napoli Unit, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43120508</person_id>
				<author_profile_id><![CDATA[81100492921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Giuseppe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Longo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; Federico II di Napoli and INFN Napoli Unit, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P701954</person_id>
				<author_profile_id><![CDATA[81100539260]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Ciro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Donalek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; Federico II di Napoli and INFN Napoli Unit, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702167</person_id>
				<author_profile_id><![CDATA[81341493919]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[Gennaro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miele]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; Federico II di Napoli and INFN Napoli Unit, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702035</person_id>
				<author_profile_id><![CDATA[81100415844]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>10</seq_no>
				<first_name><![CDATA[Diego]]></first_name>
				<middle_name><![CDATA[Di]]></middle_name>
				<last_name><![CDATA[Bernardo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Telethon Institute for Genetics and Medicine, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033456</article_id>
		<sort_key>209</sort_key>
		<display_label></display_label>
		<pages>209-216</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[On Local Spatial Outliers]]></title>
		<page_from>209</page_from>
		<page_to>216</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033456</url>
		<abstract>
			<par><![CDATA[We propose a measure, Spatial Local Outlier Measure (SLOM) which captures the local behaviour of datum in their spatial neighborhood. With the help of SLOM we are able to discern local spatial outliers which are usually missed by global techniques like "three standard deviations away from the mean". Furthermore the measure takes into account the local stability around a data point and supresses the reporting of outliers in highly unstable areas, where data is too heterogeneous and the notion of outliers is not meaningful. We prove several properties of SLOM and report experiments on synthetic and real data sets which show that our approach is novel and scalable to large data sets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14156753</person_id>
				<author_profile_id><![CDATA[81539770956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Sydney, Australia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15019435</person_id>
				<author_profile_id><![CDATA[81100002847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sanjay]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chawla]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Sydney, Australia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033457</article_id>
		<sort_key>217</sort_key>
		<display_label></display_label>
		<pages>217-224</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[MMAC]]></title>
		<subtitle><![CDATA[A New Multi-Class, Multi-Label Associative Classification Approach]]></subtitle>
		<page_from>217</page_from>
		<page_to>224</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033457</url>
		<abstract>
			<par><![CDATA[Building fast and accurate classifiers for large-scale databases is an important task in data mining. There is growing evidence that integrating classification and association rule mining together can produce more efficient and accurate classifiers than traditional classification techniques. In this paper, the problem of producing rules with multiple labels is investigated. We propose a new associative classification approach called multi-class, multi-label associative classification (MMAC). This paper also presents three measures for evaluating the accuracy of data mining classification approaches to a wide range of traditional and multi-label classification problems. Results for 28 different datasets show that the MMAC approach is an accurate and effective classification technique, highly competitive and scalable in comparison with other classification approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P702119</person_id>
				<author_profile_id><![CDATA[81336493382]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fadi]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Thabtah]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Modelling Optimisation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42049891</person_id>
				<author_profile_id><![CDATA[81100128167]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cowling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Modelling Optimisation]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP38022715</person_id>
				<author_profile_id><![CDATA[81310482790]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yonghong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Bradford, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033458</article_id>
		<sort_key>225</sort_key>
		<display_label></display_label>
		<pages>225-232</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Analysis of Consensus Partition in Cluster Ensemble]]></title>
		<page_from>225</page_from>
		<page_to>232</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033458</url>
		<abstract>
			<par><![CDATA[In combination of multiple partitions, one is usually interested in deriving a consensus solution with a quality better than that of given partitions. Several recent studies have empirically demonstrated improved accuracy of clustering ensembles on a number of artificial and real-world data sets. Unlike certain multiple supervised classifier systems, convergence properties of unsupervised clustering ensembles remain unknown for conventional combination schemes. In this paper we present formal arguments on the effectiveness of cluster ensemble from two perspectives. The first is based on a stochastic partition generation model related to re-labeling and consensus function with plurality voting. The second is to study the property of the "mean" partition of an ensemble with respect to a metric on the space of all possible partitions. In both the cases, the consensus solution can be shown to converge to a true underlying clustering solution as the number of partitions in the ensemble increases. This paper provides a rigorous justification for the use of cluster ensemble.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39053537</person_id>
				<author_profile_id><![CDATA[81100661928]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Topchy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Michigan State University, East Lansing]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P690747</person_id>
				<author_profile_id><![CDATA[81100048232]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Martin]]></first_name>
				<middle_name><![CDATA[H.  C.]]></middle_name>
				<last_name><![CDATA[Law]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Michigan State University, East Lansing]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15022472</person_id>
				<author_profile_id><![CDATA[81100113904]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Anil]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Jain]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Michigan State University, East Lansing]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P701755</person_id>
				<author_profile_id><![CDATA[81100628590]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ana]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Fred]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Instituto Superior Tecnico, Lisbon, Portugal]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033459</article_id>
		<sort_key>233</sort_key>
		<display_label></display_label>
		<pages>233-240</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Privacy-Preserving Outlier Detection]]></title>
		<page_from>233</page_from>
		<page_to>240</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033459</url>
		<abstract>
			<par><![CDATA[Outlier detection can lead to the discovery of truly unexpected knowledge in many areas such as electronic commerce, credit card fraud and especially national security. We look at the problem of finding outliers in large distributed databases where privacy/security concerns restrict the sharing of data. Both homogeneous and heterogeneous distribution of data is considered. We propose techniques to detect outliers in such scenarios while giving formal guarantees on the amount of information disclosed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14173564</person_id>
				<author_profile_id><![CDATA[81100496660]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jaideep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vaidya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rutgers University, Newark, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40024826</person_id>
				<author_profile_id><![CDATA[81100204478]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Clifton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rutgers University, Newark, NJ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033460</article_id>
		<sort_key>241</sort_key>
		<display_label></display_label>
		<pages>241-248</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[SUMMARY]]></title>
		<subtitle><![CDATA[Efficiently Summarizing Transactions for Clustering]]></subtitle>
		<page_from>241</page_from>
		<page_to>248</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033460</url>
		<abstract>
			<par><![CDATA[Frequent itemset mining was initially proposed and has been studied extensively in the context of association rule mining. In recent years, several studies have also extended its applicationto the transaction (or document) classification and clustering. However, most of the frequent-itemset based clustering algorithms need to first mine a large intermediate set of frequent itemsets in order to identify a subset of the most promising ones that can be used for clustering. In this paper, we study how to directly find a subset of high quality frequent itemsets that can be used as a concise summary of the transaction database and to clusterthe categorical data. By exploring some properties of the subset of itemsets that we are interested in, we proposed several search space pruning methods and designed an efficient algorithm called SUMMARY. Our empirical results have shown that SUMMARY runs very fast even when the minimum support is extremely low and scales very well with respect to the database size, and surprisingly, as a pure frequent itemset mining algorithm it is very effectivein clustering the categorical data and smmarizing the dense transaction databases.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40025148</person_id>
				<author_profile_id><![CDATA[81451601319]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jianyong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota, Minneapolis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14015889</person_id>
				<author_profile_id><![CDATA[81100008465]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Karypis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota, Minneapolis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033461</article_id>
		<sort_key>249</sort_key>
		<display_label></display_label>
		<pages>249-256</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Bottom-Up Generalization]]></title>
		<subtitle><![CDATA[A Data Mining Solution to Privacy Protection]]></subtitle>
		<page_from>249</page_from>
		<page_to>256</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033461</url>
		<abstract>
			<par><![CDATA[The well-known privacy-preserved data mining modifies existing data mining techniques to randomized data. In this paper, we investigate data mining as a technique for masking data, therefore, termed data mining based privacy protection. This approach incorporates partially the requirement of a targeted data mining task into the process of masking data so that essential structure is preserved in the masked data. The idea is simple but novel: we explore the data generalization concept from data mining as a way to hide detailed information, rather than discover trends and patterns. Once the data is masked, standard data mining techniques can be applied without modification. Our work demonstrated another positive use of data mining technology: not only can it discover useful patterns, but also mask private information. We consider the following privacy problem: a data holder wants to release a version of datafor building classification models, but wants to protect against linking the released data to an external source for inferring sensitive information. We adapt an iterative bottom-up generalization from data mining to generalize the data. The generalized data remains useful to classification but becomes difficult to link to other sources. The generalization space is specified by a hierarchical structure of generalizations. A key is identifying the best generalization to climb up the hierarchy at each iteration. Enumerating all candidate generalizations is impractical. We present a scalable solution that examines at most one generalization in each iteration for each attribute involved in the linking.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15025867</person_id>
				<author_profile_id><![CDATA[81350574174]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research Center]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14209231</person_id>
				<author_profile_id><![CDATA[81100605702]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Sourav]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chakraborty]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033463</article_id>
		<sort_key>257</sort_key>
		<display_label></display_label>
		<pages>257-264</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[A Probabilistic Approach for Adapting Information Extraction Wrappers and Discovering New Attributes]]></title>
		<page_from>257</page_from>
		<page_to>264</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033463</url>
		<abstract>
			<par><![CDATA[We develop a probabilistic framework for adapting information extraction wrappers with new attribute discovery. Wrapper adaptation aims at automatically adapting a previously learned wrapper from the source Web site to a new unseen site for information extraction. One unique characteristic of our framework is that it can discover new or previously unseen attributes as well as headers from the new site. It is based on a generative model for the generation of text fragments related to attribute items and formatting data in a Web page. To solve the wrapper adaptation problem, we consider two kinds of information from the source Web site. The first kind of information is the extraction knowledge contained in the previously learned wrapper from the source Web site. The second kind of information is the previously extracted or collected items. We employ a Bayesian learning approach to automatically select a set of training examples for adapting a wrapper for the new unseen site. To solve the new attribute discovery problem, we develop a model which analyzes the surrounding text fragments of the attributes in the new unseen site. A Bayesian learning method is developed to discover the new attributes and their headers. EM technique is employed in both Bayesian learning models. We conducted extensive experiments from a number of real-world Web sites to demonstrate the effectiveness of our framework.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP28001615</person_id>
				<author_profile_id><![CDATA[81343508867]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tak-Lam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Chinese University of Hong Kong, Shatin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39033920</person_id>
				<author_profile_id><![CDATA[81423592360]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lam]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Chinese University of Hong Kong, Shatin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033462</article_id>
		<sort_key>265</sort_key>
		<display_label></display_label>
		<pages>265-272</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[Aligning Boundary in Kernel Space for Learning Imbalanced Dataset]]></title>
		<page_from>265</page_from>
		<page_to>272</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033462</url>
		<abstract>
			<par><![CDATA[An imbalanced training dataset poses serious problem for many real-world supervised learning tasks. In this paper, we propose a kernel-boundary-alignment algorithm, which considers training-data imbalance as prior information to augment SVMs to improve class-prediction accuracy. Using a simple example, we first show that SVMs can suffer from high incidences of false negatives when the training instances of the target class are heavily outnumbered by the training instances of a non-target class. The remedy we propose is to adjust the class boundary by modifying the kernel matrix, according to the imbalanced data distribution. Through theoretical analysis backed by empirical study, we show that our kernel-boundary-alignment algorithm works effectively on several datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP43122497</person_id>
				<author_profile_id><![CDATA[81100657852]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Santa Barbara]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39034367</person_id>
				<author_profile_id><![CDATA[81344489120]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Edward]]></first_name>
				<middle_name><![CDATA[Y.]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Santa Barbara]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033464</article_id>
		<sort_key>273</sort_key>
		<display_label></display_label>
		<pages>273-280</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[IRC]]></title>
		<subtitle><![CDATA[An Iterative Reinforcement Categorization Algorithm for Interrelated Web Objects]]></subtitle>
		<page_from>273</page_from>
		<page_to>280</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033464</url>
		<abstract>
			<par><![CDATA[Most existing categorization algorithms deal with homogeneous Web data objects, and consider interrelated objects as additional features when taking the interrelationships withother types of objects into account. However, focusing on any single aspects of these interrelationships and objects will not fully reveal their true categories. In this paper, wepropose a novel categorization algorithm, the Iterative Reinforcement Categorization algorithm (IRC), to exploit the full interrelationships between the heterogeneous objects on the Web.IRC attempts to classify the interrelated Web objects by iterative reinforcement between individual classification results of different types via the interrelationships. Experiments on a clickthrough log dataset from MSN search engine show that, with the F1 measures, IRC achieves a 26.4% improvement over a pure content-based classification method, a 21% improvement over a query metadata-based method, and a 16.4% improvement over a virtual document-based method. Furthermore, our experiments show that IRC converges rapidly.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P550553</person_id>
				<author_profile_id><![CDATA[81100142932]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gui-Rong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xue]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Shanghai Jiao-Tong University, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15029674</person_id>
				<author_profile_id><![CDATA[81313483930]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dou]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TsingHua University, Beijing, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77040843</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14216704</person_id>
				<author_profile_id><![CDATA[81100630328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hua-Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zeng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia, Beijing, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79025821</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia, Beijing, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79025213</person_id>
				<author_profile_id><![CDATA[81363594294]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Yong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Shanghai Jiao-Tong University, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P701004</person_id>
				<author_profile_id><![CDATA[81100625548]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[WenSi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Virginia Polytechnic Institute and State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79023395</person_id>
				<author_profile_id><![CDATA[81350592994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Wei-Ying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia, Beijing, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033465</article_id>
		<sort_key>281</sort_key>
		<display_label></display_label>
		<pages>281-288</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[A Polygonal Line Algorithm based Nonlinear Feature Extraction Method]]></title>
		<page_from>281</page_from>
		<page_to>288</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033465</url>
		<abstract>
			<par><![CDATA[We propose a polygonal line based principal curve algorithm for nonlinear feature extraction, in which the nonlinearities among the multivariable data can be described by a set of local linear models. The proposed algorithm integrates the linear PCA approach with the polygonal line algorithm to represent complicated nonlinear data structure. Statistical redundancy elimination for high dimensional data is also discussed for describing the underlying principal curves without much loss of information among the original data sets. The polygonal line algorithm can produce robust and accurate nonlinear curve estimation for different multivariate data types, and it is helpful in reducing the computation complexity for existing principal curve approaches when the sample size is large.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP25000963</person_id>
				<author_profile_id><![CDATA[81336494408]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Feng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Texas A&M University, College Station, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033466</article_id>
		<sort_key>289</sort_key>
		<display_label></display_label>
		<pages>289-296</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[AVT-NBL]]></title>
		<subtitle><![CDATA[An Algorithm for Learning Compact and Accurate Na&#239;ve Bayes Classifiers from Attribute Value Taxonomies and Data]]></subtitle>
		<page_from>289</page_from>
		<page_to>296</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033466</url>
		<abstract>
			<par><![CDATA[In many application domains, there is a need for learning algorithms that can effectively exploit attribute value taxonomies (AVT) - hierarchical groupings of attribute values - to learn compact, comprehensible, and accurate classifiers from data - including data that are partially specified. This paper describes AVT-NBL, a natural generalization of the Na&#239;ve Bayes learner (NBL), for learning classifiers from AVT and data. Our experimental results show that AVT-NBL is able to generate classifiers that are substantially more compact and more accurate than those produced by NBL on a broad range of data sets with different percentages of partiallyspecified values. We also show that AVT-NBL is more efficient in its use of training data: AVT-NBL produces classifiers that outperform those produced by NBL using substantially fewer training examples.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14054342</person_id>
				<author_profile_id><![CDATA[81100124134]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University, Ames]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15031604</person_id>
				<author_profile_id><![CDATA[81100409481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vasant]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Honavar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Iowa State University, Ames]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033467</article_id>
		<sort_key>297</sort_key>
		<display_label></display_label>
		<pages>297-304</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>44</seq_no>
		<title><![CDATA[Cost-Guided Class Noise Handling for Effective Cost-Sensitive Learning]]></title>
		<page_from>297</page_from>
		<page_to>304</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033467</url>
		<abstract>
			<par><![CDATA[Recent research in machine learning, data mining and related areas has produced a wide variety of algorithms for cost-sensitive (CS) classification, where instead of maximizing the classification accuracy, minimizing the misclassification cost becomes the objective. However, these methods assume that training sets do not contain significant noise, which is rarely the case in real-world environments. In this paper, we systematically study the impacts of class noise on CS learning, and propose a cost-guided class noise handling algorithm to identify noise for effective CS learning. We call it Cost-guided Iterative Classification Filter (CICF), because it seamlessly integrates costs and an existing Classification Filter for noise identification. Instead of putting equal weights to handle noise in all classes in existing efforts, CICF puts more emphasis on expensive classes, which makes it especially successful in dealing with datasets with a large cost-ratio. Experimental results and comparative studies from real-world datasets indicate that the existence of noise may seriously corrupt the performance of CS classifiers, and by adopting the proposed CICF algorithm, we can significantly reduce the misclassification cost of a CS classifier in noisy environments.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39041696</person_id>
				<author_profile_id><![CDATA[81452600756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xingquan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont, Burlington VT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39052906</person_id>
				<author_profile_id><![CDATA[81452596585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xindong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont, Burlington VT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033469</article_id>
		<sort_key>305</sort_key>
		<display_label></display_label>
		<pages>305-312</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>45</seq_no>
		<title><![CDATA[Dynamic Classifier Selection for Effective Mining from Noisy Data Streams]]></title>
		<page_from>305</page_from>
		<page_to>312</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033469</url>
		<abstract>
			<par><![CDATA[Recently, mining from data streams has become an important and challenging task for many real-world applications such as credit card fraud protection and sensor networking. One popular solution is to separate stream data into chunks, learn a base classifier from each chunk, and then integrate all base classifiers for effective classification. In this paper, we propose a new dynamic classifier selection (DCS) mechanism to integrate base classifiers for effective mining from data streams. The proposed algorithm dynamically selects a single "best" classifier to classify each test instance at run time. Our scheme uses statistical information from attribute values, and uses each attribute to partition the evaluation set into disjoint subsets, followed by a procedure that evaluates the classification accuracy of each base classifier on these subsets. Given a test instance, its attribute values determine the subsets that the similar instances in the evaluation set have constructed, and the classifier with the highest classification accuracy on those subsets is selected to classify the test instance. Experimental results and comparative studies demonstrate the efficiency and efficacy of our method. Such a DCS scheme appears to be promising in mining data streams with dramatic concept drifting or with a significant amount of noise, where the base classifiers are likely conflictive or have low confidence.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39041696</person_id>
				<author_profile_id><![CDATA[81452600756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xingquan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont, Burlington VT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39052906</person_id>
				<author_profile_id><![CDATA[81452596585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xindong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont, Burlington VT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77042619</person_id>
				<author_profile_id><![CDATA[81375599061]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Vermont, Burlington VT]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033468</article_id>
		<sort_key>315</sort_key>
		<display_label></display_label>
		<pages>315-318</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>46</seq_no>
		<title><![CDATA[Using Emerging Patterns and Decision Trees in Rare-Class Classification]]></title>
		<page_from>315</page_from>
		<page_to>318</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033468</url>
		<abstract>
			<par><![CDATA[The problem of classifying rarely occurring cases is faced in many real life applications. The scarcity of the rare cases makes it difficult to classify them correctly using traditional classifiers. In this paper, we propose a new approach to use emerging patterns (EPs) and decision trees (DTs) in rare-class classification (EPDT). EPs are those itemsets whose supports in one class are significantly higher than their supports in the other classes. EPDT employs the power of EPs to improve the quality of rare-case classification. To achieve this aim, we first introduce the idea of generating new non-existing rare-class instances, and then we over-sample the most important rare-class instances. Our experiments show that EPDT outperforms many classification methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P702229</person_id>
				<author_profile_id><![CDATA[81100196816]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hamad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alhammady]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Melbourne, Australia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15035326</person_id>
				<author_profile_id><![CDATA[81100532239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kotagiri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ramamohanarao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Melbourne, Australia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033470</article_id>
		<sort_key>319</sort_key>
		<display_label></display_label>
		<pages>319-322</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>47</seq_no>
		<title><![CDATA[Discovery of Functional Relationships in Multi-Relational Data using Inductive Logic Programming]]></title>
		<page_from>319</page_from>
		<page_to>322</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033470</url>
		<abstract>
			<par><![CDATA[ILP systems have been largely applied to datamining classification tasks with a considerable success. The use of ILP systems in regression tasks has been far less successful. Current systems have very limited numerical reasoning capabilities, which limits the application of ILP to discovery of functional relationships of numeric nature. This paper proposes improvements in numerical reasoning capabilities of ILP systems for dealing with regression tasks. It proposes the use of statistical-based techniques like Model Validation and Model Selection to improve noise handling and it introduces a new search stopping criterium based on the PAC method to evaluate learning performance. We have found these extensions essential to improve on results over machine learning and statistical-based algorithms used in the empirical evaluation study.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P701739</person_id>
				<author_profile_id><![CDATA[81100085477]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexessander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alves]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[LIACC, Rua do Campo Alegre, Portugal]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P491363</person_id>
				<author_profile_id><![CDATA[81100587886]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Camacho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[FEUP, Rua Dr Roberto Frias, Portugal]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP45026433</person_id>
				<author_profile_id><![CDATA[81363600387]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Eugenio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Oliveira]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[FEUP, Rua Dr Roberto Frias, Portugal]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033471</article_id>
		<sort_key>323</sort_key>
		<display_label></display_label>
		<pages>323-326</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>48</seq_no>
		<title><![CDATA[Attribute Measurement Policies for Time and Cost Sensitive Classification]]></title>
		<page_from>323</page_from>
		<page_to>326</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033471</url>
		<abstract>
			<par><![CDATA[Attribute measurement is an important component of classification algorithms, which could limit their applicability in realtime settings. The time taken to assign a value to an unknown attribute may reduce the overall utility of the final result. We identify three different costs that must be considered, including a time sensitive utility function. We model this attribute measurement problem as a Markov decision process (MDP), and build a policy to control this process using AO* heuristic search. The results offer a cost-effective approach to attribute measurement and classification for a variety of realtime applications.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P641159</person_id>
				<author_profile_id><![CDATA[81100093983]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Arnt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts at Amherst]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P264363</person_id>
				<author_profile_id><![CDATA[81100061211]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shlomo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zilberstein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts at Amherst]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033472</article_id>
		<sort_key>327</sort_key>
		<display_label></display_label>
		<pages>327-330</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>49</seq_no>
		<title><![CDATA[Detecting Patterns of Appliances from Total Load Data Using a Dynamic Programming Approach]]></title>
		<page_from>327</page_from>
		<page_to>330</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033472</url>
		<abstract>
			<par><![CDATA[Nonintrusive Appliance Load Monitoring (NIALM) systems require sufficient accurate total load data to separate the load into its major appliances. The most available solutions separate the whole electric energy consumption based on the measurement of all three voltages and currents. Aside from the cost for special measuring devices, the intrusion into the local installation is the main problem for reaching a high market distribution. The use of standard digital electricity meters could avoid this problem but the loss of information of the measured data has to be compensated by more intelligent algorithms and implemented rules to disaggregate the total load trace of only the active power measurements. The paper presents a new NIALM approach to analyse data, collected form a standard digital electricity meter. To disaggregate the consumption of the entire active power into its major electrical end uses, an algorithm consisting of clustering methods, a genetic algorithm and a dynamic programming approach is presented. The genetic algorithm is used to combine frequently occuring events to create hypothetical finite state machines to model detectable appliances. The time series of each finite state machine is optimized using a dynamic programming method similar to the viterbi algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P702733</person_id>
				<author_profile_id><![CDATA[81100208598]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Baranski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Member IEEE, VDE]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702490</person_id>
				<author_profile_id><![CDATA[81100090099]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jurgen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Voss]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Member IEEE, VDE]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033473</article_id>
		<sort_key>331</sort_key>
		<display_label></display_label>
		<pages>331-334</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>50</seq_no>
		<title><![CDATA[Text Classification by Boosting Weak Learners based on Terms and Concepts]]></title>
		<page_from>331</page_from>
		<page_to>334</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033473</url>
		<abstract>
			<par><![CDATA[Document representations for text classification are typically based on the classical Bag-Of-Words paradigm. This approach comes with deficiencies that motivate the integration of features on a higher semantic level than single words. In this paper we propose an enhancement of the classical document representation through concepts extracted from background knowledge. Boosting is used for actual classification. Experimental evaluations on two well known text corpora support our approach through consistent improvement of the results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P703127</person_id>
				<author_profile_id><![CDATA[81100273161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Stephan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bloehdorn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Karlsruhe, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P443307</person_id>
				<author_profile_id><![CDATA[81100539734]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Andreas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hotho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Kassel, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033474</article_id>
		<sort_key>335</sort_key>
		<display_label></display_label>
		<pages>335-338</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>51</seq_no>
		<title><![CDATA[Matching in Frequent Tree Discovery]]></title>
		<page_from>335</page_from>
		<page_to>338</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033474</url>
		<abstract>
			<par><![CDATA[Various definitions and frameworks for discovering frequent trees in forests have been developed recently. At the heart of these frameworks lies the notion of matching, which determines when a pattern tree matches a tree in a data set. We introduce a novel notion of tree matching for use in frequent tree mining and we show that it generalizes the framework of Zaki while still being more specific than that of Termier et al. Furthermore, we show how Zaki's TreeMinerV algorithm can be adapted towards our notion of tree matching. Experiments show the promise of the approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15032938</person_id>
				<author_profile_id><![CDATA[81100467326]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bjorn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bringmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Freiburg, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033475</article_id>
		<sort_key>339</sort_key>
		<display_label></display_label>
		<pages>339-342</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>52</seq_no>
		<title><![CDATA[A Biobjective Model to Select Features with Good Classification Quality and Low Cost]]></title>
		<page_from>339</page_from>
		<page_to>342</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033475</url>
		<abstract>
			<par><![CDATA[In this paper we address a multi-group classification problem in which we want to take into account, together with the generalization ability, cots associated with the features. This cost is not limited to an economical payment, but can also refer to risk, computational effort, space requirements, etc. In order to get a good generalization ability, we use Support Vector Machines (SVM) as the basic mechanism by considering the maximization of the margin. We formulate the problem as a biobjective mixed integer problem, for which Pareto optimal solutions can be obtained.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P77364</person_id>
				<author_profile_id><![CDATA[81100068784]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Emilio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Carrizosa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidad de Sevilla (Spain)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P701826</person_id>
				<author_profile_id><![CDATA[81350597802]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Belen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Martin-Barragan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidad de Sevilla (Spain)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702042</person_id>
				<author_profile_id><![CDATA[81100308240]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Dolores]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Romero Morales]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Oxford (United Kingdom)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033476</article_id>
		<sort_key>343</sort_key>
		<display_label></display_label>
		<pages>343-346</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>53</seq_no>
		<title><![CDATA[Incremental Mining of Frequent XML Query Patterns]]></title>
		<page_from>343</page_from>
		<page_to>346</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033476</url>
		<abstract>
			<par><![CDATA[Recently, the discovering of frequent XML query patterns gains its focus due to its many applications in XML data management, and several algorithms have been proposed to discover frequent query patterns using the frequent structure mining techniques. In this paper we consider the problem of incremental mining of frequent XML query patterns. We propose a novel method to minimize the I/O and computation requirements for handling incremental updates.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14055528</person_id>
				<author_profile_id><![CDATA[81414614400]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese Academy of Sciences]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77037732</person_id>
				<author_profile_id><![CDATA[81350594628]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Liang]]></first_name>
				<middle_name><![CDATA[Huai]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Peking Univerity]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P703369</person_id>
				<author_profile_id><![CDATA[81414594207]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yu]]></first_name>
				<middle_name><![CDATA[Guo]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese Academy of Sciences]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033477</article_id>
		<sort_key>347</sort_key>
		<display_label></display_label>
		<pages>347-350</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>54</seq_no>
		<title><![CDATA[Spam Filtering using a Markov Random Field Model with Variable Weighting Schemas]]></title>
		<page_from>347</page_from>
		<page_to>350</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033477</url>
		<abstract>
			<par><![CDATA[In this paper we present a Markov Random Field model based approach to filter spam. Our approach examines the importance of the neighborhood relationship (MRF cliques) among words in an email message for the purpose of spam classification. We propose and test several different theoretical bases for weighting schemes among corresponding neighborhood windows. Our results demonstrate that unexpected side effects depending on the neighborhood window size may have larger accuracy impact than the neighborhood relationship effects of the Markov Random Field.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P691513</person_id>
				<author_profile_id><![CDATA[81100070305]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shalendra]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chhabra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UC Riverside, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P339861</person_id>
				<author_profile_id><![CDATA[81100641019]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yerazunis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MERL, Cambridge, Massachusetts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P701933</person_id>
				<author_profile_id><![CDATA[81100566291]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Siefkes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[GKVI/FU Berlin, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033478</article_id>
		<sort_key>351</sort_key>
		<display_label></display_label>
		<pages>351-354</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>55</seq_no>
		<title><![CDATA[An Adaptive Learning Approach for Noisy Data Streams]]></title>
		<page_from>351</page_from>
		<page_to>354</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033478</url>
		<abstract>
			<par><![CDATA[Two critical challenges typically associated with mining data streams are concept drift and data contamination. To address these challenges, we seek learning techniques and models that are robust to noise and can adapt to changes in timely fashion. We approach the stream-mining problem using a statistical estimation framework, and propose a fast and robust discriminative model for learning noisy data streams. We build an ensemble of classifiers to achieve timely adaptation by weighting classifiers in a way that maximizes the likelihood of the data. We further employ robust statistical techniques to alleviate the problem of noise sensitivity. Experimental results on both synthetic and real-life data sets demonstrate the effectiveness of this new model learning approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P514904</person_id>
				<author_profile_id><![CDATA[81450592250]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14090801</person_id>
				<author_profile_id><![CDATA[81100233088]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yizhou]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40027029</person_id>
				<author_profile_id><![CDATA[81100417054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Carlo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zaniolo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Los Angeles]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033479</article_id>
		<sort_key>355</sort_key>
		<display_label></display_label>
		<pages>355-358</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>56</seq_no>
		<title><![CDATA[Scalable Multi-Relational Association Mining]]></title>
		<page_from>355</page_from>
		<page_to>358</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033479</url>
		<abstract>
			<par><![CDATA[We propose the new RADAR technique for multi-relational data mining. This permits the mining of very large collections and provides a new technique for discovering multi-relational associations. Results show that RADAR is reliable and scalable for mining a large yeast homology collection, and that it does not have the main-memory scalability constraints of the Farmer and Warmr tools.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P15812</person_id>
				<author_profile_id><![CDATA[81100095604]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Amanda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Clare]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wales Aberystwyth, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42049034</person_id>
				<author_profile_id><![CDATA[81339536786]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hugh]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[RMIT University, Melbourne, Australia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14155133</person_id>
				<author_profile_id><![CDATA[81309500307]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Nicholas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lester]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[RMIT University, Melbourne, Australia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033480</article_id>
		<sort_key>359</sort_key>
		<display_label></display_label>
		<pages>359-362</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>57</seq_no>
		<title><![CDATA[An Evaluation of Approaches to Classification Rule Selection]]></title>
		<page_from>359</page_from>
		<page_to>362</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033480</url>
		<abstract>
			<par><![CDATA[In this paper a number of Classification Rule evaluation measures are considered. In particular the authors review the use of a variety of selection techniques used to order classification rules contained in a classifier, and a number of mechanisms used to classify unseen data. The authors demonstrate that rule ordering founded on the size of antecedent works well given certain conditions.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Classification rule evaluation measures]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P86339</person_id>
				<author_profile_id><![CDATA[81100499892]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Frans]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Coenen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Liverpool, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37026780</person_id>
				<author_profile_id><![CDATA[81100359326]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Liverpool, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033481</article_id>
		<sort_key>363</sort_key>
		<display_label></display_label>
		<pages>363-366</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>58</seq_no>
		<title><![CDATA[Mining Frequent Closed Patterns in Microarray Data]]></title>
		<page_from>363</page_from>
		<page_to>366</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033481</url>
		<abstract>
			<par><![CDATA[Microarray data typically contains a large number of columns and a small number of rows, which poses a great challenge for existing frequent (closed) pattern mining algorithms that discover patterns in item enumeration space. In this paper, we propose two new algorithms that explore the row enumeration space to mine frequent closed patterns. Several experiments on real-life gene expression data show that the new algorithms are faster than existing algorithms, including CLOSET, CHARM, CLOSET+ and CARPENTER.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP43120219</person_id>
				<author_profile_id><![CDATA[81100468764]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P161509</person_id>
				<author_profile_id><![CDATA[81451597529]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kian-Lee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P524170</person_id>
				<author_profile_id><![CDATA[81100486586]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[K.  H.]]></middle_name>
				<last_name><![CDATA[Tung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15033821</person_id>
				<author_profile_id><![CDATA[81100484594]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Feng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033482</article_id>
		<sort_key>367</sort_key>
		<display_label></display_label>
		<pages>367-370</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>59</seq_no>
		<title><![CDATA[Clustering on Demand for Multiple Data Streams]]></title>
		<page_from>367</page_from>
		<page_to>370</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033482</url>
		<abstract>
			<par><![CDATA[In the data stream environment, the patterns generated by the mining techniques are usually distinct at different time because of the evolution of data. In order to deal with various types of multiple data streams and to support flexible mining requirements, we devise in this paper a Clustering on Demand framework, abbreviated as COD framework, to dynamically cluster multiple data streams. While providing a general framework of clustering on multiple data streams, the COD framework has two major features, namely one data scan for online statistics collection and compact multi-resolution approximations, which are designed to address, respectively, the time and the space constraints in a data stream environment. Furthermore, with the multi-resolution approximations of data streams, flexible clustering demands can be supported.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P701840</person_id>
				<author_profile_id><![CDATA[81100172065]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bi-Ru]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Taiwan University, Taipei]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14040258</person_id>
				<author_profile_id><![CDATA[81451595001]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jen-Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Taiwan University, Taipei]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702728</person_id>
				<author_profile_id><![CDATA[81100102028]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mi-Yen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yeh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Taiwan University, Taipei]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023750</person_id>
				<author_profile_id><![CDATA[81450594725]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ming-Syan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Taiwan University, Taipei]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033483</article_id>
		<sort_key>371</sort_key>
		<display_label></display_label>
		<pages>371-374</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>60</seq_no>
		<title><![CDATA[Extensible Markov Model]]></title>
		<page_from>371</page_from>
		<page_to>374</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033483</url>
		<abstract>
			<par><![CDATA[A Markov Chain is a popular data modeling tool. This paper presents a variation of Markov Chain, namely Extensible Markov Model (EMM). By providing a dynamically adjustable structure, EMM overcomes the problems caused by the static nature of the traditional Markov Chain. Therefore, EMMs are particularly well suited to model spatiotemporal data such as network traffic, environmental data, weather data, and automobile traffic. Performance studies using EMMs for spatiotemporal prediction problems show the advantages of this approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14161471</person_id>
				<author_profile_id><![CDATA[81409595451]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Margaret]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Dunham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Southern Methodist University, Dallas, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP94030447</person_id>
				<author_profile_id><![CDATA[81387602356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Meng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Southern Methodist University, Dallas, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14040321</person_id>
				<author_profile_id><![CDATA[81100084338]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Texas Southwestern, Dallas, Texas]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033484</article_id>
		<sort_key>375</sort_key>
		<display_label></display_label>
		<pages>375-378</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>61</seq_no>
		<title><![CDATA[Using Representative-Based Clustering for Nearest Neighbor Dataset Editing]]></title>
		<page_from>375</page_from>
		<page_to>378</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033484</url>
		<abstract>
			<par><![CDATA[The goal of dataset editing in instance-based learning is to remove objects from a training set in order to increase the accuracy of a classifier. For example, Wilson editing removes training examples that are misclassified by a nearest neighbor classifier so as to smooth the shape of the resulting decision boundaries. This paper revolves around the use of representative-based clustering algorithms for nearest neighbor dataset editing. We term this approach supervised clustering editing. The main idea is to replace a dataset by a set of cluster prototypes. A novel clustering approach called supervised clustering is introduced for this purpose. Our empirical evaluation using eight UCI datasets shows that both Wilson and supervised clustering editing improve accuracy on more than 50% of the datasets tested. However, supervised clustering editing achieves four times higher compression rates than Wilson editing.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP43126261</person_id>
				<author_profile_id><![CDATA[81339498116]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christoph]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Eick]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Houston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702815</person_id>
				<author_profile_id><![CDATA[81100547059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nidal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zeidat]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Houston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42051180</person_id>
				<author_profile_id><![CDATA[81339533935]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ricardo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vilalta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Houston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033485</article_id>
		<sort_key>379</sort_key>
		<display_label></display_label>
		<pages>379-382</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>62</seq_no>
		<title><![CDATA[Decision Tree Evolution Using Limited Number of Labeled Data Items from Drifting Data Streams]]></title>
		<page_from>379</page_from>
		<page_to>382</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033485</url>
		<abstract>
			<par><![CDATA[Most previously proposed mining methods on data streams make an unrealistic assumption that "labelled" data stream is readily available and can be mined at anytime. However, in most real-world problems, labelled data streams are rarely immediately available. Due to this reason, models are reconstructed only when labelled data become available periodically. This passive stream mining model has several drawbacks. We propose a new concept of demand-driven active data mining. In active mining, the loss of the model is either continuously guessed without using any true class labels or estimated, whenever necessary, from a small number of instances whose actual class labels are verified by paying an affordable cost. When the estimated loss is more than a tolerable threshold, the model evolves by using a small number of instances with verified true class labels. Previous work on active mining concentrates on error guess and estimation. In this paper, we discuss several approaches on decision tree evolution.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40027830</person_id>
				<author_profile_id><![CDATA[81367591181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research, Hawthorne, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14039996</person_id>
				<author_profile_id><![CDATA[81407592487]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yi-an]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology, Atlanta, GA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research, Hawthorne, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033486</article_id>
		<sort_key>383</sort_key>
		<display_label></display_label>
		<pages>383-386</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>63</seq_no>
		<title><![CDATA[A Machine Learning Approach to Improve Congestion Control over Wireless Computer Networks]]></title>
		<page_from>383</page_from>
		<page_to>386</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033486</url>
		<abstract>
			<par><![CDATA[In this paper, we present the application of machine learning techniques to the improvement of the congestion control of TCP in wired/wireless networks. TCP is sub-optimal in hybrid wired/wireless networks because it reacts in the same way to losses due to congestion and losses due to link errors. We thus propose to use machine learning techniques to build automatically a loss classifier from a database obtained by simulations of random network topologies. Several machine learning algorithms are compared for this task and the best method for this application turns out to be decision tree boosting. It outperforms ad hoc classifiers proposed in the networking literature.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P487499</person_id>
				<author_profile_id><![CDATA[81100360352]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pierre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Geurts]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Li&#232;ge, Belgium]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P464056</person_id>
				<author_profile_id><![CDATA[81100098919]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ibtissam]]></first_name>
				<middle_name><![CDATA[El]]></middle_name>
				<last_name><![CDATA[Khayat]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Li&#232;ge, Belgium]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39040278</person_id>
				<author_profile_id><![CDATA[81100382254]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Guy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leduc]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Li&#232;ge, Belgium]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033487</article_id>
		<sort_key>387</sort_key>
		<display_label></display_label>
		<pages>387-390</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>64</seq_no>
		<title><![CDATA[LOADED]]></title>
		<subtitle><![CDATA[Link-Based Outlier and Anomaly Detection in Evolving Data Sets]]></subtitle>
		<page_from>387</page_from>
		<page_to>390</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033487</url>
		<abstract>
			<par><![CDATA[In this paper, we present LOADED, an algorithm for outlier detection in evolving data sets containing both continuous and categorical attributes. LOADED is a tunable algorithm, wherein one can trade off computation for accuracy so that domain-specific response times are achieved. Experimental results show that LOADED provides very good detection and false positive rates, which are several times better than those of existing distance-based schemes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P701749</person_id>
				<author_profile_id><![CDATA[81100596069]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Amol]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ghoting]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43121148</person_id>
				<author_profile_id><![CDATA[81100546102]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[Eric]]></middle_name>
				<last_name><![CDATA[Otey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15030535</person_id>
				<author_profile_id><![CDATA[81100375834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Srinivasan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Parthasarathy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033488</article_id>
		<sort_key>391</sort_key>
		<display_label></display_label>
		<pages>391-394</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>65</seq_no>
		<title><![CDATA[SVD based Term Suggestion and Ranking System]]></title>
		<page_from>391</page_from>
		<page_to>394</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033488</url>
		<abstract>
			<par><![CDATA[In this paper, we consider the application of the singular value decomposition (SVD) to a search term suggestion system in a pay-for-performance search market. We propose a novel positive and negative refinement method based on orthogonal subspace projections. We demonstrate that SVD subspace-based methods: 1) expand coverage by reordering the results, and 2) enhance the clustered structure of the data. The numerical experiments reported in this paper were performed on Overture's pay-per-performance search market data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P702007</person_id>
				<author_profile_id><![CDATA[81555506056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gleich]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Harvey Mudd College, Claremont, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P412784</person_id>
				<author_profile_id><![CDATA[81100096510]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Leonid]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhukov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Yahoo! Research Labs, Pasadena, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033489</article_id>
		<sort_key>395</sort_key>
		<display_label></display_label>
		<pages>395-398</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>66</seq_no>
		<title><![CDATA[The Anatomy of a Hierarchical Clustering Engine for Web-page, News and Book Snippets]]></title>
		<page_from>395</page_from>
		<page_to>398</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033489</url>
		<abstract>
			<par><![CDATA[In this paper, we investigate the web snippet hierarchical clustering problem in its full extent by devising an algorithmic solution, and a software prototype called SnakeT (accessible at http://roquefort.di.unipi.it/), that: (1) draws the snippets from 16 Web search engines, the Amazon collection of books a9.com, the news of Google News and the blogs of Blogline; (2) builds the clusters on-the-fly (ephemeral clustering) in response to a user query without adopting any pre-defined organization in categories; (3) labels the clusters with sentences of variable length, drawn from the snippets and possibly missing some terms, provided they are not too many;]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40026962</person_id>
				<author_profile_id><![CDATA[81100411624]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paolo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ferragina]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; di Pisa, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P701784</person_id>
				<author_profile_id><![CDATA[81100034732]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Antonio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gulli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#224; di Pisa, Italy]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033490</article_id>
		<sort_key>399</sort_key>
		<display_label></display_label>
		<pages>399-402</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>67</seq_no>
		<title><![CDATA[Query-Driven Support Pattern Discovery for Classification Learning]]></title>
		<page_from>399</page_from>
		<page_to>402</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033490</url>
		<abstract>
			<par><![CDATA[We propose a novel query-driven lazy learning algorithm which attempts to discover useful local patterns, called support patterns, for classifying a given query. The learning is customized to the query to avoid the horizon effect. We show that this query-driven learning algorithm can guarantee to discover all support patterns with perfect expected accuracy in polynomial time. The experimental results on benchmark data sets also demonstrate that our learning algorithm really has prominent learning performance.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P514569</person_id>
				<author_profile_id><![CDATA[81100051462]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yiqiu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Chinese University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP80031389</person_id>
				<author_profile_id><![CDATA[81423592360]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lam]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Chinese University of Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033491</article_id>
		<sort_key>403</sort_key>
		<display_label></display_label>
		<pages>403-406</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>68</seq_no>
		<title><![CDATA[Evolutionary Algorithms for Clustering Gene-Expression Data]]></title>
		<page_from>403</page_from>
		<page_to>406</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033491</url>
		<abstract>
			<par><![CDATA[This work deals with the problem of automatically finding optimal partitions in bioinformatics datasets. We propose incremental improvements for a Clustering Genetic Algorithm (CGA), culminating in the Evolutionary Algorithm for Clustering (EAC). The CGA and its modified versions are evaluated in five gene-expression datasets, showing that the proposed EAC is a promising tool for clustering gene-expression data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40022943</person_id>
				<author_profile_id><![CDATA[81100032982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eduardo]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Hruschka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidade Cat&#243;lica de Santos (UniSantos)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023695</person_id>
				<author_profile_id><![CDATA[81100523502]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Leandro]]></first_name>
				<middle_name><![CDATA[N.  de]]></middle_name>
				<last_name><![CDATA[Castro]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidade Cat&#243;lica de Santos (UniSantos)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702953</person_id>
				<author_profile_id><![CDATA[81100307349]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ricardo]]></first_name>
				<middle_name><![CDATA[J.  G.  B.]]></middle_name>
				<last_name><![CDATA[Campello]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidade Cat&#243;lica de Santos (UniSantos)]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033492</article_id>
		<sort_key>407</sort_key>
		<display_label></display_label>
		<pages>407-410</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>69</seq_no>
		<title><![CDATA[Mining Ratio Rules Via Principal Sparse Non-Negative Matrix Factorization]]></title>
		<page_from>407</page_from>
		<page_to>410</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033492</url>
		<abstract>
			<par><![CDATA[Association rules are traditionally designed to capture statistical relationship among itemsets in a given database. To additionally capture the quantitative association knowledge, F.Korn et al recently proposed a paradigm named Ratio Rules for quantifiable data mining. However, their approach is mainly based on Principle Component Analysis (PCA) and as a result, it cannot guarantee that the ratio coefficient is non-negative. This may lead to serious problems in the rules' application. In this paper, we propose a new method, called Principal Sparse Non-Negative Matrix Factorization (PSNMF), for learning the associations between itemsets in the form of Ratio Rules. In addition, we provide a support measurement to weigh the importance of each rule for the entire dataset.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P701917</person_id>
				<author_profile_id><![CDATA[81436597759]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chenyong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institute of Software, CAS, Beijing, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36024131</person_id>
				<author_profile_id><![CDATA[81309512327]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Benyu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia, Beijing]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P494106</person_id>
				<author_profile_id><![CDATA[81100044797]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shuicheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[LMAM, Peking University, Beijing, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77041617</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong University of Science and Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15020446</person_id>
				<author_profile_id><![CDATA[81100045080]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[LMAM, Peking University, Beijing, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79025821</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia, Beijing]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79023395</person_id>
				<author_profile_id><![CDATA[81350592994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Wei-Ying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia, Beijing]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033493</article_id>
		<sort_key>411</sort_key>
		<display_label></display_label>
		<pages>411-414</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>70</seq_no>
		<title><![CDATA[Feature Selection via Supervised Model Construction]]></title>
		<page_from>411</page_from>
		<page_to>414</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033493</url>
		<abstract>
			<par><![CDATA[ReliefF is a feature mining technique, which has been successfully used in data mining applications.However, ReliefF is sensitive to the definition of relevance that is used in its implementation and when handling a large data set, it is computationally expensive.This paper presents an optimisation (Feature Selection via Supervised Model Construction) for data transformation and starter selection, and evaluates its effectiveness with C4.5.Experiments indicate that the proposed method gave improvement of computation efficiency whilst maintaining classification accuracy of trial data sets.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Feature Selection, ReliefF]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14040010</person_id>
				<author_profile_id><![CDATA[81100083589]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Y.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Ulster, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14169027</person_id>
				<author_profile_id><![CDATA[81100483072]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[P.]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[McCullagh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Ulster, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14199183</person_id>
				<author_profile_id><![CDATA[81100576295]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Black]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Ulster, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033494</article_id>
		<sort_key>415</sort_key>
		<display_label></display_label>
		<pages>415-418</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>71</seq_no>
		<title><![CDATA[Mining Generalized Substructures from a Set of Labeled Graphs]]></title>
		<page_from>415</page_from>
		<page_to>418</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033494</url>
		<abstract>
			<par><![CDATA[The problem of mining frequent itemsets in transactional data has been studied frequently and has yielded several algorithms that can find the itemsets within a limited amount of time. Some of them can derive "generalized" frequent itemsets consisting of items at any level of a taxonomy. Recently, several approaches have been proposed to mine frequent substructures (patterns) from a set of labeled graphs. The graph mining approaches are easily extended to mine generalized patterns where some vertices and/or edges have labels at any level of a taxonomy of the labels by extending the definition of "subgraph". However, the extended method outputs a massive set of the patterns most of which are over-generalized, which causes computation explosion. In this paper, an efficient and novel method is proposed to discover all frequent patterns which are not over-generalized from labeled graphs, when taxonomies on vertex and edge labels are available.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P417876</person_id>
				<author_profile_id><![CDATA[81100361535]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Akihiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Inokuchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tokyo Research Laboratory, IBM Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033495</article_id>
		<sort_key>419</sort_key>
		<display_label></display_label>
		<pages>419-422</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>72</seq_no>
		<title><![CDATA[Divide and Prosper]]></title>
		<subtitle><![CDATA[Comparing Models of Customer Behavior From Populations to Individuals]]></subtitle>
		<page_from>419</page_from>
		<page_to>422</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033495</url>
		<abstract>
			<par><![CDATA[This paper compares customer segmentation, 1-to-1, and aggregate marketing approaches across a broad range of experimental settings, including multiple segmentation levels, marketing datasets, dependent variables, and different types of classifiers, segmentation techniques, and predictive measures. Our experimental results show that, overall, 1-to-1 modeling significantly outperforms the aggregate approach among high-volume customers and is never worse than aggregate approach among low-volume customers. Moreover, the best segmentation techniques tend to outperform 1-to-1 modeling among low-volume customers.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14209924</person_id>
				<author_profile_id><![CDATA[81100607875]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tianyi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15030372</person_id>
				<author_profile_id><![CDATA[81100364633]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tuzhilin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033496</article_id>
		<sort_key>423</sort_key>
		<display_label></display_label>
		<pages>423-426</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>73</seq_no>
		<title><![CDATA[Filling-in Missing Objects in Orders]]></title>
		<page_from>423</page_from>
		<page_to>426</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033496</url>
		<abstract>
			<par><![CDATA[Filling-in techniques are important, since missing values frequently appear in real data. Such techniques have been established for categorical or numerical values. Though lists of ordered objects are widely used as representational forms (e.g., Web search results, best-seller lists), filling-in techniques for orders have received little attention. We therefore propose a simple but effective technique to fill-in missing objects in orders. We built this technique into our collaborative filtering system.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15031214</person_id>
				<author_profile_id><![CDATA[81100394205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Toshihiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kamishima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institute of Advanced Industrial Science and Technology (AIST), Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15025713</person_id>
				<author_profile_id><![CDATA[81100206468]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shotaro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Akaho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Institute of Advanced Industrial Science and Technology (AIST), Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033497</article_id>
		<sort_key>427</sort_key>
		<display_label></display_label>
		<pages>427-430</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>74</seq_no>
		<title><![CDATA[Orthogonal Decision Trees]]></title>
		<page_from>427</page_from>
		<page_to>430</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033497</url>
		<abstract>
			<par><![CDATA[This paper introduces orthogonal decision trees that offer an effective way to construct a redundancy-free, accurate, and meaningful representation of large decision-tree-ensembles often created by popular techniques such as Bagging, Boosting, Random Forests and many distributed and data stream mining algorithms. Orthogonal decision trees are functionally orthogonal to each other and they correspond to the principal components of the underlying function space. This paper offers a technique to construct such trees based on eigen-analysis of the ensemble and offers experimental results to document the performance of orthogonal trees on grounds of accuracy and model complexity.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39029854</person_id>
				<author_profile_id><![CDATA[81100150749]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hillol]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kargupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Maryland Baltimore County]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P678483</person_id>
				<author_profile_id><![CDATA[81100634447]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haimonti]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dutta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Maryland Baltimore County]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033498</article_id>
		<sort_key>431</sort_key>
		<display_label></display_label>
		<pages>431-434</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>75</seq_no>
		<title><![CDATA[Integrating Multi-Objective Genetic Algorithms into Clustering for Fuzzy Association Rules Mining]]></title>
		<page_from>431</page_from>
		<page_to>434</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033498</url>
		<abstract>
			<par><![CDATA[In this paper, we propose an automated method to decide on the number of fuzzy sets and for the autonomous mining of both fuzzy sets and fuzzy association rules. We compare the proposed multi-objective GA based approach with: 1) CURE based approach; 2) Chien et al clustering approach. Experimental results on 100K transactions extracted from the adult data of United States census in year 2000 show that the proposed method exhibits good performance over the other two approaches in terms of runtime, number of large itemsets and number of association rules.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP45027187</person_id>
				<author_profile_id><![CDATA[81336490511]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mehmet]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kaya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Firat University, Turkey]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14211269</person_id>
				<author_profile_id><![CDATA[81100613277]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Reda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alhajj]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033499</article_id>
		<sort_key>435</sort_key>
		<display_label></display_label>
		<pages>435-438</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>76</seq_no>
		<title><![CDATA[Feature-Based Prediction of Unknown Preferences for Nearest-Neighbor Collaborative Filtering]]></title>
		<page_from>435</page_from>
		<page_to>438</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033499</url>
		<abstract>
			<par><![CDATA[Recommendation systems analyze user preferences and recommend items to a user by predicting the user's preference for those items.Among various kinds of recommendation methods, collaborative filtering (CF) has been widely used and successfully applied to practical applications.However, collaborative filtering has two inherent problems: data sparseness and the cold-start problems.In this paper, we propose a method of integrating additional feature information of users and items into CF to overcome the difficulties caused by sparseness and improve the accuracy of recommendation. Several experimental results that show the effectiveness of the proposed method are also presented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14227122</person_id>
				<author_profile_id><![CDATA[81100661599]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hyungil]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Dongguk University, Seoul, Korea]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14228467</person_id>
				<author_profile_id><![CDATA[81100664535]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Juntae]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Dongguk University, Seoul, Korea]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702436</person_id>
				<author_profile_id><![CDATA[81100461010]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jonathan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Herlocker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Oregon State University, Corvallis, Oregon]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033500</article_id>
		<sort_key>439</sort_key>
		<display_label></display_label>
		<pages>439-442</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>77</seq_no>
		<title><![CDATA[GREW-A Scalable Frequent Subgraph Discovery Algorithm]]></title>
		<page_from>439</page_from>
		<page_to>442</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033500</url>
		<abstract>
			<par><![CDATA[Existing algorithms that mine graph datasets to discover patterns corresponding to frequently occurring subgraphs can operate efficiently on graphs that are sparse, contain a large number of relatively small connected components, have vertices with low and bounded degrees, and contain well-labeled vertices and edges. However, for graphs that do not share these characteristics, these algorithms become highly unscalable. In this paper we present a heuristic algorithm called GREW to overcome the limitations of existing complete or heuristic frequent subgraph discovery algorithms. GREW is designed to operate on a large graph and to find patterns corresponding to connected subgraphs that have a large number of vertex-disjoint embeddings. Our experimental evaluation shows that GREW is efficient, can scale to very large graphs, and find non-trivial patterns.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[frequent pattern discovery, frequent subgraph, graph mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P481304</person_id>
				<author_profile_id><![CDATA[81100101621]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michihiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuramochi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14015889</person_id>
				<author_profile_id><![CDATA[81100008465]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Karypis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033501</article_id>
		<sort_key>443</sort_key>
		<display_label></display_label>
		<pages>443-446</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>78</seq_no>
		<title><![CDATA[Predicting Density-Based Spatial Clusters Over Time]]></title>
		<page_from>443</page_from>
		<page_to>446</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033501</url>
		<abstract>
			<par><![CDATA[Most of existing clustering algorithms are designed to discover snapshot clusters that reflect only the current status of a database. Snapshot clusters do not reveal the fact that clusters may either persist over a period of time, or slowly fade away as other clusters may gradually develop. Predicting dynamic cluster evolutions and their occurring periods are important because this information can guide users to prepare appropriate actions toward the right areas during the right time for the most effective results. In this paper we developed a simple but effective approach in predicting the future distance among object pairs. Objects that will be close in distance over different periods of time are then processed to discover density-based clusters that may occur or change over time.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14188999</person_id>
				<author_profile_id><![CDATA[81545858956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chih]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of St. Thomas, St. Paul, MN]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702807</person_id>
				<author_profile_id><![CDATA[81100511398]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nga]]></first_name>
				<middle_name><![CDATA[T.]]></middle_name>
				<last_name><![CDATA[Nguyen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of St. Thomas, St. Paul, MN]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033502</article_id>
		<sort_key>447</sort_key>
		<display_label></display_label>
		<pages>447-450</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>79</seq_no>
		<title><![CDATA[Dynamic Daily-Living Patterns and Association Analyses in Tele-Care Systems]]></title>
		<page_from>447</page_from>
		<page_to>450</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033502</url>
		<abstract>
			<par><![CDATA[Tele-care systems aim to carry out intelligent analyses of a person's wellbeing using data about their daily activities. This is a very challenging task because the massive dataset is likely to be erroneous, possibly with misleading sections due to noise or missing values. Furthermore, the interpretation of the data is highly sensitive to the lifestyle of the monitored person and the environment in which they interact. In our tele-care project, sensor-network domain knowledge is used to overcome the difficulties of monitoring long-term wellbeing with an imperfect data source. In addition, a fuzzy association analysis is leveraged to implement a dynamic and flexible analysis over individual- and environment-dependent data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14136832</person_id>
				<author_profile_id><![CDATA[81100386336]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[B.-S.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Bristol, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14150226</person_id>
				<author_profile_id><![CDATA[81100426202]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Martin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Bristol, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702784</person_id>
				<author_profile_id><![CDATA[81100390521]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Clarke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Bristol, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP28002361</person_id>
				<author_profile_id><![CDATA[81100273634]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Majeed]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[British Telecom PLC, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14121061</person_id>
				<author_profile_id><![CDATA[81100335580]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nauck]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[British Telecom PLC, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033503</article_id>
		<sort_key>451</sort_key>
		<display_label></display_label>
		<pages>451-454</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>80</seq_no>
		<title><![CDATA[Mining Temporal Patterns Without Predefined Time Windows]]></title>
		<page_from>451</page_from>
		<page_to>454</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033503</url>
		<abstract>
			<par><![CDATA[This paper proposes algorithms for discovering temporal patterns without predefined time windows.The problem of discovering temporal patterns is divided into two sub-tasks: (1) using "cheap statistics" for dependence testing and candidates removal (2) identifying the temporal relationships between dependent event types.The dependence problem is formulated as the problem of comparing two probability distributions and is solved using a technique reminiscent of the distance methods used in spatial point process, while the latter problem is solved using an approach based on Chi-Squared tests.Experiments are conducted to evalaute the effectiveness and scalability of the proposed methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40027682</person_id>
				<author_profile_id><![CDATA[81100475528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Florida International University, Miami, FL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P263310</person_id>
				<author_profile_id><![CDATA[81100447843]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM T. J. Watson Research Center, Hawthorne, NY]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033504</article_id>
		<sort_key>455</sort_key>
		<display_label></display_label>
		<pages>455-458</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>81</seq_no>
		<title><![CDATA[Classifying Biomedical Citations without Labeled Training Examples]]></title>
		<page_from>455</page_from>
		<page_to>458</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033504</url>
		<abstract>
			<par><![CDATA[In this paper we introduce a novel technique for classifying text citations without labeled training examples. We first utilize the search results of a general search engine as original training data. We then proposed a mutually reinforcing learning algorithm (MRL) to mine the classification knowledge and to "clean" the training data. With the help of a set of established domain-specific ontological terms or keywords, the MRL mining step derives the relevant classification knowledge. The MRL cleaning step then builds a Naive Bayes classifier based on the mined classification knowledge and tries to clean the training set. The MRL algorithm is iteratively applied until a clean training set is obtained. We show the effectiveness of the proposed technique in the classification of biomedical citations from a large medical literature database.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14169232</person_id>
				<author_profile_id><![CDATA[81100483541]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiaoli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Singapore MIT Alliance]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14220256</person_id>
				<author_profile_id><![CDATA[81100641989]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rohit]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Joshi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P703114</person_id>
				<author_profile_id><![CDATA[81100517214]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Sreeram]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ramachandaran]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP308908300</person_id>
				<author_profile_id><![CDATA[81547772756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Tze-Yun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Singapore MIT Alliance]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033505</article_id>
		<sort_key>459</sort_key>
		<display_label></display_label>
		<pages>459-462</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>82</seq_no>
		<title><![CDATA[Improving the Reliability of Decision Tree and Naive Bayes Learners]]></title>
		<page_from>459</page_from>
		<page_to>462</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033505</url>
		<abstract>
			<par><![CDATA[The C4.5 Decision Tree and Naive Bayes learners are known to produce unreliable probability forecasts. We have used simple Binning and Laplace Transform techniques to improve the reliability of these learners and compare their effectiveness with that of the newly developed Venn Probability Machine (VPM) meta-learner. We assess improvements in reliability using loss functions, Receiver Operator Characteristic (ROC) curves and Empirical Reliability Curves (ERC). The VPM outperforms the simple techniques to improve reliability, although at the cost of increased computational intensity and slight increase in error rate. These trade-offs are discussed.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14076470</person_id>
				<author_profile_id><![CDATA[81332512921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lindsay]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of London, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P703099</person_id>
				<author_profile_id><![CDATA[81100290632]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cox]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of London, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033506</article_id>
		<sort_key>463</sort_key>
		<display_label></display_label>
		<pages>463-466</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>83</seq_no>
		<title><![CDATA[Revealing True Subspace Clusters in High Dimensions]]></title>
		<page_from>463</page_from>
		<page_to>466</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033506</url>
		<abstract>
			<par><![CDATA[Subspace clustering is one of the best approaches for discovering meaningful clusters in high dimensional space. One cluster in high dimensional space may be transcribed into multiple distinct maximal clusters by projecting onto different subspaces. A direct consequence of clustering independently in each subspace is an overwhelmingly large set of overlapping clusters which may be significantly similar. To reveal the true underlying clusters, we propose a similarity measurement of the overlapping clusters. We adopt the model of Gaussian tailed hyper-rectangles to capture the distribution of any subspace cluster. A set of experiments on a synthetic dataset demonstrates the effectiveness of our approach. Application to real gene expression data also reveals impressive meta-clusters expected by biologists.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Subspace Clustering, Overlapping Cluster, Adhesion, Gaussian Tails, Cluster Intersection, Local Grid, Gene Expression]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP77035784</person_id>
				<author_profile_id><![CDATA[81405595453]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jinze]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P514636</person_id>
				<author_profile_id><![CDATA[81100613133]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Karl]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Strohmaier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77036343</person_id>
				<author_profile_id><![CDATA[81452601906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina, Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033507</article_id>
		<sort_key>467</sort_key>
		<display_label></display_label>
		<pages>467-470</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>84</seq_no>
		<title><![CDATA[An Adaptive Density-Based Clustering Algorithm for Spatial Database with Noise]]></title>
		<page_from>467</page_from>
		<page_to>470</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033507</url>
		<abstract>
			<par><![CDATA[Clustering spatial data has various applications. Several clustering algorithms have been proposed to cluster objects in spatial databases. Spatial object distribution has significant effect on the results of clustering. Few of current algorithms consider the distribution of objects while processing clusters. In this paper, we propose an adaptive density-based clustering algorithm, ADBC, which uses a novel adaptive strategy for neighbor selection based on spatial object distribution to improve clustering accuracy. We perform a series of experiments on simulated data sets and real data sets. A comparison with DBSCAN and OPTICS shows the superiority of our new approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P701998</person_id>
				<author_profile_id><![CDATA[81100447380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daoying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State University of New York at Buffalo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023845</person_id>
				<author_profile_id><![CDATA[81100115610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Aidong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[State University of New York at Buffalo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033508</article_id>
		<sort_key>471</sort_key>
		<display_label></display_label>
		<pages>471-474</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>85</seq_no>
		<title><![CDATA[Finding Constrained Frequent Episodes Using Minimal Occurrences]]></title>
		<page_from>471</page_from>
		<page_to>474</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033508</url>
		<abstract>
			<par><![CDATA[Recurrent combinations of events within an event sequence, known as episodes, oftenreveal useful information. Most of the proposed episode mining algorithms adopt an apriori-like approach that generates candidates and then calculates their support levels. Obviously, such an approach is computationally expensive. Moreover, those algorithms are capable ofhandling only a limited range of constraints. In this paper, we introduce two miningalgorithms - Episode Prefix Tree (EPT) and Position Pairs Set (PPS) - based on a prefix-growth approach to overcome the above limitations. Both algorithms push constraints systematically into the mining process. Performance study shows that the proposed algorithms run considerably faster than MINEPI.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P703313</person_id>
				<author_profile_id><![CDATA[81100447153]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31029252</person_id>
				<author_profile_id><![CDATA[81100143812]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[HweeHwa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Institute for Infocomm Research, Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95033916</person_id>
				<author_profile_id><![CDATA[81451597529]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kian-Lee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033509</article_id>
		<sort_key>475</sort_key>
		<display_label></display_label>
		<pages>475-478</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>86</seq_no>
		<title><![CDATA[Estimation of False Negatives in Classification]]></title>
		<page_from>475</page_from>
		<page_to>478</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033509</url>
		<abstract>
			<par><![CDATA[In many classification problems such as spam detection and network intrusion, a large number of unlabeled test instances are predicted negative by the classifier. However, the high costsas well as time constraints on an expert's time prevent further analysis of the "predicted false" class instances in order to segregate the false negatives from the true negatives. A systematic method is thus required to obtain an estimate of the number of false negatives. A capture-recapture based method can be used to obtain an ML-estimate of false negatives when two or more independent classifiers are available. In the case for which independence does not hold, we can apply log-linear models to obtain an estimate of false negatives. However, as shown in this paper, lesser the dependencies among the classifiers, better is the estimate obtained for false negatives. Thus, ideally independent classifiers should be used to estimate the false negatives in an unlabeled dataset. Experimental results on the spam dataset from the UCI Machine Learning Repository are presented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15038031</person_id>
				<author_profile_id><![CDATA[81100631453]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sandeep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mane]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota, Minneapolis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39025487</person_id>
				<author_profile_id><![CDATA[81100063012]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jaideep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Srivastava]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota, Minneapolis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37029256</person_id>
				<author_profile_id><![CDATA[81452597326]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[San-Yih]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hwang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National Sun-Yat-Sen University, Kaohsiung, Taiwan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702368</person_id>
				<author_profile_id><![CDATA[81100501192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jamshid]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vayghan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[IBM Corporation, Minneapolis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033510</article_id>
		<sort_key>479</sort_key>
		<display_label></display_label>
		<pages>479-482</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>87</seq_no>
		<title><![CDATA[Correlation Preserving Discretization]]></title>
		<page_from>479</page_from>
		<page_to>482</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033510</url>
		<abstract>
			<par><![CDATA[Discretization is a crucial preprocessing primitive for a variety of data warehousing and mining tasks. In this article we present a novel PCA-based unsupervised algorithm for the discretization of continuous attributes in multivariate datasets. The algorithm leverages the underlying correlation structure in the dataset to obtain the discrete intervals, and ensures that the inherent correlations are preserved. The approach also extends easily to datasets containing missing values. We demonstrate the efficacy of the approach on real datasets and as a preprocessing step for both classification and frequent itemset mining tasks. We also show that the intervals are meaningful and can uncover hidden patterns in data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Unsupervised Discretization, Missing Data]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P703034</person_id>
				<author_profile_id><![CDATA[81100653723]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sameep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mehta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15030535</person_id>
				<author_profile_id><![CDATA[81100375834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Srinivasan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Parthasarathy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15030068</person_id>
				<author_profile_id><![CDATA[81406591873]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The Ohio State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033511</article_id>
		<sort_key>483</sort_key>
		<display_label></display_label>
		<pages>483-486</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>88</seq_no>
		<title><![CDATA[Active Feature-Value Acquisition for Classifier Induction]]></title>
		<page_from>483</page_from>
		<page_to>486</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033511</url>
		<abstract>
			<par><![CDATA[Many induction problems include missing data that can be acquired at a cost. For building accurate predictive models, acquiring complete information for all instances is often expensive or unnecessary, while acquiring information for a random subset of instances may not be most effective. Active feature-value acquisition tries to reduce the cost of achieving a desired model accuracy by identifying instances for which obtaining complete information is most informative. We present an approach in which instances are selected for acquisition based on the current model's accuracy and its confidence in the prediction. Experimental results demonstrate that our approach can induce accurate models using substantially fewer feature-value acquisitions as compared to alternative policies.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15037004</person_id>
				<author_profile_id><![CDATA[81100590712]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Prem]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Melville]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40029205</person_id>
				<author_profile_id><![CDATA[81335496720]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Maytal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Saar-Tsechansky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15037178</person_id>
				<author_profile_id><![CDATA[81100596683]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Foster]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Provost]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15035642</person_id>
				<author_profile_id><![CDATA[81100539345]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Raymond]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mooney]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Univ. of Texas at Austin]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033512</article_id>
		<sort_key>487</sort_key>
		<display_label></display_label>
		<pages>487-490</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>89</seq_no>
		<title><![CDATA[Privacy-Sensitive Bayesian Network Parameter Learning]]></title>
		<page_from>487</page_from>
		<page_to>490</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033512</url>
		<abstract>
			<par><![CDATA[This paper considers the problem of learning the parameters of a Bayesian Network, assuming the structure of the network is given, from a privacy-sensitive dataset that is distributed between multiple parties. For a binary-valued dataset, we show that the count information required to estimate the conditional probabilities in a Bayesian network can be obtained as a solution to a set of linear equations involving some inner product between the relevantdifferent feature vectors. We consider a random projection-based method that was proposed elsewhere to securely compute the inner product (with a modified implementation of that method).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP29025236</person_id>
				<author_profile_id><![CDATA[81100222815]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[D.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Meng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Washington State University, Pullman, WA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP48023110</person_id>
				<author_profile_id><![CDATA[81100106585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sivakumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Washington State University, Pullman, WA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P404034</person_id>
				<author_profile_id><![CDATA[81100150749]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kargupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UMBC, Baltimore, MD]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033513</article_id>
		<sort_key>491</sort_key>
		<display_label></display_label>
		<pages>491-494</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>90</seq_no>
		<title><![CDATA[MMSS]]></title>
		<subtitle><![CDATA[Multi-Modal Story-Oriented Video Summarization]]></subtitle>
		<page_from>491</page_from>
		<page_to>494</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033513</url>
		<abstract>
			<par><![CDATA[We propose multi-modal story-oriented video summarization (MMSS) which, unlike previous works that use fine-tuned, domain-specific heuristics, provides a domain-independent, graph-based framework. MMSS uncovers correlation between information of different modalities which gives meaningful story-oriented news video summaries. MMSS can also be applied for video retrieval, giving performance that matches the best traditional retrieval techniques (OKAPI and LSI), with no fine-tuned heuristics such as tf/idf.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15033915</person_id>
				<author_profile_id><![CDATA[81100485214]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jia-Yu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15030073</person_id>
				<author_profile_id><![CDATA[81309483835]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hyungjeong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15030495</person_id>
				<author_profile_id><![CDATA[81100373169]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Christos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Faloutsos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carnegie Mellon University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033514</article_id>
		<sort_key>495</sort_key>
		<display_label></display_label>
		<pages>495-498</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>91</seq_no>
		<title><![CDATA[A Comparative Study of Linear and Nonlinear Feature Extraction Methods]]></title>
		<page_from>495</page_from>
		<page_to>498</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033514</url>
		<abstract>
			<par><![CDATA[This paper presents theoretical relationships among several generalized LDA algorithms and proposes computationally efficient approaches for them utilizing the relationships. Generalized LDA algorithms are extended nonlinearly by kernel methods resulting in nonlinear discriminant analysis. Performances and computational complexities of these linear and nonlinear discriminant analysis algorithms are compared.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39030187</person_id>
				<author_profile_id><![CDATA[81384617662]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cheong]]></first_name>
				<middle_name><![CDATA[Hee]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota, Minneapolis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030206</person_id>
				<author_profile_id><![CDATA[81100158952]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haesun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Minnesota, Minneapolis]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P337051</person_id>
				<author_profile_id><![CDATA[81350591177]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Panos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pardalos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Florida, Gainesville]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033515</article_id>
		<sort_key>499</sort_key>
		<display_label></display_label>
		<pages>499-502</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>92</seq_no>
		<title><![CDATA[SVM and Graphical Algorithms]]></title>
		<subtitle><![CDATA[A Cooperative Approach]]></subtitle>
		<page_from>499</page_from>
		<page_to>502</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033515</url>
		<abstract>
			<par><![CDATA[We present a cooperative approach using both Support Vector Machine (SVM) algorithms and visualization methods. SVM are widely used today and often give high quality results, but they are used as "black-box" (it is very difficult to explain the obtained results) and cannot treat easily very large datasets. We have developed graphical methods to help the user to evaluate and explain the SVM results. The first method is a graphical representation of the separating frontier quality, it is then linked with other visualization tools to help the user explaining SVM results. The information provided by these graphical methods is also used for SVM parameter tuning, they are then used together with automatic algorithms to deal with very large datasets on standard computers. We present an evaluation of our approach with the UCI and the Kent Ridge Bio-medical data sets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP36023744</person_id>
				<author_profile_id><![CDATA[81381599793]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Francois]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Poulet]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[ESIEA - P&#244;le ECD, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033516</article_id>
		<sort_key>503</sort_key>
		<display_label></display_label>
		<pages>503-506</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>93</seq_no>
		<title><![CDATA[RDF]]></title>
		<subtitle><![CDATA[A Density-Based Outlier Detection Method using Vertical Data Representation]]></subtitle>
		<page_from>503</page_from>
		<page_to>506</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033516</url>
		<abstract>
			<par><![CDATA[Outlier detection can lead to discovering unexpected and interesting knowledge, which is critical important to some areas such as monitoring of criminal activities in electronic commerce, credit card fraud, etc. In this paper, we developed an efficient density-based outlier detection method for large datasets. Our contributions are: a) We introduce a relative density factor (RDF); b) Based on RDF, we propose an RDF-based outlier detection method which can efficiently prune the data points which are deep in clusters, and detect outliers only within the remaining small subset of the data; c) The performance of our method is further improved by means of a vertical data representation, P-trees. We tested our method with NHL and NBA data. Our method shows an order of magnitude speed improvement compared to the contemporary approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P587670</person_id>
				<author_profile_id><![CDATA[81100597844]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dongmei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ren]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[North Dakota State University, Fargo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P587668</person_id>
				<author_profile_id><![CDATA[81547175456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Baoying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[North Dakota State University, Fargo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15027893</person_id>
				<author_profile_id><![CDATA[81100272378]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perrizo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[North Dakota State University, Fargo]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033517</article_id>
		<sort_key>507</sort_key>
		<display_label></display_label>
		<pages>507-510</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>94</seq_no>
		<title><![CDATA[Quantitative Association Rules Based on Half-Spaces]]></title>
		<subtitle><![CDATA[An Optimization Approach]]></subtitle>
		<page_from>507</page_from>
		<page_to>510</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033517</url>
		<abstract>
			<par><![CDATA[We tackle the problem of finding association rules for quantitative data. Whereas most of the previous approaches operate on hyperrectangles, we propose a representation based on half-spaces. Consequently, the left-hand side and right-hand side of an association rule does not contain a conjunction of items or intervals, but a weighted sum of variables tested against a threshold. Since the downward closure property does not hold for such rules, we propose an optimization setting for finding locally optimal rules. A simple gradient descent algorithm optimizes a parameterized score function, where iterations optimizing the first separating hyperplane alternate with iterations optimizing the second. Experiments with two real-world data sets show that the approach finds non-random patterns and scales up well. We therefore propose quantitative association rules based on half-spaces as an interesting new class of patterns with a high potential for applications.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP3300020600</person_id>
				<author_profile_id><![CDATA[83458846257]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ulrich]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ruckert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technische Universit&#228;t M&#252;nchen, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702592</person_id>
				<author_profile_id><![CDATA[81100351552]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lothar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Richter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technische Universit&#228;t M&#252;nchen, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43117111</person_id>
				<author_profile_id><![CDATA[81100175708]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kramer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Technische Universit&#228;t M&#252;nchen, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033518</article_id>
		<sort_key>511</sort_key>
		<display_label></display_label>
		<pages>511-514</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>95</seq_no>
		<title><![CDATA[Evaluating Attraction in Spatial Point Patterns with an Application in the Field of Cultural History]]></title>
		<page_from>511</page_from>
		<page_to>514</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033518</url>
		<abstract>
			<par><![CDATA[Spatial collocation rules are often useful for describing dependencies between spatial features. Still, the commonly used criteria for the interestingness of the rules and the selected neighbourhood constraints for spatial objects may be too rough for capturing the essentials of such dependencies. We demonstrate the difficulties with concrete examples on a large place-name data set. We propose a technique based on simple density estimation for assessing the interestingness with different neighbouring constraints.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P339947</person_id>
				<author_profile_id><![CDATA[81100067937]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Salmenkivi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[FIN-University of Helsinki, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033519</article_id>
		<sort_key>515</sort_key>
		<display_label></display_label>
		<pages>515-518</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>96</seq_no>
		<title><![CDATA[Spatial Collocation Rules are Often Useful for Describing]]></title>
		<page_from>515</page_from>
		<page_to>518</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033519</url>
		<abstract>
			<par><![CDATA[Multi-relational data mining(MRDM) is concerned with data that contains heterogeneous and semantically rich relationships among various entity types. In this paper, we introduce multi-relational iceberg-cubes (MRI-Cubes) as a scalable approach to efficiently compute data cubes (aggregations) over multiple database relations and, in particular, as mechanisms to compute frequent multi-relational patterns ("itemsets"). We also present a summary of performance results of our algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P700923</person_id>
				<author_profile_id><![CDATA[81100067842]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dawit]]></first_name>
				<middle_name><![CDATA[Yimam]]></middle_name>
				<last_name><![CDATA[Seid]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Irvine]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43124185</person_id>
				<author_profile_id><![CDATA[81331499070]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sharad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mehrotra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of California, Irvine]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033520</article_id>
		<sort_key>519</sort_key>
		<display_label></display_label>
		<pages>519-522</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>97</seq_no>
		<title><![CDATA[Cluster Cores-Based Clustering for High Dimensional Data]]></title>
		<page_from>519</page_from>
		<page_to>522</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033520</url>
		<abstract>
			<par><![CDATA[We propose a new approach to clustering high dimensional data based on a novel notion of cluster cores, instead of on nearest neighbors. A cluster core is a fairly dense group with a maximal number of pairwise similar objects. It represents the core of a cluster, as all objects in a cluster are with a great degree attracted to it. As a result, building clusters from cluster cores achieves high accuracy. Other major characteristics of the approach include: (1) It uses a semantics-based similarity measure. (2) It does not incur the curse of dimensionality and is scalable linearly with the dimensionality of data. (3) It outperforms the well-known clustering algorithm, ROCK, with both lower time complexity and higher accuracy.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP94029747</person_id>
				<author_profile_id><![CDATA[81450594087]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yi-Dong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese Academy of Sciences, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P703394</person_id>
				<author_profile_id><![CDATA[81392598013]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zhi-Yong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese Academy of Sciences, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P703085</person_id>
				<author_profile_id><![CDATA[81414616287]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shi-Ming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Chinese Academy of Sciences, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77025006</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hong Kong Univ. of Sci. & Technology, Hong Kong]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033521</article_id>
		<sort_key>523</sort_key>
		<display_label></display_label>
		<pages>523-526</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>98</seq_no>
		<title><![CDATA[Metric Incremental Clustering of Nominal Data]]></title>
		<page_from>523</page_from>
		<page_to>526</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033521</url>
		<abstract>
			<par><![CDATA[We present an algorithm for clustering nominal data that is based on a metric on the set of partitions of a finite set of objects; this metric is defined starting from a lower valuation of the lattice of partitions. The proposed algorithm seeks to determine a clustering partition such that the total distance between this partition and the partitions determined by the attributes of the objects has a local minimum. The resulting clustering is quite stable relative to the ordering of the objects.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P58253</person_id>
				<author_profile_id><![CDATA[81100393892]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Simovici]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts at Boston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702798</person_id>
				<author_profile_id><![CDATA[81100139971]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Namita]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Singla]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Massachusetts at Boston]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702737</person_id>
				<author_profile_id><![CDATA[81100154440]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuperberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Karlsruhe University, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033522</article_id>
		<sort_key>527</sort_key>
		<display_label></display_label>
		<pages>527-530</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>99</seq_no>
		<title><![CDATA[On Ranking Refinements in the Step-by-Step Searching through a Product Catalogue]]></title>
		<page_from>527</page_from>
		<page_to>530</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033522</url>
		<abstract>
			<par><![CDATA[In our previous work we have developed a logic-based approach for the refinement of ontology-based queries that enables a user to search through a repository in a step-by-step fashion. Since the set of refinements in a step can be large, they should be ranked according to their relevance for fulfilling a user's need. In this paper we present such a ranking model, which takes into account the information content (informativeness) of a refinement as well as the preferences of the user.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP48023899</person_id>
				<author_profile_id><![CDATA[81339530715]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nenad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stojanovic]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Karlsruhe, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033523</article_id>
		<sort_key>531</sort_key>
		<display_label></display_label>
		<pages>531-534</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>100</seq_no>
		<title><![CDATA[Learning Conditional Independence Tree for Ranking]]></title>
		<page_from>531</page_from>
		<page_to>534</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033523</url>
		<abstract>
			<par><![CDATA[Accurate ranking is desired in many real-world data mining applications. Traditional learning algorithms, however, aim only at high classification accuracy. It has been observed that both traditional decision trees and naive Bayes produce good classification accuracy but poor probability estimates. In this paper, we use a new model, conditional independence tree (CITree), which is a combination of decision tree and naive Bayes and more suitable for ranking and more learnable in practice. We propose a novel algorithm for learning CITree for ranking, and the experiments show that the CITree algorithm outperforms the state-of-the-art decision tree learning algorithm C4.4 and naive Bayes significantly in yielding accurate rankings. Our work provides an effective data mining algorithm for applications in which an accurate ranking is required.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP24009571</person_id>
				<author_profile_id><![CDATA[81323496337]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Su]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of New Brunswick, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31028144</person_id>
				<author_profile_id><![CDATA[81100120645]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Harry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of New Brunswick, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033524</article_id>
		<sort_key>535</sort_key>
		<display_label></display_label>
		<pages>535-538</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>101</seq_no>
		<title><![CDATA[Supervised Latent Semantic Indexing for Document Categorization]]></title>
		<page_from>535</page_from>
		<page_to>538</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033524</url>
		<abstract>
			<par><![CDATA[Latent Semantic Indexing (LSI) is a successful technology in information retrieval (IR) which attempts to explore the latent semantics implied by a query or a document through representing them in a dimension-reduced space. However, LSI is not optimal for document categorization tasks because it aims to find the most representative features for document representation rather than the most discriminative ones. In this paper, we propose Supervised LSI (SLSI) which selects the most discriminative basis vectors using the training data iteratively. The extracted vectors are then used to project the documents into a reduced dimensional space for better classification. Experimental evaluations show that the SLSI approach leads to dramatic dimension reduction while achieving good classification results.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP77031253</person_id>
				<author_profile_id><![CDATA[81351592034]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jian-Tao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TsingHua University, Beijing, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79027892</person_id>
				<author_profile_id><![CDATA[81416601059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14216704</person_id>
				<author_profile_id><![CDATA[81100630328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hua-Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zeng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P696335</person_id>
				<author_profile_id><![CDATA[81350589703]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Yu-Chang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TsingHua University, Beijing, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P695265</person_id>
				<author_profile_id><![CDATA[81100647381]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Chun-Yi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TsingHua University, Beijing, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP79028820</person_id>
				<author_profile_id><![CDATA[81350592994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Wei-Ying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Research Asia, P.R. China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033525</article_id>
		<sort_key>539</sort_key>
		<display_label></display_label>
		<pages>539-542</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>102</seq_no>
		<title><![CDATA[Sparse Kernel Least Squares Classifier]]></title>
		<page_from>539</page_from>
		<page_to>542</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033525</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a new learning algorithm for constructing kernel least squares classifier. The new algorithm adopts a recursive learning way and a novel two-step sparsification procedure is incorporated into learning phase. These two most importantfeatures not only provide a feasible approach for large-scale problems as it is not necessary to store the entire kernel matrix, but also produce a very sparse model with fast training and testing time. Experimental results on a number of data classification problems are presented to demonstrate the competitiveness of new proposed algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP25003750</person_id>
				<author_profile_id><![CDATA[81539771056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Birmingham, UK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033526</article_id>
		<sort_key>543</sort_key>
		<display_label></display_label>
		<pages>543-546</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>103</seq_no>
		<title><![CDATA[DRYADE]]></title>
		<subtitle><![CDATA[A New Approach for Discovering Closed Frequent Trees in Heterogeneous Tree Databases]]></subtitle>
		<page_from>543</page_from>
		<page_to>546</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033526</url>
		<abstract>
			<par><![CDATA[In this paper we present a novel algorithm for discovering tree patterns in a tree database. This algorithm uses a relaxed tree inclusion definition, making the problem more complex (checking tree inclusion is NP-complete), but allowing to mine highly heterogeneous databases. To obtain good performances, our DRYADE algorithm discovers only closed frequent tree patterns.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15027231</person_id>
				<author_profile_id><![CDATA[81100245571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexandre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Termier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INRIA (Futurs), France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39035471</person_id>
				<author_profile_id><![CDATA[81100273126]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Marie-Christine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rousset]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INRIA (Futurs), France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15037662</person_id>
				<author_profile_id><![CDATA[81100614693]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michele]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sebag]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[INRIA (Futurs), France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033527</article_id>
		<sort_key>547</sort_key>
		<display_label></display_label>
		<pages>547-550</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>104</seq_no>
		<title><![CDATA[A Greedy Algorithm for Selecting Models in Ensembles]]></title>
		<page_from>547</page_from>
		<page_to>550</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033527</url>
		<abstract>
			<par><![CDATA[We are interested in ensembles of models built over k data sets. Common approaches are either to combine models by vote averaging, or to build a meta-model on the outputs of the local models. In this paper, we consider the model assignment approach, in which a meta-model selects one of the local statistical models for scoring. We introduce an algorithm called Greedy Data Labeling (GDL) that improves the initial data partition by reallocating some data, so that when each model is built on its local data subset, the resulting hierarchical system has minimal error. We present evidence that model assignment may in certain situations be more natural than traditional ensemble learning, and if enhanced by GDL, it often outperforms traditional ensembles.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P601778</person_id>
				<author_profile_id><![CDATA[81100308452]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrei]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Turinsky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39044713</person_id>
				<author_profile_id><![CDATA[81100478239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Grossman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Chicago, USA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033528</article_id>
		<sort_key>551</sort_key>
		<display_label></display_label>
		<pages>551-554</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>105</seq_no>
		<title><![CDATA[Mining Web Data to Create Online Navigation Recommendations]]></title>
		<page_from>551</page_from>
		<page_to>554</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033528</url>
		<abstract>
			<par><![CDATA[A system to provide online navigation recommendation for web visitors is introduced. We call visitor the anonymous user, i.e., when only data about her/his browsing behavior (web logs) are available. We first apply clustering techniques over a large sample of web data. Next, from thesignificant patterns that are discovered, a set of rules about how to use them is created. Finally, comparing the current web visitor session with the patterns, online navigation recommendations are proposed using the mentioned rules. The system was tested using data from a real web site, showing its effectiveness.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14076523</person_id>
				<author_profile_id><![CDATA[81100191715]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Juan]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Velasquez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tokyo, Japan; University of Chile]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14043171</person_id>
				<author_profile_id><![CDATA[81100094346]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alejandro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bassi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tokyo, Japan; University of Chile]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36030605</person_id>
				<author_profile_id><![CDATA[81100610717]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hiroshi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yasuda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P279448</person_id>
				<author_profile_id><![CDATA[81100590293]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Terumasa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aoki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tokyo, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033529</article_id>
		<sort_key>555</sort_key>
		<display_label></display_label>
		<pages>555-558</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>106</seq_no>
		<title><![CDATA[Alpha Galois Lattices]]></title>
		<page_from>555</page_from>
		<page_to>558</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033529</url>
		<abstract>
			<par><![CDATA[In many applications there is a need to represent a large number of data by clustering them in a hierarchy of classes. Our basic representation is a Galois lattice, a structure that exhaustively represents the whole set of concepts that are distinguishable given the instance set and the representation language. What we propose here is a method to reduce the size of the lattice, and thus simplify our view of the data, while conserving its formal structure and exhaustivity. For that purpose we use a preliminary partition of the instance set, representing the association of a "type" to each instance. By redefining the notion of extent of a term in order to cope, to a certain degree (denoted as ¿), with this partition, we define a particular family of Galois lattices denoted as Alpha Galois lattices. We also discuss the related implication rules defined as inclusion of such ¿-extents.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P703256</person_id>
				<author_profile_id><![CDATA[81100592239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Veronique]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ventos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#233; Paris-Sud, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14054734</person_id>
				<author_profile_id><![CDATA[81100125485]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Soldano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#233; Paris-Nord, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P703188</person_id>
				<author_profile_id><![CDATA[81100346219]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Thibaut]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lamadon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#233; Paris-Sud, France]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033530</article_id>
		<sort_key>559</sort_key>
		<display_label></display_label>
		<pages>559-562</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>107</seq_no>
		<title><![CDATA[AGILE]]></title>
		<subtitle><![CDATA[A General Approach to Detect Transitions in Evolving Data Streams]]></subtitle>
		<page_from>559</page_from>
		<page_to>562</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033530</url>
		<abstract>
			<par><![CDATA[In many applications such as e-commerce, system diagnosis and telecommunication services, data arrives in streams at a high speed. It is common that the underlying process generating the stream may change over time, either as a result of the fundamental evolution or in response to some external stimulus. Detecting these changes is a very challenging problem of great practical importance. The overall volume of the stream usually far exceeds the available main memory and access to the data stream is typically performed via a linear scan in ascending order of the indices of the records. In this paper, we propose a novel approach, AGILE, to monitor streaming data and to detect distinguishable transitions of the underlying processes. AGILE has many advantages over the traditional Hidden Markov Model, e.g., AGILE only requires one scan of the data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Stream processing, Transition detection, Variable memory Markov model, Emission tree]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP54031571</person_id>
				<author_profile_id><![CDATA[81351603409]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jiong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Case Western Reserve University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP55041905</person_id>
				<author_profile_id><![CDATA[81416594540]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of North Carolina at Chapel Hill]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033531</article_id>
		<sort_key>563</sort_key>
		<display_label></display_label>
		<pages>563-566</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>108</seq_no>
		<title><![CDATA[Scalable Construction of Topic Directory with Nonparametric Closed Termset Mining]]></title>
		<page_from>563</page_from>
		<page_to>566</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033531</url>
		<abstract>
			<par><![CDATA[A topic directory, e.g., Yahoo directory, provides a view of a document set at different levelsof abstraction and is ideal for the interactive exploration and visualization of the document set. We present a method that dynamically generates a topic directory from a document set usinga frequent closed termset mining algorithm. Our method shows experimental results of equal quality to recent document clustering methods and has additional benefits such as automatic generation of topic labels and determination of a clustering parameter.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[topic directory, document clustering, hierarchical clustering]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14164934</person_id>
				<author_profile_id><![CDATA[81452596142]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hwanjo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Urbana-Champaign]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702054</person_id>
				<author_profile_id><![CDATA[81435603987]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Duane]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Searsmith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Urbana-Champaign]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P703320</person_id>
				<author_profile_id><![CDATA[81351597612]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xiaolei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Urbana-Champaign]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023202</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Illinois at Urbana-Champaign]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033532</article_id>
		<sort_key>567</sort_key>
		<display_label></display_label>
		<pages>567-570</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>109</seq_no>
		<title><![CDATA[Learning Weighted Naive Bayes with Accurate Ranking]]></title>
		<page_from>567</page_from>
		<page_to>570</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033532</url>
		<abstract>
			<par><![CDATA[Naive Bayes is one of most effective classification algorithms. In many applications, however, a ranking of examples are more desirable than just classification. How to extend naive Bayes to improve its ranking performance is an interesting and useful question in practice. Weighted naive Bayes is an extension of naive Bayes, in which attributes have different weights. This paper investigates how to learn a weighted naive Bayes with accurate ranking from data, or more precisely, how to learn the weights of a weighted naive Bayes to produce accurate ranking. We explore various methods: the gain ratio method, the hill climbing method, and the Markov Chain Monte Carlo method, the hill climbing method combined with the gain ratio method, and the Markov Chain Monte Carlo method combined with the gain ratio method. Our experiments show that a weighted naive Bayes trained to produce accurate ranking outperforms naive Bayes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31028144</person_id>
				<author_profile_id><![CDATA[81100120645]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Harry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of New Brunswick, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15027168</person_id>
				<author_profile_id><![CDATA[81309493236]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shengli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sheng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Western Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033533</article_id>
		<sort_key>571</sort_key>
		<display_label></display_label>
		<pages>571-574</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>110</seq_no>
		<title><![CDATA[Learning Rules from Highly Unbalanced Data Sets]]></title>
		<page_from>571</page_from>
		<page_to>574</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033533</url>
		<abstract>
			<par><![CDATA[This paper presents a simple and effective rule learning algorithm for highly unbalanced data sets. By using the small size of the minority class to its advantage this algorithm can conduct an almost exhaustive search for patterns within the known fraudulent cases. This algorithm was designed for and successfully applied to a law enforcement problem, which involves discovering common patterns of fraudulent transactions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP45023601</person_id>
				<author_profile_id><![CDATA[81343510227]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jianping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[AOL, Inc., Dulles, VA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P77921</person_id>
				<author_profile_id><![CDATA[81100286682]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bloedorn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MITRE Corporation, McLean, Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702594</person_id>
				<author_profile_id><![CDATA[81344497208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Lowell]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rosen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MITRE Corporation, McLean, Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P701995</person_id>
				<author_profile_id><![CDATA[81100527720]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Venese]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[MITRE Corporation, McLean, Virginia]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033534</article_id>
		<sort_key>575</sort_key>
		<display_label></display_label>
		<pages>575-578</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>111</seq_no>
		<title><![CDATA[Relational Peculiarity Oriented Data Mining]]></title>
		<page_from>575</page_from>
		<page_to>578</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033534</url>
		<abstract>
			<par><![CDATA[Peculiarity rules are a new type of interesting rules which can be discovered by searching the relevance among peculiar data. A main task of mining peculiarity rules is the identification of peculiarity. Traditional methods of finding peculiar data are attribute-based approaches. This paper extends peculiarity oriented mining to relational peculiarity oriented mining. Peculiar data are identified on record level, and peculiar rules are mined and explained in a relational mining framework. The results from preliminary experiments show that relational peculiarity oriented mining is very effective.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP43125736</person_id>
				<author_profile_id><![CDATA[81327492811]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Maebashi Institute of Technology, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95037798</person_id>
				<author_profile_id><![CDATA[81452598184]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chunnian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Beijing University of Technology, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43135668</person_id>
				<author_profile_id><![CDATA[81100543359]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Y.]]></first_name>
				<middle_name><![CDATA[Y.]]></middle_name>
				<last_name><![CDATA[Yao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Regina, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43135839</person_id>
				<author_profile_id><![CDATA[81336491909]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Muneaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ohshima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Maebashi Institute of Technology, Japan]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P702759</person_id>
				<author_profile_id><![CDATA[81342497834]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Mingxin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Beijing University of Technology, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43139792</person_id>
				<author_profile_id><![CDATA[81342497887]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Jiajin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Beijing University of Technology, China]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033427</article_id>
		<sort_key>579</sort_key>
		<display_label></display_label>
		<pages>579-579</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>112</seq_no>
		<title><![CDATA[Invited Talks]]></title>
		<page_from>579</page_from>
		<page_to>579</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033427</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033428</article_id>
		<sort_key>580</sort_key>
		<display_label></display_label>
		<pages>580-580</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>113</seq_no>
		<title><![CDATA[Tutorials]]></title>
		<page_from>580</page_from>
		<page_to>580</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033428</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033429</article_id>
		<sort_key>581</sort_key>
		<display_label></display_label>
		<pages>581-581</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>114</seq_no>
		<title><![CDATA[Workshops]]></title>
		<page_from>581</page_from>
		<page_to>581</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033429</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1033535</article_id>
		<sort_key>583</sort_key>
		<display_label></display_label>
		<pages>583-585</pages>
		<article_publication_date>11-01-2004</article_publication_date>
		<seq_no>115</seq_no>
		<title><![CDATA[Author Index]]></title>
		<page_from>583</page_from>
		<page_to>585</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1033535</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
</content>
</proceeding>

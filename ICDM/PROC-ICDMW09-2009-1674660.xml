<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>12-06-2009</start_date>
		<end_date>12-06-2009</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url>http://computer.org/proceedings/icdmw/2009/3902</conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES11453</series_id>
		<series_title><![CDATA[ICDMW]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1674660</proc_id>
	<acronym>ICDMW '09</acronym>
	<proc_desc>Proceedings of the 2009 IEEE International Conference on Data Mining Workshops</proc_desc>
	<conference_number></conference_number>
	<proc_class>conference</proc_class>
	<proc_title></proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn13>978-0-7695-3902-7</isbn13>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2009</copyright_year>
	<publication_date>12-06-2009</publication_date>
	<pages></pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB769</publisher_id>
		<publisher_code>IEEEW</publisher_code>
		<publisher_name>IEEE Computer Society</publisher_name>
		<publisher_address>1730 Massachusetts Ave., NW             Washington, DC</publisher_address>
		<publisher_city></publisher_city>
		<publisher_state></publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>20036-1992</publisher_zip_code>
		<publisher_contact></publisher_contact>
		<publisher_phone></publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url></publisher_url>
	</publisher>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>1677203</article_id>
		<sort_key>10</sort_key>
		<display_label>Page</display_label>
		<pages>C4,C1</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Cover Art]]></title>
		<page_from>C1</page_from>
		<doi_number>10.1109/ICDMW.2009.118</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677203</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677204</article_id>
		<sort_key>20</sort_key>
		<display_label>Page</display_label>
		<pages>i</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Title Page i]]></title>
		<page_from>i</page_from>
		<doi_number>10.1109/ICDMW.2009.1</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677204</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677205</article_id>
		<sort_key>30</sort_key>
		<display_label>Page</display_label>
		<pages>iii</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Title Page iii]]></title>
		<page_from>iii</page_from>
		<doi_number>10.1109/ICDMW.2009.2</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677205</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677206</article_id>
		<sort_key>40</sort_key>
		<display_label>Page</display_label>
		<pages>iv</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Copyright Page]]></title>
		<page_from>iv</page_from>
		<doi_number>10.1109/ICDMW.2009.3</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677206</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677207</article_id>
		<sort_key>60</sort_key>
		<display_label>Page</display_label>
		<pages>xiii</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Message from General Co-chairs]]></title>
		<page_from>xiii</page_from>
		<doi_number>10.1109/ICDMW.2009.4</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677207</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677208</article_id>
		<sort_key>70</sort_key>
		<display_label>Page</display_label>
		<pages>xiv</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Message from Workshop Co-chairs]]></title>
		<page_from>xiv</page_from>
		<doi_number>10.1109/ICDMW.2009.5</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677208</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677209</article_id>
		<sort_key>100</sort_key>
		<display_label>Pages</display_label>
		<pages>1-6</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[SISC]]></title>
		<subtitle><![CDATA[A Text Classification Approach Using Semi Supervised Subspace Clustering]]></subtitle>
		<page_from>1</page_from>
		<page_to>6</page_to>
		<doi_number>10.1109/ICDMW.2009.61</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677209</url>
		<abstract>
			<par><![CDATA[Text classification poses some specific challenges. One such challenge is its high dimensionality where each document (data point) contains only a small subset of them. In this paper, we propose Semi-supervised Impurity based Subspace Clustering (SISC) in conjunction with k-Nearest Neighbor approach, based on semi-supervised subspace clustering that considers the high dimensionality as well as the sparse nature of them in text data. SISC finds clusters in the subspaces of the high dimensional text data where each text document has fuzzy cluster membership. This fuzzy clustering exploits two factors - chi square statistic of the dimensions and the impurity measure within each cluster. Empirical evaluation on real world data sets reveals the effectiveness of our approach as it significantly outperforms other state-of-the-art text classification and subspace clustering algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831654</person_id>
				<author_profile_id><![CDATA[81421594519]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mohammad]]></first_name>
				<middle_name><![CDATA[Salim]]></middle_name>
				<last_name><![CDATA[Ahmed]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831655</person_id>
				<author_profile_id><![CDATA[81100344538]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Latifur]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Khan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677210</article_id>
		<sort_key>110</sort_key>
		<display_label>Pages</display_label>
		<pages>7-12</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[High Quality True-Positive Prediction for Fiscal Fraud Detection]]></title>
		<page_from>7</page_from>
		<page_to>12</page_to>
		<doi_number>10.1109/ICDMW.2009.59</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677210</url>
		<abstract>
			<par><![CDATA[In this paper we describe an experience resulting from the collaboration among Data Mining researchers, domain experts of the Italian Revenue Agency, and IT professionals, aimed at detecting fraudulent VAT credit claims. The outcome is an auditing methodology based on a rule-based system, which is capable of trading among conflicting issues, such as maximizing audit benefits, minimizing false positive audit predictions, or deterring probable upcoming frauds. We describe the methodology in detail, and illustrate its practical effectiveness compared to classical predictive systems from the literature.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1821139</person_id>
				<author_profile_id><![CDATA[81100040711]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Stefano]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Basta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821140</person_id>
				<author_profile_id><![CDATA[81314493715]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fabio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fassetti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821141</person_id>
				<author_profile_id><![CDATA[81442615194]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Massimo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Guarascio]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821142</person_id>
				<author_profile_id><![CDATA[81100074564]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Giuseppe]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Manco]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821143</person_id>
				<author_profile_id><![CDATA[81100458577]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Fosca]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Giannotti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821144</person_id>
				<author_profile_id><![CDATA[81100352341]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Dino]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pedreschi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821145</person_id>
				<author_profile_id><![CDATA[81375619472]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Laura]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Spinsanti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821146</person_id>
				<author_profile_id><![CDATA[81453657164]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Gianfilippo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Papi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821147</person_id>
				<author_profile_id><![CDATA[81453606075]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[Stefano]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pisani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677211</article_id>
		<sort_key>120</sort_key>
		<display_label>Pages</display_label>
		<pages>13-18</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Building Classifiers with Independency Constraints]]></title>
		<page_from>13</page_from>
		<page_to>18</page_to>
		<doi_number>10.1109/ICDMW.2009.83</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677211</url>
		<abstract>
			<par><![CDATA[In this paper we study the problem of classifier learning where the input data contains unjustified dependencies between some data attributes and the class label. Such cases arise for example when the training data is collected from different sources with different labeling criteria or when the data is generated by a biased decision process. When a classifier is trained directly on such data, these undesirable dependencies will carry over to the classifier&#8217;s predictions. In order to tackle this problem, we study the classification with independency constraints problem: find an accurate model for which the predictions are independent from a given binary attribute. We propose two solutions for this problem and present an empirical validation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828644</person_id>
				<author_profile_id><![CDATA[81100650328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Toon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Calders]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828645</person_id>
				<author_profile_id><![CDATA[81453661983]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Faisal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kamiran]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828646</person_id>
				<author_profile_id><![CDATA[81100136358]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mykola]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pechenizkiy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677212</article_id>
		<sort_key>130</sort_key>
		<display_label>Pages</display_label>
		<pages>19-24</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Discovering Domain Specific Concepts within User-Generated Taxonomies]]></title>
		<page_from>19</page_from>
		<page_to>24</page_to>
		<doi_number>10.1109/ICDMW.2009.57</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677212</url>
		<abstract>
			<par><![CDATA[Collaborative tagging of resources on the Web has become a commonplace occurrence. Web sites allowing resources to be tagged provide a tremendous amount of user-generated taxonomic information. However, information seekers are hindered by the lack of organization within these tags as well as the multitude of domains encompassed within these sites. To address these issues, we propose a multi-step approach for creating domain specific concept hierarchies from collaborative tags. Each concept hierarchy is based on domain specific subject matters, which may span more than one tag, as opposed to related work which are only concerned with the relationships between single tags.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822751</person_id>
				<author_profile_id><![CDATA[81313481862]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jonathan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Klinginsmith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822752</person_id>
				<author_profile_id><![CDATA[81100444274]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Malika]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mahoui]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822753</person_id>
				<author_profile_id><![CDATA[81453638154]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yuqing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822754</person_id>
				<author_profile_id><![CDATA[81442613048]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Josette]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jones]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677220</article_id>
		<sort_key>140</sort_key>
		<display_label>Pages</display_label>
		<pages>25-30</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[A Game Theoretical Model for Adversarial Learning]]></title>
		<page_from>25</page_from>
		<page_to>30</page_to>
		<doi_number>10.1109/ICDMW.2009.9</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677220</url>
		<abstract>
			<par><![CDATA[It is now widely accepted that in many situations where classifiers are deployed, adversaries deliberately manipulate data in order to reduce the classifier&#8217;s accuracy. The most prominent example is email spam, where spammers routinely modify emails to get past classifier-based spam filters. In this paper we model the interaction between the adversary and the data miner as a two-person sequential noncooperative Stackelberg game and analyze the outcomes when there is a natural leader and a follower. We then proceed to model the interaction (both discrete and continuous) as an optimization problem and note that even solving linear Stackelberg game is NP-Hard. Finally we use a real spam email data set and evaluate the performance of local search algorithm under different strategy spaces.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830157</person_id>
				<author_profile_id><![CDATA[81467646317]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830158</person_id>
				<author_profile_id><![CDATA[81100002847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sanjay]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chawla]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677221</article_id>
		<sort_key>150</sort_key>
		<display_label>Pages</display_label>
		<pages>31-36</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Discovery of Quantitative Sequential Patterns from Event Sequences]]></title>
		<page_from>31</page_from>
		<page_to>36</page_to>
		<doi_number>10.1109/ICDMW.2009.13</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677221</url>
		<abstract>
			<par><![CDATA[In this paper, we consider the problem of frequent pattern mining in databases of temporal events with intervals. Since quantitative temporal information might play important roles in many application domains, it is critical to discover patterns to which numerical attributes are associated. To this end, we consider two kinds of temporal patterns with quantitative information on the durations and time differences of events, and propose corresponding algorithms by incorporating numerical clustering techniques into existing temporal pattern miners. The effectiveness of the proposed algorithms was assessed by using real world datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1821166</person_id>
				<author_profile_id><![CDATA[81453652781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fumiya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nakagaito]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821167</person_id>
				<author_profile_id><![CDATA[81100275524]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tomonobu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ozaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821168</person_id>
				<author_profile_id><![CDATA[81100104240]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Takenao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ohkawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677222</article_id>
		<sort_key>160</sort_key>
		<display_label>Pages</display_label>
		<pages>37-42</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Information Extraction for Clinical Data Mining]]></title>
		<subtitle><![CDATA[A Mammography Case Study]]></subtitle>
		<page_from>37</page_from>
		<page_to>42</page_to>
		<doi_number>10.1109/ICDMW.2009.63</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677222</url>
		<abstract>
			<par><![CDATA[Breast cancer is the leading cause of cancer mortality in women between the ages of 15 and 54. During mammography screening, radiologists use a strict lexicon (BI-RADS) to describe and report their findings. Mammography records are then stored in a well-defined database format (NMD). Lately, researchers have applied data mining and machine learning techniques to these databases. They successfully built breast cancer classifiers that can help in early detection of malignancy. However, the validity of these models depends on the quality of the underlying databases. Unfortunately, most databases suffer from inconsistencies, missing data, inter-observer variability and inappropriate term usage. In addition, many databases are not compliant with the NMD format and/or solely consist of text reports. BI-RADS feature extraction from free text and consistency checks between recorded predictive variables and text reports are crucial to addressing this problem. We describe a general scheme for concept information retrieval from free text given a lexicon, and present a BI-RADS features extraction algorithm for clinical data mining. It consists of a syntax analyzer, a concept finder and a negation detector. The syntax analyzer preprocesses the input into individual sentences. The concept finder uses a semantic grammar based on the BI-RADS lexicon and the experts&#8217; input. It parses sentences detecting BI-RADS concepts. Once a concept is located, a lexical scanner checks for negation. Our method can handle multiple latent concepts within the text, filtering out ultrasound concepts. On our dataset, our algorithm achieves 97.7% precision, 95.5% recall and an F1-score of 0.97. It outperforms manual feature extraction at the 5% statistical significance level.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830159</person_id>
				<author_profile_id><![CDATA[81453658723]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Houssam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nassif]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830160</person_id>
				<author_profile_id><![CDATA[81453611674]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ryan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Woods]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830161</person_id>
				<author_profile_id><![CDATA[81100495846]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Elizabeth]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Burnside]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830162</person_id>
				<author_profile_id><![CDATA[81453653982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Mehmet]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ayvaci]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830163</person_id>
				<author_profile_id><![CDATA[81100551445]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jude]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shavlik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830164</person_id>
				<author_profile_id><![CDATA[81405593471]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Page]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677223</article_id>
		<sort_key>170</sort_key>
		<display_label>Pages</display_label>
		<pages>43-50</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[A New Minimally Supervised Learning Method for Semantic Term Classification - Experimental Results on Classifying Ratable Aspects Discussed in Customer Reviews]]></title>
		<page_from>43</page_from>
		<page_to>50</page_to>
		<doi_number>10.1109/ICDMW.2009.58</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677223</url>
		<abstract>
			<par><![CDATA[We present Bautext, a new minimally supervised approach for automatically extracting ratable aspects from customer reviews and classifying them to some previously defined categories. Bautext requires a small amount of seed words as supervised data and uses a bootstrapping mechanism o progressively collect new member for each category. Learning new category members and the category-specific terms for each category at the same time is the unique and featured classification mechanism of Bautext. Category-specific terms are terms that play important roles for properly extracting new category members. Furthermore, we proposed to use an additional Trash category to filter non-purpose aspects, thus led to a significant improvement in precision score but could constrain the trade-off in decreasing recall score. Experimental results, conducted on a Japanese hotel review dataset, showed that Bautext outperforms the alternative techniques in all terms of precision, recall score and significantly in running time. And in the further comparison to Adaboost (as the state-of-the-art machine learning technique for semantic term classification task), we found that Adaboost require about 50% training data to deliver a similar performance as Bautext does with less than ten selective seed words for each category.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825666</person_id>
				<author_profile_id><![CDATA[81453608616]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thao]]></first_name>
				<middle_name><![CDATA[Pham Thanh]]></middle_name>
				<last_name><![CDATA[Nguyen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825667</person_id>
				<author_profile_id><![CDATA[81453608626]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Takahiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hayashi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825668</person_id>
				<author_profile_id><![CDATA[81100253292]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Rikio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Onai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825669</person_id>
				<author_profile_id><![CDATA[81453633386]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Yuhei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nishioka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825670</person_id>
				<author_profile_id><![CDATA[81453635741]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Takamasa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Takenaka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825671</person_id>
				<author_profile_id><![CDATA[81453632438]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Masaya]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mori]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677224</article_id>
		<sort_key>180</sort_key>
		<display_label>Pages</display_label>
		<pages>51-57</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[A Paradigm Shift]]></title>
		<subtitle><![CDATA[Combined Literature and Ontology-Driven Data Mining for Discovering Novel Relations in Biomedical Domain]]></subtitle>
		<page_from>51</page_from>
		<page_to>57</page_to>
		<doi_number>10.1109/ICDMW.2009.56</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677224</url>
		<abstract>
			<par><![CDATA[We introduce a novel domain-driven rule discovery and evaluation algorithm based on Swanson&#8217;s logical relation approach. Over more than a decade, rules have been mined from large biomedical datasets and been evaluated solely based on statistical properties of the rules or user-belief specifications. This approach faces tremendous challenges to determine novel, actionable and interesting rules. In this paper, we introduce a new paradigm in addressing rule interestingness problem using domain knowledge. We demonstrate that novel and interesting association rules can be discovered from large medical datasets based on its ability to infer previously unknown relations in biomedical domain. Our data mining algorithm shows that we can effectively achieve this task by incorporating biomedical domain knowledge by combining both literatures and ontology. We outline the conceptual-architectural framework for future implementation of this methodology.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830165</person_id>
				<author_profile_id><![CDATA[81453661657]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yakub]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sebastian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830166</person_id>
				<author_profile_id><![CDATA[81453645882]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[Chung Shiong]]></middle_name>
				<last_name><![CDATA[Loh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830167</person_id>
				<author_profile_id><![CDATA[81421600481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Patrick]]></first_name>
				<middle_name><![CDATA[Hang Hui]]></middle_name>
				<last_name><![CDATA[Then]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677231</article_id>
		<sort_key>190</sort_key>
		<display_label>Pages</display_label>
		<pages>58-63</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Weighted Frequent Subgraph Mining in Weighted Graph Databases]]></title>
		<page_from>58</page_from>
		<page_to>63</page_to>
		<doi_number>10.1109/ICDMW.2009.12</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677231</url>
		<abstract>
			<par><![CDATA[We focus on the problem of pattern discovery from externally and internally weighted labeled graphs because the target data can be modeled more naturally and in detail by using weighted graphs. For example, while external weight can be used for representing a degree of importance and reliability of a graph itself, internal weight reflects utility and significance of each component in a graph. Therefore, we can expect to realize more precise knowledge discovery by employing weighted graphs. From these backgrounds, in this paper, we discuss two pattern mining problems with external and internal weighted frequencies, and propose two algorithms to solve them efficiently.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822823</person_id>
				<author_profile_id><![CDATA[81453653988]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Masaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shinoda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822824</person_id>
				<author_profile_id><![CDATA[81100275524]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tomonobu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ozaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822825</person_id>
				<author_profile_id><![CDATA[81100104240]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Takenao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ohkawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677232</article_id>
		<sort_key>200</sort_key>
		<display_label>Pages</display_label>
		<pages>64-69</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Detecting and Interpreting Variable Interactions in Observational Ornithology Data]]></title>
		<page_from>64</page_from>
		<page_to>69</page_to>
		<doi_number>10.1109/ICDMW.2009.84</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677232</url>
		<abstract>
			<par><![CDATA[In this paper we demonstrate a practical approach to interaction detection on real data describing the abundance of different species of birds in the prairies east of the southern Rocky Mountains. This data is very noisy---predictive models built from it perform only slightly better than baseline. Previous approaches for interaction detection, including a recently proposed algorithm based on Additive Groves, often do not work well on such noisy data for a number of reasons. We describe the issues that appear when working with such data sets and suggest solutions to them. In the end, we discuss results of our analysis for several bird species.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831743</person_id>
				<author_profile_id><![CDATA[81317490095]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daria]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sorokina]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831744</person_id>
				<author_profile_id><![CDATA[81100100877]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rich]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Caruana]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831745</person_id>
				<author_profile_id><![CDATA[81100207912]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mirek]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Riedewald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831746</person_id>
				<author_profile_id><![CDATA[81317488414]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wesley]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hochachka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831747</person_id>
				<author_profile_id><![CDATA[81317489156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Steve]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kelling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677233</article_id>
		<sort_key>210</sort_key>
		<display_label>Pages</display_label>
		<pages>70-75</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[Tree-Based Approach to Missing Data Imputation]]></title>
		<page_from>70</page_from>
		<page_to>75</page_to>
		<doi_number>10.1109/ICDMW.2009.92</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677233</url>
		<abstract>
			<par><![CDATA[Missing data is a well-recognized issue in data mining, and imputation is one way to handle the problem. In this paper, we propose a novel tree-based imputation algorithm called &#8220;Imputation Tree&#8221; (ITree). It first studies the predictability of missingness using all observations by constructing a binary classification tree called &#8220;Missing Pattern Tree&#8221; (MPT). Then, missing values in each cluster or terminal node are estimated by a regression tree of observations at that node. We present empirical results using both synthetic and real data. Almost all experiments demonstrate that ITree is superior to other commonly used methods in estimating missing values. The algorithm not only produces an impressive accuracy, but also provides information on the nature of missingness.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1827179</person_id>
				<author_profile_id><![CDATA[81453652715]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peerapon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vateekul]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827180</person_id>
				<author_profile_id><![CDATA[81100487203]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kanoksri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sarinnapakorn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677234</article_id>
		<sort_key>220</sort_key>
		<display_label>Pages</display_label>
		<pages>76-81</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Theoretical Study of the Relationship between Diversity and Single-Class Measures for Class Imbalance Learning]]></title>
		<page_from>76</page_from>
		<page_to>81</page_to>
		<doi_number>10.1109/ICDMW.2009.29</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677234</url>
		<abstract>
			<par><![CDATA[This paper presents the theoretical research about the relationship between diversity of classification ensembles and single-class measures that are commonly used in class imbalance learning. Although there have been studies on diversity and its links to overall ensemble accuracy, little work has been done on the impact of diversity on single-class performance measures in class imbalance learning. The study of class imbalance learning is important, because many real-world problems, such as those in medical diagnosis, fraud detection, condition monitoring, etc., have imbalanced classes, where a minority class is usually more important and interesting than the majority class. In order to gain a deeper understanding of ensemble learning for imbalanced classes, this paper studies the impact of diversity on single-class performance measures theoretically and empirically. One of the main objectives of this paper is to find out if and when ensemble diversity can improve the classification performance on the important (minority) class.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1821211</person_id>
				<author_profile_id><![CDATA[81453620488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shuo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821212</person_id>
				<author_profile_id><![CDATA[81453642402]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677235</article_id>
		<sort_key>230</sort_key>
		<display_label>Pages</display_label>
		<pages>82-87</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Multi-sphere Support Vector Data Description for Outliers Detection on Multi-distribution Data]]></title>
		<page_from>82</page_from>
		<page_to>87</page_to>
		<doi_number>10.1109/ICDMW.2009.87</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677235</url>
		<abstract>
			<par><![CDATA[SVDD has been proved a powerful tool for outlier detection. However, in detecting outliers on multi-distribution data, namely there are distinctive distributions in the data, it is very challenging for SVDD to generate a hyper-sphere for distinguishing outliers from normal data. Even if such a hyper-sphere can be identified, its performance is usually not good enough. This paper proposes an multi-sphere SVDD approach, named MS-SVDD, for outlier detection on multi-distribution data. First, an adaptive sphere detection method is proposed to detect data distributions in the dataset. The data is partitioned in terms of the identified data distributions, and the corresponding SVDD classifiers are constructed separately. Substantial experiments on both artificial and real-world datasets have demonstrated that the proposed approach outperforms original SVDD.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831748</person_id>
				<author_profile_id><![CDATA[81472652199]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yanshan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xiao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831749</person_id>
				<author_profile_id><![CDATA[81328489008]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831750</person_id>
				<author_profile_id><![CDATA[81451595792]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Longbing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831751</person_id>
				<author_profile_id><![CDATA[81452596585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Xindong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831752</person_id>
				<author_profile_id><![CDATA[81453613242]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Chengqi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831753</person_id>
				<author_profile_id><![CDATA[81319492636]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Zhifeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831754</person_id>
				<author_profile_id><![CDATA[81453628987]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Fengzhao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831755</person_id>
				<author_profile_id><![CDATA[81453607835]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Jie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677236</article_id>
		<sort_key>240</sort_key>
		<display_label>Pages</display_label>
		<pages>88-93</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Integrating Knowledge in Search of Biologically Relevant Genes]]></title>
		<page_from>88</page_from>
		<page_to>93</page_to>
		<doi_number>10.1109/ICDMW.2009.21</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677236</url>
		<abstract>
			<par><![CDATA[Gene selection aims at detecting biologically relevant genes to assist biologists' research. The cDNA Microarray data used in gene selection is usually "wide". With more than ten thousand genes, but only less than a hundred of samples, many biologically irrelevant genes can gain their statistical relevance by sheer randomness. Moreover, even for genes that are biologically relevant, biologists often prefer the "trigger" to the "fire". Addressing these problems goes beyond what the cDNA Microarray can offer and necessitates the use of additional information. Recent developments in bioinformatics have made various knowledge sources available, such as the KEGG pathway repository and Gene Ontology database. Integrating different types of knowledge for gene selection could provide more information about genes and samples. In this work, we propose a novel framework to integrate different types of knowledge for identifying biologically relevant genes. The framework converts different types of external knowledge to its internal knowledge, which can be used to rank genes. Upon obtaining the ranking lists, it aggregates them via a probabilistic model and generates a final ranking list. Experimental results from our study on acute lymphoblastic leukemia demonstrate the novelty and efficacy of the proposed framework and show that using different types of knowledge together can help detect biologically relevant genes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831756</person_id>
				<author_profile_id><![CDATA[81453607745]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831757</person_id>
				<author_profile_id><![CDATA[81453613319]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shashvata]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sharma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831758</person_id>
				<author_profile_id><![CDATA[81100021279]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Nitin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Agarwal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831759</person_id>
				<author_profile_id><![CDATA[81367594306]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Huan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831760</person_id>
				<author_profile_id><![CDATA[81367596466]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jiangxin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831761</person_id>
				<author_profile_id><![CDATA[81367591471]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Yung]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677241</article_id>
		<sort_key>250</sort_key>
		<display_label>Pages</display_label>
		<pages>94-99</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[Towards Context Aware Food Sales Prediction]]></title>
		<page_from>94</page_from>
		<page_to>99</page_to>
		<doi_number>10.1109/ICDMW.2009.60</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677241</url>
		<abstract>
			<par><![CDATA[Sales prediction is a complex task because of a large number of factors affecting the demand. We present a context aware sales prediction approach, which selects the base predictor depending on the structural properties of the historical sales. In the experimental part we show that there exist product subsets on which, using this strategy, it is possible to outperform naive methods. We also show the dependencies between product categorization accuracies and sales prediction accuracies. A case study of a food wholesaler indicates that moving average prediction can be outperformed by intelligent methods, if proper categorization is in place, which appears to be a difficult task.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828756</person_id>
				<author_profile_id><![CDATA[81453632246]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Indre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[&#142;liobaite]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828757</person_id>
				<author_profile_id><![CDATA[81442593383]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jorn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bakker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828758</person_id>
				<author_profile_id><![CDATA[81100136358]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mykola]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pechenizkiy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677242</article_id>
		<sort_key>260</sort_key>
		<display_label>Pages</display_label>
		<pages>100-105</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Privacy Preserving Classification with Emerging Patterns]]></title>
		<page_from>100</page_from>
		<page_to>105</page_to>
		<doi_number>10.1109/ICDMW.2009.82</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677242</url>
		<abstract>
			<par><![CDATA[In privacy preserving classification, when data is stored in a centralized database and distorted using a randomization-based technique, we have information loss and reduced accuracy of classification. This paper presents a new approach to privacy preserving classification for centralized data based on Emerging Patterns. The presented solution gives higher accuracy of classification than a decision tree proposed in the literature, especially for high privacy. Effectiveness of this solution has been tested on real data sets and presented in this paper.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828759</person_id>
				<author_profile_id><![CDATA[81381597227]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Piotr]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Andruszkiewicz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677243</article_id>
		<sort_key>270</sort_key>
		<display_label>Pages</display_label>
		<pages>106-113</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Efficient Anonymizations with Enhanced Utility]]></title>
		<page_from>106</page_from>
		<page_to>113</page_to>
		<doi_number>10.1109/ICDMW.2009.15</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677243</url>
		<abstract>
			<par><![CDATA[The k-anonymization method is a commonly used privacy-preserving technique. Previous studies used various measures of utility that aim at enhancing the correlation between the original public data and the generalized public data. We, bearing in mind that a primary goal in releasing the anonymized database for data mining is to deduce methods of predicting the private data from the public data, propose a new information-theoretic measure that aims at enhancing the correlation between the generalized public data and the private data. Such a measure significantly enhances the utility of the released anonymized database for data mining. We then proceed to describe a new and highly efficient algorithm that is designed to achieve $k$-anonymity with high utility. That algorithm is based on a modified version of sequential clustering which is the method of choice in clustering, and it is independent of the underlying measure of utility.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825742</person_id>
				<author_profile_id><![CDATA[81100023307]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jacob]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goldberger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825743</person_id>
				<author_profile_id><![CDATA[81100082572]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tamir]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tassa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677244</article_id>
		<sort_key>280</sort_key>
		<display_label>Pages</display_label>
		<pages>114-121</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[A Practical Differentially Private Random Decision Tree Classifier]]></title>
		<page_from>114</page_from>
		<page_to>121</page_to>
		<doi_number>10.1109/ICDMW.2009.93</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677244</url>
		<abstract>
			<par><![CDATA[In this paper, we study the problem of constructing private classifiers using decision trees, within the framework of differential privacy. We first construct privacy-preserving ID3 decision trees using differentially private sum queries. Our experiments show that for many data sets a reasonable privacy guarantee can only be obtained via this method at a steep cost of accuracy in predictions. We then present a differentially private decision tree ensemble algorithm using the random decision tree approach. We demonstrate experimentally that our approach yields good prediction accuracy even when the size of the datasets is small. We also present a differentially private algorithm for the situation in which new data is periodically appended to an existing database. Our experiments show that our differentially private random decision tree classifier handles data updates in a way that maintains the same level of privacy guarantee.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1821260</person_id>
				<author_profile_id><![CDATA[81100208712]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Geetha]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jagannathan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821261</person_id>
				<author_profile_id><![CDATA[81100451415]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Krishnan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pillaipakkamnatt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821262</person_id>
				<author_profile_id><![CDATA[81100659919]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Rebecca]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Wright]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677245</article_id>
		<sort_key>290</sort_key>
		<display_label>Pages</display_label>
		<pages>122-129</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[A Differentially Private Graph Estimator]]></title>
		<page_from>122</page_from>
		<page_to>129</page_to>
		<doi_number>10.1109/ICDMW.2009.96</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677245</url>
		<abstract>
			<par><![CDATA[We consider the problem of making graph databases such as social network structures available to researchers for knowledge discovery while providing privacy to the participating entities. We show that for a specific parametric graph model, the Kronecker graph model, one can construct an estimator of the true parameter in a way that both satisfies the rigorous requirements of differential privacy and is asymptotically efficient in the statistical sense. The estimator, which may then be published, defines a probability distribution on graphs. Sampling such a distribution yields a synthetic graph that mimics important properties of the original sensitive graph and, consequently, could be useful for knowledge discovery.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825744</person_id>
				<author_profile_id><![CDATA[81453662303]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Darakhshan]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Mir]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825745</person_id>
				<author_profile_id><![CDATA[81100659919]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rebecca]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Wright]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677246</article_id>
		<sort_key>300</sort_key>
		<display_label>Pages</display_label>
		<pages>130-137</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[An Attack on the Privacy of Sanitized Data that Fuses the Outputs of Multiple Data Miners]]></title>
		<page_from>130</page_from>
		<page_to>137</page_to>
		<doi_number>10.1109/ICDMW.2009.28</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677246</url>
		<abstract>
			<par><![CDATA[Data sanitization has been used to restrict re-identification of individuals and disclosure of sensitive information from published data. We propose an attack on the privacy of the published sanitized data that simply fuses outputs of multiple data miners that are applied to the sanitized data. That attack is practical and does not require any background or additional information. We use a number of experiments to show scenarios where an adversary can combine outputs of multiple miners using a simple fusion strategy to increase their success chance of breaching privacy of individuals whose data is stored in the database. The fusion attack provides a powerful method of breaching privacy in the form of partial disclosure, for both anonymized and perturbed data. It also provides an effective way of approximating predictions of the best miner (a miner that provides the best results among all considered miners) when this miner cannot be determined.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1827216</person_id>
				<author_profile_id><![CDATA[81100051790]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sramka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827217</person_id>
				<author_profile_id><![CDATA[81309493710]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Reihaneh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Safavi-Naini]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827218</person_id>
				<author_profile_id><![CDATA[81100597356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[J&#246;rg]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Denzinger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677247</article_id>
		<sort_key>310</sort_key>
		<display_label>Pages</display_label>
		<pages>138-143</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[Differential Privacy for Clinical Trial Data]]></title>
		<subtitle><![CDATA[Preliminary Evaluations]]></subtitle>
		<page_from>138</page_from>
		<page_to>143</page_to>
		<doi_number>10.1109/ICDMW.2009.52</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677247</url>
		<abstract>
			<par><![CDATA[The concept of differential privacy as a rigorous definition of privacy has emerged from the cryptographic community. However, further careful evaluation is needed before we can apply these theoretical results to privacy preservation in everyday data mining and statistical analysis. In this paper we demonstrate how to integrate a differential privacy framework with the classical statistical hypothesis testing in the domain of clinical trials where personal information is sensitive. We develop concrete methodology that researchers can use. We derive rules for the sample size adjustment whereby both statistical efficiency and differential privacy can be achieved for the specific tests for binomial random variables and in contingency tables.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1821263</person_id>
				<author_profile_id><![CDATA[81453614089]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Duy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821264</person_id>
				<author_profile_id><![CDATA[81100494824]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Aleksandra]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Slavkovic]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677248</article_id>
		<sort_key>320</sort_key>
		<display_label>Pages</display_label>
		<pages>144-151</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Video2Text]]></title>
		<subtitle><![CDATA[Learning to Annotate Video Content]]></subtitle>
		<page_from>144</page_from>
		<page_to>151</page_to>
		<doi_number>10.1109/ICDMW.2009.79</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677248</url>
		<abstract>
			<par><![CDATA[This paper discusses a new method for automatic discovery and organization of descriptive concepts (labels) within large real-world corpora of user-uploaded multimedia, such as YouTube. com. Conversely, it also provides validation of existing labels, if any. While training, our method does not assume any explicit manual annotation other than the weak labels already available in the form of video title, description, and tags. Prior work related to such auto-annotation assumed that a vocabulary of labels of interest (e. g., indoor, outdoor, city, landscape) is specified a priori. In contrast, the proposed method begins with an empty vocabulary. It analyzes audiovisual features of 25 million YouTube. com videos -- nearly 150 years of video data -- effectively searching for consistent correlation between these features and text metadata. It autonomously extends the label vocabulary as and when it discovers concepts it can reliably identify, eventually leading to a vocabulary with thousands of labels and growing. We believe that this work significantly extends the state of the art in multimedia data mining, discovery, and organization based on the technical merit of the proposed ideas as well as the enormous scale of the mining exercise in a very challenging, unconstrained, noisy domain.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830291</person_id>
				<author_profile_id><![CDATA[81100648205]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hrishikesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aradhye]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830292</person_id>
				<author_profile_id><![CDATA[81339532669]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Toderici]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830293</person_id>
				<author_profile_id><![CDATA[81309496914]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jay]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yagnik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677249</article_id>
		<sort_key>330</sort_key>
		<display_label>Pages</display_label>
		<pages>152-157</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[Automatic Image Annotations by Mining Web Image Data]]></title>
		<page_from>152</page_from>
		<page_to>157</page_to>
		<doi_number>10.1109/ICDMW.2009.19</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677249</url>
		<abstract>
			<par><![CDATA[The exponential growth of Web images has created a compelling need for innovative methods to retrieve and manage them. Automatic image annotation is an effective way for resolving this problem. In this paper, we propose a novel system that automatically annotates images by semantic corpus which is constructed by mining Web image data. It includes three parts: 1) Constructing the semantic annotation corpus by mining 413,006 Web images and their surrounding text collected from several image search engine; 2) Searching for visually similar images in this semantic annotation corpus and extracting candidate annotation terms; 3) Ranking candidate annotation terms to filter out noisy ones. Our system is evaluated using two benchmark image datasets. Experimental results indicate that this approach is effective.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830294</person_id>
				<author_profile_id><![CDATA[81100136158]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Guiguang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ding]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830295</person_id>
				<author_profile_id><![CDATA[81408602894]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jianmin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830296</person_id>
				<author_profile_id><![CDATA[81453606411]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Na]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830297</person_id>
				<author_profile_id><![CDATA[81453606625]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Lu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677250</article_id>
		<sort_key>340</sort_key>
		<display_label>Pages</display_label>
		<pages>158-163</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[A Study of Language Model for Image Retrieval]]></title>
		<page_from>158</page_from>
		<page_to>163</page_to>
		<doi_number>10.1109/ICDMW.2009.114</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677250</url>
		<abstract>
			<par><![CDATA[Recently, various language model approaches have been proposed in the information retrieval realm, with their promising performances in general document and Web page retrieval applications. Based on these achievements, in this paper, we investigate and discuss whether language model approaches can be adapted to content based image retrieval (CBIR), based on the &#8220;bag of visual words&#8221; image representation. A critical element of language model estimation is smoothing, which adjusts the maximum likelihood estimation to overcome the data sparseness problem. Therefore, we perform extensive studies over different smoothing methods, strategies, and parameters, by showing their impacts to the retrieval performances. Experiments are performed over two popular image retrieval databases, together with some insightful conclusions to facilitate the adaptation of language model approaches to CBIR.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[content based image retrieval, language model]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825795</person_id>
				<author_profile_id><![CDATA[81384607903]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Geng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825796</person_id>
				<author_profile_id><![CDATA[81335499805]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Linjun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825797</person_id>
				<author_profile_id><![CDATA[81384602600]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677251</article_id>
		<sort_key>350</sort_key>
		<display_label>Pages</display_label>
		<pages>164-169</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[MSRA-MM 2.0]]></title>
		<subtitle><![CDATA[A Large-Scale Web Multimedia Dataset]]></subtitle>
		<page_from>164</page_from>
		<page_to>169</page_to>
		<doi_number>10.1109/ICDMW.2009.46</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677251</url>
		<abstract>
			<par><![CDATA[In this paper, we introduce the second version of Microsoft Research Asia Multimedia (MSRA-MM), a dataset that aims to facilitate research in multimedia information retrieval and related areas. The images and videos in the dataset are collected from a commercial search engine with more than 1000 queries. It contains about 1 million images and 20,000 videos. We also provide the surrounding texts that are obtained from more than 1 million web pages. The images and videos have been comprehensively annotated, including their relevance levels to corresponding queries, semantic concepts of images, and category and quality information of videos. We define six standard tasks on the dataset: (1) image search reranking; (2) image annotation; (3) query-by-example image search; (4) video search reranking; (5) video categorization; and (6) video quality assessment.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1824331</person_id>
				<author_profile_id><![CDATA[81453646736]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1824332</person_id>
				<author_profile_id><![CDATA[81351595589]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Meng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1824333</person_id>
				<author_profile_id><![CDATA[81453612511]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Xian-Sheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hua]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677252</article_id>
		<sort_key>360</sort_key>
		<display_label>Pages</display_label>
		<pages>170-175</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Localized Content Based Image Retrieval with Self-Taught Multiple Instance Learning]]></title>
		<page_from>170</page_from>
		<page_to>175</page_to>
		<doi_number>10.1109/ICDMW.2009.105</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677252</url>
		<abstract>
			<par><![CDATA[There are many scenarios in which multi-instance learning problems may be difficult to solve because of a lack of correctly labeled examples for algorithm training. Labeled examples may be difficult or expensive to obtain because human effort is often needed to produce labels and because there may be limitations on the ability to collect large samples for training from a homogeneous population. In this paper, we present a technique called self-taught multiple-instance learning (STMIL) that deals with learning from a limited number of ambiguously labeled examples. STMIL uses a sparse representation for examples belonging to different classes in terms of a shared dictionary derived from the unlabeled data. This sparse representation can be optimized under the multiple instance setting to both construct high-level features and unite the data distribution. We present an optimization procedure for STMIL along with experiments on localized content-based image retrieval. Our experimental results suggest that, though it learns from a small number of labeled examples, STMIL is superior to standard algorithms in terms of computational efficiency and is at least competitive in terms of accuracy.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828796</person_id>
				<author_profile_id><![CDATA[81453634463]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Qifeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Qiao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828797</person_id>
				<author_profile_id><![CDATA[81100642341]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Peter]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Beling]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677254</article_id>
		<sort_key>370</sort_key>
		<display_label>Pages</display_label>
		<pages>176-183</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[Mining Event Definitions from Queries for Video Retrieval on the Internet]]></title>
		<page_from>176</page_from>
		<page_to>183</page_to>
		<doi_number>10.1109/ICDMW.2009.70</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677254</url>
		<abstract>
			<par><![CDATA[Since the amount of videos on the internet is huge and continuously increases, it is impossible to pre-index events in these videos. Thus, we extract the definition of each event from example videos provided as a query. But, different from positive examples, it is impractical to manually provide a variety of negative examples. Hence, we use "partially supervised learning'' where the definition of the event is extracted from positive and unlabeled examples. Specifically, negative examples are firstly selected based on similarities between positive and unlabeled examples. Here, to appropriately calculate similarities, we use a &#8216;&#8216;video mask'' which represent relevant features based on a typical layout of objects in the event. Then, we extract the event definition from positive and negative examples. In this process, we consider that shots of the event contain significantly different features due to various camera techniques and object movements. In order to cover such a large variation of features, we use "rough set theory'' to extract multiple definitions of the event. Experimental results on TRECVID 2008 video collection validate the effectiveness of our method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828824</person_id>
				<author_profile_id><![CDATA[81309494647]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kimiaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shirahama]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828825</person_id>
				<author_profile_id><![CDATA[81444606786]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chieri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sugihara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828826</person_id>
				<author_profile_id><![CDATA[81453605401]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kana]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Matsumura]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828827</person_id>
				<author_profile_id><![CDATA[81444598170]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Yuta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Matsuoka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828828</person_id>
				<author_profile_id><![CDATA[81100128268]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Kuniaki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Uehara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677255</article_id>
		<sort_key>380</sort_key>
		<display_label>Pages</display_label>
		<pages>184-189</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Cross-Domain Web Image Annotation]]></title>
		<page_from>184</page_from>
		<page_to>189</page_to>
		<doi_number>10.1109/ICDMW.2009.47</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677255</url>
		<abstract>
			<par><![CDATA[In recent years, cross-domain learning algorithms have attracted much attention to solve labeled data insufficient problem. However, these cross-domain learning algorithms cannot be applied for subspace learning, which plays a key role in multimedia, e. g., web image annotation. This paper envisions the cross-domain discriminative subspace learning and provides an effective solution to cross-domain subspace learning. In particular, we propose the cross-domain discriminative Hessian Eigenmaps or CDHE for short. CDHE connects the training and the testing samples by minimizing the quadratic distance between the distribution of the training samples and that of the testing samples. Therefore, a common subspace for data representation can be preserved. We basically expect the discriminative information to separate the concepts in the training set can be shared to separate the concepts in the testing set as well and thus we have a chance to address above cross-domain problem duly. The margin maximization is duly adopted in CDHE so the discriminative information for separating different classes can be well preserved. Finally, CDHE encodes the local geometry of each training class in the local tangent space which is locally isometric to the data manifold and thus can locally preserve the intra-class local geometry. Experimental evidence on real world image datasets demonstrates the effectiveness of CDHE for cross-domain web image annotation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831856</person_id>
				<author_profile_id><![CDATA[81453617072]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Si]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Si]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831857</person_id>
				<author_profile_id><![CDATA[81100159571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dacheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831858</person_id>
				<author_profile_id><![CDATA[81100177812]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kwok-Ping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677253</article_id>
		<sort_key>390</sort_key>
		<display_label>Pages</display_label>
		<pages>190-195</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[TubeTagger - YouTube-based Concept Detection]]></title>
		<page_from>190</page_from>
		<page_to>195</page_to>
		<doi_number>10.1109/ICDMW.2009.41</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677253</url>
		<abstract>
			<par><![CDATA[We present TubeTagger, a concept-based video retrieval system that exploits web video as an information source. The system performs a visual learning on YouTube clips (i. e., it trains detectors for semantic concepts like "soccer" or "windmill"), and a semantic learning on the associated tags (i.e., relations between concepts like "swimming" and "water" are discovered). This way, a text-based video search free of manual indexing is realized. We present a quantitative study on web-based concept detection comparing several features and statistical models on a large-scale dataset of YouTube content. Beyond this, we report several key findings related to concept learning from YouTube and its generalization to different domains, and illustrate certain characteristics of YouTube-learned concepts, like focus of interest and redundancy. To get a hands-on impression of web-based concept detection, we invite researchers and practitioners to test our web demo.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822895</person_id>
				<author_profile_id><![CDATA[81309504243]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Adrian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ulges]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822896</person_id>
				<author_profile_id><![CDATA[81444594536]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Markus]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Koch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822897</person_id>
				<author_profile_id><![CDATA[81384605810]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Damian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Borth]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822898</person_id>
				<author_profile_id><![CDATA[81100197006]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Breuel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677256</article_id>
		<sort_key>400</sort_key>
		<display_label>Pages</display_label>
		<pages>196-201</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[Semantic Linking between Video Ads and Web Services with Progressive Search]]></title>
		<page_from>196</page_from>
		<page_to>201</page_to>
		<doi_number>10.1109/ICDMW.2009.43</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677256</url>
		<abstract>
			<par><![CDATA[With the proliferation of online media services, ad video has become an important way to promote various products, services and ideas. Research efforts have been devoted to the contextual advertising whereas comprehensive recommendation of video ads is less exploited. In this paper, we propose to establish a semantic linking between video ads and relevant product/service online in a cross-media manner. First, we extract a representative key frame from the ad video and then conduct a three-step progressive search (i. e., visual search, tag aggregation and textual re-search) to link video ads with relevant Web service. We search visually similar product images, rank the context textual information by tags aggregation, and refine the results by textual re-search. Finally, we collect relevant products for user recommendation. Experiments on some popular E-commerce websites like eBay and Amazon have demonstrated the attractiveness of the semantic linking.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828829</person_id>
				<author_profile_id><![CDATA[81453621855]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828830</person_id>
				<author_profile_id><![CDATA[81384611314]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jinqiao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828831</person_id>
				<author_profile_id><![CDATA[81413604401]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828832</person_id>
				<author_profile_id><![CDATA[81409592820]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ling-Yu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Duan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828833</person_id>
				<author_profile_id><![CDATA[81381601864]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Hanqing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677257</article_id>
		<sort_key>410</sort_key>
		<display_label>Pages</display_label>
		<pages>202-207</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Mining Personal Image Collection for Social Group Suggestion]]></title>
		<page_from>202</page_from>
		<page_to>207</page_to>
		<doi_number>10.1109/ICDMW.2009.77</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677257</url>
		<abstract>
			<par><![CDATA[Popular photo-sharing sites have attracted millions of people and helped construct massive social networks in cyberspace. Different from traditional social relationship, users actively interact within groups where common interests are shared on certain types of events or topics captured by photos and videos. Contributing images to a group would greatly promote the interactions between users and expand their social networks. In this work, we intend to produce accurate predictions of suitable photo-sharing groups from a user's images by mining images both on the Web and in the user&#8217;s personal collection. To this end, we designed a new approach to cluster popular groups into categories by analyzing the similarity of groups via SimRank. Both visual content and its annotations are integrated to understand the events or topics depicted in the images. Experiments on real user images demonstrate the feasibility of the proposed approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825837</person_id>
				<author_profile_id><![CDATA[81100472949]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825838</person_id>
				<author_profile_id><![CDATA[81436594994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825839</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825840</person_id>
				<author_profile_id><![CDATA[81100416852]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jiebo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Luo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677258</article_id>
		<sort_key>420</sort_key>
		<display_label>Pages</display_label>
		<pages>208-213</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[Induction of Mean Output Prediction Trees from Continuous Temporal Meteorological Data]]></title>
		<page_from>208</page_from>
		<page_to>213</page_to>
		<doi_number>10.1109/ICDMW.2009.30</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677258</url>
		<abstract>
			<par><![CDATA[In this paper, we present a novel method for fast data-driven construction of regression trees from temporal datasets including continuous data streams. The proposed Mean Output Prediction Tree (MOPT) algorithm transforms continuous temporal data into two statistical moments according to a user-specified time resolution and builds a regression tree for estimating the prediction interval of the output (dependent) variable. Results on two benchmark data sets show that the MOPT algorithm produces more accurate and easily interpretable prediction models than other state-of-the-art regression tree methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822917</person_id>
				<author_profile_id><![CDATA[81392618828]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dima]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822918</person_id>
				<author_profile_id><![CDATA[81100232034]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Last]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822919</person_id>
				<author_profile_id><![CDATA[81453626005]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Roni]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Neuman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822920</person_id>
				<author_profile_id><![CDATA[81453637608]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Avi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sharon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677145</article_id>
		<sort_key>430</sort_key>
		<display_label>Pages</display_label>
		<pages>214-216</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[Data Mining Geophysical Content from Satellites and Global Climate Models]]></title>
		<page_from>214</page_from>
		<page_to>216</page_to>
		<doi_number>10.1109/ICDMW.2009.109</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677145</url>
		<abstract>
			<par><![CDATA[We present an example of a simulated global climate model that is intended to stream real-time NASA data into the geophysical and climate science and assessment community over the next 5-10 years. It is known that the 3-D atmospheric wave structures and transport physics interact with spatially and time varying surface sources and sinks of CO2, and that this communication between surface and atmosphere results in an exceedingly complicated evolution of atmospheric CO2 in time and space. Data mining techniques may be applied to the further development this 4-D model by incorporating satellite-generated data sets for hundreds of geophysical climate variables into existing simulation structures. These data sets are of order 100&#8217;s of Terabytes. Data mining will allow the determination of the fluxes of atmospheric CO2. Data mining and knowledge acquisition contribute to the accurate determination of the sources and sinks of atmospheric CO2, facilitating among other scientific discoveries, global treaty verification.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831298</person_id>
				<author_profile_id><![CDATA[81406591947]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Erickson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831299</person_id>
				<author_profile_id><![CDATA[81453618729]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jamison]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Daniel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831300</person_id>
				<author_profile_id><![CDATA[81453610848]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Melissa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Allen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831301</person_id>
				<author_profile_id><![CDATA[81100305556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Auroop]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ganguly]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831302</person_id>
				<author_profile_id><![CDATA[81100537792]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Forrest]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hoffman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831303</person_id>
				<author_profile_id><![CDATA[81453659994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pawson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831304</person_id>
				<author_profile_id><![CDATA[81453642762]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Lesley]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ott]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831305</person_id>
				<author_profile_id><![CDATA[81453660272]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Neilson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677144</article_id>
		<sort_key>440</sort_key>
		<display_label>Pages</display_label>
		<pages>217-222</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[Understanding Climate Change Patterns with Multivariate Geovisualization]]></title>
		<page_from>217</page_from>
		<page_to>222</page_to>
		<doi_number>10.1109/ICDMW.2009.91</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677144</url>
		<abstract>
			<par><![CDATA[Climate change has been a challenging and urgent research problem for many related research fields. Climate change trends and patterns are complex, which may involve many factors and vary across space and time. However, most existing visualization and mapping approaches for climate data analysis are limited to one variable or one perspective at a time. For example, it is common to map the surface temperature anomaly at different locations or plot trends of time series. Although such approaches are useful in presenting information and knowledge, they have limited capability to support discovery and understanding of unknown complex patterns from data that span across multiple dimensions. This paper introduces the application of a multivariate geovisualization approach to explore and understand complex climate change patterns across multiple perspectives, including the geographic space, time, and multiple variables.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822166</person_id>
				<author_profile_id><![CDATA[81477641357]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822167</person_id>
				<author_profile_id><![CDATA[81453608651]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Diansheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Guo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677146</article_id>
		<sort_key>450</sort_key>
		<display_label>Pages</display_label>
		<pages>223-230</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[Motivating Complex Dependence Structures in Data Mining]]></title>
		<subtitle><![CDATA[A Case Study with Anomaly Detection in Climate]]></subtitle>
		<page_from>223</page_from>
		<page_to>230</page_to>
		<doi_number>10.1109/ICDMW.2009.37</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677146</url>
		<abstract>
			<par><![CDATA[While data mining aims to identify hidden knowledge from massive and high dimensional datasets, the importance of dependence structure among time, space, and between different variables is less emphasized. Analogous to the use of probability density functions in modeling individual variables, it is now possible to characterize the complete dependence space mathematically through the application of copulas. By adopting copulas, the multivariate joint probability distribution can be constructed without constraint to specific types of marginal distributions. Some common assumptions, like normality and independence between variables, can also be relieved. This study provides fundamental introduction and illustration of dependence structure, aimed at the potential applicability of copulas in general data mining. The case study in hydro-climatic anomaly detection shows that the frequency of multivariate anomalies is affected by the dependence level between variables. The appropriate multivariate thresholds can be determined through a copula-based approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822351</person_id>
				<author_profile_id><![CDATA[81447592589]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shih-Chieh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822352</person_id>
				<author_profile_id><![CDATA[81100305556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Auroop]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Ganguly]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822353</person_id>
				<author_profile_id><![CDATA[81392619081]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Karsten]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Steinhaeuser]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677147</article_id>
		<sort_key>460</sort_key>
		<display_label>Pages</display_label>
		<pages>231-232</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[A Distributed Computing Infrastructure for the Evaluation of Climate Models Using NASA Observational Data]]></title>
		<page_from>231</page_from>
		<page_to>232</page_to>
		<doi_number>10.1109/ICDMW.2009.23</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677147</url>
		<abstract>
			<par><![CDATA[We describe and motivate an emerging distributed data analysis environment for the empirical evaluation of climate models. This work has several components, including: model scoring, initialization and parameterization, all of which require massive amounts of NASA observational data. Though the effort is in its nascence, there has been recent success in partnering with the DOE Earth System Grid to unify data from NASA&#8217;s AIRS mission and model outputs available from the Program for Climate Model Diagnosis and Intercomparison (PCMDI).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1826744</person_id>
				<author_profile_id><![CDATA[81100396050]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Mattmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826745</person_id>
				<author_profile_id><![CDATA[81321490391]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Crichton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826746</person_id>
				<author_profile_id><![CDATA[81324488018]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Amy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Braverman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826747</person_id>
				<author_profile_id><![CDATA[81453608570]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dean]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826748</person_id>
				<author_profile_id><![CDATA[81453651325]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gunson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826749</person_id>
				<author_profile_id><![CDATA[81314486443]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Woollard]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826750</person_id>
				<author_profile_id><![CDATA[81407594121]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Sean]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kelly]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826751</person_id>
				<author_profile_id><![CDATA[81453659073]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cayanan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677148</article_id>
		<sort_key>470</sort_key>
		<display_label>Pages</display_label>
		<pages>233-240</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>44</seq_no>
		<title><![CDATA[Ensemble-Vis]]></title>
		<subtitle><![CDATA[A Framework for the Statistical Visualization of Ensemble Data]]></subtitle>
		<page_from>233</page_from>
		<page_to>240</page_to>
		<doi_number>10.1109/ICDMW.2009.55</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677148</url>
		<abstract>
			<par><![CDATA[Scientists increasingly use ensemble data sets to explore relationships present in dynamic systems. Ensemble data sets combine spatio-temporal simulation results generated using multiple numerical models, sampled input conditions and perturbed parameters. While ensemble data sets are a powerful tool for mitigating uncertainty, they pose significant visualization and analysis challenges due to their complexity. In this article, we present Ensemble-Vis, a framework consisting of a collection of overview and statistical displays linked through a high level of interactivity. Ensemble-Vis allows scientists to gain key scientific insight into the distribution of simulation results as well as the uncertainty associated with the scientific data. In contrast to methods that present large amounts of diverse information in a single display, we argue that combining multiple linked displays yields a clearer presentation of the data and facilitates a greater level of visual data analysis. We demonstrate our framework using driving problems from climate modeling and meteorology and discuss generalizations to other fields.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822354</person_id>
				<author_profile_id><![CDATA[81453621128]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kristin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Potter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822355</person_id>
				<author_profile_id><![CDATA[81536778656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wilson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822356</person_id>
				<author_profile_id><![CDATA[81100310011]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Peer-Timo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bremer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822357</person_id>
				<author_profile_id><![CDATA[81100005865]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dean]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822358</person_id>
				<author_profile_id><![CDATA[81453651699]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Doutriaux]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822359</person_id>
				<author_profile_id><![CDATA[81408602369]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Valerio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pascucci]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822360</person_id>
				<author_profile_id><![CDATA[81453614215]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677149</article_id>
		<sort_key>480</sort_key>
		<display_label>Pages</display_label>
		<pages>241-247</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>45</seq_no>
		<title><![CDATA[Uncertainty Quantification in the Presence of Limited Climate Model Data with Discontinuities]]></title>
		<page_from>241</page_from>
		<page_to>247</page_to>
		<doi_number>10.1109/ICDMW.2009.111</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677149</url>
		<abstract>
			<par><![CDATA[Uncertainty quantification in climate models is challenged by the sparsity of the available climate data due to the high computational cost of the model runs. Another feature that prevents classical uncertainty analyses from being easily applicable is the bifurcative behavior in the climate data with respect to certain parameters. A typical example is the Meridional Overturning Circulation in the Atlantic Ocean. The maximum overturning stream function exhibits discontinuity across a curve in the space of two uncertain parameters, namely climate sensitivity and CO2 forcing. We develop a methodology that performs uncertainty quantification in this context in the presence of limited data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[uncertainty quantification, climate models, polynomial chaos, discontinuity detection, Bayesian inference, Rosenblatt transformation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1826752</person_id>
				<author_profile_id><![CDATA[81453662198]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Khachik]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sargsyan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826753</person_id>
				<author_profile_id><![CDATA[81453659793]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Cosmin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Safta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826754</person_id>
				<author_profile_id><![CDATA[81100603514]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Debusschere]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826755</person_id>
				<author_profile_id><![CDATA[81100278209]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Habib]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Najm]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677150</article_id>
		<sort_key>490</sort_key>
		<display_label>Pages</display_label>
		<pages>248-253</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>46</seq_no>
		<title><![CDATA[Change Detection in Climate Data over the Iberian Peninsula]]></title>
		<page_from>248</page_from>
		<page_to>253</page_to>
		<doi_number>10.1109/ICDMW.2009.27</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677150</url>
		<abstract>
			<par><![CDATA[This paper addresses the space-time change detection problem in climate data over the Iberian Peninsula using a 50 years dataset. The data were analyzed concerning the temporal and geographical information, using the following methodology: information about space-time drifts in climate data was obtained by applying a change detection algorithm on all the temporal data available for each physical location considered in this study; the performance and the robustness of this algorithm were then assessed by the McNemar nonparametric statistical test on cluster structures; geographical correlations were inferred using visualization tools and graphical representations of data. Most of the space-temporal drifts detected by the algorithm were confirmed by the results of the McNemar test and are in accordance with visual and graphical representations, supporting the advantage of using inter-disciplinary methods. This analysis also shows that there are locations which do not reveal any change along all the observed years.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831306</person_id>
				<author_profile_id><![CDATA[81436592540]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Raquel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sebasti&#227;o]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831307</person_id>
				<author_profile_id><![CDATA[81363597439]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pedro]]></first_name>
				<middle_name><![CDATA[Pereira]]></middle_name>
				<last_name><![CDATA[Rodrigues]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831308</person_id>
				<author_profile_id><![CDATA[81100028845]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jo&#227;o]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gama]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677151</article_id>
		<sort_key>500</sort_key>
		<display_label>Pages</display_label>
		<pages>254-261</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>47</seq_no>
		<title><![CDATA[The Flexible Climate Data Analysis Tools (CDAT) for Multi-model Climate Simulation Data]]></title>
		<page_from>254</page_from>
		<page_to>261</page_to>
		<doi_number>10.1109/ICDMW.2009.64</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677151</url>
		<abstract>
			<par><![CDATA[Being able to incorporate, inspect, and analyze data with newly developed technologies, diagnostics, and visualizations in an easy and flexible way has been a longstanding challenge for scientists interested in understanding the intrinsic and extrinsic empirical assessment of multi-model climate output. To improve research ability and productivity, these technologies and tool must be made easily available to help scientists understand and solve complex scientific climate changes. To increase productivity and ease the challenges of incorporating new tools into the hands of scientists, the Program for Climate Model Diagnosis and Intercomparison (PCMDI) developed the Climate Data Analysis Tools (CDAT). CDAT is an application for developing and bringing together disparate software tools for the discovery, examination, and intercomparison of coupled multi-model climate data. By collaborating with top climate institutions, computational organizations, and other science communities, the CDAT community of developers is leading the way to provide proven data management, analysis, visualization, and diagnostics capabilities to scientists. This communitywide effort has developed CDAT into a powerful and insightful application for knowledge discovery of observed and simulation climate data. As an analysis engine in the Earth System Grid (ESG) data infrastructure, CDAT is making it possible to remotely access and analyze climate data located at multiple sites around the world.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831332</person_id>
				<author_profile_id><![CDATA[81100005865]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dean]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831333</person_id>
				<author_profile_id><![CDATA[81453651699]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Doutriaux]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831334</person_id>
				<author_profile_id><![CDATA[81430655652]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Drach]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831335</person_id>
				<author_profile_id><![CDATA[81453615884]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Renata]]></first_name>
				<middle_name><![CDATA[B.]]></middle_name>
				<last_name><![CDATA[McCoy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677152</article_id>
		<sort_key>510</sort_key>
		<display_label>Pages</display_label>
		<pages>262-269</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>48</seq_no>
		<title><![CDATA[Link Prediction on Evolving Data Using Matrix and Tensor Factorizations]]></title>
		<page_from>262</page_from>
		<page_to>269</page_to>
		<doi_number>10.1109/ICDMW.2009.54</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677152</url>
		<abstract>
			<par><![CDATA[The data in many disciplines such as social networks, web analysis, etc. is link-based, and the link structure can be exploited for many different data mining tasks. In this paper, we consider the problem of temporal link prediction: Given link data for time periods 1 through T, can we predict the links in time period T +1? Specifically, we look at bipartite graphs changing over time and consider matrix- and tensor-based methods for predicting links. We present a weight-based method for collapsing multi-year data into a single matrix. We show how the well-known Katz method for link prediction can be extended to bipartite graphs and, moreover, approximated in a scalable way using a truncated singular value decomposition. Using a CANDECOMP/PARAFAC tensor decomposition of the data, we illustrate the usefulness of exploiting the natural three-dimensional structure of temporal link data. Through several numerical experiments, we demonstrate that both matrix and tensor-based techniques are effective for temporal link prediction despite the inherent difficulty of the problem.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1829717</person_id>
				<author_profile_id><![CDATA[81318497714]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Evrim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Acar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829718</person_id>
				<author_profile_id><![CDATA[81100093244]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Dunlavy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829719</person_id>
				<author_profile_id><![CDATA[81100225962]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tamara]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Kolda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677153</article_id>
		<sort_key>520</sort_key>
		<display_label>Pages</display_label>
		<pages>270-275</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>49</seq_no>
		<title><![CDATA[SIMPLE]]></title>
		<subtitle><![CDATA[A Strategic Information Mining Platform for Licensing and Execution]]></subtitle>
		<page_from>270</page_from>
		<page_to>275</page_to>
		<doi_number>10.1109/ICDMW.2009.36</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677153</url>
		<abstract>
			<par><![CDATA[Intellectual Properties (IP), such as patents and trademarks, are one of the most critical assets in today&#8217;s enterprises and research organizations. They represent the core innovation and differentiators of an organization. When leveraged effectively, they not only protect a business from its competition, but also generate significant opportunities in licensing, execution, long term research and innovation. In certain industries, e. g., Pharmaceutical industry, patents lead to multi-billion dollar revenue per year. In this paper, we present a holistic information mining solution, called SIMPLE, which mines large corpus of patents and scientific literature for insights. Unlike much prior work that deals with specific aspects of analytics, SIMPLE is an integrated and end-to-end IP analytics solution which addresses a wide range of challenges in patent analytics such as the data complexity, scale, and nomenclature issues. It encompasses techniques for patent data processing and modeling, analytics algorithms, web interface and web services for analytics service delivery and end-user interaction. We use real-world case studies to demonstrate the effectiveness of SIMPLE.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828204</person_id>
				<author_profile_id><![CDATA[81548028760]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828205</person_id>
				<author_profile_id><![CDATA[81100017611]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Scott]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Spangler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828206</person_id>
				<author_profile_id><![CDATA[81100434591]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jeffrey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kreulen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828207</person_id>
				<author_profile_id><![CDATA[81344488518]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Boyer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828208</person_id>
				<author_profile_id><![CDATA[81343494077]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Griffin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828209</person_id>
				<author_profile_id><![CDATA[81375603519]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Alfredo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alba]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828210</person_id>
				<author_profile_id><![CDATA[81326487789]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Amit]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Behal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828211</person_id>
				<author_profile_id><![CDATA[81339503886]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Bin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828212</person_id>
				<author_profile_id><![CDATA[81442618108]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[Linda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kato]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828213</person_id>
				<author_profile_id><![CDATA[81326490498]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>10</seq_no>
				<first_name><![CDATA[Ana]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lelescu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828214</person_id>
				<author_profile_id><![CDATA[81311485767]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>11</seq_no>
				<first_name><![CDATA[Cheryl]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kieliszewski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828215</person_id>
				<author_profile_id><![CDATA[81453649285]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>12</seq_no>
				<first_name><![CDATA[Xian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828216</person_id>
				<author_profile_id><![CDATA[81453606622]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>13</seq_no>
				<first_name><![CDATA[Li]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677154</article_id>
		<sort_key>530</sort_key>
		<display_label>Pages</display_label>
		<pages>276-281</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>50</seq_no>
		<title><![CDATA[HOCT]]></title>
		<subtitle><![CDATA[A Highly Scalable Algorithm for Training Linear CRF on Modern Hardware]]></subtitle>
		<page_from>276</page_from>
		<page_to>281</page_to>
		<doi_number>10.1109/ICDMW.2009.69</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677154</url>
		<abstract>
			<par><![CDATA[This paper proposes an efficient algorithm, HOCT, for CRF training on modern computer architectures. First, software prefetching techniques are utilized to hide cache miss latency. Second, we exploit SIMD to process data in parallel. Third, when dealing with large data sets, we let HOCT instead of operating system to manage swapping operations. Our experiments on various real data sets show that HOCT yields a fourfold speedup when the data can fit in memory, and over a 30-fold speedup when the memory requirement exceeds the physical memory.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1826788</person_id>
				<author_profile_id><![CDATA[81453609927]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tianyuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826789</person_id>
				<author_profile_id><![CDATA[81453639554]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826790</person_id>
				<author_profile_id><![CDATA[81453625780]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jianqing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826791</person_id>
				<author_profile_id><![CDATA[81453627553]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826792</person_id>
				<author_profile_id><![CDATA[81453641251]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Feng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677155</article_id>
		<sort_key>540</sort_key>
		<display_label>Pages</display_label>
		<pages>282-289</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>51</seq_no>
		<title><![CDATA[Why Naive Ensembles Do Not Work in Cloud Computing]]></title>
		<page_from>282</page_from>
		<page_to>289</page_to>
		<doi_number>10.1109/ICDMW.2009.85</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677155</url>
		<abstract>
			<par><![CDATA[One of the greatest challenges of data mining is dealing with very large datasets. Cloud computing has demonstrated great advantages in processing very large datasets. When considering taking advantage of the high performance data cloud to do data mining, there are different approaches to make an existing data mining algorithm parallelizable in a cloud computing environment. One concern is how to achieve better performance by making use of the data in a more intelligent way. In this paper, we describe two different approaches to parallelize the existing random decision tree mining algorithm, which we have built on the Sector/Sphere cloud computing environment. We compare the cost and accuracy between those two different implementations and analyze the result of this experimental study.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828217</person_id>
				<author_profile_id><![CDATA[81453628922]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wenxuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828218</person_id>
				<author_profile_id><![CDATA[81100478239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grossman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828219</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828220</person_id>
				<author_profile_id><![CDATA[81100501488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Yunhong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677156</article_id>
		<sort_key>550</sort_key>
		<display_label>Pages</display_label>
		<pages>290-295</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>52</seq_no>
		<title><![CDATA[EigenSpokes]]></title>
		<subtitle><![CDATA[Surprising Patterns and Scalable Community Chipping in Large Graphs]]></subtitle>
		<page_from>290</page_from>
		<page_to>295</page_to>
		<doi_number>10.1109/ICDMW.2009.103</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677156</url>
		<abstract>
			<par><![CDATA[We report a surprising, persistent pattern in an important class of large sparse social graphs, which we term EigenSpokes. We focus on large Mobile Call graphs, spanning hundreds of thousands of nodes and edges, and find that the singular vectors of these graphs exhibit a striking EigenSpokes pattern wherein, when plotted against each other, they have clear, separate lines that often neatly align along specific axes (hence the term "spokes"). We show this phenomenon to be persistent across both temporal and geographic samples of Mobile Call graphs. Through experiments on synthetic graphs, EigenSpokes are shown to be associated with the presence of community structure in these social networks. This is further verified by analysing the eigenvectors of the Mobile Call graph, which yield nodes that form tightly-knit communities. The presence of such patterns in the singular spectra has useful applications, and could potentially be used to design simple, efficient community extraction algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1823857</person_id>
				<author_profile_id><![CDATA[81414613593]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[B.]]></first_name>
				<middle_name><![CDATA[Aditya]]></middle_name>
				<last_name><![CDATA[Prakash]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823858</person_id>
				<author_profile_id><![CDATA[81100151416]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mukund]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Seshadri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823859</person_id>
				<author_profile_id><![CDATA[81100641406]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ashwin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sridharan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823860</person_id>
				<author_profile_id><![CDATA[81100241228]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Sridhar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Machiraju]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823861</person_id>
				<author_profile_id><![CDATA[81100373169]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Christos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Faloutsos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677157</article_id>
		<sort_key>560</sort_key>
		<display_label>Pages</display_label>
		<pages>296-301</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>53</seq_no>
		<title><![CDATA[Toolkit-Based High-Performance Data Mining of Large Data on MapReduce Clusters]]></title>
		<page_from>296</page_from>
		<page_to>301</page_to>
		<doi_number>10.1109/ICDMW.2009.34</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677157</url>
		<abstract>
			<par><![CDATA[The enormous growth of data in a variety of applications has increased the need for high performance data mining based on distributed environments. However, standard data mining toolkits per se do not allow the usage of computing clusters. The success of MapReduce for analyzing large data has raised a general interest in applying this model to other, data intensive applications. Unfortunately current research has not lead to an integration of GUI based data mining toolkits with distributed file system based MapReduce systems. This paper defines novel principles for modeling and design of the user interface, the storage model and the computational model necessary for the integration of such systems. Additionally, it introduces a novel system architecture for interactive GUI based data mining of large data on clusters based on MapReduce that overcomes the limitations of data mining toolkits. As an empirical demonstration we show an implementation based on Weka and Hadoop.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825343</person_id>
				<author_profile_id><![CDATA[81361600664]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dennis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wegener]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825344</person_id>
				<author_profile_id><![CDATA[81100376224]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mock]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825345</person_id>
				<author_profile_id><![CDATA[81453659668]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Deyaa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Adranale]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825346</person_id>
				<author_profile_id><![CDATA[81100099179]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wrobel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677158</article_id>
		<sort_key>570</sort_key>
		<display_label>Pages</display_label>
		<pages>302-307</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>54</seq_no>
		<title><![CDATA[Scalable Attribute-Value Extraction from Semi-structured Text]]></title>
		<page_from>302</page_from>
		<page_to>307</page_to>
		<doi_number>10.1109/ICDMW.2009.81</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677158</url>
		<abstract>
			<par><![CDATA[This paper describes a general methodology for extracting attribute-value pairs from web pages. It consists of two phases: candidate generation, in which syntactically likely attribute-value pairs are annotated; and candidate filtering, in which semantically improbable annotations are removed. We describe three types of candidate generators and two types of candidate filters, all of which are designed to be massively parallelizable. Our methods can handle 1 billion web pages in less than 6 hours with 1,000 machines. The best generator and filter combination achieves 70% F-measure compared to a hand-annotated corpus.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828283</person_id>
				<author_profile_id><![CDATA[81453607959]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yuk]]></first_name>
				<middle_name><![CDATA[Wah]]></middle_name>
				<last_name><![CDATA[Wong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828284</person_id>
				<author_profile_id><![CDATA[81100267989]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dominic]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Widdows]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828285</person_id>
				<author_profile_id><![CDATA[81100205029]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lokovic]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828286</person_id>
				<author_profile_id><![CDATA[81453613373]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Kamal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nigam]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677159</article_id>
		<sort_key>580</sort_key>
		<display_label>Pages</display_label>
		<pages>308-313</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>55</seq_no>
		<title><![CDATA[Estimating the Parameters of Randomly Interleaved Markov Models]]></title>
		<page_from>308</page_from>
		<page_to>313</page_to>
		<doi_number>10.1109/ICDMW.2009.17</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677159</url>
		<abstract>
			<par><![CDATA[Sequences that can be assumed to have been generated by a number of Markov models, whose outputs are randomly interleaved but where the actual sources are hidden, occur in a number of practical situations where data is captured as an unlabeled stream of events. We present a practical method for estimating model parameters on large data sets under the assumption that all sources are identical. Results on representative examples are presented, together with a discussion on the accuracy and performance of the proposed estimation algorithms. Finally, we describe a real-world case study where we apply the technique to the sequence of events recorded in the technical support database of an IT vendor.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1823885</person_id>
				<author_profile_id><![CDATA[81442611984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gillblad]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823886</person_id>
				<author_profile_id><![CDATA[81453659678]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Rebecca]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Steinert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823887</person_id>
				<author_profile_id><![CDATA[81384618191]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Diogo]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Ferreira]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677160</article_id>
		<sort_key>590</sort_key>
		<display_label>Pages</display_label>
		<pages>314-319</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>56</seq_no>
		<title><![CDATA[Sparse Least-Squares Methods in the Parallel Machine Learning (PML) Framework]]></title>
		<page_from>314</page_from>
		<page_to>319</page_to>
		<doi_number>10.1109/ICDMW.2009.106</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677160</url>
		<abstract>
			<par><![CDATA[We describe parallel methods for solving large-scale, high-dimensional, sparse least-squares problems that arise in machine learning applications such as document classification. The basic idea is to solve a two-class response problem using a fast regression technique based on minimizing a loss function, which consists of an empirical squared-error term, and one or more regularization terms. We consider the use of Lenclos-based methods for solving these regularized least-squares problems, with the parallel implementation in the Parallel MachineLearning (PML) framework, and performance results on the IBM Blue Gene/P parallel computer.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1826824</person_id>
				<author_profile_id><![CDATA[81100450092]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Natarajan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826825</person_id>
				<author_profile_id><![CDATA[81309499649]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vikas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sindhwani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826826</person_id>
				<author_profile_id><![CDATA[81320495589]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shirish]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tatikonda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677161</article_id>
		<sort_key>600</sort_key>
		<display_label>Pages</display_label>
		<pages>320-325</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>57</seq_no>
		<title><![CDATA[Fast Induction of Multiple Decision Trees in Text Categorization from Large Scale, Imbalanced, and Multi-label Data]]></title>
		<page_from>320</page_from>
		<page_to>325</page_to>
		<doi_number>10.1109/ICDMW.2009.94</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677161</url>
		<abstract>
			<par><![CDATA[The paper focuses on automated categorization of text documents, each labeled with one or more classes and described by tens of thousands of features. The computational costs of induction in such domains are so high as almost to disqualify the use of decision trees; the reduction of these costs is thus an important research issue. Our own solution, FDT ("fast decision-tree induction"), uses a two-pronged strategy: (1) feature-set pre-selection, and (2) induction of several trees, each from a different data subset, with the combination of the results from multiple trees with a data-fusion technique tailored to domains with imbalanced classes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822437</person_id>
				<author_profile_id><![CDATA[81453652715]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Peerapon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vateekul]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822438</person_id>
				<author_profile_id><![CDATA[81100282026]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Miroslav]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kubat]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677162</article_id>
		<sort_key>610</sort_key>
		<display_label>Pages</display_label>
		<pages>326-331</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>58</seq_no>
		<title><![CDATA[Greedy is not Enough]]></title>
		<subtitle><![CDATA[An Efficient Batch Mode Active Learning Algorithm]]></subtitle>
		<page_from>326</page_from>
		<page_to>331</page_to>
		<doi_number>10.1109/ICDMW.2009.38</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677162</url>
		<abstract>
			<par><![CDATA[Active learning algorithms actively select training examples to acquire labels from domain experts, which are very effective to reduce human labeling effort in the context of supervised learning. To reduce computational time in training, as well as provide more convenient user interaction environment, it is necessary to select batches of new training examples instead of a single example. Batch mode active learning algorithms incorporate a diversity measure to construct a batch of diversified candidate examples. Existing approaches use greedy algorithms to make it feasible to the scale of thousands of data. Greedy algorithms, however, are not efficient enough to scale to even larger real world classification applications, which contain millions of data. In this paper, we present an extremely efficient active learning algorithm. This new active learning algorithm achieves the same results as the traditional greedy algorithm, while the run time is reduced by a factor of several hundred times. We prove that the objective function of the algorithm is submodular, which guarantees to find the same solution as the greedy algorithm. We evaluate our approach on several largescale real-world text classification problems, and show that our new approach achieves substantial speedups, while obtaining the same classification accuracy.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1829756</person_id>
				<author_profile_id><![CDATA[81453629701]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zuobing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829757</person_id>
				<author_profile_id><![CDATA[81436593629]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hogan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829758</person_id>
				<author_profile_id><![CDATA[81384612085]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bauer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677163</article_id>
		<sort_key>620</sort_key>
		<display_label>Pages</display_label>
		<pages>332-337</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>59</seq_no>
		<title><![CDATA[Efficient Dense Structure Mining Using MapReduce]]></title>
		<page_from>332</page_from>
		<page_to>337</page_to>
		<doi_number>10.1109/ICDMW.2009.48</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677163</url>
		<abstract>
			<par><![CDATA[Structure mining plays an important part in the researches in biology, physics, Internet and telecommunications in recently emerging network science. As a main task in this area, the problem of structure mining on graph has attracted much interest and been studied in variant avenues in prior works. However, most of these works mainly rely on single chip computational capacity and have been constrained by local optimization. Thus it is an impossible mission for these methods to process massive graphs. In this paper, we propose an unified distributed method in solving some critical graph mining problems on top of a cluster system with the help of MapReduce. These problems include graph transformation, subgraph partition, maximal clique enumeration, connected component finding and community detection. All of these methods are implemented to fully utilize MapReduce execution mechanism, namely the &#8220;map-reduce&#8221; process. Moreover, considering how our algorithms can be applied in further &#8220;cloud&#8221; service, we employ several large scale datasets to demonstrate the efficiency and scalability of our solutions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1823939</person_id>
				<author_profile_id><![CDATA[81447598934]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shengqi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823940</person_id>
				<author_profile_id><![CDATA[81319503960]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823941</person_id>
				<author_profile_id><![CDATA[81453634644]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Haizhou]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823942</person_id>
				<author_profile_id><![CDATA[81331507150]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Bin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677164</article_id>
		<sort_key>630</sort_key>
		<display_label>Pages</display_label>
		<pages>338-343</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>60</seq_no>
		<title><![CDATA[Efficient Incremental Mining of Qualified Web Traversal Patterns without Scanning Original Databases]]></title>
		<page_from>338</page_from>
		<page_to>343</page_to>
		<doi_number>10.1109/ICDMW.2009.16</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677164</url>
		<abstract>
			<par><![CDATA[Discovering web traversal patterns is an important issue in web usage mining with various applications like navigation prediction and improvement of website management. Since web data grows so rapidly and some web data may become out of date over time, we need not only consider the new data but also delete the old one to re-mine new web traversal patterns. To reduce the overhead of re-mining the web traversal patterns from the whole web data, an incremental mining approach is needed by using the previous mining results and computing new patterns just from the inserted or deleted part of the web data. In this paper, we propose an efficient incremental web traversal pattern mining algorithm named IncWTP_PLM (Incremental mining of Web Traversal Patterns by using Projected-database Link Matrix). Meanwhile, a special data structure named Projected-database Link Matrix is proposed to avoid scanning original database. Besides, the website structure is also considered in IncWTP_PLM such that each web traversal pattern discovered is qualified. The experimental results show that our algorithm outperforms other approaches substantially in terms of efficiency.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1820926</person_id>
				<author_profile_id><![CDATA[81453650165]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jia-Ching]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ying]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1820927</person_id>
				<author_profile_id><![CDATA[81100582402]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vincent]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Tseng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1820928</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677165</article_id>
		<sort_key>640</sort_key>
		<display_label>Pages</display_label>
		<pages>344-349</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>61</seq_no>
		<title><![CDATA[Compressed Spectral Clustering]]></title>
		<page_from>344</page_from>
		<page_to>349</page_to>
		<doi_number>10.1109/ICDMW.2009.22</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677165</url>
		<abstract>
			<par><![CDATA[Compressed sensing has received much attention in both data mining and signal processing communities. In this paper, we provide theoretical results to show that compressed spectral clustering, separating data samples into different clusters directly in the compressed measurement domain, is possible. Specifically, we provide theoretical bounds guaranteeing that if the data is measured directly in the compressed domain, spectral clustering on the compressed data works almost as well as that in the data domain. Moreover, we show that for a family of well-known compressed sensing matrices, compressed spectral clustering is universal, i. e., clustering in the measurement domain works provided that the data are sparse in some, even unknown, basis. Finally, experimental results on both toy and real world data sets demonstrate that compressed spectral clustering achieves comparable clustering performance with traditional spectral clustering that works directly in the data domain, with much less computational time.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1829793</person_id>
				<author_profile_id><![CDATA[81453632414]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829794</person_id>
				<author_profile_id><![CDATA[81372592002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Changshui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677166</article_id>
		<sort_key>650</sort_key>
		<display_label>Pages</display_label>
		<pages>350-355</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>62</seq_no>
		<title><![CDATA[Mining of Attribute Interactions Using Information Theoretic Metrics]]></title>
		<page_from>350</page_from>
		<page_to>355</page_to>
		<doi_number>10.1109/ICDMW.2009.51</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677166</url>
		<abstract>
			<par><![CDATA[Knowledge of the statistical interactions between the attributes in a data set provides insight into the underlying structure of the data and explains the relationships (independence, synergy, redundancy) between the attributes. In a supervised learning problem, normally, a small subset of the classifying attributes are actually associated with the class label. Interaction information among the attributes captures the multivariate dependencies (synergy and redundancy) among the attributes and the class label. Mining the significant statistical interactions that contain information about the class label is a computationally challenging task - the number of possible interactions increases exponentially and most of these interactions contain redundant information when a number of correlated attributes are present. In this paper, we present a data mining method (named IM or Interaction Mining) to mine non-redundant attribute sets that have significant interactions with the class label. We further demonstrate that the mined statistical interactions are useful for improved feature selection as they successfully capture the multivariate inter-dependencies among the attributes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1820929</person_id>
				<author_profile_id><![CDATA[81388594855]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pritam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chanda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1820930</person_id>
				<author_profile_id><![CDATA[81322491009]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Young-Rae]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1820931</person_id>
				<author_profile_id><![CDATA[81453644135]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Aidong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1820932</person_id>
				<author_profile_id><![CDATA[81100198525]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Murali]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ramanathan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677167</article_id>
		<sort_key>660</sort_key>
		<display_label>Pages</display_label>
		<pages>356-361</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>63</seq_no>
		<title><![CDATA[Kernel K-means Based Framework for Aggregate Outputs Classification]]></title>
		<page_from>356</page_from>
		<page_to>361</page_to>
		<doi_number>10.1109/ICDMW.2009.33</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677167</url>
		<abstract>
			<par><![CDATA[Aggregate outputs learning is a newly proposed setting in data mining and machine learning. It differs from the classical supervised learning setting in that, training samples are packed into bags with only the aggregate outputs (labels for classification or real values for regression) provided. This problem is associated with several kinds of application background. We focus on the aggregate outputs classification problem in this paper, and set up a framework based on kernel K-means to solve it. Two concrete algorithms based on our framework are proposed, each of which can cope with both binary and multi-class scenarios. The experimental results suggest that our algorithms outperform the state-of-art technique. Also, we propose a new setting for patch extraction in the Content Based Image Retrieval procedure by using the algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1829795</person_id>
				<author_profile_id><![CDATA[81447604802]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shuo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829796</person_id>
				<author_profile_id><![CDATA[81387601905]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829797</person_id>
				<author_profile_id><![CDATA[81447597753]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mingjie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Qian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829798</person_id>
				<author_profile_id><![CDATA[81372592002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Changshui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677168</article_id>
		<sort_key>670</sort_key>
		<display_label>Pages</display_label>
		<pages>362-367</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>64</seq_no>
		<title><![CDATA[GLSVM]]></title>
		<subtitle><![CDATA[Integrating Structured Feature Selection and Large Margin Classification]]></subtitle>
		<page_from>362</page_from>
		<page_to>367</page_to>
		<doi_number>10.1109/ICDMW.2009.39</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677168</url>
		<abstract>
			<par><![CDATA[High dimensional data challenges current feature selection methods. For many real world problems we often have prior knowledge about the relationship of features. For example in microarray data analysis, genes from the same biological pathways are expected to have similar relationship to the outcome that we target to predict. Recent regularization methods on Support Vector Machine (SVM) have achieved great success to perform feature selection and model selection simultaneously for high dimensional data, but neglect such relationship among features. To build interpretable SVM models, the structure information of features should be incorporated. In this paper, we propose an algorithm GLSVM that automatically perform model selection and feature selection in SVMs. To incorporate the prior knowledge of feature relationship, we extend standard 2 norm SVM and use a penalty function that employs a L2 norm regularization term including the normalized Laplacian of the graph and L1 penalty. We have demonstrated the effectiveness of our methods and compare them to the state-of-the-art using two real-world benchmarks.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1823986</person_id>
				<author_profile_id><![CDATA[81384615965]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hongliang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823987</person_id>
				<author_profile_id><![CDATA[81384621689]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Quanz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1823988</person_id>
				<author_profile_id><![CDATA[81342497864]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Huan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677169</article_id>
		<sort_key>680</sort_key>
		<display_label>Pages</display_label>
		<pages>368-373</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>65</seq_no>
		<title><![CDATA[An Effective Network Partitioning Algorithm Based on Two-Point Diffusing Strategy]]></title>
		<page_from>368</page_from>
		<page_to>373</page_to>
		<doi_number>10.1109/ICDMW.2009.26</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677169</url>
		<abstract>
			<par><![CDATA[The network modeling and analysis have played important roles in fields of physics, sociology, biology, and computer science. Recently, community structure has been considered as an important character for complex networks, and its detection can bring great benefit in real world affairs. In the paper, a new heuristic algorithm based on two-point diffusing strategy is proposed. At first, two pseudo-core points are identified according to the clue of the longest path in a network. Then, two embryonic communities and an undecided node set are generated through performing diffusing operation on such two points. Subsequently, an experience rule is used to classify the undecided nodes to form the final community structure. In addition, the effectiveness and efficiency are validated by comparison experiments with four real-world networks. The experiment results show that our TPD algorithm can yield better community partition results and shorter computing time than the existing classical community detecting algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1826886</person_id>
				<author_profile_id><![CDATA[81453641120]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chengying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677170</article_id>
		<sort_key>690</sort_key>
		<display_label>Pages</display_label>
		<pages>374-381</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>66</seq_no>
		<title><![CDATA[Nonsmooth Bilevel Programming for Hyperparameter Selection]]></title>
		<page_from>374</page_from>
		<page_to>381</page_to>
		<doi_number>10.1109/ICDMW.2009.74</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677170</url>
		<abstract>
			<par><![CDATA[We propose a nonsmooth bilevel programming method for training linear learning models with hyperparameters optimized via $T$-fold cross-validation (CV). This algorithm scales well in the sample size. The method handles loss functions with embedded maxima such as in support vector machines. Current practice constructs models over a predefined grid of hyperparameter combinations and selects the best one, an inefficient heuristic. Innovating over previous bilevel CV approaches, this paper represents an advance towards the goal of self-tuning supervised data mining as well as a significant innovation in scalable bilevel programming algorithms. Using the bilevel CV formulation, the lower-level problems are treated as unconstrained optimization problems and are replaced with their optimality conditions. The resulting nonlinear program is nonsmooth and nonconvex. We develop a novel bilevel programming algorithm to solve this class of problems, and apply it to linear least-squares support vector regression having hyperparameters $C$ (tradeoff) and $\epsilon$ (loss insensitivity). This new approach outperforms grid search and prior smooth bilevel CV methods in terms of modeling performance. Increased speed foresees modeling with an increased number of hyperparameters.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825414</person_id>
				<author_profile_id><![CDATA[81453633900]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gregory]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Moore]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825415</person_id>
				<author_profile_id><![CDATA[81421597982]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bergeron]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825416</person_id>
				<author_profile_id><![CDATA[81100291848]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kristin]]></first_name>
				<middle_name><![CDATA[P.]]></middle_name>
				<last_name><![CDATA[Bennett]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677171</article_id>
		<sort_key>700</sort_key>
		<display_label>Pages</display_label>
		<pages>382-387</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>67</seq_no>
		<title><![CDATA[A New Measure of Feature Selection Algorithms' Stability]]></title>
		<page_from>382</page_from>
		<page_to>387</page_to>
		<doi_number>10.1109/ICDMW.2009.32</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677171</url>
		<abstract>
			<par><![CDATA[Stability or robustness of feature selection methods is a topic of recent interest. A new stability measure based on the Shannon entropy is proposed in this paper to evaluate the overall occurrence of individual features in selected subsets of possibly varying cardinality. We compare the new measure to stability measures proposed recently by Somol et al. The new measure is computationally very efficient and adds another type of insight into the stability problem. All considered measures have been used to compare the stability of several feature selection methods (individually best ranking, sequential forward selection, sequential forward floating selection and dynamic oscillating search) on a set of examples.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831428</person_id>
				<author_profile_id><![CDATA[81100412355]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jana]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Novovicov&#225;]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831429</person_id>
				<author_profile_id><![CDATA[81452600091]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Petr]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Somol]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831430</person_id>
				<author_profile_id><![CDATA[81100144647]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Pavel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pudil]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677172</article_id>
		<sort_key>710</sort_key>
		<display_label>Pages</display_label>
		<pages>388-393</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>68</seq_no>
		<title><![CDATA[Improved Multi Label Classification in Hierarchical Taxonomies]]></title>
		<page_from>388</page_from>
		<page_to>393</page_to>
		<doi_number>10.1109/ICDMW.2009.110</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677172</url>
		<abstract>
			<par><![CDATA[Hierarchical taxonomies are used to organize and retrieve information in many domains, especially those dealing with large and rapidly growing amounts of information. In many of these domains data also tends to be multi-label in nature. In this paper, we consider the problem of automated text classification in these scenarios. We present a post-processing based approach that performs smoothing on the output of an underlying one-vs-all ensemble. In order to do this we formulate a Regularized Unimodal Regression problem and give an exact algorithm to solve it. We evaluate the performance of our approach on several real-world large-scale multi-label hierarchical taxonomies and demonstrate that our proposed method provides significant gains over other related approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1829844</person_id>
				<author_profile_id><![CDATA[81502813002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kunal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Punera]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829845</person_id>
				<author_profile_id><![CDATA[81100661196]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Suju]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rajan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677173</article_id>
		<sort_key>720</sort_key>
		<display_label>Pages</display_label>
		<pages>394-399</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>69</seq_no>
		<title><![CDATA[Probabilistic Labeled Semi-supervised SVM]]></title>
		<page_from>394</page_from>
		<page_to>399</page_to>
		<doi_number>10.1109/ICDMW.2009.14</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677173</url>
		<abstract>
			<par><![CDATA[Semi-supervised learning has been paid increasing attention and is widely used in many fields such as data mining, information retrieval and knowledge management as it can utilize both labeled and unlabeled data. Laplacian SVM (LapSVM) is a very classical method whose effectiveness has been validated by large number of experiments. However, LapSVM is sensitive to labeled data and it exposes to cubic computation complexity which limit its application in large scale scenario. In this paper, we propose a multi-class method called Probabilistic labeled Semi-supervised SVM (PLSVM) in which the optimal decision surface is taught by probabilistic labels of all the training data including the labeled and unlabeled data. Then we propose a kernel version dual coordinate descent method to efficiently solve the dual problems of our Probabilistic labeled Semi-supervised SVM and decrease its requirement of memory. Synthetic data and several benchmark real world datasets show that PLSVM is less sensitive to labeling and has better performance over traditional methods like SVM, LapSVM (LapSVM) and Transductive SVM (TSVM).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1829846</person_id>
				<author_profile_id><![CDATA[81447597753]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mingjie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Qian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829847</person_id>
				<author_profile_id><![CDATA[81365596650]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Feiping]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nie]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1829848</person_id>
				<author_profile_id><![CDATA[81372592002]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Changshui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677174</article_id>
		<sort_key>730</sort_key>
		<display_label>Pages</display_label>
		<pages>400-405</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>70</seq_no>
		<title><![CDATA[Feature Selection for Maximizing the Area Under the ROC Curve]]></title>
		<page_from>400</page_from>
		<page_to>405</page_to>
		<doi_number>10.1109/ICDMW.2009.25</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677174</url>
		<abstract>
			<par><![CDATA[Feature selection is an important pre-processing step for solving classification problems. A good feature selection method may not only improve the performance of the final classifier, but also reduce the computational complexity of it. Traditionally, feature selection methods were developed to maximize the classification accuracy of a classifier. Recently, both theoretical and experimental studies revealed that a classifier with the highest accuracy might not be ideal in real-world problems. Instead, the Area Under the ROC Curve (AUC) has been suggested as the alternative metric, and many existing learning algorithms have been modified in order to seek the classifier with maximum AUC. However, little work was done to develop new feature selection methods to suit the requirement of AUC maximization. To fill this gap in the literature, we propose in this paper a novel algorithm, called AUC and Rank Correlation coefficient Optimization (ARCO) algorithm. ARCO adopts the general framework of a well-known method, namely minimal redundancy- maximal-relevance (mRMR) criterion, but defines the terms &#8221;relevance&#8221; and &#8221;redundancy&#8221; in totally different ways. Such a modification looks trivial from the perspective of algorithmic design. Nevertheless, experimental study on four gene expression data sets showed that feature subsets obtained by ARCO resulted in classifiers with significantly larger AUC than the feature subsets obtained by mRMR. Moreover, ARCO also outperformed the Feature Assessment by Sliding Thresholds algorithm, which was recently proposed for AUC maximization, and thus the efficacy of ARCO was validated.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828410</person_id>
				<author_profile_id><![CDATA[81453608868]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828411</person_id>
				<author_profile_id><![CDATA[81375596514]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677175</article_id>
		<sort_key>740</sort_key>
		<display_label>Pages</display_label>
		<pages>406-411</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>71</seq_no>
		<title><![CDATA[Multiple Instance Transfer Learning]]></title>
		<page_from>406</page_from>
		<page_to>411</page_to>
		<doi_number>10.1109/ICDMW.2009.72</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677175</url>
		<abstract>
			<par><![CDATA[Transfer Learning is a very important branch in both Machine Learning and Data Mining. Its main objective is to transfer knowledge across domains, tasks and distributions that are similar but not the same. Currently, almost all of the transfer learning methods are designed to deal with the traditional single instance learning problems. However, in many real-world applications, such as drug design, Localized Content Based Image Retrieval (LCBIR), Text Categorization, we have to deal with multiple instance problems, where training patterns are given as {\em bags} and each bag consists of some \emph{instances}. This paper formulates a novel Multiple Instance Transfer Learning (MITL) problem and suggests a method to solve it. An extensive set of empirical results demonstrate the advantages of the proposed method against several existed ones.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825457</person_id>
				<author_profile_id><![CDATA[81343509984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825458</person_id>
				<author_profile_id><![CDATA[81100394305]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Luo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Si]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677176</article_id>
		<sort_key>750</sort_key>
		<display_label>Pages</display_label>
		<pages>412-415</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>72</seq_no>
		<title><![CDATA[Detecting Similarity of Transferring Datasets Based on Features of Classification Rules]]></title>
		<page_from>412</page_from>
		<page_to>415</page_to>
		<doi_number>10.1109/ICDMW.2009.99</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677176</url>
		<abstract>
			<par><![CDATA[In order to transfer mined knowledge for various datasets obtained from transferring situations, it is important to detect not only availability of transferring the knowledge but also detecting their limitations of the transfer. Although most of methods to detect the limitations use performance indices of sets of classifiers such as accuracies of classifier sets, those of each classifier are also useful. Data characterizing techniques have been developed to control learning algorithm selection by using statistical measurements of a dataset. Expanding this framework, we consider a method to reuse objective rule evaluation indices of classification rules such as support, precision, and recall, to measure similarity of different datasets. In this paper, we present a method to characterize given datasets based on objective rule evaluation indices and classification learning algorithms. The experimental results show the method can detect similarity of datasets even if the datasets have totally different attribute sets. This indicates that the limitations of transferring both of classifiers and learning algorithms can be detected as the similarity among datasets by using a learning algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1826919</person_id>
				<author_profile_id><![CDATA[81100308224]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hidenao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Abe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826920</person_id>
				<author_profile_id><![CDATA[81548011389]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shusaku]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsumoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677177</article_id>
		<sort_key>760</sort_key>
		<display_label>Pages</display_label>
		<pages>416-421</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>73</seq_no>
		<title><![CDATA[Transferred Feature Selection]]></title>
		<page_from>416</page_from>
		<page_to>421</page_to>
		<doi_number>10.1109/ICDMW.2009.102</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677177</url>
		<abstract>
			<par><![CDATA[Traditional feature selection algorithms require a large number of labeled training instances to find out the most informative subset of features. However, in many real-world applications, the labeled data are often difficult, expensive or time-consuming to obtain. Recently, several semi-supervised feature selection algorithms were proposed, which aim at doing feature selection with the help of some unlabeled data. But such methods assume the labeled and unlabeled data are under the same data distribution. In this paper, we propose a new framework named Transferred Feature Selection (TFS), which uses out-of-domain labeled data to alleviate the lack of same-distribution labeled training data. The out-of-domain data are labeled but have different distributions with the same-distribution data, so most supervised or semi-supervised feature selection algorithms fail to work well with them. The key idea of TFS is to transfer knowledge from the out-of-domain instances to select a feature subset that can yield high prediction accuracy. The framework is then implemented by k-NN method. Analysis and experiments show that TFS can effectively exploit the out-of-domain instances to improve the performance of feature selection.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1820987</person_id>
				<author_profile_id><![CDATA[81453620000]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1820988</person_id>
				<author_profile_id><![CDATA[81392594990]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1820989</person_id>
				<author_profile_id><![CDATA[81453648763]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Zhenzhong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677178</article_id>
		<sort_key>770</sort_key>
		<display_label>Pages</display_label>
		<pages>422-428</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>74</seq_no>
		<title><![CDATA[Set-Based Boosting for Instance-Level Transfer]]></title>
		<page_from>422</page_from>
		<page_to>428</page_to>
		<doi_number>10.1109/ICDMW.2009.97</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677178</url>
		<abstract>
			<par><![CDATA[The success of transfer to improve learning on a target task is highly dependent on the selected source data. Instance-based transfer methods reuse data from the source tasks to augment the training data for the target task. If poorly chosen, this source data may inhibit learning, resulting in negative transfer. The current best performing algorithm for instance-based transfer, TrAdaBoost, performs poorly when given irrelevant source data. We present a novel set-based boosting technique for instance-based transfer. The proposed algorithm, TransferBoost, boosts both individual instances and collective sets of instances from each source task. In effect, TransferBoost boosts each source task, assigning higher weight to those source tasks which show positive transferability to the target task, and then adjusts the weights of the instances within each source task via AdaBoost. The results demonstrate that TransferBoost significantly improves transfer performance over existing instance-based algorithms when given a mix of relevant and irrelevant source data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1826921</person_id>
				<author_profile_id><![CDATA[81381597668]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Eaton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826922</person_id>
				<author_profile_id><![CDATA[81100325069]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Marie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[desJardins]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677179</article_id>
		<sort_key>780</sort_key>
		<display_label>Pages</display_label>
		<pages>429-434</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>75</seq_no>
		<title><![CDATA[Knowledge Transfer among Heterogeneous Information Networks]]></title>
		<page_from>429</page_from>
		<page_to>434</page_to>
		<doi_number>10.1109/ICDMW.2009.100</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677179</url>
		<abstract>
			<par><![CDATA[Online recommendation systems are becoming more and more popular with the development of web. However, a critical problem of such system is that new users and items are always added to the system with time. How to overcome the data sparseness for such new incoming entities become an important issue. In this paper, we try to reduce the data sparseness in the link prediction problem via involving heterogeneous information network as auxiliary information sources. We developed two models based on the Collective Matrix Factorization (CMF) framework. We also provided a detailed empirical study on how effectively different information networks could help with two real world link prediction tasks. We will report some preliminary results of our current work and also point our several potential research issues.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825481</person_id>
				<author_profile_id><![CDATA[81443597416]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Evan]]></first_name>
				<middle_name><![CDATA[Wei]]></middle_name>
				<last_name><![CDATA[Xiang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825482</person_id>
				<author_profile_id><![CDATA[81363596428]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nathan]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825483</person_id>
				<author_profile_id><![CDATA[81335495649]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Sinno]]></first_name>
				<middle_name><![CDATA[Jialin]]></middle_name>
				<last_name><![CDATA[Pan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825484</person_id>
				<author_profile_id><![CDATA[81372591186]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Qiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677180</article_id>
		<sort_key>790</sort_key>
		<display_label>Pages</display_label>
		<pages>435-440</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>76</seq_no>
		<title><![CDATA[Towards a Universal Text Classifier]]></title>
		<subtitle><![CDATA[Transfer Learning Using Encyclopedic Knowledge]]></subtitle>
		<page_from>435</page_from>
		<page_to>440</page_to>
		<doi_number>10.1109/ICDMW.2009.101</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677180</url>
		<abstract>
			<par><![CDATA[Document classification is a key task for many text mining applications. However, traditional text classification requires labeled data to construct reliable and accurate classifiers. Unfortunately, labeled data are seldom available. In this work, we propose a {\textit {universal text classifier}}, which does not require any labeled document. Our approach simulates the capability of people to classify documents based on background knowledge. As such, we build a classifier that can effectively group documents based on their content, under the guidance of few words describing the classes of interest. Background knowledge is modeled using encyclopedic knowledge, namely Wikipedia. The universal text classifier can also be used to perform document retrieval. In our experiments with real data we test the feasibility of our approach for both the classification and retrieval tasks.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1824046</person_id>
				<author_profile_id><![CDATA[81453647765]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1824047</person_id>
				<author_profile_id><![CDATA[81100062921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Carlotta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Domeniconi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677181</article_id>
		<sort_key>800</sort_key>
		<display_label>Pages</display_label>
		<pages>441-446</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>77</seq_no>
		<title><![CDATA[Knowledge Transformation by Cross-Domain Belief Propagation]]></title>
		<page_from>441</page_from>
		<page_to>446</page_to>
		<doi_number>10.1109/ICDMW.2009.73</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677181</url>
		<abstract>
			<par><![CDATA[Belief propagation is an iterative algorithm for computing marginals of functions on a graphical model most commonly used in information retrieval. In this paper, we consider the problem of performing cross-domain belief propagation on multi-relational data for semi-supervised learning. We demonstrate that partial knowledge on one type of variables can help knowledge discovery on the other type of variables with cross-domain belief propagation by utilizing the existing relationships in multi-relation data. For example, in a word-document data set, information on the word domain can effectively enhance the labeling of document domain. In this paper, we explore this new area, knowledge transformation of multi-relation data for semi-supervised learning tasks. We show that partial knowledge on one data variable domain can help knowledge discovery on the other variable domain with crossdomain belief propagation by utilizing the existing relationships in multi-relation data. The experimental results on several real world data sets are presented to show the effectiveness of our method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1826957</person_id>
				<author_profile_id><![CDATA[81453606160]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1826958</person_id>
				<author_profile_id><![CDATA[81100475528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677182</article_id>
		<sort_key>810</sort_key>
		<display_label>Pages</display_label>
		<pages>447-452</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>78</seq_no>
		<title><![CDATA[Determining the Training Window for Small Sample Size Classification with Concept Drift]]></title>
		<page_from>447</page_from>
		<page_to>452</page_to>
		<doi_number>10.1109/ICDMW.2009.20</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677182</url>
		<abstract>
			<par><![CDATA[We consider classification of sequential data in the presence of frequent and abrupt concept changes. The current practice is to use the data after the change to train a new classifier. However, if the window with the new data is too small, the classifier will be undertrained and hence less accurate that the "old'' classifier. Here we propose a method (called WR*) for resizing the training window after detecting a concept change. Experiments with synthetic and real data demonstrate the advantages of WR* over other window resizing methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825485</person_id>
				<author_profile_id><![CDATA[81453632246]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Indre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[&#142;liobaite]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825486</person_id>
				<author_profile_id><![CDATA[81100442435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ludmila]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Kuncheva]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677183</article_id>
		<sort_key>820</sort_key>
		<display_label>Pages</display_label>
		<pages>453-458</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>79</seq_no>
		<title><![CDATA[Pattern Mining over Star Schemas in the Onto4AR Framework]]></title>
		<page_from>453</page_from>
		<page_to>458</page_to>
		<doi_number>10.1109/ICDMW.2009.68</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677183</url>
		<abstract>
			<par><![CDATA[Storing data according to the multidimensional model, in particular following star schemas, has demonstrated to be one of the most adequate forms to ease the exploration of data. However, this exploration has been limited to be query-based, leaving the discovery of hidden information to a second plan. The main reason for this, relates to the inability of traditional mining techniques to deal with several data tables at the same time. In this paper, we propose a new approach to mine patterns among data stored as a star schema, based in a domain driven framework, where available knowledge is represented in a domain ontology. Pattern mining is performed by an apriori-based algorithm - the D2Apriori, but more efficient algorithms are being implemented and tested, in order to solve performance issues related with the large amount of data stored in data warehouses.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831494</person_id>
				<author_profile_id><![CDATA[81100226111]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cl&#225;udia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Antunes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677184</article_id>
		<sort_key>830</sort_key>
		<display_label>Pages</display_label>
		<pages>459-464</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>80</seq_no>
		<title><![CDATA[Document Clustering Using Semantic Kernels Based on Term-Term Correlations]]></title>
		<page_from>459</page_from>
		<page_to>464</page_to>
		<doi_number>10.1109/ICDMW.2009.88</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677184</url>
		<abstract>
			<par><![CDATA[Document clustering algorithms usually use vector space model (VSM) as their underlying model for document representation. VSM assumes that terms are independent and accordingly ignores any semantic relations between them. This results in mapping documents to a space where the proximity between document vectors does not reflect their true semantic similarity. In this paper, we propose the use of semantic kernels that are based on term-term correlations for improving the effectiveness of document clustering algorithms. The used kernels measure proximity between documents based on how their terms are statistically correlated. We analyze semantic kernels that capture different aspects of correlations between terms, and evaluate them by conducting experiments on different benchmark data sets. Results show that the proposed method achieves significant improvement in document clustering compared to VSM.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825487</person_id>
				<author_profile_id><![CDATA[81453627252]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ahmed]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Farahat]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825488</person_id>
				<author_profile_id><![CDATA[81100436158]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mohamed]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Kamel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677185</article_id>
		<sort_key>840</sort_key>
		<display_label>Pages</display_label>
		<pages>465-470</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>81</seq_no>
		<title><![CDATA[Semantic-Rich Markov Models for Web Prefetching]]></title>
		<page_from>465</page_from>
		<page_to>470</page_to>
		<doi_number>10.1109/ICDMW.2009.18</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677185</url>
		<abstract>
			<par><![CDATA[Domain knowledge for web applications is currently being made available as domain ontology with the advent of the semantic web, in which semantics govern relationships among objects of interest (e. g., commercial items to be purchased in an e-Commerce web site). Our earlier work proposed to integrate semantic information into all phases of the web usage mining process, for an intelligent semantics-aware web usage mining framework. There are ways to integrate semantic information into Markov models used in the third phase for next page request prediction. Semantic information is combined with the transition probability matrix of a Markov model. This way, it provides a low order Markov model with intelligent accurate predictions and less complexity than higher order models, also solving the problem of contradicting prediction. This paper proposes to use semantic information to prune states in Selective Markov models SMM, semantic information can lead to context-aware higher order Markov models with about 16% less space complexity.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825514</person_id>
				<author_profile_id><![CDATA[81447601583]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nizar]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Mabroukeh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825515</person_id>
				<author_profile_id><![CDATA[81100187384]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christie]]></first_name>
				<middle_name><![CDATA[I.]]></middle_name>
				<last_name><![CDATA[Ezeife]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677186</article_id>
		<sort_key>850</sort_key>
		<display_label>Pages</display_label>
		<pages>471-476</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>82</seq_no>
		<title><![CDATA[Parameterized Contrast in Second Order Soft Co-occurrences]]></title>
		<subtitle><![CDATA[A Novel Text Representation Technique in Text Mining and Knowledge Extraction]]></subtitle>
		<page_from>471</page_from>
		<page_to>476</page_to>
		<doi_number>10.1109/ICDMW.2009.49</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677186</url>
		<abstract>
			<par><![CDATA[In this article, we present a novel statistical representation method for knowledge extraction from a corpus containing short texts. Then we introduce the contrast parameter which could be adjusted for targeting different conceptual levels in text mining and knowledge extraction. The method is based on second order co-occurrence vectors whose efficiency for representing meaning has been established in many applications, especially for representing word senses in different contexts and for disambiguation purposes. We evaluate our method on two tasks: classification of textual description of dreams, and classification of medical abstracts for systematic reviews.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1824093</person_id>
				<author_profile_id><![CDATA[81436599352]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Amir]]></first_name>
				<middle_name><![CDATA[Hossein]]></middle_name>
				<last_name><![CDATA[Razavi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1824094</person_id>
				<author_profile_id><![CDATA[81100488606]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Stan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Matwin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1824095</person_id>
				<author_profile_id><![CDATA[81323491458]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Diana]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Inkpen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1824096</person_id>
				<author_profile_id><![CDATA[81436601547]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Alexandre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kouznetsov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677187</article_id>
		<sort_key>860</sort_key>
		<display_label>Pages</display_label>
		<pages>477-482</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>83</seq_no>
		<title><![CDATA[A WordNet-Based Semantic Model for Enhancing Text Clustering]]></title>
		<page_from>477</page_from>
		<page_to>482</page_to>
		<doi_number>10.1109/ICDMW.2009.86</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677187</url>
		<abstract>
			<par><![CDATA[Most of text mining techniques are based on word and/or phrase analysis of the text. The statistical analysis of a term (word or phrase) frequency captures the importance of the term within a document. However, to achieve a more accurate analysis, the underlying mining technique should indicate terms that capture the semantics of the text from which the importance of a term in a sentence and in the document can be derived. Incorporating semantic features from the WordNet lexical database is one of many approaches that have been tried to improve the accuracy of text clustering techniques. A new semantic-based model that analyzes documents based on their meaning is introduced. The proposed model analyzes terms and their corresponding synonyms and/or hypernyms on the sentence and document levels. In this model, if two documents contain different words and these words are semantically related, the proposed model can measure the semantic-based similarity between the two documents. The similarity between documents relies on a new semantic-based similarity measure which is applied to the matching concepts between documents. Experiments using the proposed semantic-based model in text clustering are conducted. Experimental results demonstrate that the newly developed semantic-based model enhances the clustering quality of sets of documents substantially.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825516</person_id>
				<author_profile_id><![CDATA[81321498121]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shady]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shehata]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677188</article_id>
		<sort_key>870</sort_key>
		<display_label>Pages</display_label>
		<pages>483-488</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>84</seq_no>
		<title><![CDATA[A Data Mining Method to Extract and Rank Papers Describing Coexpression Predicates Semantically]]></title>
		<page_from>483</page_from>
		<page_to>488</page_to>
		<doi_number>10.1109/ICDMW.2009.53</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677188</url>
		<abstract>
			<par><![CDATA[Information management and extraction in the field of biomedical research has become a requirement with the rapid increase in the amount of data being published in this area. In this paper, a graphical model, Conditional Random Fields has been used to extract a particular gene-gene relationship called &#8220;coexpression&#8221; from the existing literature. First, a Conditional Random Fields based model has been trained and tested on full-length papers downloaded from PubMed, to label the predicates that talk about coexpression of genes. Proper local and contextual text features at both word and sentence levels are proposed and extracted during the pre-processing step. The classification performance of the model trained based on the proposed features has been compared with the that of Support Vector Machines, Nearest Neighbor with generalization, and Neural Networks algorithms, and seen to outperform them all. In our second experiment, the proposed ranking scheme, which is based on classification results, is applied to the ranked lists of papers returned by PubMed and Google, respectively. The comparison of our ranked results to that of PubMed and Google demonstrates that our proposed ranking scheme performs better than both in distinguishing a positive paper from a negative paper. In conclusion, this paper describes a specialized classification and ranking framework that can retrieve papers that really talk about coexpression between and among genes based on mining of semantics and not just lexical search.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828504</person_id>
				<author_profile_id><![CDATA[81453613241]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chengcui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828505</person_id>
				<author_profile_id><![CDATA[81365591445]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Richa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tiwari]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828506</person_id>
				<author_profile_id><![CDATA[81313481624]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wei-Bang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677189</article_id>
		<sort_key>880</sort_key>
		<display_label>Pages</display_label>
		<pages>489-494</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>85</seq_no>
		<title><![CDATA[LNBC]]></title>
		<subtitle><![CDATA[A Link-Based Naive Bayes Classifier]]></subtitle>
		<page_from>489</page_from>
		<page_to>494</page_to>
		<doi_number>10.1109/ICDMW.2009.116</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677189</url>
		<abstract>
			<par><![CDATA[Many databases store data in relational format, with different types of entities and information about links between the entities. Link-based classification is the problem of predicting the class label of a target entity given information about features of the entity and about features of the related entities. A natural approach to link-based classification is to upgrade standard classification methods from the propositional, single-table testing. In this paper we propose a new classification rule for upgrading naive Bayes classifiers (NBC). Previous work on relational NBC has achieved the best results with link independency assumption which says that the probability of each link to an object is independent from the other links to the object. We formalize our method by breaking it into two parts: (1) the independent influence assumption: that the influence of one path from the target object to a related entity is independent of another. We consider object-path independency and (2) the independent feature assumption of NBC: that features of the target entity and a related entity are probabilistically independent given a target class label. We derive a new relational NBC rule that places more weight on the target entity features than formulations of the link independency assumption. The new NBC rule yields higher accuracies on three benchmark datasets-Mutagenesis, MovieLens, and Cora-with average improvements ranging from 2% to 10%]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822641</person_id>
				<author_profile_id><![CDATA[81453622561]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bahareh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bina]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822642</person_id>
				<author_profile_id><![CDATA[81100278948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Oliver]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schulte]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822643</person_id>
				<author_profile_id><![CDATA[81436592655]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hassan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Khosravi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677190</article_id>
		<sort_key>890</sort_key>
		<display_label>Pages</display_label>
		<pages>495-500</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>86</seq_no>
		<title><![CDATA[TagLearner]]></title>
		<subtitle><![CDATA[A P2P Classifier Learning System from Collaboratively Tagged Text Documents]]></subtitle>
		<page_from>495</page_from>
		<page_to>500</page_to>
		<doi_number>10.1109/ICDMW.2009.90</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677190</url>
		<abstract>
			<par><![CDATA[The amount of text data on the Internet is growing at a very fast rate. Online text repositories for news agencies, digital libraries and other organizations currently store giga and tera-bytes of data. Large amounts of unstructured text poses a serious challenge for data mining and knowledge extraction. End user participation coupled with distributed computation can play a crucial role in meeting these challenges. In many applications involving classification of text documents, web users often participate in the tagging process. This collaborative tagging results in the formation of large scale Peer-to-Peer (P2P) systems which can function, scale and self-organize in the presence of highly transient population of nodes and do not need a central server for co-ordination. In this paper, we describe TagLearner, a P2P classifier learning system for extracting patterns from text data where the end users can participate both in the task of labeling the data and building a distributed classifier on it. We present a novel distributed linear programming based classification algorithm which is asynchronous in nature. The paper also provides extensive empirical results on text data obtained from an online repository - the NSF Abstracts Data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830014</person_id>
				<author_profile_id><![CDATA[81100634447]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Haimonti]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dutta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830015</person_id>
				<author_profile_id><![CDATA[81453639792]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xianshu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830016</person_id>
				<author_profile_id><![CDATA[81453661617]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tushar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mahule]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830017</person_id>
				<author_profile_id><![CDATA[81100150749]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hillol]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kargupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830018</person_id>
				<author_profile_id><![CDATA[81317491203]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Kirk]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Borne]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830019</person_id>
				<author_profile_id><![CDATA[81453651190]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Codrina]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lauth]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830020</person_id>
				<author_profile_id><![CDATA[81461641015]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Florian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Holz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830021</person_id>
				<author_profile_id><![CDATA[81100294698]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Gerhard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Heyer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677191</article_id>
		<sort_key>900</sort_key>
		<display_label>Pages</display_label>
		<pages>501-506</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>87</seq_no>
		<title><![CDATA[Mining Multiple Satellite Sensor Data Using Collaborative Clustering]]></title>
		<page_from>501</page_from>
		<page_to>506</page_to>
		<doi_number>10.1109/ICDMW.2009.42</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677191</url>
		<abstract>
			<par><![CDATA[In recent years, satellite sensor data have become easier to acquire. Several different satellite systems are now available and produce a large amount of data used for Earth observation. To better grasp the complexity of the Earth surface, it became usual to use different images from different satellites. However, it is generally difficult to predict the potential gain of using multisource satellite sensor data before actually acquiring the data. In this paper, we present a simulation approach to create different views of remote sensing sensor data according to different satellite characteristics. These different views are then used in a collaborative clustering approach to assess the interest of using these multisource data together. Experiments provide some insights on couple of satellite systems able to leverage the complementary of the sources.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830022</person_id>
				<author_profile_id><![CDATA[81361593237]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Germain]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Forestier]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830023</person_id>
				<author_profile_id><![CDATA[81100263918]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[C&#233;dric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wemmert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830024</person_id>
				<author_profile_id><![CDATA[81100009462]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Pierre]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gancarski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830025</person_id>
				<author_profile_id><![CDATA[81414599093]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jordi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Inglada]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677192</article_id>
		<sort_key>910</sort_key>
		<display_label>Pages</display_label>
		<pages>507-514</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>88</seq_no>
		<title><![CDATA[Feature Selection with High-Dimensional Imbalanced Data]]></title>
		<page_from>507</page_from>
		<page_to>514</page_to>
		<doi_number>10.1109/ICDMW.2009.35</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677192</url>
		<abstract>
			<par><![CDATA[Feature selection is an important topic in data mining, especially for high dimensional datasets. Filtering techniques in particular have received much attention, but detailed comparisons of their performance is lacking. This work considers three filters using classifier performance metrics and six commonly-used filters. All nine filtering techniques are compared and contrasted using five different microarray expression datasets. In addition, given that these datasets exhibit an imbalance between the number of positive and negative examples, the utilization of sampling techniques in the context of feature selection is examined.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830026</person_id>
				<author_profile_id><![CDATA[81312484395]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jason]]></first_name>
				<middle_name><![CDATA[Van]]></middle_name>
				<last_name><![CDATA[Hulse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830027</person_id>
				<author_profile_id><![CDATA[81100596670]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Taghi]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Khoshgoftaar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830028</person_id>
				<author_profile_id><![CDATA[81361598707]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Amri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Napolitano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830029</person_id>
				<author_profile_id><![CDATA[81453652426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Randall]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wald]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677193</article_id>
		<sort_key>920</sort_key>
		<display_label>Pages</display_label>
		<pages>515-520</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>89</seq_no>
		<title><![CDATA[Theoretically Optimal Distributed Anomaly Detection]]></title>
		<page_from>515</page_from>
		<page_to>520</page_to>
		<doi_number>10.1109/ICDMW.2009.40</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677193</url>
		<abstract>
			<par><![CDATA[A novel general framework for distributed anomaly detection with theoretical performance guarantees is proposed. Our algorithmic approach combines existing anomaly detection procedures with a novel method for computing global statistics using local sufficient statistics. Under a Gaussian assumption, our distributed algorithm is guaranteed to perform as well as its centralized counterpart, a condition we call &#8216;zero information loss&#8217;. We further report experimental results on synthetic as well as real-world data to demonstrate the viability of our approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831562</person_id>
				<author_profile_id><![CDATA[81100052105]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Aleksandar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lazarevic]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831563</person_id>
				<author_profile_id><![CDATA[81453608674]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nisheeth]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Srivastava]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831564</person_id>
				<author_profile_id><![CDATA[81453633206]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ashutosh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tiwari]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831565</person_id>
				<author_profile_id><![CDATA[81443597052]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Josh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Isom]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831566</person_id>
				<author_profile_id><![CDATA[81100418152]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Nikunj]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Oza]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831567</person_id>
				<author_profile_id><![CDATA[81453616325]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Jaideep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Srivastava]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677194</article_id>
		<sort_key>930</sort_key>
		<display_label>Pages</display_label>
		<pages>521-526</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>90</seq_no>
		<title><![CDATA[Hybrid Clustering by Integrating Text and Citation Based Graphs in Journal Database Analysis]]></title>
		<page_from>521</page_from>
		<page_to>526</page_to>
		<doi_number>10.1109/ICDMW.2009.65</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677194</url>
		<abstract>
			<par><![CDATA[We propose a hybrid clustering strategy by integrating heterogeneous information sources as graphs. The hybrid clustering method is extended on the basis of modularity based Louvain method. We introduce two different approaches, graph coupling and graph fusion. The weights of these combined graphs are optimized with the criterion of maximizing the Average Normalized Mutual Information(ANMI). The methods are applied to obtain structural mapping of large scale Web of Science (WoS) journal database by integrating attribute based textual information and relation based citation information. From the experimental, the proposed graph combination scheme is compared with individual graph clustering, spectral clustering and Vector Space Model(VSM) based clustering methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1827042</person_id>
				<author_profile_id><![CDATA[81464646093]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xinhai]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827043</person_id>
				<author_profile_id><![CDATA[81464648429]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827044</person_id>
				<author_profile_id><![CDATA[81100006328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yves]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Moreau]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827045</person_id>
				<author_profile_id><![CDATA[81318489516]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Frizo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Janssens]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827046</person_id>
				<author_profile_id><![CDATA[81100198267]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Bart]]></first_name>
				<middle_name><![CDATA[De]]></middle_name>
				<last_name><![CDATA[Moor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827047</person_id>
				<author_profile_id><![CDATA[81329488950]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Wolfgang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gl&#228;nzel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677195</article_id>
		<sort_key>940</sort_key>
		<display_label>Pages</display_label>
		<pages>527-532</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>91</seq_no>
		<title><![CDATA[Frequent Pattern Discovery from a Single Graph with Quantitative Itemsets]]></title>
		<page_from>527</page_from>
		<page_to>532</page_to>
		<doi_number>10.1109/ICDMW.2009.11</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677195</url>
		<abstract>
			<par><![CDATA[In this paper, we focus on a single graph whose vertices contain a set of quantitative attributes. Several networks can be naturally represented in this complex graph. An example is a social network whose vertex corresponds to a person with some quantitative items such as age, salary and so on. Although it can be expected that this kind of data will increase rapidly, most of current graph mining algorithms do not handle these complex graphs directly. Motivated by the above background, by effectively combining techniques of graph mining and quantitative itemset mining, we developed an algorithm named FAG-gSpan for finding frequent patterns from a graph with quantitative itemsets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1827048</person_id>
				<author_profile_id><![CDATA[81453649414]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yuuki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miyoshi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827049</person_id>
				<author_profile_id><![CDATA[81100275524]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tomonobu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ozaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827050</person_id>
				<author_profile_id><![CDATA[81100104240]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Takenao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ohkawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677196</article_id>
		<sort_key>950</sort_key>
		<display_label>Pages</display_label>
		<pages>533-538</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>92</seq_no>
		<title><![CDATA[Efficient Discovery of Closed Hyperclique Patterns in Multidimensional Structured Databases]]></title>
		<page_from>533</page_from>
		<page_to>538</page_to>
		<doi_number>10.1109/ICDMW.2009.10</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677196</url>
		<abstract>
			<par><![CDATA[Structured data is becoming increasingly abundant in many application domains recently. Furthermore, more complex but valuable databases will be obtained by combining plural structured databases. In this paper, we focus on "Multidimensional Structured Databases'' as one of the typical examples of such complex databases, and propose a new data mining problem of finding closed hyperclique patterns, i.e., closed sets of correlated patterns, in them. To solve this problem efficiently, an algorithm named CHPMS is proposed which effectively utilizes the generality ordering and the properties of correlation and closedness. The effectiveness of the proposed algorithm is confirmed through the experiments with real world datasets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830030</person_id>
				<author_profile_id><![CDATA[81100275524]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tomonobu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ozaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830031</person_id>
				<author_profile_id><![CDATA[81100104240]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Takenao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ohkawa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677197</article_id>
		<sort_key>960</sort_key>
		<display_label>Pages</display_label>
		<pages>539-544</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>93</seq_no>
		<title><![CDATA[Bucket Learning]]></title>
		<subtitle><![CDATA[Improving Model Quality through Enhancing Local Patterns]]></subtitle>
		<page_from>539</page_from>
		<page_to>544</page_to>
		<doi_number>10.1109/ICDMW.2009.66</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677197</url>
		<abstract>
			<par><![CDATA[It is always desirable to improve the quality of a global classification model with the existence of other models. In this work, \textit{Bucket Learning} methodology is first proposed to improve the model quality through enhancing its local patterns. We formally define the concept of slab as a tri-tuple $$, which unifies the data view, model view and evaluation view of a data mining task. The \textit{Bucket Learning} framework includes main modules of \textit{slab generation}, \textit{short slab discovery}, and \textit{short slab replacement} as necessary steps to improve the model's quality. Algorithms are designed to facilate the operations of quantifying the model merits, identifying the inferior local patterns and improving the global model. A prototype system is developed to verify the proposed methodology. The \textit{Bucket Learning} prototype system is evaluated on $16$ representative data sets from UCI data repository. Experimental results show that the improved model have an averaged \textit{F-measure} of $79.5\%$ with an improvement of $7.3\%$ from the original model learned by J48.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1824177</person_id>
				<author_profile_id><![CDATA[81453626641]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Guangzhi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Qu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1824178</person_id>
				<author_profile_id><![CDATA[81453646474]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677198</article_id>
		<sort_key>970</sort_key>
		<display_label>Pages</display_label>
		<pages>545-550</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>94</seq_no>
		<title><![CDATA[Improving Similarity Join Algorithms Using Fuzzy Clustering Technique]]></title>
		<page_from>545</page_from>
		<page_to>550</page_to>
		<doi_number>10.1109/ICDMW.2009.50</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677198</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a pre-processing technique to improve existing string similarity join algorithms using fuzzy clustering. Our approach first identifies groups of related attributes and then, using this information, we apply existing string similarity join algorithms on these attributes. To identify the clustered attributes we use fuzzy techniques. This approach can be applied to the integration of knowledge bases and databases, as well as handle inconsistent values and naming conventions, incorrect or missing data values, and incomplete information from multiple sources with semi-compatible attributes or homogenous attributes. Using an experimental study, we have shown our preprocessing approach improves existing string similarity join algorithms by about 10 percent on precision and recall.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1821101</person_id>
				<author_profile_id><![CDATA[81453634173]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lisa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821102</person_id>
				<author_profile_id><![CDATA[81100250083]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Farshad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fotouhi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821103</person_id>
				<author_profile_id><![CDATA[81100462414]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[William]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grosky]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821104</person_id>
				<author_profile_id><![CDATA[81100479648]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Horia]]></first_name>
				<middle_name><![CDATA[F.]]></middle_name>
				<last_name><![CDATA[Pop]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821105</person_id>
				<author_profile_id><![CDATA[81453636847]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Noureddine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mouaddib]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677199</article_id>
		<sort_key>980</sort_key>
		<display_label>Pages</display_label>
		<pages>551-557</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>95</seq_no>
		<title><![CDATA[Mining Data from Multiple Software Development Projects]]></title>
		<page_from>551</page_from>
		<page_to>557</page_to>
		<doi_number>10.1109/ICDMW.2009.78</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677199</url>
		<abstract>
			<par><![CDATA[A large system often goes through multiple software project development cycles, in part due to changes in operation and development environments. For example, rapid turnover of the development team between releases can influence software quality, making it important to mine software project data over multiple system releases when building defect predictors. Data collection of software attributes are often conducted independent of the quality improvement goals, leading to the availability of a large number of attributes for analysis. Given the problems associated with variations in development process, data collection, and quality goals from one release to another emphasizes the importance of selecting a best-set of software attributes for software quality prediction. Moreover, it is intuitive to remove attributes that do not add to, or have an adverse effect on, the knowledge of the consequent model. Based on real-world software projects&#8217; data, we present a large case study that compares wrapper-based feature ranking techniques (WRT) and our proposed hybrid feature selection (HFS) technique. The comparison is done using both threefold cross-validation (CV) and three-fold cross-validation with risk impact (CVR). It is shown that HFS is better than WRT, while CV is superior to CVR.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825608</person_id>
				<author_profile_id><![CDATA[81452603737]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[H.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825609</person_id>
				<author_profile_id><![CDATA[81502757620]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Khoshgoftaar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825610</person_id>
				<author_profile_id><![CDATA[81100132054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1825611</person_id>
				<author_profile_id><![CDATA[81100588068]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[N.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Seliya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677200</article_id>
		<sort_key>990</sort_key>
		<display_label>Pages</display_label>
		<pages>558-563</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>96</seq_no>
		<title><![CDATA[Mining for Core Patterns in Stock Market Data]]></title>
		<page_from>558</page_from>
		<page_to>563</page_to>
		<doi_number>10.1109/ICDMW.2009.115</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677200</url>
		<abstract>
			<par><![CDATA[We introduce an algorithm that uses stock sector information directly in conjunction with time series subsequences for mining core patterns within the sectors of stock market data. The core patterns within a sector are representative groups of stocks for the sector when it shows coherent behavior. Multiple core patterns may exist in a sector at the same time. In comparison with clustering algorithms, the core patterns are shown to be more stable as the stock price evolves. The proposed algorithm has only one free parameter, for which we provide an empirical choice. We demonstrate the effectiveness of the algorithm through a comparison with the DBScan clustering algorithm using data from the Standard and Poor 500 Index.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[core pattern]]></kw>
			<kw><![CDATA[desity histogram]]></kw>
			<kw><![CDATA[quasi-clique]]></kw>
			<kw><![CDATA[time series]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1821106</person_id>
				<author_profile_id><![CDATA[81448599756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jianfei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821107</person_id>
				<author_profile_id><![CDATA[81309485232]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Anne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Denton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821108</person_id>
				<author_profile_id><![CDATA[81453656221]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Omar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Elariss]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821109</person_id>
				<author_profile_id><![CDATA[81453613984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dianxiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677201</article_id>
		<sort_key>1000</sort_key>
		<display_label>Pages</display_label>
		<pages>564-570</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>97</seq_no>
		<title><![CDATA[Spatio-temporal Multi-dimensional Relational Framework Trees]]></title>
		<page_from>564</page_from>
		<page_to>570</page_to>
		<doi_number>10.1109/ICDMW.2009.95</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677201</url>
		<abstract>
			<par><![CDATA[The real world is composed of sets of objects that move and morph in both space and time. Useful concepts can be defined in terms of the complex interactions between the multi-dimensional attributes of subsets of these objects and of the relationships that exist between them. In this paper, we present Spatiotemporal Multi-dimensional Relational Framework (SMRF) Trees, a new data mining technique that extends the successful Spatiotemporal Relational Probability Tree models. From a set of labeled, multi-object examples of a target concept, our algorithm infers both the set of objects that participate in the concept and the key object and relation attributes that describe the concept. In contrast to other relational model approaches, SMRF trees do not rely on pre-defined relations between objects. Instead, our algorithm infers the relations from the continuous attributes. In addition, our approach explicitly acknowledges the multi-dimensional nature of attributes such as position, orientation and color. Our method performs well in exploratory experiments, demonstrating its viability as a relational learning approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1827093</person_id>
				<author_profile_id><![CDATA[81453652646]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bodenhamer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827094</person_id>
				<author_profile_id><![CDATA[81453651191]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Samuel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bleckley]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827095</person_id>
				<author_profile_id><![CDATA[81453652410]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fennelly]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827096</person_id>
				<author_profile_id><![CDATA[81453612538]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Fagg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827097</person_id>
				<author_profile_id><![CDATA[81100298011]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Amy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McGovern]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677202</article_id>
		<sort_key>1010</sort_key>
		<display_label>Pages</display_label>
		<pages>571-576</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>98</seq_no>
		<title><![CDATA[Spatiotemporal Modeling and Monitoring of Atmospheric Hazardous Emissions Using Sensor Networks]]></title>
		<page_from>571</page_from>
		<page_to>576</page_to>
		<doi_number>10.1109/ICDMW.2009.67</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677202</url>
		<abstract>
			<par><![CDATA[A spatiotemporal methodology is presented for the analysis and visualization of atmospheric emissions in a metropolitan area. Numerical transport and dispersion models are used to build a library of time-dependent emissions of hazardous gases under various atmospheric conditions and from multiple potential sources in Washington DC. This library comprises representative emergency events that may involve natural or man-made hazardous emissions. To represent and analyze the events of this library we use the model of the spatiotemporal helix, which provides concise summaries of complex spatiotemporal events. We demonstrate the ability to compare emerging situations to library entries in order to predict their future evolution, thus recognizing potentially hazardous conditions early in their development.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830061</person_id>
				<author_profile_id><![CDATA[81100269929]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Guido]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cervone]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830062</person_id>
				<author_profile_id><![CDATA[81100308467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stefanidis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830063</person_id>
				<author_profile_id><![CDATA[81392602274]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Pasquale]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Franzese]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830064</person_id>
				<author_profile_id><![CDATA[81100005592]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Peggy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Agouris]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677214</article_id>
		<sort_key>1020</sort_key>
		<display_label>Pages</display_label>
		<pages>577-582</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>99</seq_no>
		<title><![CDATA[Multi-granularity Visualization of Trajectory Clusters Using Sub-trajectory Clustering]]></title>
		<page_from>577</page_from>
		<page_to>582</page_to>
		<doi_number>10.1109/ICDMW.2009.24</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677214</url>
		<abstract>
			<par><![CDATA[With the surging of the requirements of location-based services, mining various interesting patterns from the spatial data becomes more and more important. In this paper, we propose an approach for visualizing the trajectory clustering results based on sub-trajectory clusters discovered from large-scale trajectory data. At first, we segment each trajectory into a set of sub-trajectories by detecting its corner points. And then, we choose Fr&#233;chet distance to compute the similarity between sub-trajectories, and use a density-based clustering method to cluster sub-trajectories and get an augmented order of the sub-trajectories. The visualization method can support multi-granularity views of the generated sub-trajectory clusters. Experiments have demonstrated the applicability and benefits of the proposed approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1821148</person_id>
				<author_profile_id><![CDATA[81453650315]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821149</person_id>
				<author_profile_id><![CDATA[81453632044]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Baoyao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677215</article_id>
		<sort_key>1030</sort_key>
		<display_label>Pages</display_label>
		<pages>583-590</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>100</seq_no>
		<title><![CDATA[Deriving Low-Level Steering Behaviors from Trajectory Data]]></title>
		<page_from>583</page_from>
		<page_to>590</page_to>
		<doi_number>10.1109/ICDMW.2009.76</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677215</url>
		<abstract>
			<par><![CDATA[Emergent behavior, such as flocks and swarms appears in numerous multi-agent systems in nature. Such behaviors emerge not through centralized high-level control, but through low-level local interactions between each agent and its immediate environment. The understanding of individual local interactions between agents within a group is therefore essential for the understanding of emergent group behaviors. The focus of recent work has been primarily on developing tools for the detection and mining of group behaviors (e. g., spatiotemporal clusters), without offering the ability to link such behaviors to individual agent behavior. Focusing on steering behaviors, this work aims to address this gap by developing a methodology for estimating agent steering behaviors that would explain the emergent group behavior observed in trajectory data. In particular, we present a particle swarm optimization-based tracking scheme for deriving agent steering behaviors based on Reynolds' boids model. The paper formally outlines the low-level agent behavior derivation problem and discusses our proposed methodology. In addition, results from implementing our approach on real-world data are presented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831656</person_id>
				<author_profile_id><![CDATA[81300092001]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Arie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Croitoru]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677216</article_id>
		<sort_key>1040</sort_key>
		<display_label>Pages</display_label>
		<pages>591-596</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>101</seq_no>
		<title><![CDATA[Greedy Optimization for Contiguity-Constrained Hierarchical Clustering]]></title>
		<page_from>591</page_from>
		<page_to>596</page_to>
		<doi_number>10.1109/ICDMW.2009.75</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677216</url>
		<abstract>
			<par><![CDATA[The discovery and construction of inherent regions in large spatial datasets is an important task for many research domains such as climate zoning, eco-region analysis, public health mapping, and political redistricting. From the perspective of cluster analysis, it requires that each cluster is geographically contiguous. This paper presents a contiguity constrained hierarchical clustering and optimization method that can partition a set of spatial objects into a hierarchy of contiguous regions while optimizing an objective function. The method consists of two steps: contiguity constrained hierarchical clustering and two-way fine-tuning. The above two steps are repeated to create a hierarchy of regions. Evaluations and comparison show that the proposed method consistently and significantly outperforms existing methods by a large margin in terms of optimizing the objective function. Moreover, the method is flexible to accommodate different objective functions and additional constraints (such as the minimum size of each region), which are useful to for various application domains.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1825645</person_id>
				<author_profile_id><![CDATA[81453608652]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Diansheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Guo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677217</article_id>
		<sort_key>1050</sort_key>
		<display_label>Pages</display_label>
		<pages>597-603</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>102</seq_no>
		<title><![CDATA[Spatially Adaptive Classification and Active Learning of Multispectral Data with Gaussian Processes]]></title>
		<page_from>597</page_from>
		<page_to>603</page_to>
		<doi_number>10.1109/ICDMW.2009.107</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677217</url>
		<abstract>
			<par><![CDATA[Multispectral remote sensing images are widely used for automated land use and land cover classification tasks. Remotely sensed images usually cover large geographical areas, and spectral characteristics of each class often varies over time and space. We apply a spatially adaptive classification scheme that models spatial variation with Gaussian processes, and apply uncertainty sampling based active learning algorithm to achieve better classification accuracies with a fewer number of samples. The spatially adaptive classifier shows better performances than the conventional maximum likelihood classifier in both passive and active learning settings, and the active learners achieves better classification accuracies than passive learners with fewer number of samples for both classification algorithms.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822755</person_id>
				<author_profile_id><![CDATA[81435593804]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Goo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822756</person_id>
				<author_profile_id><![CDATA[81100528438]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ranga]]></first_name>
				<middle_name><![CDATA[Raju]]></middle_name>
				<last_name><![CDATA[Vatsavai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822757</person_id>
				<author_profile_id><![CDATA[81100558602]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Joydeep]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ghosh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677218</article_id>
		<sort_key>1060</sort_key>
		<display_label>Pages</display_label>
		<pages>604-609</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>103</seq_no>
		<title><![CDATA[FARM]]></title>
		<subtitle><![CDATA[Feature-Assisted Aggregate Route Mining in Trajectory Data]]></subtitle>
		<page_from>604</page_from>
		<page_to>609</page_to>
		<doi_number>10.1109/ICDMW.2009.31</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677218</url>
		<abstract>
			<par><![CDATA[An aggregate route of a set of trajectories is the representative movement direction of the set. Existing solutions address the problem of finding representative routes by finding clusters in the data with minimum intra-cluster deviation and then deriving a simplified trajectory to represent each cluster. However, existing similarity measures for trajectories are not discriminative and are sensitive to noise. This paper presents FARM, a framework for extracting aggregate routes from trajectory data. FARM first transforms the trajectories into a feature space. Next, it applies spectral clustering to find clusters in the feature space. Finally, we find a representative route for each cluster obtained. Experimental studies demonstrate the effectiveness of the proposed method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1827130</person_id>
				<author_profile_id><![CDATA[81453611488]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shrikant]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kashyap]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827131</person_id>
				<author_profile_id><![CDATA[81453605758]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sujoy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Roy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827132</person_id>
				<author_profile_id><![CDATA[81453605902]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mong]]></first_name>
				<middle_name><![CDATA[Li]]></middle_name>
				<last_name><![CDATA[lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827133</person_id>
				<author_profile_id><![CDATA[81350592750]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wynne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hsu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677219</article_id>
		<sort_key>1070</sort_key>
		<display_label>Pages</display_label>
		<pages>610-615</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>104</seq_no>
		<title><![CDATA[K-BestMatch Reconstruction and Comparison of Trajectory Data]]></title>
		<page_from>610</page_from>
		<page_to>615</page_to>
		<doi_number>10.1109/ICDMW.2009.62</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677219</url>
		<abstract>
			<par><![CDATA[In this paper we propose a map matching method to overcoming the limitations of standard best-match reconstruction strategies. We use a more flexible approach which consider the k-optimal alternative paths to reconstruct the trajectories from the GPS raw data. The preliminary results, obtained on a real dataset of car users in Milan area, suggest that our method leads to beneficial effects on the successive analysis to be performed such as KNN and clustering.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1827134</person_id>
				<author_profile_id><![CDATA[81100522716]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mirco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nanni]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827135</person_id>
				<author_profile_id><![CDATA[81313481541]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Roberto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Trasarti]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677225</article_id>
		<sort_key>1080</sort_key>
		<display_label>Pages</display_label>
		<pages>616-621</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>105</seq_no>
		<title><![CDATA[Analyzing Abnormal Events from Spatio-temporal Trajectories]]></title>
		<page_from>616</page_from>
		<page_to>621</page_to>
		<doi_number>10.1109/ICDMW.2009.45</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677225</url>
		<abstract>
			<par><![CDATA[Advances in RFID based sensor technologies has been used in applications which requires the tracking of assets, products and individuals. The recording of such movements is captured in a trajectory database and can be analyzed for the monitoring of abnormal events. In this paper, we describe a system called InViTA for analyzing abnormal events from spatio-temporal trajectories captured during an office evacuation after an explosion. InViTA utilizes a trajectory representation scheme and extract the features to derive a set of rules that label each person's trajectory as belonging to a suspect, witness, or victim, etc. We run the system on the office evacuation data provided in VAST 2008 challenge and obtain comparable results with that obtained from visualization and human analysis. The system includes a user-friendly graphical interface for parameter tuning and intuitive result analysis.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1831695</person_id>
				<author_profile_id><![CDATA[81323494659]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dhaval]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Patel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831696</person_id>
				<author_profile_id><![CDATA[81453609747]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chidansh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bhatt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831697</person_id>
				<author_profile_id><![CDATA[81350592750]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wynne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hsu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831698</person_id>
				<author_profile_id><![CDATA[81100386574]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Mong]]></first_name>
				<middle_name><![CDATA[Li]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1831699</person_id>
				<author_profile_id><![CDATA[81453647671]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Mohan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kankanhalli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677226</article_id>
		<sort_key>1090</sort_key>
		<display_label>Pages</display_label>
		<pages>622-629</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>106</seq_no>
		<title><![CDATA[Multilayer Scene Similarity Assessment]]></title>
		<page_from>622</page_from>
		<page_to>629</page_to>
		<doi_number>10.1109/ICDMW.2009.117</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677226</url>
		<abstract>
			<par><![CDATA[As we move increasingly towards multi-source data analysis, the assessment of similarity of complex, multilayer scenes is becoming increasingly important for spatial data mining. In this paper, we present a content-based approach for scene similarity assessment. The proposed approach is based on a graph-matching scheme that models linear feature networks (road network) as graphs and additional GIS information (e.g. buildings) as layer content. This allows us to combine diverse but co-located pieces of information (e.g. roads and buildings) in an integrated similarity assessment process. In the paper we present key theoretical concepts and provide experimental results to demonstrate the capability and robustness of the proposed approach.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graph]]></kw>
			<kw><![CDATA[road network]]></kw>
			<kw><![CDATA[scene query]]></kw>
			<kw><![CDATA[similarity]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1822790</person_id>
				<author_profile_id><![CDATA[81100308467]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stefanidis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822791</person_id>
				<author_profile_id><![CDATA[81453617254]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Caixia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822792</person_id>
				<author_profile_id><![CDATA[81453643400]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Lu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1822793</person_id>
				<author_profile_id><![CDATA[81453655994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Curtin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677227</article_id>
		<sort_key>1100</sort_key>
		<display_label>Pages</display_label>
		<pages>630-635</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>107</seq_no>
		<title><![CDATA[Spatiotemporal Relational Random Forests]]></title>
		<page_from>630</page_from>
		<page_to>635</page_to>
		<doi_number>10.1109/ICDMW.2009.89</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677227</url>
		<abstract>
			<par><![CDATA[We introduce and validate Spatiotemporal Relational Random Forests, which are random forests created with spatiotemporal relational probability trees. We build on the documented success of random forests by bringing spatiotemporal capabilities to the trees, enabling them to identify critical spatial, temporal, and spatiotemporal features in the data. We validate our results on simulated data and real-world convectively-induced turbulence data from a commercial airline flying in the continental United States.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1821169</person_id>
				<author_profile_id><![CDATA[81453661531]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Timothy]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Supinie]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821170</person_id>
				<author_profile_id><![CDATA[81100298011]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Amy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McGovern]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821171</person_id>
				<author_profile_id><![CDATA[81453649027]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Williams]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821172</person_id>
				<author_profile_id><![CDATA[81453636129]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jennifer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Abernathy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677228</article_id>
		<sort_key>1110</sort_key>
		<display_label>Pages</display_label>
		<pages>636-643</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>108</seq_no>
		<title><![CDATA[Accurate Discovery of Valid Convoys from Moving Object Trajectories]]></title>
		<page_from>636</page_from>
		<page_to>643</page_to>
		<doi_number>10.1109/ICDMW.2009.71</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677228</url>
		<abstract>
			<par><![CDATA[Given a set of moving object trajectories, it is of interest to find a group of objects, called a convoy, that are spatially density-connected for a certain duration of time. However, existing convoy discovery algorithms have a critical problem of accuracy; they tend to both miss larger convoys and retrieve invalid ones where the density-connectivity among the objects is not completely satisfied. We propose a new valid convoy discovery algorithm, called VCoDA, for the accurate discovery of valid convoys from moving object trajectories. Specifically, VCoDA first retrieves all partially connected convoys while guaranteeing no false dismissal of any valid convoys and then validates their density-connectivity to eventually obtain a complete set of valid convoys. Our extensive experiments on three real-world datasets demonstrate the effectiveness of our technique; VCoDA improves the precision by a factor of 3 on average and the recall by up to 2 orders of magnitude as compared to an existing method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1827163</person_id>
				<author_profile_id><![CDATA[81453644665]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hyunjin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yoon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827164</person_id>
				<author_profile_id><![CDATA[81100616904]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Cyrus]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shahabi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677229</article_id>
		<sort_key>1120</sort_key>
		<display_label>Pages</display_label>
		<pages>644-649</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>109</seq_no>
		<title><![CDATA[A Semi-supervised Framework for Simultaneous Classification and Regression of Zero-Inflated Time Series Data with Application to Precipitation Prediction]]></title>
		<page_from>644</page_from>
		<page_to>649</page_to>
		<doi_number>10.1109/ICDMW.2009.80</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677229</url>
		<abstract>
			<par><![CDATA[Time series data with abundant number of zeros are common in many applications, including climate and ecological modeling, disease monitoring, manufacturing defect detection, and traffic accident monitoring. Classical regression models are inappropriate to handle data with such skewed distribution because they tend to underestimate the frequency of zeros and the magnitude of non-zero values in the data. This paper presents a hybrid framework that simultaneously perform classification and regression to accurately predict future values of a zero-inflated time series. A classifier is initially used to determine whether the value at a given time step is zero while a regression model is invoked to estimate its magnitude only if the predicted value has been classified as nonzero. The proposed framework is extended to a semi-supervised learning setting via graph regularization. The effectiveness of the framework is demonstrated via its application to the precipitation prediction problem for climate impact assessment studies.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1828692</person_id>
				<author_profile_id><![CDATA[81387608180]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zubin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Abraham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1828693</person_id>
				<author_profile_id><![CDATA[81453617024]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pang-Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677230</article_id>
		<sort_key>1130</sort_key>
		<display_label>Pages</display_label>
		<pages>650-655</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>110</seq_no>
		<title><![CDATA[Visualization and Classification of Power System Frequency Data Streams]]></title>
		<page_from>650</page_from>
		<page_to>655</page_to>
		<doi_number>10.1109/ICDMW.2009.104</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677230</url>
		<abstract>
			<par><![CDATA[Two challenges in the realization of the smart grid technology are the ability to visualize the deluge of expected data streams for global situational awareness; as well as the ability to detect disruptive and classify such events from spatially-distributed high-speed power system frequency measurements. This paper presents an interactive visualization model for high speed power system frequency data streams that displays both local and global views of the data streams for decision making process. It also presents a K-Median approach for clustering and identifying disruptive events in spatially distributed data streams. The results from experimental evaluation on a variety of datasets show that K-Median achieve better performance and empowers analysts with the ability to make sense of a deluge of frequency measurements in a real-time situation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1821173</person_id>
				<author_profile_id><![CDATA[81453632025]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jason]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Bank]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821174</person_id>
				<author_profile_id><![CDATA[81453625778]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Olufemi]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Omitaomu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821175</person_id>
				<author_profile_id><![CDATA[81453608340]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Fernandez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1821176</person_id>
				<author_profile_id><![CDATA[81453642625]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Yilu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677237</article_id>
		<sort_key>1140</sort_key>
		<display_label>Pages</display_label>
		<pages>656-661</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>111</seq_no>
		<title><![CDATA[Information Services and Middleware for the Coastal Sensor Web]]></title>
		<page_from>656</page_from>
		<page_to>661</page_to>
		<doi_number>10.1109/ICDMW.2009.108</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677237</url>
		<abstract>
			<par><![CDATA[It is well recognized that semantic conflicts are responsible for the most serious data heterogeneity problems hindering the efficient interoperability between heterogeneous information sources. In recent years, ontologies are widely used as a means for solving the information heterogeneity problems because of their capability to provide explicit meaning to the information. Several organizations are undertaking the development of domain specific ontlolgies to resolve the semantic ambiguities between various domain specific representations. These ontologies designed for a particular task could be a unique representation of their project needs. Hence, there arises a need to align heterogeneous ontologies to facilitate meaningful knowledge interchange between various sources. Thus, ontology mapping has emerged as an important requirement to enable semantic interoperability between different representations within a domain. In this paper we focus on the semantic heterogeneities present in the coastal information sources whose data are highly heterogeneous in syntax, structure and semantics. Ontological modeling was carried out for the various information sources. A data mining approach was adopted to align the concepts belonging to various land cover ontologies. We present a set of standardized information services and middleware for seamless access to information from various networks.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1827181</person_id>
				<author_profile_id><![CDATA[81392605519]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Surya]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Durbha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827182</person_id>
				<author_profile_id><![CDATA[81416599753]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Roger]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[King]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827183</person_id>
				<author_profile_id><![CDATA[81453652697]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Santhosh]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Amanchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827184</person_id>
				<author_profile_id><![CDATA[81392617480]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Shruthi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bheemireddy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827185</person_id>
				<author_profile_id><![CDATA[81343509282]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Nicolas]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Younan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677238</article_id>
		<sort_key>1150</sort_key>
		<display_label>Pages</display_label>
		<pages>662-667</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>112</seq_no>
		<title><![CDATA[Enhancing the DBSCAN and Agglomerative Clustering Algorithms to Solve Network Planning Problem]]></title>
		<page_from>662</page_from>
		<page_to>667</page_to>
		<doi_number>10.1109/ICDMW.2009.98</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677238</url>
		<abstract>
			<par><![CDATA[With existing telephone networks nearing saturation and demand for wire and wireless services continuing to grow, telecommunication engineers are looking at technologies that will deliver sites and can satisfy the required demand and grade of service constraints while achieving minimum possible costs. The city data is given as a map of streets, intersection nodes coordinates, distribution of the subscribers&#8217; loads within the city and the location of base station in mobile network in this city. The available cable sizes, the cost per unit for each size and the maximum distance of wire that satisfied the allowed grade of service. NetPlan (Network Planning package) is developed in the spirit of DBSCAN and Agglomerative clustering algorithms. In this paper we studied the problem of congestion in Multi Service Access Node (MSAN) due to the increasing the number of subscribers which cause degradation in grade of service and in some time impossible to add new subscribers. The NetPlan algorithm is introduced to solve this problem. This algorithm is Density-based clustering algorithm using physical shortest paths available routes and the subscriber loads. In other hand decreasing the cost also is our deal in this paper so in the second phase in clustering process we modify the agglomerative algorithm that merge the neighboring cluster which satisfying certain condition. Experimental results and analysis indicate that the combination to algorithms was effective, leads to minimum costs for network construction and make the best grade of service.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1827186</person_id>
				<author_profile_id><![CDATA[81100633712]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lamia]]></first_name>
				<middle_name><![CDATA[Fattouh]]></middle_name>
				<last_name><![CDATA[Ibrahim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827187</person_id>
				<author_profile_id><![CDATA[81453656073]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Weam]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Minshawi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827188</person_id>
				<author_profile_id><![CDATA[81453660535]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Isra]]></first_name>
				<middle_name><![CDATA[Yosef]]></middle_name>
				<last_name><![CDATA[Ekkab]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827189</person_id>
				<author_profile_id><![CDATA[81453661877]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Nehal]]></first_name>
				<middle_name><![CDATA[Mahmoud]]></middle_name>
				<last_name><![CDATA[Al-Jurf]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827190</person_id>
				<author_profile_id><![CDATA[81453659334]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Afnan]]></first_name>
				<middle_name><![CDATA[Salem]]></middle_name>
				<last_name><![CDATA[Babrahim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1827191</person_id>
				<author_profile_id><![CDATA[81453652800]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Samar]]></first_name>
				<middle_name><![CDATA[Faisl]]></middle_name>
				<last_name><![CDATA[Al-Halees]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677239</article_id>
		<sort_key>1160</sort_key>
		<display_label>Pages</display_label>
		<pages>668-673</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>113</seq_no>
		<title><![CDATA[Fast Visual Trajectory Analysis Using Spatial Bayesian Networks]]></title>
		<page_from>668</page_from>
		<page_to>673</page_to>
		<doi_number>10.1109/ICDMW.2009.44</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677239</url>
		<abstract>
			<par><![CDATA[During the past years the first tools for visual analysis of trajectory data appeared. Considering the growing sizes of trajectory collections, one important task is to ensure user interactivity during data analysis. In this paper we present a fast, model-based visualization approach for the analysis of location dependencies in large trajectory collections. Existing approaches are not suitable for visual dependency analysis as the size and complexity of trajectory data constrain ad hoc and advance computations. Also recent developments in the area of trajectory data warehouses cannot be applied because the spatial correlations are lost during trajectory aggregation. Our approach builds a compact model which represents the dependency structures of the data. The visualisation toolkit then interacts only with the model and is thus independent of the size of the underlying trajectory database. More precisely, we build a Bayesian Network model using the Scalable Sparse Bayesian Network Learning (SSBNL) algorithm, which we improve to represent also negative correlations. We implement our approach into the GIS MapInfo using MapBasic scripts for the user interface and an independent mediator script to retrieve patterns from the model. We demonstrate our approach using mobile phone data of the city of Milan, Italy.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1830215</person_id>
				<author_profile_id><![CDATA[81392599684]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liebig]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830216</person_id>
				<author_profile_id><![CDATA[81331496761]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[K&#246;rner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1830217</person_id>
				<author_profile_id><![CDATA[81406593989]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[May]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677213</article_id>
		<sort_key>1170</sort_key>
		<display_label>Pages</display_label>
		<pages>674-679</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>114</seq_no>
		<title><![CDATA[Author Index]]></title>
		<page_from>674</page_from>
		<page_to>679</page_to>
		<doi_number>10.1109/ICDMW.2009.112</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677213</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>1677240</article_id>
		<sort_key>1180</sort_key>
		<display_label>Page</display_label>
		<pages>680</pages>
		<article_publication_date>12-06-2009</article_publication_date>
		<seq_no>115</seq_no>
		<title><![CDATA[Publisher's Information]]></title>
		<page_from>680</page_from>
		<doi_number>10.1109/ICDMW.2009.113</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1677240</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
</content>
</proceeding>

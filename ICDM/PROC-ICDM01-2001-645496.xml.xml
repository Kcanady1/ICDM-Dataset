<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>11-29-2001</start_date>
		<end_date>12-02-2001</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[]]></city>
		<state></state>
		<country></country>
	</conference_loc>
	<conference_url>http://computer.org/proceedings/icdm/2001/1119</conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES11036</series_id>
		<series_title><![CDATA[ICDM]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>645496</proc_id>
	<acronym>ICDM '01</acronym>
	<proc_desc>Proceedings of the 2001 IEEE International Conference</proc_desc>
	<conference_number></conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Data Mining</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn>0-7695-1119-8</isbn>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2001</copyright_year>
	<publication_date>11-29-2001</publication_date>
	<pages></pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<publisher>
		<publisher_id>PUB769</publisher_id>
		<publisher_code>IEEEW</publisher_code>
		<publisher_name>IEEE Computer Society</publisher_name>
		<publisher_address>1730 Massachusetts Ave., NW             Washington, DC</publisher_address>
		<publisher_city></publisher_city>
		<publisher_state></publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>20036-1992</publisher_zip_code>
		<publisher_contact></publisher_contact>
		<publisher_phone></publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url></publisher_url>
	</publisher>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<chair_editor>
		<ch_ed>
			<person_id>PP14102013</person_id>
			<author_profile_id><![CDATA[81100270029]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Nick]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Cercone]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Editor]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>PP39100817</person_id>
			<author_profile_id><![CDATA[81385604385]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>2</seq_no>
			<first_name><![CDATA[Tsau]]></first_name>
			<middle_name><![CDATA[Young]]></middle_name>
			<last_name><![CDATA[Lin]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Editor]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>PP39115702</person_id>
			<author_profile_id><![CDATA[81452596559]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>3</seq_no>
			<first_name><![CDATA[Xindong]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Wu]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[]]></affiliation>
			<role><![CDATA[Editor]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
</proceeding_rec>
<content>
	<article_rec>
		<article_id>878511</article_id>
		<sort_key>.13</sort_key>
		<display_label></display_label>
		<pages>xiii</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Welcome from the Steering Committee Chair]]></title>
		<page_from>.13</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=878511</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>878513</article_id>
		<sort_key>.15</sort_key>
		<display_label></display_label>
		<pages>xv</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Message from the Program Chairs]]></title>
		<page_from>.15</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=878513</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>878512</article_id>
		<sort_key>.17</sort_key>
		<display_label></display_label>
		<pages>xvii</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Conference Organization]]></title>
		<page_from>.17</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=878512</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>878508</article_id>
		<sort_key>.18</sort_key>
		<display_label></display_label>
		<pages>xviii</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Steering Committee]]></title>
		<page_from>.18</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=878508</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>878509</article_id>
		<sort_key>.19</sort_key>
		<display_label></display_label>
		<pages>xix</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Program Committee]]></title>
		<page_from>.19</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=878509</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>878510</article_id>
		<sort_key>.21</sort_key>
		<display_label></display_label>
		<pages>xxi</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Non-PC Reviewers]]></title>
		<page_from>.21</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=878510</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>878516</article_id>
		<sort_key>1</sort_key>
		<display_label></display_label>
		<pages>11</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[Comparisons of Classification Methods for Screening Potential Compounds]]></title>
		<page_from>1</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=878516</url>
		<abstract>
			<par><![CDATA[We compare a number of data mining and statistical methods on the drug design problem of modeling molecular structure-activity relationships. The relationships can be use to identify active compounds base on their chemical structures from a large inventory of chemical compounds. The data set of this application has a highly skewed class distribution, in which only 2%of the compounds are considered active. We apply a number of classification methodsto this extremely imbalance data set and propose to use different performance measures to evaluate these methods. We report our findings on the characteristics of theperformance measures, the effect of using pruning techniques in this application and a comparison of local learning methodswith global techniques. We also investigate whetherreducing the imbalance in the training data by up-sampling or down-sampling would improve the predictive performance.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658021</article_id>
		<sort_key>3</sort_key>
		<display_label></display_label>
		<pages>3</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[On Effective Conceptual Indexing and Similarity Search in Text Data]]></title>
		<page_from>3</page_from>
		<page_to>10</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658021</url>
		<abstract>
			<par><![CDATA[Similarity search in text has proven to be an interesting problem from the qualitative perspective because of inherent redundancies and ambiguities in textual descriptions. The methods used in search engines in order to retrieve documents most similar to user-defined sets of keywords are not applicable to targets which are medium to large size documents, because of even greater noise effects stemming from the presence of a large number of words unrelated to the overall topic in the document. The inverted representation is the dominant method for indexing text, but it is not as suitable for document-to-document similarity search, as for short user-queries. One way of improving the quality of similarity search is Latent Semantic Indexing (LSI), which maps the documents from the original set of words to a concept space. U fortunately, LSI maps the data into a domain in which it is not possible to provide effectiveindexing techniques. In this paper, we investigate new ways of providing conceptual search among documents bycreating a representation in terms of conceptual word-chains. This technique also allows effective indexing techniques so that similarity queries ca be performed on large collectionsof documents by accessing a small amount of data. We demonstrate that our scheme outperforms standard textual similarity search o the inverted representation both in terms of quality a d search efficiency.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14020603</person_id>
				<author_profile_id><![CDATA[81350594201]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Charu]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Aggarwal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P226577</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657856</article_id>
		<sort_key>11</sort_key>
		<display_label></display_label>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Comparisons of Classification Methods for Screening Potential Compounds]]></title>
		<page_from>11</page_from>
		<page_to>18</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657856</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP310830100</person_id>
				<author_profile_id><![CDATA[81541079856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Aijun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[An]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40025174</person_id>
				<author_profile_id><![CDATA[81100232777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yuanyuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657885</article_id>
		<sort_key>19</sort_key>
		<display_label></display_label>
		<pages>19</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[Knowledge Discovery from Diagrammatically Represented Data]]></title>
		<page_from>19</page_from>
		<page_to>26</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657885</url>
		<abstract>
			<par><![CDATA[Knowledge discover from diagrammatic data can be facilitated by a language that permits queries on such data.Such a language (diagrammatic SQL) is being developed to expedite the development of an autonomous artificially intelligent agent with a capacity to deal with diagrammatic information.This language is described and examples of how it can be used to facilitatediagrammatic data mining are detaled]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP77044242</person_id>
				<author_profile_id><![CDATA[81100101207]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Anderson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658059</article_id>
		<sort_key>27</sort_key>
		<display_label></display_label>
		<pages>27</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Integrating E-Commerce and Data Mining]]></title>
		<subtitle><![CDATA[Architecture and Challenges]]></subtitle>
		<page_from>27</page_from>
		<page_to>34</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658059</url>
		<abstract>
			<par><![CDATA[We show that the e-commerce domain can provide all the right ingredients for successful data mining. We describe an integrate architecture for supporting this integration. Thearchitecture can dramatically reduce the pre-processing, cleaning, and data understanding effort often documented to take 80%of the time in knowledge discovery projects. We emphasize the need for data collection at the application server layer (not the web server)in order to support logging of data and metadata that is essential to the discovery process. We describe the datatransformation bridges require from the transaction processing systems an customer event streams (e.g.,clickstreams) to the data warehouse. We detail the mining workbench, which needs to provide multiple views of the data through reporting, data mining algorithms, visualization, and OLAP. We conclude with a set of challenges.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P495885</person_id>
				<author_profile_id><![CDATA[81100305469]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Suhail]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ansari]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43140623</person_id>
				<author_profile_id><![CDATA[81342500850]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ron]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kohavi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P172814</person_id>
				<author_profile_id><![CDATA[81100340921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Llew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mason]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP310860300</person_id>
				<author_profile_id><![CDATA[81310484563]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Zijian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zheng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657857</article_id>
		<sort_key>35</sort_key>
		<display_label></display_label>
		<pages>35</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>12</seq_no>
		<title><![CDATA[Classification with Degree of Membership]]></title>
		<subtitle><![CDATA[A Fuzzy Approach]]></subtitle>
		<page_from>35</page_from>
		<page_to>42</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657857</url>
		<abstract>
			<par><![CDATA[algorithms adopt either a decision tree based approach or an approach that requires users to provide some user-specifiedthresholds to guide the search for interesting rules. In this paper, we propose a new approach based on the use of an objective interestingness measure todistinguish interesting rules from uninteresting ones. Using linguistic terms to represent the revealed regularities and exceptions, this approach s especially useful when the discovered rules are presented to human experts for examination because of the affinity with thehuman knowledge representation. The use of fuzzy technique allows the predict on of attribute values to be associated with degree of membership. Our approach s, therefore, able to deal with the cases that an object can belong to more than one class. For example, a person can suffer from cold and fever to certain extent at the same time. Furthermore, our approach is more resilient to noise and missing data values because of the use of fuzzy technique. To evaluate the performance of our approach, we tested it using several real-life databases. The experimental results show that it can be very effective at data mining tasks. In fact, when compared to popular data mining algorithms, our approach can be better ableto uncover useful rules hidden in databases.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P295977</person_id>
				<author_profile_id><![CDATA[81100100540]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wai-Ho]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Au]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37024739</person_id>
				<author_profile_id><![CDATA[81100177764]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Keith]]></first_name>
				<middle_name><![CDATA[C. C.]]></middle_name>
				<last_name><![CDATA[Chan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658060</article_id>
		<sort_key>43</sort_key>
		<display_label></display_label>
		<pages>43</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>13</seq_no>
		<title><![CDATA[Provably Fast Training Algorithms for Support Vector Machines]]></title>
		<page_from>43</page_from>
		<page_to>50</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658060</url>
		<abstract>
			<par><![CDATA[Support Vector Machines are a family of data analysis algorithms, based on convex Quadratic Programming. We focus on their use for classification that case the SVM algorithms work by maximizing the margin of a classifying hyperplane in a feature space. The feature space is handled by means of kernels f the problems are formulated in dual form. Random Sampling techniques successfully used for similar problems are studied here. The main contribute onis a random zed algorithm for training SVMs for which we can formally prove an upper bound on the expected running time that is quasilinear on the number of data points. To ourknowledge, this is the first algorithm for training SVMs in dual formulation and with kernels for which such a quasi-linear time bound has been formally proved.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P148093</person_id>
				<author_profile_id><![CDATA[81100489969]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jos&#233;]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Balc&#225;zar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14070442</person_id>
				<author_profile_id><![CDATA[81100172132]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14129880</person_id>
				<author_profile_id><![CDATA[81100363767]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Osamu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Watanabe]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>757722</article_id>
		<sort_key>51</sort_key>
		<display_label></display_label>
		<pages>51</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>14</seq_no>
		<title><![CDATA[Who Links to Whom]]></title>
		<subtitle><![CDATA[Mining Linkage between Web Sites]]></subtitle>
		<page_from>51</page_from>
		<page_to>58</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=757722</url>
		<abstract>
			<par><![CDATA[Previous studies of the web graph structure have focused on the graph structure at the level of individual pages. In actuality the web is a hierarchically nested graph, with domains, hosts and web sites introducing intermediate levels of affiliation and administrativecontrol. To better understand the growth of the web we need to understand its macro-structure, in terms of the linkage between web sites. In this paper e approximate this by studying the graph of the linkage between hosts on the web. This as done based on snapshots of the web taken by Google in Oct 1999,Aug 2000 and Jun 2001.The connectivity between hosts is represented by a directed graph, with hosts as nodes and weighted edges representingthe count of hyperlinks between pages on the corresponding hosts. We demonstrate how such a "hostgraph" an be used to study connectivity properties of hosts and domains over time, anddiscuss a modified "copy model" too explain observed link eight distributions as a function of subgraph size. We discuss changes in the web over time in the size and connectivity of web sites and country domains. We also describe a data mining application of the hostgraph: a related host finding algorithm which achieves a precision of 0.65 at rank 3.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39048930</person_id>
				<author_profile_id><![CDATA[81100567677]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Krishna]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bharat]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P28374</person_id>
				<author_profile_id><![CDATA[81100247192]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bay-Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P202716</person_id>
				<author_profile_id><![CDATA[81100031872]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Monika]]></first_name>
				<middle_name><![CDATA[Rauch]]></middle_name>
				<last_name><![CDATA[Henzinger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP37025857</person_id>
				<author_profile_id><![CDATA[81100271470]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Matthias]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ruhl]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658191</article_id>
		<sort_key>59</sort_key>
		<display_label></display_label>
		<pages>59</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>15</seq_no>
		<title><![CDATA[Better Rules, Few Features]]></title>
		<subtitle><![CDATA[A Semantic Approach to Selecting Features from Text]]></subtitle>
		<page_from>59</page_from>
		<page_to>66</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658191</url>
		<abstract>
			<par><![CDATA[The choice of features used to represent a domain has a profound effect on the quality of the model produced; yet, few researchers have investigated the relationship between the features used to represent text and the quality of the final model. We explored this relationship formedical texts by comparing association rules based on features with three different semantic levels: (1) words (2) manually assigned keywords and (3) automatically selected medical concepts. Our preliminary findings indicate that bi-directional association rules based onconcepts or keywords are more plausible and more useful than those based on word features. The concept and keyword representations also required 90% fewer features than the word representation. This drastic dimensionality reduction suggests that this approach is well suited to large textual corpus of medical text, such as parts of the Web.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P448390</person_id>
				<author_profile_id><![CDATA[81100243801]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Catherine]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Blake]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39036573</person_id>
				<author_profile_id><![CDATA[81100298117]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wanda]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pratt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657877</article_id>
		<sort_key>67</sort_key>
		<display_label></display_label>
		<pages>67</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>16</seq_no>
		<title><![CDATA[Significance Tests for Patterns in Continuous Data]]></title>
		<page_from>67</page_from>
		<page_to>74</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657877</url>
		<abstract>
			<par><![CDATA[In this paper we consider the question of uncertainty of detected patterns in data mining. In particular, we develop statistical tests for patterns found in continuous data, indicating the significance of these patterns in terms of the probability that they have occurred by chance. We examine the performance of these tests on patterns detected in several large data sets, including a data set describing the locations of earthquakes in California and another describing flow cytometry measurements on phytoplankton.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39046769</person_id>
				<author_profile_id><![CDATA[81100516778]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Bolton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P61871</person_id>
				<author_profile_id><![CDATA[81100494561]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Hand]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657728</article_id>
		<sort_key>75</sort_key>
		<display_label></display_label>
		<pages>75</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>17</seq_no>
		<title><![CDATA[Distributed Web Mining Using Bayesian Networks from Multiple Data Streams]]></title>
		<page_from>75</page_from>
		<page_to>82</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657728</url>
		<abstract>
			<par><![CDATA[We present a collective approach to mine Bayesian net-works from distributed heterogenous web-log data streams. In this approach we first learn a local Bayesian network at each site using the local data. Then each site identifies the observations that are most likely to be evidence of coupling between local and non-local variables and transmits asub-set of these observations to a central site. Another Bayesian network is learnt at the central site using the data transmittedfrom the local site. The local and central Bayesian networks are combined to obtain a collective Bayesian net-work, that models the entire data. We applied this techniqueto mine multiple data streams where data centralization is difficult because of large response time and scalability issues.Experimental results and theoretical justification that demonstrate the feasibility of our approach are presented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14047149</person_id>
				<author_profile_id><![CDATA[81100107095]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[R.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P163158</person_id>
				<author_profile_id><![CDATA[81100106585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Krishnamoorthy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sivakumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39029854</person_id>
				<author_profile_id><![CDATA[81100150749]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hillol]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kargupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658031</article_id>
		<sort_key>83</sort_key>
		<display_label></display_label>
		<pages>83</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>18</seq_no>
		<title><![CDATA[A Hypergraph Based Clustering Algorithm for Spatial Data Sets]]></title>
		<page_from>83</page_from>
		<page_to>90</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658031</url>
		<abstract>
			<par><![CDATA[Clustering is a discovery process in data mining an can be used to group together the objects of a database into meaningful subclasses which serve as the foundation for other data analysis techniques.In this paper, we focus on dealing with a set of spatial data. For the spatial data, the clustering problem becomes that of finding the densely populate regions of the space and thus grouping these regions into clusters such that the intracluster similarity is maximized and theintercluster similarity is minimized. We develop a novel hierarchical clustering algorithm that uses a hypergraph to represent a set of spatial data. This hypergraph is initially constructed from the Delaunay triangulation graph of the data set and can correctly capture the relationships among sets of data points. Two phases are developed for the proposed clustering algorithm to find the clusters in the data set.We evaluate our hierarchical clustering algorithm with some spatial data sets in which contain clusters of different sizes, shapes, densities, and noise. Experimental results on these data sets are very encouraging.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Data Mining, Clustering,  Hypergraph.]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P469520</person_id>
				<author_profile_id><![CDATA[81100408910]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jong-Sheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cherng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P480373</person_id>
				<author_profile_id><![CDATA[81100147101]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mei-Jung]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658045</article_id>
		<sort_key>91</sort_key>
		<display_label></display_label>
		<pages>91</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>19</seq_no>
		<title><![CDATA[Efficient Determination of Dynamic Split Points in a Decision Tree]]></title>
		<page_from>91</page_from>
		<page_to>98</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658045</url>
		<abstract>
			<par><![CDATA[We consider the problem of choosing split points forcontinuous predictor variables in a decision tree. Previousapproaches to this problem typically either (1) discretize the continuous predictor values prior to learning or (2) apply a dynamic method that considers all possible split points for each potential split. In this paper, we describe anumber of alternative approaches that generate a smallnumber of candidate split points dynamically with littleoverhead. We argue that these approaches are preferable to pre-discretization, and provide experimental evidence that they yield probabilistic decision trees with the same prediction accuracy as the traditional dynamic approach.Furthermore, because the time to grow a decision tree isproportional to the number of split points evaluated, our approach is significantly faster than the traditional dynamic approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P60964</person_id>
				<author_profile_id><![CDATA[81100277962]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[Maxwell]]></middle_name>
				<last_name><![CDATA[Chickering]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15028809</person_id>
				<author_profile_id><![CDATA[81100312568]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Meek]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P490470</person_id>
				<author_profile_id><![CDATA[81100159968]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rounthwaite]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>878514</article_id>
		<sort_key>93</sort_key>
		<display_label></display_label>
		<pages>393</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>20</seq_no>
		<title><![CDATA[Closing the Loop]]></title>
		<subtitle><![CDATA[Heuristics for Autonomous Discovery]]></subtitle>
		<page_from>93</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=878514</url>
		<abstract>
			<par><![CDATA[Autonomous discovery systems will be able to peruse very large databases more thoroughly than people can. In a companion paper [1], we describe a general frame-work for autonomous systems. We present and evaluate heuristics for use in this framework. Although these heuristics were designed for a prototype system, we believe they provide good initial solutions to problems encountered when implementing fully autonomous discovery systems. As such, these heuristics may be used as the starting point for future research into fully autonomousdiscovery systems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658054</article_id>
		<sort_key>99</sort_key>
		<display_label></display_label>
		<pages>99</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>21</seq_no>
		<title><![CDATA[Efficient Yet Accurate Clustering]]></title>
		<page_from>99</page_from>
		<page_to>106</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658054</url>
		<abstract>
			<par><![CDATA[In this paper we show that most hierarchical agglomerativeclustering (HAC)algorithms follow a 90-10 rule where roughly 90%iterations from the beginning merge cluster pairs with dissimilarity less than 10%of the maximumdissimilarity. We propose two algorithms - 2-phase andnested - based on partially overlapping partitioning (POP).To handle high-dimensional data efficiently, we propose a tree structure particularly suitable for POP. Extensive experimentsshow that the proposed algorithms reduce the time andmemory requirement of existing HAC algorithms significantly without compromising in accuracy.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP18001682</person_id>
				<author_profile_id><![CDATA[81100440528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Manoranjan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dash]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95043275</person_id>
				<author_profile_id><![CDATA[81451597529]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kian-Lee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77038405</person_id>
				<author_profile_id><![CDATA[81367594306]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Huan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658058</article_id>
		<sort_key>107</sort_key>
		<display_label></display_label>
		<pages>107</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>22</seq_no>
		<title><![CDATA[A Min-max Cut Algorithm for Graph Partitioning and Data Clustering]]></title>
		<page_from>107</page_from>
		<page_to>114</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658058</url>
		<abstract>
			<par><![CDATA[An important application of graph partitioning is data clustering using a graph model - the pairwise similarities between all data objects form a weighted graph adjacency matrix that contains all necessary information for clustering. Here we propose a new algorithm for graph partition with an objective function that follows the min-max clustering principle. The relaxed version of the optimization of the min-max cut objective function leads to the Fiedler vector in spectral graph partition. Theoretical analyses of min-max cut indicate that it leads to balanced partitions, and lower bonds are derived. The min-max cut algorithm is tested on news-group datasets and is found to outperform other current popular partitioning/clustering methods. The linkage-based refinements in the algorithm further improve the quality of clustering substantially. We also demonstrate that the linearized search order based on linkage differential is better than that based on the Fiedler vector, providing another effectivepartition method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP43124102</person_id>
				<author_profile_id><![CDATA[81100136610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[H. Q.]]></middle_name>
				<last_name><![CDATA[Ding]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P339969</person_id>
				<author_profile_id><![CDATA[81100332307]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xiaofeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15035182</person_id>
				<author_profile_id><![CDATA[81100528811]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hongyuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15034437</person_id>
				<author_profile_id><![CDATA[81100501719]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Ming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42052427</person_id>
				<author_profile_id><![CDATA[81339528640]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Horst]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Simon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657897</article_id>
		<sort_key>115</sort_key>
		<display_label></display_label>
		<pages>115</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>23</seq_no>
		<title><![CDATA[Preprocessing Opportunities in Optimal Numerical Range Partitioning]]></title>
		<page_from>115</page_from>
		<page_to>122</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657897</url>
		<abstract>
			<par><![CDATA[We show that only the segment borders have to be taken into account as cut point candidates in searching for theoptimal multisplit of a numerical value range with respect to convex attribute evaluation functions. Segment borders can be found efficiently in a linear-time preprocessing step. With Training Set Error, which is not strictly convex, the data can be preprocessed into an even smaller number of cut point candidates, called alternations, when striving for the optimal partition. We show that no segment borders(resp. alternations) can be overlooked with strictly convex functions (resp. Training Set Error) without risking to lose optimality. Our experiments show that while in real-world domainssignificant reduction in the number of cut point candidates can be obtained for Training Set Error, the number of segment borders is usually not much lower than that of boundary points.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P278445</person_id>
				<author_profile_id><![CDATA[81100604655]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tapio]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Elomaa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14137862</person_id>
				<author_profile_id><![CDATA[81100389431]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Juho]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rousu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658057</article_id>
		<sort_key>123</sort_key>
		<display_label></display_label>
		<pages>123</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>24</seq_no>
		<title><![CDATA[Using Artificial Anomalies to Detect Unknown and Known Network Intrusions]]></title>
		<page_from>123</page_from>
		<page_to>130</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658057</url>
		<abstract>
			<par><![CDATA[Intrusion detection systems (IDSs) must be capable of detecting new and unknown attacks, or anomalies. We study the problem of building detection models for both pure anomaly detection and combined misuse and anomaly detection (i.e., detection of both known and unknown intrusions). We propose an algorithm to generate artificial anomalies to coerce the inductive learner into discovering an accurate boundary between known classes (normal connections and known intrusions) and anomalies.Empirical studies show that our pure anomaly detection model trained using nor al and artificial anomalies is capable of detecting ore than 77%of all unknown intrusion classes with more than 50%accuracy per intrusion class. The combined misuse and anomaly detection models are as accurate as a pure misuse detection model in detecting known intrusions and are capable of detecting at least 50%of unknown intrusion classes with accuracy measurements between 75% and 100%per class.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40027830</person_id>
				<author_profile_id><![CDATA[81367591181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P410221</person_id>
				<author_profile_id><![CDATA[81100161781]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Miller]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P258871</person_id>
				<author_profile_id><![CDATA[81100583572]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Salvatore]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Stolfo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77034768</person_id>
				<author_profile_id><![CDATA[81381593761]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wenke]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77036469</person_id>
				<author_profile_id><![CDATA[81408600551]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Chan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658022</article_id>
		<sort_key>131</sort_key>
		<display_label></display_label>
		<pages>131</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>25</seq_no>
		<title><![CDATA[Using Rule Sets to Maximize ROC Performance]]></title>
		<page_from>131</page_from>
		<page_to>138</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658022</url>
		<abstract>
			<par><![CDATA[Rules are commonly use for classification because they are modular, intelligible and easy to learn. Existing work in classification rule learning assumes the goal is to produce categorical classifications to maximize classification accuracy. Recent work in machine learning has pointed out the limitations of classification accuracy: when class distributions are skewed, or error costs are unequal, an accuracy maximizing rule set can perform poorly. Amore flexible use of a rule set is to produce instance scores indicating the likelihood that an instance belongs to a given class. With such an ability, we can apply rulesets effectively whendistributions are skewed or error costs are unequal. This paper empirically investigates different strategies for evaluating rule sets when the goal is to maximize the scoring (ROC)performance.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39044519</person_id>
				<author_profile_id><![CDATA[81100475242]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tom]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fawcett]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658050</article_id>
		<sort_key>139</sort_key>
		<display_label></display_label>
		<pages>139</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>26</seq_no>
		<title><![CDATA[A Synchronization Based Algorithm for Discovering Ellipsoidal Clusters in Large Datasets]]></title>
		<page_from>139</page_from>
		<page_to>146</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658050</url>
		<abstract>
			<par><![CDATA[This paper introduces a new scalable approach to clusteringbased on synchronization of pulse-coupled oscillators. Eachdata point is represented by an integrate-and-fire oscillator, and the interaction between oscillators is defined according to the relative similarity between the points. The set of oscillators will self-organize into stable phase-locked subgroups. Our approach proceeds by loading only a subset of the data and allowing it to self-organize. Groups ofsynchronized oscillators are then summarized and purged from memory. We show that our method is robust, scales linearly, and can determine the number of clusters. The proposedapproach is empirically evaluated with several synthetic data sets and is used to segment large color images.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39025074</person_id>
				<author_profile_id><![CDATA[81100053726]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hichem]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Frigui]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P202274</person_id>
				<author_profile_id><![CDATA[81100595906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mohamed]]></first_name>
				<middle_name><![CDATA[Ben Hadj]]></middle_name>
				<last_name><![CDATA[Rhouma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657732</article_id>
		<sort_key>147</sort_key>
		<display_label></display_label>
		<pages>147</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>27</seq_no>
		<title><![CDATA[Functional Trees for Classification]]></title>
		<page_from>147</page_from>
		<page_to>154</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657732</url>
		<abstract>
			<par><![CDATA[The design of algorithms that explore multiple representation languages and explore different search space has an intuitive appeal.In this context of classification problems, algorithmsthat generate multivariate trees are able to explore multiplerepresentation languages by using decision test based on acombination of attributes.The same applies to models threesalgorithms, in regression domains, but using linear models atleaf nodes.In this paper we study where to use combinations of attributes in decision tree learning.We present an algorithm for multivariate tree learning that combines a univariate decision tree with a discriminant function by means of constructiveinduction.This algorithm is able to use decision nodes with multivariate tests, and leaf nodes that predict a class using adiscrimnant. Multivariate decision nodes are built when growing the tree, while functional leaves are built when pruning the tree.Functional trees can be seen as a generalization of multivariate trees.Our algorithm was compared against to its components and two simplified versions using 30 benchmark datasets. The experimental evaluation shows that our algorithm has clear Advantages with respect to the generalization ability and model sizes at statistically significant.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14022875</person_id>
				<author_profile_id><![CDATA[81100028845]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Joao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gama]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657870</article_id>
		<sort_key>155</sort_key>
		<display_label></display_label>
		<pages>155</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>28</seq_no>
		<title><![CDATA[A Tight Upper Bound on the Number of Candidate Patterns]]></title>
		<page_from>155</page_from>
		<page_to>162</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657870</url>
		<abstract>
			<par><![CDATA[In the context of mining for frequent patterns using the standard level wise algorithm, the following question arises: given the current level and the current set of frequentpatterns, what is the maximal number of candidate patterns that can be generated on the next level? We answer this question by providing a tight upper bound, derived from a combinatorial result from the sixties by Kruskal andKatona. Our result is useful to educe the number of databasescans.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14091494</person_id>
				<author_profile_id><![CDATA[81100234746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Floris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Geerts]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39047136</person_id>
				<author_profile_id><![CDATA[81100529915]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Bart]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Goethals]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P466752</person_id>
				<author_profile_id><![CDATA[81452616156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jan]]></first_name>
				<middle_name><![CDATA[Van den]]></middle_name>
				<last_name><![CDATA[Bussche]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658047</article_id>
		<sort_key>163</sort_key>
		<display_label></display_label>
		<pages>163</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>29</seq_no>
		<title><![CDATA[Efficiently Mining Maximal Frequent Itemsets]]></title>
		<page_from>163</page_from>
		<page_to>170</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658047</url>
		<abstract>
			<par><![CDATA[We present GenMax, a backtrack search based algorithm for mining maximal frequent itemsets. GenMax uses a number of optimizations to prune the search space.It usesa novel technique called progressive focusing to perform maximality checking, and diffset propagation to perform fast frequency computation. Systematic experimental comparison with previous work indicates that different methods have varying strengths and weaknesses based on dataset characteristics. We found GenMax to be a highly efficient method to mine the exact set of maximal patterns.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP45022995</person_id>
				<author_profile_id><![CDATA[81343493585]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Karam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gouda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P202473</person_id>
				<author_profile_id><![CDATA[81100229027]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mohammed]]></first_name>
				<middle_name><![CDATA[Javeed]]></middle_name>
				<last_name><![CDATA[Zaki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658055</article_id>
		<sort_key>171</sort_key>
		<display_label></display_label>
		<pages>171</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>30</seq_no>
		<title><![CDATA[The DIAsDEM Framework for Converting Domain-Specific Texts into XML Documents with Data Mining Techniques]]></title>
		<page_from>171</page_from>
		<page_to>178</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658055</url>
		<abstract>
			<par><![CDATA[Modern organizations are accumulating huge volumesof textual documents. To turn archives into valuable know-ledge sources, textual content must become explicit andqueryable. Semantic tagging with markup languages suchas XML satisfies both requirements. We thus introduce theDIAsDEM* framework for extra ting semantics from structural text units (e.g., sentences), assigning XML tags to them and deriving a flat XML DTD for the archive. DIAsDEM focuses on archives characterized by a peculiar terminologyand by an implicit structure such as court filings and company reports. In the knowledge discovery phase, text units are iteratively clustered by similarity of their content. Eachiteration outputs clusters satisfying a set of quality criteria.Text units contained in these clusters are tagged with semi-automatically determined luster labels and XML tags respectively. Additionally, extracted named entities (e.g.,per-sons) serve as attributes of XML tags. We apply the frame-work in a case study on the German Commercial Register.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P462343</person_id>
				<author_profile_id><![CDATA[81100035878]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Henner]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Graubitz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39037143</person_id>
				<author_profile_id><![CDATA[81319501878]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Myra]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Spiliopoulou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P471901</person_id>
				<author_profile_id><![CDATA[81100186386]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Karsten]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Winkler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658051</article_id>
		<sort_key>179</sort_key>
		<display_label></display_label>
		<pages>179</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>31</seq_no>
		<title><![CDATA[A Scalable Algorithm for Clustering Sequential Data]]></title>
		<page_from>179</page_from>
		<page_to>186</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658051</url>
		<abstract>
			<par><![CDATA[In recent years, we have seen an enormous growth in the amount of available commercial and scientific data. Data from domains such as protein sequences, retail transactions, intrusion detection, and web-logs have an inherent sequential nature. Clustering of such data sets is usefulfor various purposes. For example, clustering of sequences from commercialdata sets may help marketer identify different customer groups based upon their purchasing patterns. Grouping protein sequences that share similar structure helps in identifying sequences with similar functionality. Over the years, many methods have been developed for clustering objects according to their similarity. However these methods tend to have a computational complexity that is at least quadratic on the number of sequences. In this paperwe present an entirely different approach to sequence clustering that does not require an all-against-all analysis and uses a nearlinear complexity K-means based clustering algorithm. Our experiments using data sets derived from sequences of purchasing transactions and protein sequences show that this approach is scalable and leads to reasonably good clusters.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P500394</person_id>
				<author_profile_id><![CDATA[81100421465]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Valerie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Guralnik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14015889</person_id>
				<author_profile_id><![CDATA[81100008465]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Karypis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657864</article_id>
		<sort_key>187</sort_key>
		<display_label></display_label>
		<pages>187</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>32</seq_no>
		<title><![CDATA[Clustering Validity Assessment]]></title>
		<subtitle><![CDATA[Finding the Optimal Partitioning of a Data Set]]></subtitle>
		<page_from>187</page_from>
		<page_to>194</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657864</url>
		<abstract>
			<par><![CDATA[Clustering s a mostly unsupervised procedure and the majority of the clustering algorithms depend on certain assumptions in order to define the subgroups present in a data set. As a consequence, in most applications the resulting clustering scheme requires some sort ofevaluation as regards its validity. In this paper we present a clustering validity procedure,which evaluates the results of clustering algorithms on data sets. We define a validity index, S_Dbw, based on well-defined clustering criteria enabling the selection of the optimal input parameters' values for a clustering algorithm that result in the best partitioning of a data set.We evaluate the reliability of our index both theoretically and experimentally, considering three representative clustering algorithms ran on synthetic and real data sets. Also, we carried out an evaluation study to compare S_Dbw performance with other known validity indices.Our approach performed favorably in all cases, even in those that other indices failed to indicate the correct partitions in a data set.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P381181</person_id>
				<author_profile_id><![CDATA[81100649267]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Maria]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Halkidi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP38025076</person_id>
				<author_profile_id><![CDATA[81100414295]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michalis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vazirgiannis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658188</article_id>
		<sort_key>195</sort_key>
		<display_label></display_label>
		<pages>195</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>33</seq_no>
		<title><![CDATA[Automatic Topic Identification Using Webpage Clustering]]></title>
		<page_from>195</page_from>
		<page_to>202</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658188</url>
		<abstract>
			<par><![CDATA[Grouping webpage into distinct topics is one way to organize the large amount of retrieved information on the web. In this paper, we report that based on similaritymetric which incorporates textual information, hyperlinkstructure and co-citation relations, an unsupervised clustering method can automatically and effectively identify relevant topics, a shown in experiments on several retrieved sets of webpages. The clustering method is a state-of-art spectral graph partitioning method based on normalized cutcriterion first developed for image segmentation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P339969</person_id>
				<author_profile_id><![CDATA[81100332307]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiaofeng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[He]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43124102</person_id>
				<author_profile_id><![CDATA[81100136610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[H. Q.]]></middle_name>
				<last_name><![CDATA[Ding]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15035182</person_id>
				<author_profile_id><![CDATA[81100528811]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hongyuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42052427</person_id>
				<author_profile_id><![CDATA[81339528640]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Horst]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Simon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>756507</article_id>
		<sort_key>203</sort_key>
		<display_label></display_label>
		<pages>203</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>34</seq_no>
		<title><![CDATA[Time Series Segmentation for Context Recognition in Mobile Devices]]></title>
		<page_from>203</page_from>
		<page_to>210</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=756507</url>
		<abstract>
			<par><![CDATA[Recognizing the context of se is important in making mobile devices as simple to use as possible. Finding out what the user's situation is can help the device andunderlying service in providing an adaptive and personalized user interface. The device can infer parts of the context of the user from sensor data: the mobile device can includesensors for acceleration, noise level, luminosity, humidity, etc. In this paper we consider context recognition by unsupervisedsegmentation of time series produced by sensors.Dynamic programming can be used to find segments that minimize the intra-segment variances. While this method produces optimal solutions, it is too slow for long sequencesof data. We present and analyze randomized variations of the algorithm. One of them, Global Iterative Replacement or GIR, gives approximately optimal results in a fraction of the time required by dynamic programming. Wedemonstrate the se of time series segmentation in contextrecognition for mobile phone applications.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P317196</person_id>
				<author_profile_id><![CDATA[81100518734]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Johan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Himberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P471530</person_id>
				<author_profile_id><![CDATA[81100453972]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kalle]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Korpiaho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P108656</person_id>
				<author_profile_id><![CDATA[81100086722]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Heikki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mannila]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P468988</person_id>
				<author_profile_id><![CDATA[81100589609]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Johanna]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tikanm&#228;ki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39050668</person_id>
				<author_profile_id><![CDATA[81100609333]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Hannu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Toivonen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658044</article_id>
		<sort_key>211</sort_key>
		<display_label></display_label>
		<pages>211</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>35</seq_no>
		<title><![CDATA[Indiscernibility Degree of Objects for Evaluating Simplicity of Knowledge in the Clustering Procedure]]></title>
		<page_from>211</page_from>
		<page_to>217</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658044</url>
		<abstract>
			<par><![CDATA[This paper presents a new, rough sets-based clusteringmethod that enables evaluation of simplicity of classification knowledge during the clustering procedure. The method iteratively refines equivalence relations so that they become more simple set of relations that give adequately coarse classification to the objects. At each step ofiteration, importance of the equivalence relation is evaluated on the basis of the newly introduced measure, indiscernibility degree. An indiscernibility degree is defined as a ratio of equivalence relations that classify the two objects into the same equivalence class. If an equivalence relation hasability to discern the two objects that have high indiscernibility degree, it is considered to perform too fine classification and then modified to regard them as indiscernible objects. The refinement is repeated decreasing the threshold level ofindiscernibility degree, and finally simple clusters can beobtained. Experimental results on the artificial data showed that iterative refinement of equivalence relation lead tosuccessful generation of coarse clusters that can be representedby simple knowledge.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P432865</person_id>
				<author_profile_id><![CDATA[81100281744]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Shoji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hirano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40025004</person_id>
				<author_profile_id><![CDATA[81100219997]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Shusaku]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tsumoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657860</article_id>
		<sort_key>218</sort_key>
		<display_label></display_label>
		<pages>218</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>36</seq_no>
		<title><![CDATA[Mining Coverage-Based Fuzzy Rules by Evolutional Computation]]></title>
		<page_from>218</page_from>
		<page_to>224</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657860</url>
		<abstract>
			<par><![CDATA[In this paper, we propose a novel mining approach based on the genetic process and an evaluation mechanism to automatically construct an effective fuzzy rule base. The proposed approach consists of three phases: fuzzy-rule generating, fuzzy-rule encoding and fuzzy-ruleevolution. In the fuzzy-rule generating phase, a number of fuzzy rules are randomly generated. In the fuzzy-rule encoding phase, all the rules generated are translated into fixed-length bit strings to form an initial population. In the fuzzy-rule evolution phase, genetic operations andcredit assignment are applied at the rule level. The proposed mining approach chooses good individuals in the population for mating, gradually creating better offspring fuzzy rules. A concise and compact fuzzy rule base is thus constructed effectively without human expertintervention.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Data mining, machine learning, genetic algorithm, fuzzy set, rule base.]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40029459</person_id>
				<author_profile_id><![CDATA[81100648630]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tzung-Pei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77039079</person_id>
				<author_profile_id><![CDATA[81409594140]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yeong-Chyi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657878</article_id>
		<sort_key>225</sort_key>
		<display_label></display_label>
		<pages>225</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>37</seq_no>
		<title><![CDATA[An Efficient Fuzzy C-Means Clustering Algorithm]]></title>
		<page_from>225</page_from>
		<page_to>232</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657878</url>
		<abstract>
			<par><![CDATA[The Fuzzy C-Means (FCM) algorithm is commonly used for clustering.The performance of the FCM algorithm depends on the selection of the initial cluster center and/or the initial membership value.If a good initial cluster center that is close to the actual final clustercenter can be found, the FCM algorithm will converge very quickly and the processing time can be drastically.In this paper, we propose a novel algorithm for efficient clustering.This algorithm is a modified FCM called the psFCM algorithm, which significantly reduces the computation timerequired to partition a dataset into desired cluster.We find the actual cluster center by using a simplified set of the original complete dataset.It refines the initial value of the FCM algorithm to speed up the convergence time.Our Experiments show that the proposed psFCM algorithm isAlgorithm.We also demonstrate that the quality of the Proposed psFCM algorithm is the same as the FCM algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P481730</person_id>
				<author_profile_id><![CDATA[81100111336]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ming-Chuan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14126458</person_id>
				<author_profile_id><![CDATA[81100353172]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Don-Lin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657724</article_id>
		<sort_key>233</sort_key>
		<display_label></display_label>
		<pages>233</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>38</seq_no>
		<title><![CDATA[Using Rough Sets Theory and Database Operations to Construct a Good Ensemble of Classifiers for Data Mining Applications]]></title>
		<page_from>233</page_from>
		<page_to>240</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657724</url>
		<abstract>
			<par><![CDATA[In this paper we present a new approach to construct a good ensemble of classifiers using rough sets theory and database operations. Ensembles of classifiers is formulated precisely within the framework of rough sets theory and constructed very efficiently by using set-oriented database operations. Our method first computes a set of reductswhich include all the indispensable attributes required for the decision categories. For each reduct, a reduct table is generated by removing those attributes which are not in the reduct. Next, a novel rule induction algorithm is used to compute the maximal generalized rules for each reducttable and a set of reduct classifiers is formed based on thecorresponding reducts. The distinctive features of our method as compared to other methods of constructing ensembles of classifiers are:(1) present a theoretical model to explain the mechanism of constructing ensemble of classifiers, (2) each reduct is a minimum subset of attributes, has the same classification ability as the entire attributes,(3)ea h reduct classifier constructed from the corresponding reduct has a minimal set of classification rules, and is as accurate andcomplete as possible and at the same time as diverse as possible from the other classifiers, (4)the test indicates that the number of classifiers used to improve the accuracy is muchless than other methods]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15027481</person_id>
				<author_profile_id><![CDATA[81100254535]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiaohua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657871</article_id>
		<sort_key>241</sort_key>
		<display_label></display_label>
		<pages>241</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>39</seq_no>
		<title><![CDATA[Fuzzy Data Mining]]></title>
		<subtitle><![CDATA[Effect of Fuzzy Discretization]]></subtitle>
		<page_from>241</page_from>
		<page_to>248</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657871</url>
		<abstract>
			<par><![CDATA[When we generate association rules, continuous attributes have to be discretized into intervals while our knowledge representation is not always based on such discretiztion.Forexample, we usually use some linguistic terms (e.g., young, middle age, and old) for dividing our ages into somefuzzy categories.In this paper, we describe the extraction of linguistic association rules and examine the performanceof extracted rules.First we modify the definitions of the two basic measures (i.e., confidence and support) ofassociation rules for extracting linguistic association rules. The main difference between standard and linguistics association rules is the discretiztion of continuous attributes. We divide the domain interval of each attribute into some Fuzzy discretiztion with standard on-fuzzy discretiztion Through computer simulations on a pattern classificationproblem with many continuous attributes.The classification performance of extracted rules on unseen test patterns is examined under various conditions.Simulation results show that linguistic association rules with rule weights have highgeneralization ability even when the domain of each continuous attribute is homogeneously partitioned.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P111225</person_id>
				<author_profile_id><![CDATA[81100483276]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hisao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ishibuchi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14208071</person_id>
				<author_profile_id><![CDATA[81100602102]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Takashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yamamoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P284032</person_id>
				<author_profile_id><![CDATA[81100576392]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tomoharu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nakashima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658052</article_id>
		<sort_key>249</sort_key>
		<display_label></display_label>
		<pages>249</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>40</seq_no>
		<title><![CDATA[The Computational Complexity of High-Dimensional Correlation Search]]></title>
		<page_from>249</page_from>
		<page_to>256</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658052</url>
		<abstract>
			<par><![CDATA[There is a growing awareness that the popular support metric (often used to guide search in market-basket analysis) is not appropriate for use in every association mining application. Support measures only the frequency of co-occurrence of a set of events when determining which pat-terns to report back to the user. It incorporates no rigorous statistical notion of surprise or interest, and many of the patterns deemed interesting by the support metric are uninteresting to the user.However, a positive aspect of support is that search using support is very efficient. The question we address in this paper is: can we retain this efficiency if we move beyond support, and to other, more rigorous metrics? We consider the computational implications of incorporating simple expectation into the data mining task. It turns out that many variations on the problem which incorporate more rigorous tests of dependence (or independence) result in NP-hard problem definitions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14202723</person_id>
				<author_profile_id><![CDATA[81100586871]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jermaine]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658037</article_id>
		<sort_key>257</sort_key>
		<display_label></display_label>
		<pages>257</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>41</seq_no>
		<title><![CDATA[Evaluating Boosting Algorithms to Classify Rare Classes]]></title>
		<subtitle><![CDATA[Comparison and Improvements]]></subtitle>
		<page_from>257</page_from>
		<page_to>264</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658037</url>
		<abstract>
			<par><![CDATA[Classification of rare vents has many important data mining applications. Boosting is a promising meta-techniquethat improves the classification performance of any weak classifier. So far, no systematic study has been conducted to evaluate how boosting performs for the task of mining rare classes. In this paper, we evaluate three existing categories of boosting algorithms from the single viewpoint of how they update the example weights in eachiteration, and discuss their possible effect on recall andprecision of the rare class. We propose enhanced algorithms in two of the categories, and justify their choice of weightupdating parameters theoretically. Using some specially designed synthetic datasets, we compare the capability of all the algorithms from the rare class perspective. Theresults support our qualitative analysis, and also indicate that our enhancements bring an extra capability for achieving better balance between recall and precision in mining rareclasses.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39052062</person_id>
				<author_profile_id><![CDATA[81100641811]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mahesh]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Joshi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95040390</person_id>
				<author_profile_id><![CDATA[81452613746]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vipin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77028146</person_id>
				<author_profile_id><![CDATA[81342487514]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ramesh]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Agarwal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658023</article_id>
		<sort_key>265</sort_key>
		<display_label></display_label>
		<pages>265</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>42</seq_no>
		<title><![CDATA[An Agglomerative Hierarchical Clustering Using Partial Maximum Array and Incremental Similarity Computation Method]]></title>
		<page_from>265</page_from>
		<page_to>272</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658023</url>
		<abstract>
			<par><![CDATA[As the tractable amount of data is growing in computer science area, fast clustering algorithm is being required because traditional clustering algorithms are not so feasible for very large and high dimensional data. Many studies have been reported for clustering of large database, but most of them circumvent this problem by using the approximation method to result in thedeterioration of accuracy. In this paper, we propose a new clustering algorithm by means of partial maximum array, which can realize the agglomerative hierarchical clustering with the same accuracy to the brute-force algorithm and has O(N 2 ) time complexity. And we alsopresent the incremental method of similarity computation which substitutes the scalar calculation for the time-consuming calculation of vector similarity. The experimental results show that clustering becomes significantly fast for large and high dimensional data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP310504700</person_id>
				<author_profile_id><![CDATA[81537702256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sung]]></first_name>
				<middle_name><![CDATA[Young]]></middle_name>
				<last_name><![CDATA[Jung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP310510000</person_id>
				<author_profile_id><![CDATA[81546562456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Taek-Soo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657890</article_id>
		<sort_key>273</sort_key>
		<display_label></display_label>
		<pages>273</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>43</seq_no>
		<title><![CDATA[Distance Measures for Effective Clustering of ARIMA Time-Series]]></title>
		<page_from>273</page_from>
		<page_to>280</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657890</url>
		<abstract>
			<par><![CDATA[Many environmental and socioeconomic time-series data can be adequately modeled using Auto-RegressiveIntegrated Moving Average (ARIMA) models. We call such Time-series ARIMA time-series. We consider the problem of clustering ARIMA time-series. We propose the use of the Linear Predictive Coding (LPC) cepstrum of time-series for clustering ARIMA time-series, by using the Euclideandistance between the LPC cepstra of two time-series as their dissimilarity measure. We demonstrate that LPC cepstral coefficients have the desire features for accurate clustering and efficient indexing of ARIMA time-series. For example, few LPC cepstral coefficients are sufficient in order todiscriminate between time-series that are modeled by different ARIMA models. In fact this approach requires fewer coefficients than traditional approaches, such as DFT and DWT. The proposed distance measure can be use for measuring the similarity between different ARIMA models as well.We cluster ARIMA time-series using the Partition Around Medoids method with various similarity measures. We present experimental results demonstrating that using the proposed measure we achieve significantly betterclusterings of ARIMA time-series data as compared to clusterings obtained by using other traditional similaritymeasures, such as DFT, DWT, PCA, etc. Experiments wereperformed both on simulated as well as real data.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Time-series, similarity measures, clustering, ARIMA models, cepstral coefficients.]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14040191</person_id>
				<author_profile_id><![CDATA[81100084066]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Konstantinos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kalpakis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P452694</person_id>
				<author_profile_id><![CDATA[81100094528]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dhiral]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gada]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P500499</person_id>
				<author_profile_id><![CDATA[81100252162]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Vasundhara]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Puttagunta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658039</article_id>
		<sort_key>281</sort_key>
		<display_label></display_label>
		<pages>281</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>44</seq_no>
		<title><![CDATA[Mining Decision Trees from Data Streams in a Mobile Environment]]></title>
		<page_from>281</page_from>
		<page_to>288</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658039</url>
		<abstract>
			<par><![CDATA[This paper presents a novel Fourier analysis-based technique toaggregate, communicate, and visualize decision trees in a mobile environment. Fourier representation of a decision tree has several useful properties that are particularly useful for mining continuous data streams from small mobile computing devices. This paper presents algorithms to compute the Fourier spectrum of a decision tree and the vice versa. It offers a framework to aggregate decision trees in their Fourier representations. It a so describes atouch-pad/ticker-based approach to visualize decision trees using their Fourier spectrum and an implementation for PDAs..]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39029854</person_id>
				<author_profile_id><![CDATA[81100150749]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hillol]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kargupta]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P345445</person_id>
				<author_profile_id><![CDATA[81100157919]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Byung-Hoon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Park]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657889</article_id>
		<sort_key>289</sort_key>
		<display_label></display_label>
		<pages>289</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>45</seq_no>
		<title><![CDATA[An Online Algorithm for Segmenting Time Series]]></title>
		<page_from>289</page_from>
		<page_to>296</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657889</url>
		<abstract>
			<par><![CDATA[In recent years, there has been an explosion of interest in mining time series databases. As with most computer science problems, representation of the data is the key to efficient and effective solutions. One of the most commonly used representations is piecewise linear approximation. This representation has been used by various researchers to support clustering, classification, indexing and association rule mining of t me series data. A variety of algorithms have been proposed to obtain this representation, with several algorithms having been independently rediscovered several times. In this paper, we undertake the first extensive review and empirical comparison of all proposed techniques. We show that allthese algorithms have fatal flaws from a data mining perspective. We introduce a novel algorithm that we empirically show to be super or to all others n the literature.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15025743</person_id>
				<author_profile_id><![CDATA[81100209161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eamonn]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Keogh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP310697900</person_id>
				<author_profile_id><![CDATA[81539772656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Selina]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77048211</person_id>
				<author_profile_id><![CDATA[81407593048]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P198389</person_id>
				<author_profile_id><![CDATA[81100408441]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Pazzani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657733</article_id>
		<sort_key>297</sort_key>
		<display_label></display_label>
		<pages>297</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>46</seq_no>
		<title><![CDATA[AINE]]></title>
		<subtitle><![CDATA[An Immunological Approach to Data Mining]]></subtitle>
		<page_from>297</page_from>
		<page_to>304</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657733</url>
		<abstract>
			<par><![CDATA[An investigation has been undertaken to repeat previous work on an artificial immune system for data analysis called AINE (Artificial Immune Network).The previous work was limited to testing the algorithm on relatively small data sets. The aim of this investigation is two fold,firstly to corroborate the results presented in previous work and secondly, to test the algorithm on a larger and more complex data set. A new re-implementation of AINE is then described and differences in behaviour are identified and explained. It is argued that the behaviourseen in the new implementation is more accurate than that seen in previous work and an in-depth analysis of the algorithm structure is undertaken in order to confirm theseobservations. The algorithm is also tested on new data and the results of this are presented. Comparisons are draw with other similar techniques for data mining and it is argued that AINE is an effective data-mining algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14081467</person_id>
				<author_profile_id><![CDATA[81339509918]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Thomas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Knight]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43117895</person_id>
				<author_profile_id><![CDATA[81100235138]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Timmis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657874</article_id>
		<sort_key>305</sort_key>
		<display_label></display_label>
		<pages>305</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>47</seq_no>
		<title><![CDATA[Concise Representation of Frequent Patterns Based on Disjunction-Free Generators]]></title>
		<page_from>305</page_from>
		<page_to>312</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657874</url>
		<abstract>
			<par><![CDATA[Many data mining problems require the discover of frequent patterns in order to be solved.Frequent Itemsets are useful in the discover of association rules, episode rules, sequential patterns and clusters. The number of frequent itemsets is usually huge. Therefore, it is important to work out concise representations of frequent itemsets. In the paper, we describe three basic loassless representations of frequent patters in a uniform wayand offer a new lossless representation of frequent patterns based on disjunction-free generators. The new representation is more concisethan two of the basic representations and more efficiently computablethan the third representation. We propose an algorithm for the determining the new representation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15024867</person_id>
				<author_profile_id><![CDATA[81100175272]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marzena]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kryszkiewicz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658027</article_id>
		<sort_key>313</sort_key>
		<display_label></display_label>
		<pages>313</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>48</seq_no>
		<title><![CDATA[Frequent Subgraph Discovery]]></title>
		<page_from>313</page_from>
		<page_to>320</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658027</url>
		<abstract>
			<par><![CDATA[As data mining techniques are being increasingly applied to non-traditional domains, existing approaches for finding frequent itemsets cannot be used as they cannot model the requirement of these domains. An alternate way of modeling the objects in these data sets is to use graphs. Within that model, the problem of finding frequent patterns becomes that of discovering subgraphs that occur frequently over the entire set of graphs. In this paper we present a computationally efficient algorithm for finding all frequent subgraphs in large graph databases. We evaluated the performance of the algorithm by experiments with synthetic datasets as well as a chemical compound dataset. The empirical results show that our algorithm scales linearly with the number of input transactions and it is able to discover frequent subgraphs from a set of graph transactions reasonably fast, even though we have to deal with computationally hard problems such as canonical labeling of graphs and subgraph isomorphism which are not necessary for traditional frequent itemset discovery.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P481304</person_id>
				<author_profile_id><![CDATA[81100101621]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michihiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuramochi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14015889</person_id>
				<author_profile_id><![CDATA[81100008465]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Karypis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657886</article_id>
		<sort_key>321</sort_key>
		<display_label></display_label>
		<pages>321</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>49</seq_no>
		<title><![CDATA[Statistical Considerations in Learning from Data]]></title>
		<page_from>321</page_from>
		<page_to>328</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657886</url>
		<abstract>
			<par><![CDATA[In this paper we focus on statistics. Classical statistics and Bayesian statistics are both employed in data mining. Both have advantages but both also have severe limitations in this context. We point out some of these limitations as well as s me of the advantages. The fact that we may need to take account of evidence both internal and external to the data set presents a difficulty for classical statistics. The need to incorporate an objective measure of reliability creates a difficulty for Bayesian statistics.We outline an approach to uncertainty that promises to capture the best of both worlds by incorporating both background knowledge and objectivity.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P109588</person_id>
				<author_profile_id><![CDATA[81100159504]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[E.]]></middle_name>
				<last_name><![CDATA[Kyburg]]></last_name>
				<suffix><![CDATA[Jr.]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658046</article_id>
		<sort_key>329</sort_key>
		<display_label></display_label>
		<pages>329</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>50</seq_no>
		<title><![CDATA[Subject Classification in the Oxford English Dictionary]]></title>
		<page_from>329</page_from>
		<page_to>336</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658046</url>
		<abstract>
			<par><![CDATA[The oxford English Dictionary is a valuable source of lexical information and a rich testing ground for mining highly structured text.Each entry is organized into a hierarchy of senses, which include definitions, labels and cited quotations.Subject labels distinguish the subject classification of a sense, for example they signal how a word may be used in Anthropology, Music or Computing.Unfortunately subject labeling in the dictionary is incomplete. To overcome thisincompleteness, we attempt to classify the senses (i.e., definitions) in the dictionary by their subjects, using thecitations as an information guide.We report on four different approaches: K Nearest Neighbors, a standard classification technique; Term Weighting, an information retrieval method dealing with text; Na&#239;ve Bayes, a probabilistic method; and Expectation Maximization, An iterative probabilistic method.Experimental performance of these Methods is compared based on standard classification metrics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P504694</person_id>
				<author_profile_id><![CDATA[81100422630]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zarrin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Langari]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43116906</person_id>
				<author_profile_id><![CDATA[81100157184]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Frank]]></first_name>
				<middle_name><![CDATA[Wm.]]></middle_name>
				<last_name><![CDATA[Tompa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658033</article_id>
		<sort_key>337</sort_key>
		<display_label></display_label>
		<pages>337</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>51</seq_no>
		<title><![CDATA[On Mining General Temporal Association Rules in a Publication Database]]></title>
		<page_from>337</page_from>
		<page_to>344</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658033</url>
		<abstract>
			<par><![CDATA[In this paper, we explore a new problem of mining general temporal association rules in publication databases. In essence, a publication database is a set of transactions where each transaction T is a set of items of which each item contains an individual exhibition period. The current model of association rule mining is not able to handle the publication database due to the following fundamental problems, i.e., (1) lack of consideration of the exhibition period of each individual item; (2) lack of an equitable support counting basis for each item. To remedy this, we propose an innovative algorithm Progressive-Partition-Miner (abbreviatedly as PPM) to discover general temporal association rules in a publication database. The basic idea ofPPM is to first partition the publication database in light of exhibition periods of items and then progressively accumulate the occurrence count of each candidate 2-itemset based on the intrinsic partitioning characteristics. Algorithm PPM is also designed to employ a filtering threshold in each partition to early prune out those cumulatively infrequent 2-itemsets. Explicitly, the execution time of PPM is, in orders of magnitude, smaller than those required by the schemes which are directly extended from existing methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P339981</person_id>
				<author_profile_id><![CDATA[81375607396]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chang-Hung]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P448863</person_id>
				<author_profile_id><![CDATA[81423596291]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Cheng-Ri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77036843</person_id>
				<author_profile_id><![CDATA[81450594725]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ming-Syan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658034</article_id>
		<sort_key>345</sort_key>
		<display_label></display_label>
		<pages>345</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>52</seq_no>
		<title><![CDATA[Preparations for Semantics-Based XML Mining]]></title>
		<page_from>345</page_from>
		<page_to>352</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658034</url>
		<abstract>
			<par><![CDATA[XML allows users to define elements using arbitrary words and organize them in a nested structure. These features of XML offer both challenges and opportunities in information retrieval, document management, and data mining. In this paper,we propose a new methodology for preparing XML documents for quantitative determination of similarity between XML documents by taking account of XML semantics (i.e.,meanings of the elements andnested structures of XML documents).Accurate quantitative determination of similarity between XML documents provides an important basis for a variety of applications of XML document mining and processing. Experiments with XML documents show that ourmethodology provides a 50-100%improvement in determining similarity, over the traditional vector-space model that considers only term-frequency and 100% accuracy in identifying the category of each document from an on-line bookstore.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP28003665</person_id>
				<author_profile_id><![CDATA[81100429432]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jung-Won]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP30029063</person_id>
				<author_profile_id><![CDATA[81409592813]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Kiho]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP92029099</person_id>
				<author_profile_id><![CDATA[81446592263]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Won]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658035</article_id>
		<sort_key>353</sort_key>
		<display_label></display_label>
		<pages>353</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>53</seq_no>
		<title><![CDATA[Mining Image Features for Efficient Query Processing]]></title>
		<page_from>353</page_from>
		<page_to>360</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658035</url>
		<abstract>
			<par><![CDATA[The number of feature required to depict an image can be very large. Using all features simultaneously to measure image similarity and to learn image query-concepts can suffer from the problem of dimensionality curse ,which degrades both search accuracy and search peed. Regarding search accuracy, the presence of irrelevant features with respect to a query can contaminate similarity measurement, and hence decrease both the recall and precision of thatquery. To remedy this problem, we present a mining method that learns online user query concept and identities important features quickly. Regarding search speed, the presence of a large number of feature can low down query-concept learning and indexing performance. We propose a divide-and-conquer method that divides the concept-learning task into G subtasks to achieve speedup. We notice that a task must be divided carefully, or search accuracy maysuffer. We thus propose a genetic-based mining algorithm to discover good feature groupings. Through analysis and mining result, we observe that organizing image features in a multi-resolution manner, and minimizing intra-group feature correlation, can peed up query-concept learning substantially while maintaining high search accuracy.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Data mining, query concept, relevance feedback.]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P437128</person_id>
				<author_profile_id><![CDATA[81100476622]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Beitao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39047851</person_id>
				<author_profile_id><![CDATA[81416596768]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wei-Cheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39034367</person_id>
				<author_profile_id><![CDATA[81344489120]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Edward]]></first_name>
				<middle_name><![CDATA[Y.]]></middle_name>
				<last_name><![CDATA[Chang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77043651</person_id>
				<author_profile_id><![CDATA[81384615208]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Kwang-Ting]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cheng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657868</article_id>
		<sort_key>361</sort_key>
		<display_label></display_label>
		<pages>361</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>54</seq_no>
		<title><![CDATA[Mining the Smallest Association Rule Set for Predictions]]></title>
		<page_from>361</page_from>
		<page_to>368</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657868</url>
		<abstract>
			<par><![CDATA[Mining transaction databases for association rules usually generates a large number of rules, most of which are unnecessary when used for subsequent prediction. In this paper we define a rule set for a given transaction database that is much smaller than the association rule set but makes the same predictions as the association rule set by the confidence priority. We call this subset the informative rule set. The informative rule set is not constrained to particular target items; and it is smaller than the non-redundant association rule set. We present an algorithm to directly generate the informative rule set, i.e., without generating all frequentitemsets first, and that accesses the database less often than other unconstrained direct methods. We show experimentally that the informative rule set is much smaller than boththe association rule set and the non-redundant association rule set, and that it can be generated more efficiently.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39045129</person_id>
				<author_profile_id><![CDATA[81100486197]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jiuyong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77045789</person_id>
				<author_profile_id><![CDATA[81327491417]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P247615</person_id>
				<author_profile_id><![CDATA[81100135456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Rodney]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Topor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657866</article_id>
		<sort_key>369</sort_key>
		<display_label></display_label>
		<pages>369</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>55</seq_no>
		<title><![CDATA[CMAR]]></title>
		<subtitle><![CDATA[Accurate and Efficient Classification Based on Multiple Class-Association Rules]]></subtitle>
		<page_from>369</page_from>
		<page_to>376</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657866</url>
		<abstract>
			<par><![CDATA[Previous studies propose that associative classification has high classification accuracy and strong flexibility at handling unstructured data. However, it still suffers from the huge set of mined rules and sometimes biased classification or overfitting since the classificationis based on only single high-confidence rule. In this study, we propose new associative classification method, CMAR, i.e., Classification based on Multiple Association Rules. The method extends an efficient frequent pattern mining method, FP-growth ,constructs classdistribution-associated FP-tree, and mines large database efficiently. Moreover, it applies CR-tree structure to store and retrieve mined association rulesefficiently, and prunes rules effectively based on confidence, correlation and database coverage. The classification is performed based on weighted X2 analysis using multiple strong association rules. Our extensive experiments on 26 databases from UCI machine learning database repository show that CMAR is consistent, highly effective at classificationof various kinds of databases and has better average classificationaccuracy in comparison with CBA and C4.5.Moreover,our performancestudy shows that the method is highly efficient and scalable in comparison with other reported associative classification methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P501912</person_id>
				<author_profile_id><![CDATA[81100480956]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wenmin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40023202</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15029106</person_id>
				<author_profile_id><![CDATA[81100323054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658041</article_id>
		<sort_key>377</sort_key>
		<display_label></display_label>
		<pages>377</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>56</seq_no>
		<title><![CDATA[Analyzing the Interestingness of Association Rules from the Temporal Dimension]]></title>
		<page_from>377</page_from>
		<page_to>384</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658041</url>
		<abstract>
			<par><![CDATA[Rule discovery is one of the central tasks of data mining. Existing research has produced many algorithms for the purpose. These algorithms, however, often generate too manyrules. In the past few years, rule interestingness techniques were proposed to help the user find interesting rules. These techniques typically employ the dataset as a whole to mine rules, and then filter and/or rank the discovered rules in various ways. In this paper, we argue that this is insufficient. These techniques are unable to answer a question that is of criticalimportance to the application of rules, i.e., can the rules be trusted? In practice, the users are always concerned with the question. They want to know whether the rules indeed represent some true and stable (or reliable)underlying relationships in the domain. If a rule is not stable, does it show any systematic pattern such as a trend? Before any rule can be used, these questions must be answered. This paper proposes a technique to use statistical methods to analyze rules from the temporal dimension to answer these questions. Experimental results show that the proposed technique is very effective.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP95041065</person_id>
				<author_profile_id><![CDATA[81414615435]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14157075</person_id>
				<author_profile_id><![CDATA[81100447655]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yiming]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P491131</person_id>
				<author_profile_id><![CDATA[81100384579]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ronnie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657725</article_id>
		<sort_key>385</sort_key>
		<display_label></display_label>
		<pages>385</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>57</seq_no>
		<title><![CDATA[Closing the Loop]]></title>
		<subtitle><![CDATA[An Agenda- and Justification-Based Framework for Selecting the Next Discovery Task to Perform]]></subtitle>
		<page_from>385</page_from>
		<page_to>392</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657725</url>
		<abstract>
			<par><![CDATA[We propose and evaluate an agenda-and justification-basedarchitecture for discovery systems that selects the next tasks to perform. This framework has manydesirable properties: (1) it facilitates the encoding of general discovery strategies using a variety of backgroundknowledge, (2) t reasons about the appropriateness of the tasks being considered, and (3) it tailors its behavior toward a user 's interests. A prototype discovery program called HAMB demonstrates that both reasons andestimates of interestingness contribute to performance in the domains of protein crystallization and patient rehabilitation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP43119444</person_id>
				<author_profile_id><![CDATA[81100365504]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gary]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Livingston]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14172391</person_id>
				<author_profile_id><![CDATA[81100492433]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Rosenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14160456</person_id>
				<author_profile_id><![CDATA[81100456580]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bruce]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Buchanan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657875</article_id>
		<sort_key>393</sort_key>
		<display_label></display_label>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>58</seq_no>
		<title><![CDATA[Closing the Loop]]></title>
		<subtitle><![CDATA[Heuristics for Autonomous Discovery]]></subtitle>
		<page_from>393</page_from>
		<page_to>400</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657875</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP43119444</person_id>
				<author_profile_id><![CDATA[81100365504]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gary]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Livingston]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14172391</person_id>
				<author_profile_id><![CDATA[81100492433]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[John]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Rosenberg]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14160456</person_id>
				<author_profile_id><![CDATA[81100456580]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bruce]]></first_name>
				<middle_name><![CDATA[G.]]></middle_name>
				<last_name><![CDATA[Buchanan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657872</article_id>
		<sort_key>401</sort_key>
		<display_label></display_label>
		<pages>401</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>59</seq_no>
		<title><![CDATA[Anchor Text Mining for Translation of Web Queries]]></title>
		<page_from>401</page_from>
		<page_to>408</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657872</url>
		<abstract>
			<par><![CDATA[This paper presents an approach to automatically extracting translations of Web query terms through mining of Web anchor texts and link structures. One of the existing difficulties in cross-language information retrieval (CLIR)and Web search is the lack of the appropriate translations of new terminology and proper names. Such a difficult problem can be effectively alleviated by our proposed approach, and the resource of anchor texts in the Web is proven a valuable corpus for this kind of term translation.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P297597</person_id>
				<author_profile_id><![CDATA[81100052538]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wen-Hsiang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP94030173</person_id>
				<author_profile_id><![CDATA[81450595233]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lee-Feng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chien]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP310554800</person_id>
				<author_profile_id><![CDATA[81539665056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hsi-Jian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657859</article_id>
		<sort_key>409</sort_key>
		<display_label></display_label>
		<pages>409</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>60</seq_no>
		<title><![CDATA[Mining Mutually Dependent Patterns]]></title>
		<page_from>409</page_from>
		<page_to>416</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657859</url>
		<abstract>
			<par><![CDATA[In some domains, such as isolating problems in computer net-worksand discovering stock market irregularities, there is more interest inpatterns consisting of infrequent, but highly correlated items rather thanpatterns that occur frequently (as defined by minsup, the minimum supportlevel). Herein, we describe the m-pattern, a new pattern that is definedin terms of minp, the minimum probability of mutual dependence of itemsin the pattern. We show that all infrequent m-pattern can be discovered byan efficient algorithm that makes use of: (a) a linear algorithm to qualifyan m-pattern; (b) an effective technique for candidate pruning based on anecessary condition for the presence of an m-pattern; and (c) a level-wisesearch for m-pattern discovery (which is possible because m-patterns aredownward closed). Further, we consider frequent m-patterns, which aredefined in terms of both minp and minsup. Using synthetic data, we studythe scalability of our algorithm. Then, we apply our algorithm to data froma production computer network both to show the m-patterns present andto contrast with frequent patterns. We show that when minp_0, our algorithmis equivalent to finding frequent patterns. However, with a larger minp, our algorithm yields a modest number of highly correlated items, which makes it possible to mine for infrequent but highly correlated item-sets. To date, many actionable m-patterns have been discovered in production systems.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P263310</person_id>
				<author_profile_id><![CDATA[81100447843]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77034661</person_id>
				<author_profile_id><![CDATA[81406597365]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Joseph]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Hellerstein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657736</article_id>
		<sort_key>417</sort_key>
		<display_label></display_label>
		<pages>417</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>61</seq_no>
		<title><![CDATA[The EQ Framework for Learning Equivalence Classes of Bayesian Networks]]></title>
		<page_from>417</page_from>
		<page_to>424</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657736</url>
		<abstract>
			<par><![CDATA[This paper proposes a theoretical and an algorithmic framework for the analysis and the design of efficient learning algorithms which explore the space of equivalence classes of Bayesian network structures.This framework is composed of a generic learning model which uses essential graphs and more general partially directed graphs i order to represent the equivalence classes evaluated during search, operational characterizations of these graphs, processing procedures and formulas for directly calculating their score.The experimental results of the algorithms designed within this framework show that the space of equivalence classes may be explored efficiently and with better results than the classical search in the space of Bayesian network structures.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P485988</person_id>
				<author_profile_id><![CDATA[81100559352]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Munteanu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P482018</person_id>
				<author_profile_id><![CDATA[81100255507]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mohamed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Bendou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658042</article_id>
		<sort_key>425</sort_key>
		<display_label></display_label>
		<pages>425</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>62</seq_no>
		<title><![CDATA[Visualizing Association Mining Results through Hierarchical Clusters]]></title>
		<page_from>425</page_from>
		<page_to>432</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658042</url>
		<abstract>
			<par><![CDATA[We propose a new methodology for visualizing association mining results. Inter-item distances are computed from combinations of item set supports. The new distances retain a simple pairwise structure, and are consistent with important frequently occurring item sets. Thus standard tools of visualization, e.g. hierarchical clustering dendrograms can still be applied, while the distance information upon which they are based is richer. Our approach is applicable to general association mining applications, as well as applications involving information spaces modeled by directed graphs, e.g. the Web. In the context of collections of hypertext documents, the inter-document distances capture the information inherent in a collection's link structure, a for of link mining. We demonstrate our methodology with document sets extracted fro the Science Citation Index, applying a metric that measures consistency between clusters and frequent itemsets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP310190100</person_id>
				<author_profile_id><![CDATA[81540364256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Noel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39046015</person_id>
				<author_profile_id><![CDATA[81100503766]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Vijay]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Raghavan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14060031</person_id>
				<author_profile_id><![CDATA[81100141923]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chee-Hung]]></first_name>
				<middle_name><![CDATA[Henry]]></middle_name>
				<last_name><![CDATA[Chu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658043</article_id>
		<sort_key>433</sort_key>
		<display_label></display_label>
		<pages>433</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>63</seq_no>
		<title><![CDATA[Mining Constrained Association Rules to Predict Heart Disease]]></title>
		<page_from>433</page_from>
		<page_to>440</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658043</url>
		<abstract>
			<par><![CDATA[This work describes our experiences on discovering association rules in medical data to predict heart disease. We focus on two aspects in this work: mapping medical data toa transaction format suitable for mining association rules and identifying useful constraints. Based on these aspects we introduce an improved algorithm to discover constrainedassociation rules. We present an experimental sectionexplaining several interesting discovered rules.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39051027</person_id>
				<author_profile_id><![CDATA[81100618426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Carlos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ordonez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39046308</person_id>
				<author_profile_id><![CDATA[81100511324]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Edward]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Omiecinski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P474811</person_id>
				<author_profile_id><![CDATA[81100550204]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Levien]]></first_name>
				<middle_name><![CDATA[de]]></middle_name>
				<last_name><![CDATA[Braal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P448499</person_id>
				<author_profile_id><![CDATA[81100249190]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Cesar]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Santana]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P210013</person_id>
				<author_profile_id><![CDATA[81100629869]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Norberto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ezquerra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P470071</person_id>
				<author_profile_id><![CDATA[81540473256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Jose]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Taboada]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P451955</person_id>
				<author_profile_id><![CDATA[81100446671]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cooke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P454609</person_id>
				<author_profile_id><![CDATA[81100419662]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Elizabeth]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Krawczynska]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP310195100</person_id>
				<author_profile_id><![CDATA[81539349156]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>9</seq_no>
				<first_name><![CDATA[Ernest]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Garcia]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657873</article_id>
		<sort_key>441</sort_key>
		<display_label></display_label>
		<pages>441</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>64</seq_no>
		<title><![CDATA[H-Mine]]></title>
		<subtitle><![CDATA[Hyper-Structure Mining of Frequent Patterns in Large Databases]]></subtitle>
		<page_from>441</page_from>
		<page_to>448</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657873</url>
		<abstract>
			<par><![CDATA[Methods for efficient mining of frequent patterns have been studied extensively by many researchers. However, the previously proposed methods still encounter someperformance bottlenecks when mining databases with different data characteristics, such as dense vs. sparse, long vs. short patterns, memory-based vs. disk-based, etc.In this study, we propose a simple and novel hyper-linkeddata structure, H-struct , and a new mining algorithm, H-mine ,which takes advantage of this data structure anddynamically adjusts links in the mining process. A distinct feature of this method is that it has very limitedand precisely predictable space overhead and runs really fast in memory-based setting. Moreover, it ca be scaled up to very large databases by database partitioning, and whenthe data set becomes dense,(conditional)FP-trees can be constructed dynamically as part of the mining process. Our study shows that H-mine has high performance in various kinds of data, outperforms the previously developedalgorithms in different settings, and is highly scalable in mining large databases. This study also proposes a new datamining methodology, space-preserving mining ,which mayhave strong impact in the future development of efficient and scalable data mining methods.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15029106</person_id>
				<author_profile_id><![CDATA[81100323054]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95041308</person_id>
				<author_profile_id><![CDATA[81351593425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jiawei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Han]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95033232</person_id>
				<author_profile_id><![CDATA[81451594025]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Hongjun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39052440</person_id>
				<author_profile_id><![CDATA[81100649235]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Shojiro]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nishio]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14219879</person_id>
				<author_profile_id><![CDATA[81100640608]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Shiwei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14126449</person_id>
				<author_profile_id><![CDATA[81452599778]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Dongqing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658032</article_id>
		<sort_key>449</sort_key>
		<display_label></display_label>
		<pages>449</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>65</seq_no>
		<title><![CDATA[FARM]]></title>
		<subtitle><![CDATA[A Framework for Exploring Mining Spaces with Multiple Attributes]]></subtitle>
		<page_from>449</page_from>
		<page_to>456</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658032</url>
		<abstract>
			<par><![CDATA[Mining for frequent itemsets typically involves a preprocessing step in which data with multiple attributes are grouped into transactions, and item are defined based on attribute values. We have observed that such fixed attribute mining can severely constrain the pattern that are discovered. Herein, we introduce mining paces, a new framework for mining multi-attribute data that include the discovery of transaction and item definition (with the exploitation of taxonomies and functional dependenciesif they are available).We prove that special downward closure properties (or anti-monotonic property) hold for mining paces, aresult that allows us to construct efficient algorithms for mining pattern without the constraint of fixed attribute mining. We apply our algorithm to real world data collected from a production computer network. The result how that by exploiting the special kind of downward closure in mining paces, execution times for mining can be reduced by a factor of three to four.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP43115864</person_id>
				<author_profile_id><![CDATA[81100072657]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chang-Shing]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP54029565</person_id>
				<author_profile_id><![CDATA[81455605782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haixun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P263310</person_id>
				<author_profile_id><![CDATA[81100447843]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Sheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77034661</person_id>
				<author_profile_id><![CDATA[81406597365]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Joseph]]></first_name>
				<middle_name><![CDATA[L.]]></middle_name>
				<last_name><![CDATA[Hellerstein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658026</article_id>
		<sort_key>457</sort_key>
		<display_label></display_label>
		<pages>457</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>66</seq_no>
		<title><![CDATA[Neural Analysis of Mobile Radio Access Network]]></title>
		<page_from>457</page_from>
		<page_to>466</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658026</url>
		<abstract>
			<par><![CDATA[The Self-Organizing Map (SOM) is an efficient tool for visualization and clustering of multidimensional data. It transforms the input vectors on two-dimensional grid of prototype vectors and orders them. The ordered prototype vectors are easier to visualize and explore than the original data. Mobile networks produce a huge amount of spatio-temporaldata. The data consists of parameters of base stations (BS)and quality information of calls. There are two alternatives in starting the data analysis. We can build either a general one-cell-model trained using state vectors from all cells, or a model of the network using state vectors with parameters from all mobile cells. In both methods,further analysis is needed to understand the reasons for various operational states of the entire network.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14028896</person_id>
				<author_profile_id><![CDATA[81318496066]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kimmo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Raivio]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39028523</person_id>
				<author_profile_id><![CDATA[81100123133]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Olli]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Simula]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P369466</person_id>
				<author_profile_id><![CDATA[81100134948]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jaana]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Laiho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658048</article_id>
		<sort_key>465</sort_key>
		<display_label></display_label>
		<pages>465</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>67</seq_no>
		<title><![CDATA[Discovery of Association Rules in Tabular Data]]></title>
		<page_from>465</page_from>
		<page_to>472</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658048</url>
		<abstract>
			<par><![CDATA[In this paper we address the problem of finding all association rules in tabular data. An Algorithm, ARA, for finding rules, that satisfy clearly specified constraints, in tabular data is presented. ARA is based on the Dense Miner algorithm but includes an additional constraintand an improved method of calculating support. ARA is tested and compared with our implementation of Dense Miner ;it is conclude that ARA is usually more efficient than Dense Miner and is often considerably more so.We also consider the potential for modifying the constraints used in ARA in order to find more generalrules.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P459857</person_id>
				<author_profile_id><![CDATA[81327491147]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Graeme]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Richards]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P290878</person_id>
				<author_profile_id><![CDATA[81312485067]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Victor]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Rayward-Smith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658190</article_id>
		<sort_key>473</sort_key>
		<display_label></display_label>
		<pages>473</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>68</seq_no>
		<title><![CDATA[Theory and Applications of Attribute Decomposition]]></title>
		<page_from>473</page_from>
		<page_to>480</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658190</url>
		<abstract>
			<par><![CDATA[This paper examines the Attribute Decomposition Approach with simple Bayesian combination for dealing with classication problems that contain high number ofattributes and moderate numbers of records. According to the attribute Decomposition approach, the set of input attributes is automatically decomposed into several subsets. classication model is built for each subset, then all the models are combined using simple Bayesian combination.This paper presents theoretical and practical foundation for the Attribute Decomposition approach. A greedyprocedure, called D-IFN, is developed to decompose the input attributes set into subsets and build a classication model for each subset separately. The results achieved in theempirical comparison testing with well-known classicationmethods (like C4.5)indicate the superiority of the decomposition approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39046509</person_id>
				<author_profile_id><![CDATA[81331503121]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lior]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rokach]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P484145</person_id>
				<author_profile_id><![CDATA[81100370302]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Oded]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mainon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657883</article_id>
		<sort_key>481</sort_key>
		<display_label></display_label>
		<pages>481</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>69</seq_no>
		<title><![CDATA[FlExPat]]></title>
		<subtitle><![CDATA[Flexible Extraction of Sequential Patterns]]></subtitle>
		<page_from>481</page_from>
		<page_to>488</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657883</url>
		<abstract>
			<par><![CDATA[This paper addresses sequential data mining, a sub-area of data mining where the data to be analyzed is organized in sequences. In many problem domains a natural ordering exists over data. Examples of sequential databases (SDBs) include: (a)collections of temporal data sequences, such as chronologicalseries of daily stock indices or multimedia data (sound, music, video..); and (b) macromolecule banks, where aminoacid or proteic sequences are represented as strings.In a SDB it is often valuable to detect regularities through one or several sequences. In particular, finding exact or approximate repetitions of segments ca be utilized directly (e.g.for determining the biochemical activity of a protein region) or indirectly, e.g. for prediction in finance. To this end, we present concepts and an algorithm for automatically extracting sequential patterns from a sequential database. Such a patter is defined as a group of significantly similar segments from one or several sequences. Appropriate functions for measuringsimilarity between sequence segments are proposed, generalizing the edit distance framework. There is a trade off here between flexibility, particularly in sequence data representation and in associated similarity metrics, and computational efficiency. Wedesigned the FlExPat algorithm to satisfactorily cope with this trade-off. FlExPat's complexity is in practice lesser than quadratic in the total length of the SDB analyzed, while allowinghigh flexibility. Some experimental results obtained with FlExPat on music data are presented and commented.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31025308</person_id>
				<author_profile_id><![CDATA[81100061225]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pierre-Yves]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rolland]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658029</article_id>
		<sort_key>489</sort_key>
		<display_label></display_label>
		<pages>489</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>70</seq_no>
		<title><![CDATA[Interestingness PreProcessing]]></title>
		<page_from>489</page_from>
		<page_to>496</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658029</url>
		<abstract>
			<par><![CDATA[As the size of databases increases, the number of rules mined from them also increases, often to a extent that overwhelms users. To address this problem, an important part of the KDD process is dedicated to determining which of these patterns is interesting. In this paper we define the Interestingness PreProcessing Step, and introduce a new framework for interestingness analysis. In asimilar fashion to data-preprocessing, this preprocessing should always be applied prior to interestingness processing. A strictrequirement, and the biggest challenge, in defining Interestingness PreProcessing techniques is that the preprocessing will not eliminate any potentially interesting patterns. That is, the preprocessing methods must be domain-,task-and user-independent. This property differentiates the preprocessing methods from existing interestingness criteria, and, since they can be applied automatically, makes them very useful. This generic nature also makes them rare: PreProcessing methods are very challenging to define.We also define in this paper the first two preprocessing techniques, and present the empirical results of applying them to six databases. The results indicate that Interestingness PreProcessing Step is very powerful: in most cases, an average of half the rules mined were eliminated by the application of the two Interestingness PreProcessing techniques. These results are Particularly significant since no user-interaction is required to achieve them.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P265150</person_id>
				<author_profile_id><![CDATA[81100217226]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sigal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sahar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658030</article_id>
		<sort_key>497</sort_key>
		<display_label></display_label>
		<pages>497</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>71</seq_no>
		<title><![CDATA[Data Analysis and Mining in Ordered Information Tables]]></title>
		<page_from>497</page_from>
		<page_to>504</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658030</url>
		<abstract>
			<par><![CDATA[Many real world problems deal with ordering objects instead of classifying objects, although majority of research in machine learning and data mining has been focused on the latter. For modeling ordering problems, we generalize the notion of information tables to ordered information tables by adding order relations on attribute values. The problem of mining ordering rules is formulated as findingassociation between orderings of attribute values and the overall ordering of objects. An ordering rules ay state that "if the value of an object x on an attribute a is ordered ahead of the value of another object y on the same attribute, then x is ordered ahead of y" For mining ordering rules, we first transform an ordered information table into a binaryinformation, and then apply any standard machine learning and data mining algorithms. As an illustration, we analyze in detail MacLean's universities ranking for the year 2000.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P503658</person_id>
				<author_profile_id><![CDATA[81100626171]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43145413</person_id>
				<author_profile_id><![CDATA[81100543359]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Y.]]></first_name>
				<middle_name><![CDATA[Y.]]></middle_name>
				<last_name><![CDATA[Yao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43125736</person_id>
				<author_profile_id><![CDATA[81327492811]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ning]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658036</article_id>
		<sort_key>505</sort_key>
		<display_label></display_label>
		<pages>505</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>72</seq_no>
		<title><![CDATA[LPMiner]]></title>
		<subtitle><![CDATA[An Algorithm for Finding Frequent Itemsets Using Length-Decreasing Support Constraint]]></subtitle>
		<page_from>505</page_from>
		<page_to>512</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658036</url>
		<abstract>
			<par><![CDATA[Over the years, a variety of algorithms or finding frequentitemsets in very large transaction databases have been developed. The key feature in most to these algorithms is that they use a constant support constraint to control the inherently exponential complexity of the problem. In general, itemsets that contain only a few items will tend to be interesting if they have a high support, whereas long itemsets can still be interesting even if their support is relatively small. Ideally, we desire to have an algorithm that finds all the frequent itemsets whose support decreases as a function of their length. In this paper we present an algorithm called LPMiner, that finds all itemsets that satisfy a length-decreasing support constraint. Our experimental evaluation shows that LPMiner is up to two orders of magnitude faster than the FP-growth algorithm or finding itemsets at a constant support constraint, and that its runtime increasesgradually as the average length of the transactions (and the discovered itemsets) increases.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P479556</person_id>
				<author_profile_id><![CDATA[81100062632]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Masakazu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Seno]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14015889</person_id>
				<author_profile_id><![CDATA[81100008465]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Karypis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658189</article_id>
		<sort_key>513</sort_key>
		<display_label></display_label>
		<pages>513</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>73</seq_no>
		<title><![CDATA[Document Clustering and Cluster Topic Extraction in Multilingual Corpora]]></title>
		<page_from>513</page_from>
		<page_to>520</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658189</url>
		<abstract>
			<par><![CDATA[A statistics-based approach for clustering documents and for extracting cluster topics is described. Relevant (meaningful) Expressions (REs) automatically extracted from corpora are used as clustering base features. These features are transformed and its number is strongly reduced in order to obtain a small set of document classificationfeatures. This is achieved on the basis of PrincipalComponents Analysis. Model-Based Clustering Analysis finds thebest number of clusters. Then, the most important REs are extracted from each cluster and taken as document cluster topics.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P468793</person_id>
				<author_profile_id><![CDATA[81384595079]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Joaquim]]></first_name>
				<middle_name><![CDATA[Ferreira da]]></middle_name>
				<last_name><![CDATA[Silva]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P468566</person_id>
				<author_profile_id><![CDATA[81100209283]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jo&#227;o]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mexia]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P448104</person_id>
				<author_profile_id><![CDATA[81543649756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Carlos]]></first_name>
				<middle_name><![CDATA[Agra]]></middle_name>
				<last_name><![CDATA[Coelho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14131033</person_id>
				<author_profile_id><![CDATA[81100368247]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jos&#233;]]></first_name>
				<middle_name><![CDATA[Gabriel Pereira]]></middle_name>
				<last_name><![CDATA[Lopes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657884</article_id>
		<sort_key>521</sort_key>
		<display_label></display_label>
		<pages>521</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>74</seq_no>
		<title><![CDATA[Hierarchical Text Classification and Evaluation]]></title>
		<page_from>521</page_from>
		<page_to>528</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657884</url>
		<abstract>
			<par><![CDATA[Hierarchical Classification refers to assigning of one or more suitable categories from a hierarchical category space to a document. While previous work in hierarchical classification focused on virtual category trees where documents are assigned only to the leaf categories, we propose atop-down level-based classification method that can classify documents to both leaf and internal categories. As the standard performance measures assume independence between categories, they have not considered the documents incorrectly classified into categories that are similar or not far from the correct ones in the category tree. We therefore propose the Category-Similarity Measures and Distance-Based Measures to consider the degree of misclassification in measuring the classification performance. An experiment has been carried out to measure the performance four proposed hierarchical classification method. The results showed that our method performs well for Reuters text collection when enough training documents are given andthe new measures have indeed considered the contributions of misclassified documents.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14156823</person_id>
				<author_profile_id><![CDATA[81100446994]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Aixin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P75781</person_id>
				<author_profile_id><![CDATA[81100399142]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ee-Peng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658028</article_id>
		<sort_key>529</sort_key>
		<display_label></display_label>
		<pages>529</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>75</seq_no>
		<title><![CDATA[Web Cartography for Online State Promotion]]></title>
		<subtitle><![CDATA[An Algorithm for Clustering Web Resources]]></subtitle>
		<page_from>529</page_from>
		<page_to>535</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658028</url>
		<abstract>
			<par><![CDATA[This paper presents an approach of Web cartography to be used in the context of online site promotion.The overall objective is to provide users with handy maps offering information about candidate sites for the creation of hyperlinks that enable a large flow of targeted visitors.Two main types of data must be considered; texts and hyperlinks.We propose to exploit the latter to construct a relevant corpus on which semantic as well as graph analysis can be applied.The stress is put on theclustering of Web resources based on the link network,which makes it possible to highlight groups of strongly connected sites which are of the utmost interest for our application.To tackle the site graph partitioning problem, we turn to a promising iterative approach initially developedin the context of computer-aided design.It uses spectral decomposition of the Laplacian matrix to embed theconsidered graph in a geometric space where efficientmethods can be applied.An algorithm that was adaptedfrom an existing one implements the method.Experimentswere conductedon a real application case concerning the promotion of a site dealing with Cognac.We present the obtained map as well as leads to exploit it.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P456838</person_id>
				<author_profile_id><![CDATA[81100616920]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fran&#231;ois]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Velin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14181273</person_id>
				<author_profile_id><![CDATA[81100522201]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Pascale]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuntz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15026491</person_id>
				<author_profile_id><![CDATA[81100224767]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Henri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Briand]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657876</article_id>
		<sort_key>536</sort_key>
		<display_label></display_label>
		<pages>536</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>76</seq_no>
		<title><![CDATA[Maintenance of Sequential Patterns for Record Deletion]]></title>
		<page_from>536</page_from>
		<page_to>541</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657876</url>
		<abstract>
			<par><![CDATA[In the past, we proposed an incremental mining algorithm for maintenance of sequential patterns based on the concept of pre-large sequences as new records were inserted. In this paper, we attempt to apply the concept of pre-large sequences to maintain sequentialpatterns as records are deleted. Pre-large sequences are defined by a lower support threshold and an upper support threshold. They act as buffers to avoid the movements of sequential patterns directly from large to small and vice-versa. Our proposed algorithm does notrequire rescanning original databases until the accumulative amount of deleted customer sequences exceeds a safety bound, which depends on database size. As databases grow larger, the numbers of deleted customer sequences allowed before database rescanningis required also grow. The proposed approach is thus efficient for a large database.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Data mining, incremental mining, record deletion, maintenance, sequentialpattern.]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P449059</person_id>
				<author_profile_id><![CDATA[81443593450]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ching-Yao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40029459</person_id>
				<author_profile_id><![CDATA[81100648630]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tzung-Pei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP38026066</person_id>
				<author_profile_id><![CDATA[81100582678]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shian-Shyong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tseng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657862</article_id>
		<sort_key>542</sort_key>
		<display_label></display_label>
		<pages>542</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>77</seq_no>
		<title><![CDATA[SSDT]]></title>
		<subtitle><![CDATA[A Scalable Subspace-Splitting Classifier for Biased Data]]></subtitle>
		<page_from>542</page_from>
		<page_to>549</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657862</url>
		<abstract>
			<par><![CDATA[Decision trees are one of the most extensively used data mining models. Recently, a number of efficient, scalable algorithms for constructing decision trees on large disk-resident dataset have been introduced. In this paper, we study the problem of learning scalable decision trees from datasets with biased class distribution. Our objective is to build decision trees that are ore concise and oreinterpretable while maintaining the scalability of the model.To achieve this, our approach searches for subspace clusters of data cases of the biased class to enable multivariate splittings based on weighted distances to such clusters. In orderto build concise and interpretable models, other approaches including multivariate decision trees and association rules, often introduce scalability and performance issues. The SSDT algorithm we present achieves the objective without loss in efficiency, scalability, and accuracy.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP54029555</person_id>
				<author_profile_id><![CDATA[81350588549]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Haixun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95043927</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>757721</article_id>
		<sort_key>550</sort_key>
		<display_label></display_label>
		<pages>550</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>78</seq_no>
		<title><![CDATA[Meta-patterns]]></title>
		<subtitle><![CDATA[Revealing Hidden Periodic Patterns]]></subtitle>
		<page_from>550</page_from>
		<page_to>557</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=757721</url>
		<abstract>
			<par><![CDATA[Discovery of periodic patterns in time series data has become an active research area with many applications. These patterns can be hierarchical in nature, where higher level pattern may consist of repetitions of lower level patterns.Unfortunately, the presence of noise m y prevent these higher level patterns from being recognized in the sense that two portions (of data sequence) that support the same (high level) pattern may have different layouts of occurrences of basic symbols. There may not exist any common representation in terms of raw symbol combinations; and hence such (high level) pattern may not be expressed by any previous model (defined on raw symbols or symbol combinations) and would not be properly recognized by any existing method. In this paper, we propose novel model, namely meta-pattern, to capture these high level patterns. As more flexible model, the number of potential meta-patterns could be very large. A substantial difficulty lies on how to identify the proper pattern candidates. However, the well-known Apriori property is not able to provide sufficient pruning power. A new property, namely component location property, is identified and used to conduct the candidate generation so that an efficient computation-based mining algorithm can be developed. Last but not least, we apply our algorithm to some real and synthetic sequences and some interesting patterns are discovered.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP77029716</person_id>
				<author_profile_id><![CDATA[81452601906]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP54031578</person_id>
				<author_profile_id><![CDATA[81350589969]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jiong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95043281</person_id>
				<author_profile_id><![CDATA[81350576309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Philip]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Yu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657858</article_id>
		<sort_key>558</sort_key>
		<display_label></display_label>
		<pages>558</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>79</seq_no>
		<title><![CDATA[Using Boosting to Simplify Classification Models]]></title>
		<page_from>558</page_from>
		<page_to>565</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657858</url>
		<abstract>
			<par><![CDATA[Ensemble classification techniques such as bagging ,boosting and arcingalgorithms have been shown to lead to reduced classification error on unseencases and seem immune t the problem of overfitting. Several explanations forthe reduction in generalisation error have been presented, with authors morerecently defining and applying diagnostics such as edge and margin [4,9,10 ].These measures pr vide insight into the behaviour of ensemble classifiers but can they be exploited further?]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P500886</person_id>
				<author_profile_id><![CDATA[81100124884]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Virginia]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wheway]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>878515</article_id>
		<sort_key>566</sort_key>
		<display_label></display_label>
		<pages>566</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>80</seq_no>
		<title><![CDATA[Interestingness, Peculiarity, and Multi-database Mining]]></title>
		<page_from>566</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=878515</url>
		<abstract>
			<par><![CDATA[In order to discover new, surprising, interesting patterns hidden in data, peculiarity oriented mining and multi-database mining are required. In the paper, we introduce peculiarity rules as new class of rules, which can be discovered from relatively low number of peculiar data by searching the relevance among the peculiar data. We give formal interpretation and comparison of three classes of rules: association rules, exception rules, and peculiarityrules, as well as describe how to mine more interesting peculiarity rules in multiple databases.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658192</article_id>
		<sort_key>577</sort_key>
		<display_label></display_label>
		<pages>577</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>81</seq_no>
		<title><![CDATA[Discovering Similar Patterns for Characterising Time Series in a Medical Domain]]></title>
		<page_from>577</page_from>
		<page_to>579</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658192</url>
		<abstract>
			<par><![CDATA[In this article, we describe the process of discovering similar patterns in time series and creating reference models for population groups in a medical domain, and particularly in the field of physiotherapy, using data mining techniques on a set of isokinetic data.The discovered knowledge was evaluated against the expertise of a physician specialised in isokinetic techniques, and applied in the I4 (Intelligent Interpretation of Isokinetic Information) project developed in conjunction with the Spanish National Centre for Sports Research and Sciences and the School of Physiotherapy of the Spanish National Organisation for the Blind for muscular diagnosis and rehabilitation, injury prevention, training evaluation and planning, etc., of elite and blind athletes.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P84211</person_id>
				<author_profile_id><![CDATA[81100146542]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fernando]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Alonso]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P149999</person_id>
				<author_profile_id><![CDATA[81100036941]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Juan]]></first_name>
				<middle_name><![CDATA[Pedro]]></middle_name>
				<last_name><![CDATA[Cara&#231;a-Valente]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P475157</person_id>
				<author_profile_id><![CDATA[81100018853]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Lo&#239;c]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mart&#237;nez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P447399</person_id>
				<author_profile_id><![CDATA[81100129826]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[C&#233;sar]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Montes]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657731</article_id>
		<sort_key>580</sort_key>
		<display_label></display_label>
		<pages>580</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>82</seq_no>
		<title><![CDATA[Creating Ensembles of Classifiers]]></title>
		<page_from>580</page_from>
		<page_to>581</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657731</url>
		<abstract>
			<par><![CDATA[Ensembles of classifiers offer promise in increasing overall classification accuracy. The availability of extremely large datasets has opened avenues for application of distributed and/or parallel learning to efficiently learn models of them. In this paper, distributed learningis done by training classifiers on disjoint subsets of the data. We examine a random partitioning method to create disjoint subsets and propose a more intelligent way of partitioning into disjointsubsets using clustering. It was observed that the intelligent method of partitioning generally performs better than random partitioning for our datasets. In both methods a significant gain in accuracy may be obtained by applying bagging to each of the disjoint subsets, creating multiple diverse classifiers. The significance of our finding is that a partition strategy for even small/moderate sized datasets when combined with bagging can yield better performancethan applying a single learner using the entire dataset.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P437805</person_id>
				<author_profile_id><![CDATA[81100002770]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Nitesh]]></first_name>
				<middle_name><![CDATA[V.]]></middle_name>
				<last_name><![CDATA[Chawla]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P495687</person_id>
				<author_profile_id><![CDATA[81100037554]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Steven]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Eschrich]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77039223</person_id>
				<author_profile_id><![CDATA[81407593306]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Lawrence]]></first_name>
				<middle_name><![CDATA[O.]]></middle_name>
				<last_name><![CDATA[Hall]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657727</article_id>
		<sort_key>582</sort_key>
		<display_label></display_label>
		<pages>582</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>83</seq_no>
		<title><![CDATA[Association Rules Enhanced Classification of Underwater Acoustic Signal]]></title>
		<page_from>582</page_from>
		<page_to>583</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657727</url>
		<abstract>
			<par><![CDATA[Classification of underwater acoustic signal is one ofthe important fields of pattern recognition. Inspired bythe experience of training man experts in sonar, wepropose a two-phase training algorithm to exploit theassociation rules to reveal the understandable intrinsicrules contributing to correct classification in the knownmisclassification datasets in this paper. Preliminaryexperimental results demonstrate the potential ofclassification association rules to enhance the accuracyof classification of underwater acoustic signals.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15023002</person_id>
				<author_profile_id><![CDATA[81100119171]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P461141</person_id>
				<author_profile_id><![CDATA[81452601656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Haiying]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14219879</person_id>
				<author_profile_id><![CDATA[81100640608]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Shiwei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657726</article_id>
		<sort_key>584</sort_key>
		<display_label></display_label>
		<pages>584</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>84</seq_no>
		<title><![CDATA[Efficient Splitting Rules Based on the Probabilities of Pre-assigned Intervals]]></title>
		<page_from>584</page_from>
		<page_to>585</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657726</url>
		<abstract>
			<par><![CDATA[This paper describes new methods for classification in orderto find an optimal tree. Unlike the current splitting rules that areprovided by searching all threshold values, this paper proposes thesplitting rules that are based on the probabilities of pre-assignedintervals.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39039897</person_id>
				<author_profile_id><![CDATA[81100372139]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[June-Suh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP310166900</person_id>
				<author_profile_id><![CDATA[81544279856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nabil]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Adam]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657892</article_id>
		<sort_key>586</sort_key>
		<display_label></display_label>
		<pages>586</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>85</seq_no>
		<title><![CDATA[Inexact Field Learning]]></title>
		<subtitle><![CDATA[An Approach to Induce High Quality Rules from Low Quality Data]]></subtitle>
		<page_from>586</page_from>
		<page_to>588</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657892</url>
		<abstract>
			<par><![CDATA[To avoid low quality problem caused by low quality data, this paper introduces an inexactfield learning approach which derives rules by working on the fields of attributes with respect to classes, rather than on individual point values of attributes. The experimental results show that field learning achieved a higher prediction accuracy rate on new unseen test cases which is particularly true when the learning is performed on large low qualitydata.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP95044477</person_id>
				<author_profile_id><![CDATA[81536418356]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Honghua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P502938</person_id>
				<author_profile_id><![CDATA[81100034446]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Xiaoshu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14166161</person_id>
				<author_profile_id><![CDATA[81100475823]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Gang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657893</article_id>
		<sort_key>589</sort_key>
		<display_label></display_label>
		<pages>589</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>86</seq_no>
		<title><![CDATA[Incremental Support Vector Machine Construction]]></title>
		<page_from>589</page_from>
		<page_to>592</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657893</url>
		<abstract>
			<par><![CDATA[SVMs suffer from the problem of large memory requirement and CPU time when trained in batch mode on large data sets. We overcome these limitations, and at the same time make SVMs suitable for learning with data streams, by constructing incremental learning algorithms.We first introduce and compare different incremental learning techniques, and show that they are capable of producing performance results similar to the batch algorithm, and in some cases superior condensation properties. We then consider the problem of training SVMs using stream data. Our objective is to maintain an updated representation of recent batches of data. We apply incremental schemes to the problem and show that their accuracy is comparable to the batch algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15020877</person_id>
				<author_profile_id><![CDATA[81100062921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Carlotta]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Domeniconi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40028104</person_id>
				<author_profile_id><![CDATA[81100515024]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dimitrios]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gunopulos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658053</article_id>
		<sort_key>593</sort_key>
		<display_label></display_label>
		<pages>593</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>87</seq_no>
		<title><![CDATA[Mining Generalized Association Rules for Sequential and Path Data]]></title>
		<page_from>593</page_from>
		<page_to>596</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658053</url>
		<abstract>
			<par><![CDATA[While association rules for set data se and describe relations between parts of set valued objects completely, association rules for sequential data are restricted by specific interpretations of the subsequence relation: contiguous subsequences describe localfeatures of a sequence valued object, noncontiguous subsequences its global features. We model both types of features with generalized subsequences that describe local deviations by wildcards, and present a new algorithm of Apriori type for mining all generalized subsequences with prescribed minim m support from a given database of sequences. Furthermore we show that the givenalgorithm automatically takes into account an eventually underlying graph structure, i.e., is applicable to path data also.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14122093</person_id>
				<author_profile_id><![CDATA[81100339107]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wolfgang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gaul]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39030857</person_id>
				<author_profile_id><![CDATA[81332525921]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lars]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Schmidt-Thieme]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>756509</article_id>
		<sort_key>597</sort_key>
		<display_label></display_label>
		<pages>597</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>88</seq_no>
		<title><![CDATA[Combining Labeled and Unlabeled Data for Text Classification with a Large Number of Categories]]></title>
		<page_from>597</page_from>
		<page_to>598</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=756509</url>
		<abstract>
			<par><![CDATA[We develop a framework to incorporate unlabeled data in the Error-Correcting Output Coding (ECOC)setup by decomposing multiclass problems into multiple binary problems and then use Co-Training to learn the individual binary classification problems. We show that our method isespecially useful for classification tasks involving a large number of categories where Co-training doesn't perform very well by itself and when combined with ECOC, outperforms several other algorithms that combine labeled and unlabeled data for text classification in terms of accuracy, precision-recall tradeoff, and efficiency.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP31041809</person_id>
				<author_profile_id><![CDATA[81100427240]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Rayid]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ghani]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657887</article_id>
		<sort_key>599</sort_key>
		<display_label></display_label>
		<pages>599</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>89</seq_no>
		<title><![CDATA[Dependency Derivation in Industrial Process Data]]></title>
		<page_from>599</page_from>
		<page_to>602</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657887</url>
		<abstract>
			<par><![CDATA[In many industrial processes, finding dependencies and the creation of dependency graphs can increase the understanding of the system significantly. This knowledge can then be used for further optimization and variable selection. Most of the measured attributes in these cases come in the form of time series. There are several ways of determining correlation between series, most of them suffering from specific problems when applied to real-world data. Here, awell performing measure based on the mutual information rate is derived and discussed with results from both synthetic and real data.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P451474</person_id>
				<author_profile_id><![CDATA[81442611984]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gillblad]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P16713</person_id>
				<author_profile_id><![CDATA[81100018350]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Anders]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Holst]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657879</article_id>
		<sort_key>603</sort_key>
		<display_label></display_label>
		<pages>603</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>90</seq_no>
		<title><![CDATA[Discovering Representative Episodal Association Rules from Event Sequences Using Frequent Closed Episode Sets and Event Constraints]]></title>
		<page_from>603</page_from>
		<page_to>606</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657879</url>
		<abstract>
			<par><![CDATA[Discovering association rules from time-series data is an important data mining problem. The number of potential rules grows quickly as the number of items in the antecedent grows. It is therefore difficult for an expert to analyze the rules and identify the useful. An approach for generating representative association rules for transactions that uses only a subset of the set of frequent itemsets called frequent closed itemsets was presented in [6 ]. We employ formalconcept analysis to develop the notion of frequent closed episodes. The concept of representative association rules is formalized in the context of event sequences. Applying constraints to target highly significant rules further reduces the number of rules. Our approach results in a significant reduction of the number of rules generated, while maintaining the minimum set of relevant association rules and retaining the ability to generate the entire set of association rules with respect to the given constraints. We show how our method can be used to discover associations in a drought risk management decision support system and use multiple climatology datasets related to automated weather stations1]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P413052</person_id>
				<author_profile_id><![CDATA[81100225610]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sherri]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Harms]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP15025040</person_id>
				<author_profile_id><![CDATA[81100183521]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jitender]]></first_name>
				<middle_name><![CDATA[S.]]></middle_name>
				<last_name><![CDATA[Deogun]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P466718</person_id>
				<author_profile_id><![CDATA[81100589017]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jamil]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Saquer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P413055</person_id>
				<author_profile_id><![CDATA[81100060978]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Tsegaye]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tadesse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658040</article_id>
		<sort_key>607</sort_key>
		<display_label></display_label>
		<pages>607</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>91</seq_no>
		<title><![CDATA[Text Clustering Based on Good Aggregations]]></title>
		<page_from>607</page_from>
		<page_to>608</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658040</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P443307</person_id>
				<author_profile_id><![CDATA[81100539734]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andreas]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hotho]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14162872</person_id>
				<author_profile_id><![CDATA[81100465867]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Maedche]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39038162</person_id>
				<author_profile_id><![CDATA[81409593685]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Steffen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Staab]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657880</article_id>
		<sort_key>609</sort_key>
		<display_label></display_label>
		<pages>609</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>92</seq_no>
		<title><![CDATA[Ad Hoc Association Rule Mining as SQL3 Queries]]></title>
		<page_from>609</page_from>
		<page_to>612</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657880</url>
		<abstract>
			<par><![CDATA[Although there have been several encouraging attempts at developing methods for data mining using SQL, simplicity and efficiency still remain significant impediments for furtherdevelopment. In this paper, we propose a significantly new approach and show that any object relational database can be mined for association rules without any restructuring orpreprocessing using only basic SQL3 constructs and functions, and hence no additional machineries are necessary. In particular, we show that the cost of computing associationrules for a given database does not depend on support and confidence thresholds. More precisely, the set of large items can be computed using one simple join query and anaggregation once the set of all possible meets (least fix point) of item set patterns in the input table is known. The principal focus of this paper is to demonstrate that several SQL3expressions exists for the mining of association rules.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P108252</person_id>
				<author_profile_id><![CDATA[81100498289]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hasan]]></first_name>
				<middle_name><![CDATA[M.]]></middle_name>
				<last_name><![CDATA[Jamil]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658056</article_id>
		<sort_key>613</sort_key>
		<display_label></display_label>
		<pages>613</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>93</seq_no>
		<title><![CDATA[Heuristic Optimization for Decentralized Frequent Itemset Counting]]></title>
		<page_from>613</page_from>
		<page_to>614</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658056</url>
		<abstract>
			<par><![CDATA[The choices for mining of decentralized data are numerous, and we have developed techniques to enumerate andoptimize decentralized frequent itemset counting. In thispaper, we introduce our heuristic approach to improve theperformance of such techniques developed in ways similarto query processing in database systems. We also describeempirical results that validate our heuristic techniques.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P500950</person_id>
				<author_profile_id><![CDATA[81100466379]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Viviane]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Crestana-Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39046057</person_id>
				<author_profile_id><![CDATA[81100504743]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nandit]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Soparkar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657867</article_id>
		<sort_key>615</sort_key>
		<display_label></display_label>
		<pages>615</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>94</seq_no>
		<title><![CDATA[Evolutionary Structure Learning Algorithm for Bayesian Network and Penalized Mutual Information Metric]]></title>
		<page_from>615</page_from>
		<page_to>616</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657867</url>
		<abstract>
			<par><![CDATA[This paper formulates the problem of learning Bayesian network structures from data as determining the structure that best approximates the probability distribution indicated by the data. A new metric, Penalized Mutual Information metric, is proposed, and a evolutionary algorithm is designed to search for the best structure among alternatives. The experimental results show that this approach is reliable and promising.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14166161</person_id>
				<author_profile_id><![CDATA[81100475823]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Li]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14139240</person_id>
				<author_profile_id><![CDATA[81100393253]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Fu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95042357</person_id>
				<author_profile_id><![CDATA[81451597200]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Honghua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dai]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658025</article_id>
		<sort_key>617</sort_key>
		<display_label></display_label>
		<pages>617</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>95</seq_no>
		<title><![CDATA[Applications of Data Mining in Hydrology]]></title>
		<page_from>617</page_from>
		<page_to>620</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658025</url>
		<abstract>
			<par><![CDATA[Long-term range streamflow forecast plays an invaluable role in water resources planning andmanagement. In this study, the potential applicability and limitations of the time series forecasting approach using neural network with the multiresolution learning paradigm (NNMLP) are investigated. The predictedlongterm range streamflows using the NNMLP are compared with the observations. The results show that the time series forecasting approach of NNMLP has good predicting skill. The NNMLP requires only historicalstreamflow information. The time series forecasting approach of NNMLP has great potential for being used alone in regions with limited available information, and for being combined with other approaches to improve long-term range streamflow forecasts.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P503032</person_id>
				<author_profile_id><![CDATA[81540190556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39024651</person_id>
				<author_profile_id><![CDATA[81100044514]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yao]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657869</article_id>
		<sort_key>621</sort_key>
		<display_label></display_label>
		<pages>621</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>96</seq_no>
		<title><![CDATA[RPCL-Based Local PCA Algorithm]]></title>
		<page_from>621</page_from>
		<page_to>622</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657869</url>
		<abstract>
			<par><![CDATA[Mining local structure is important in data analysis.Gaussian mixture is able to describe local structurethrough the covariance matrices, but when used on high dimensional data, fitly specifying such a large number of d(d + 1)=2 free elements in each covariance matrix is difficult. In this paper, by constraining the covariance matrixin decomposed orthonormal form, we propos a Local PCAalgorithm to tackle this problem in help of RPCL competitivelearning, which can automatically determine the number of local structure.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39047102</person_id>
				<author_profile_id><![CDATA[81100529214]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Zhiyong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39031927</person_id>
				<author_profile_id><![CDATA[81100196152]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Xu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657894</article_id>
		<sort_key>623</sort_key>
		<display_label></display_label>
		<pages>623</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>97</seq_no>
		<title><![CDATA[Learning Automatic Acquisition of Subcategorization Frames Using Bayesian Inference and Support Vector Machines]]></title>
		<page_from>623</page_from>
		<page_to>625</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657894</url>
		<abstract>
			<par><![CDATA[Learning Bayesian Belief Network (BBN) from corpora and Support Vector Machines (SVM) have been applied to the automatic acquisition of verb subcategorization frames for Modern Greek.We are incorporating minimal linguistic resources, i.e. basic morphological tagging and phrase chunking, to demonstrate that verb subcategorization, which is of great significance for developing robust natural language human computer interaction systems, could be achieved using large corpora, without having any general-purpose syntactic parser at all.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P477455</person_id>
				<author_profile_id><![CDATA[81100188188]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Manolis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Maragoudakis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P471163</person_id>
				<author_profile_id><![CDATA[81100134578]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[K.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kermanidis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P209314</person_id>
				<author_profile_id><![CDATA[81100618074]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Nikos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fakotakis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P95647</person_id>
				<author_profile_id><![CDATA[81100347416]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[George]]></first_name>
				<middle_name><![CDATA[K.]]></middle_name>
				<last_name><![CDATA[Kokkinakis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657882</article_id>
		<sort_key>626</sort_key>
		<display_label></display_label>
		<pages>626</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>98</seq_no>
		<title><![CDATA[Bayesian Data Mining on the Web with B-Course]]></title>
		<page_from>626</page_from>
		<page_to>629</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657882</url>
		<abstract>
			<par><![CDATA[B-Course is a free 1 web-based Bayesian data mining service. This service allows the users to analyze their own data for multivariate probabilistic dependencies represented as Bayesian network models. In addition to this, B-Course also offers facilities for inferring certain type of causal dependencies from the data. The software is especially suitable for educational purposes as the tutorial style user-friendly interface intertwines the steps in the data analysiswith support material that gives an informal introduction to the Bayesian approach adopted. Nevertheless, although the analysis methods, modeling assumptions and restrictionsare totally transparent to the user, this transparency is not achieved at the expense of analysis power: with the restrictions stated in the support material, B-Course is a powerful analysis tool exploiting several theoretically elaborate results developed recently in the fields of Bayesian and causal modeling.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P225787</person_id>
				<author_profile_id><![CDATA[81100436253]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Petri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Myllym&#228;ki]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P337665</person_id>
				<author_profile_id><![CDATA[81100253748]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Tomi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Silander]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP38024538</person_id>
				<author_profile_id><![CDATA[81100320497]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tirri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P486377</person_id>
				<author_profile_id><![CDATA[81100481191]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Pekka]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Uronen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657735</article_id>
		<sort_key>630</sort_key>
		<display_label></display_label>
		<pages>630</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>99</seq_no>
		<title><![CDATA[An Experimental Comparison of Supervised and Unsupervised Approaches to Text Summarization]]></title>
		<page_from>630</page_from>
		<page_to>632</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657735</url>
		<abstract>
			<par><![CDATA[The paper presents a direct comparison of supervised and unsupervised approaches to text summarization. As a representative supervised method, we use the C4.5 decision tree algorithm, extended with the Minimum Description Length Principle (MDL), and compare it against several unsupervised methods. It is found that a particular un-supervised method based on an extension of the K-means clustering algorithm, performs equal to and in some cases superior to the decision tree based method.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP40025198</person_id>
				<author_profile_id><![CDATA[81100236506]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tadashi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nomoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP31036920</person_id>
				<author_profile_id><![CDATA[81100316381]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yuji]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Matsumoto]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657896</article_id>
		<sort_key>633</sort_key>
		<display_label></display_label>
		<pages>633</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>100</seq_no>
		<title><![CDATA[A Fast Algorithm to Cluster High Dimensional Basket Data]]></title>
		<page_from>633</page_from>
		<page_to>636</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657896</url>
		<abstract>
			<par><![CDATA[Clustering is a data mining problem that has received significant attention by the database community. Data set size, dimensionality and sparsity have been identified as aspectsthat make clustering more difficult. This work introduces a fast algorithm to cluster large binary data sets where data points have high dimensionality and most o their coordinates are zero. This is the case with basket data transactions containing items, that can be represented as sparse binary vectors with very high dimensionality. An experimental section shows performance, advantages and limitations of the proposed approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39051027</person_id>
				<author_profile_id><![CDATA[81100618426]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Carlos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ordonez]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39046308</person_id>
				<author_profile_id><![CDATA[81100511324]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Edward]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Omiecinski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P210013</person_id>
				<author_profile_id><![CDATA[81100629869]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Norberto]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ezquerra]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657734</article_id>
		<sort_key>637</sort_key>
		<display_label></display_label>
		<pages>637</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>101</seq_no>
		<title><![CDATA[Metric Rule Generation with Septic Shock Patient Data]]></title>
		<page_from>637</page_from>
		<page_to>638</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657734</url>
		<abstract>
			<par><![CDATA[In this contribution we present an application of metric rule generation in the domain of medical research. We consider intensive car unit patients developing a septic shockduring their stay at the hospital. To analyse the patient data, rule generation is embedded in a medical data mining cycle. For rule generation, we improve an architecture basedon a growing trapezoidal basis function network.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP39049901</person_id>
				<author_profile_id><![CDATA[81100590911]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J&#252;rgen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Paetz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658049</article_id>
		<sort_key>639</sort_key>
		<display_label></display_label>
		<pages>639</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>102</seq_no>
		<title><![CDATA[The Representative Basis for Association Rules]]></title>
		<page_from>639</page_from>
		<page_to>640</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658049</url>
		<abstract>
			<par><![CDATA[We define the concept of the representative basic for interesting association rules, and an inference system which is purely qualitative. The representative basis is unique, and minimal with respect to (wrt) the inference system. On the representative basis, the inference system is correct and complete. Experimental results show that the number of rule in the representative basis is significantly reduced wrt the number of rules generated by other existing approaches.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP310173300</person_id>
				<author_profile_id><![CDATA[81541840056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Viet]]></first_name>
				<middle_name><![CDATA[Phan]]></middle_name>
				<last_name><![CDATA[Luong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657865</article_id>
		<sort_key>641</sort_key>
		<display_label></display_label>
		<pages>641</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>103</seq_no>
		<title><![CDATA[Incremental Learning with Support Vector Machines]]></title>
		<page_from>641</page_from>
		<page_to>642</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657865</url>
		<abstract>
			<par><![CDATA[Support Vector Machines (SVMs) have become a popular tool for machine learning with large amounts of high dimensional data. In this paper an approach for incremental learning with Support Vector Machines is presented, that improves the existing approach of [3 ]. Also, some insight into the interpretability of support vectors s given.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P495136</person_id>
				<author_profile_id><![CDATA[81343504023]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[R&#252;ping]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657895</article_id>
		<sort_key>643</sort_key>
		<display_label></display_label>
		<pages>643</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>104</seq_no>
		<title><![CDATA[A Clustering Method for Very Large Mixed Data Sets]]></title>
		<page_from>643</page_from>
		<page_to>644</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657895</url>
		<abstract>
			<par><![CDATA[In the developed countries, especially over the last decade, there has been an explosive growth in the capability to generate, collect and use very large data sets. The objects of these data sets could be simultaneously described by quantitative and qualitative attributes. At present, algorithms able to process either very large data sets (in metric spaces) or mixed(qualitative and quantitative) incomplete data (missing value) sets have been developed, but not for very large mixed incomplete data sets. In this paper we introduce a new clustering method named GLC+to process very large mixed incomplete data sets in order to obtain apartition in connected sets.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P460206</person_id>
				<author_profile_id><![CDATA[81100350888]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Guillermo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[S&#225;nchez-D&#237;az]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14093160</person_id>
				<author_profile_id><![CDATA[81339525589]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jos&#233;]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ruiz-Shulcloper]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658193</article_id>
		<sort_key>645</sort_key>
		<display_label></display_label>
		<pages>645</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>105</seq_no>
		<title><![CDATA[Mining the Web with Active Hidden Markov Models]]></title>
		<page_from>645</page_from>
		<page_to>646</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658193</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP37024781</person_id>
				<author_profile_id><![CDATA[81100180901]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tobias]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Scheffer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P449280</person_id>
				<author_profile_id><![CDATA[81100375408]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Decomain]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P267503</person_id>
				<author_profile_id><![CDATA[81100099179]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stefan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wrobel]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>757723</article_id>
		<sort_key>647</sort_key>
		<display_label></display_label>
		<pages>647</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>106</seq_no>
		<title><![CDATA[A Simple KNN Algorithm for Text Categorization]]></title>
		<page_from>647</page_from>
		<page_to>648</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=757723</url>
		<abstract>
			<par><![CDATA[Text categoriztion (also called text classification) is the process of identifying the class to which a text document belongs. This paper proposes to use a simple non-weighted feature KNN algorithm for text caegoriztion. We propose to use a feature selection method that finds the relevant features for the learning task at hand using feature interaction (based on word interdependencies).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P485557</person_id>
				<author_profile_id><![CDATA[81100197529]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Pascal]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Soucy]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P100920</person_id>
				<author_profile_id><![CDATA[81100402241]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Guy]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Mineau]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658038</article_id>
		<sort_key>649</sort_key>
		<display_label></display_label>
		<pages>649</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>107</seq_no>
		<title><![CDATA[Measuring Real-Time Predictive Models]]></title>
		<page_from>649</page_from>
		<page_to>650</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658038</url>
		<abstract>
			<par><![CDATA[In this paper we examine the problem of comparing real-time predictive models and propose a number of measures for selecting the best model, based on a combination of accuracy, timeliness, and cost. We apply the measure to the real-time attrition problem.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P336801</person_id>
				<author_profile_id><![CDATA[81100091974]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sam]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Steingold]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P490052</person_id>
				<author_profile_id><![CDATA[81100250234]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Richard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wherry]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39036001</person_id>
				<author_profile_id><![CDATA[81100286057]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Gregory]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Piatetsky-Shapiro]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657881</article_id>
		<sort_key>651</sort_key>
		<display_label></display_label>
		<pages>651</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>108</seq_no>
		<title><![CDATA[Incremental Learning of Bayesian Networks with Hidden Variables]]></title>
		<page_from>651</page_from>
		<page_to>652</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657881</url>
		<abstract>
			<par><![CDATA[In this paper, an incremental method for learning Bayesian networks based on evolutionary computing, IEMA, is put forward. IEMA introduces the evolutionary algorithm and EM algorithm into the process of incremental learning, can not only avoid getting into local maxima, but also incrementally learn Bayesian networks with high accuracy in presence of missing values andhidden variables. In addition, we improved the incremental learning process by Friedman et al. The experimental results verified the validity of IEMA. In terms of storage cost, IEMA is comparable with the incremental learning method of Friedman et al, while it is ore accurate.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP45023369</person_id>
				<author_profile_id><![CDATA[81340493235]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fengzhan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tian]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P463267</person_id>
				<author_profile_id><![CDATA[81344501069]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hongwei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP54031467</person_id>
				<author_profile_id><![CDATA[81350589703]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yuchang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P48571</person_id>
				<author_profile_id><![CDATA[81100647381]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Chunyi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Shi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658061</article_id>
		<sort_key>653</sort_key>
		<display_label></display_label>
		<pages>653</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>109</seq_no>
		<title><![CDATA[Mining Frequent Closed Itemsets with the Frequent Pattern List]]></title>
		<page_from>653</page_from>
		<page_to>654</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658061</url>
		<abstract>
			<par><![CDATA[The mining of the complete set of frequent itemsets willlead to a huge number of itemsets. Fortunately, thisproblem can be reduced to the mining of frequent closeditemsets (FCIs), which results in a much smaller number ofitemsets. The approaches to mining frequent closeditemsets can be categorized into two groups: those withcandidate generation and those without. In this paper, wepropose an approach to mining frequent closed itemsetswithout candidate generation: with a data structure calledthe Frequent Pattern List (FPL). We designed thealgorithm FPLC -Mining to mine the frequent closeditemsets (FCIs). Experimental result shows that our methodis faster than the previously existing ones.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Frequent closed itemset, frequent pattern list]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P456237</person_id>
				<author_profile_id><![CDATA[81100582522]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Fan-Chen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tseng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77046948</person_id>
				<author_profile_id><![CDATA[81409591958]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ching-Chi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hsu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P462435</person_id>
				<author_profile_id><![CDATA[81451600912]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658062</article_id>
		<sort_key>655</sort_key>
		<display_label></display_label>
		<pages>655</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>110</seq_no>
		<title><![CDATA[Classification through Maximizing Density]]></title>
		<page_from>655</page_from>
		<page_to>656</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658062</url>
		<abstract>
			<par><![CDATA[This paper presents a novel method for classification, which makes use of the models builtby the lattice machine (LM) [1,3 ]. The LM approximates data resulting in, as a model of data, a set of hyper tuples that are equilabelled, supported and maximal . The method presentedin this paper uses the LM model of data to classify new data with a view to maximising the density of the model. Experiments show that this method, when used with the LM, outperforms the C2 algorithm in [3 ] and it is comparable to the C5.0 classification algorithm.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP77042645</person_id>
				<author_profile_id><![CDATA[81406594270]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Hui]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39028190</person_id>
				<author_profile_id><![CDATA[81100118072]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ivo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[D&#252;ntsch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP77031043</person_id>
				<author_profile_id><![CDATA[81406600041]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Bell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14182687</person_id>
				<author_profile_id><![CDATA[81544027256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Dayou]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657861</article_id>
		<sort_key>657</sort_key>
		<display_label></display_label>
		<pages>657</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>111</seq_no>
		<title><![CDATA[An Immune Neural Network Used for Classification]]></title>
		<page_from>657</page_from>
		<page_to>658</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657861</url>
		<abstract>
			<par><![CDATA[Based on analyzing the immune phenomena in nature and utilizing performances of ANN, a novel network model, i.e., an immune neural network (INN), is proposed which integrates the immune mechanism and the function of neural information processing. The learning algorithm of INN is mainly about the selection of an excitation function and an adaptive algorithm of the network.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15026179</person_id>
				<author_profile_id><![CDATA[81408602655]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Lei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP40022878</person_id>
				<author_profile_id><![CDATA[81100027975]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Licheng]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jiao]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657888</article_id>
		<sort_key>659</sort_key>
		<display_label></display_label>
		<pages>659</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>112</seq_no>
		<title><![CDATA[alpha-Surface and Its Application to Mining Protein Data]]></title>
		<page_from>659</page_from>
		<page_to>662</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657888</url>
		<abstract>
			<par><![CDATA[Given a finite set of points in three dimensional Euclidean space R3, the subset that forms its surface could bedifferent when observed in different levels of details. In thispaper, we introduce a notion called a-surface. We presentan algorithm that extracts the a-surface from a finite set ofpoints in R3. We apply the algorithm to extracting the a-surfaces of proteins and discover patterns from these surface structures, using the pattern discovery algorithm wedeveloped earlier. We then use these patterns to classify theproteins. Experimental results show the good performanceof the proposed approach.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP15026241</person_id>
				<author_profile_id><![CDATA[81100219109]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Xiong]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657891</article_id>
		<sort_key>663</sort_key>
		<display_label></display_label>
		<pages>663</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>113</seq_no>
		<title><![CDATA[An Efficient Data Mining Technique for Discovering Interesting Sequential Patterns]]></title>
		<page_from>663</page_from>
		<page_to>664</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657891</url>
		<abstract>
			<par><![CDATA[Mining sequential patterns is to discover sequentialpurchasing behaviors of most customers from a largeamount of customer transactions. In this paper, a datamining language is presented. From the data mininglanguage, use s can specify the interested items and thecriteria of the sequential patterns to be discovered. Also,an efficient data mining technique is proposed to ext actthe sequential patterns according to the uses` requests.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP14200288</person_id>
				<author_profile_id><![CDATA[81100579881]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Show-Jane]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14136765</person_id>
				<author_profile_id><![CDATA[81100386141]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yue-Shi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>658024</article_id>
		<sort_key>665</sort_key>
		<display_label></display_label>
		<pages>665</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>114</seq_no>
		<title><![CDATA[Fast Parallel Association Rule Mining without Candidacy Generation]]></title>
		<page_from>665</page_from>
		<page_to>668</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=658024</url>
		<abstract>
			<par><![CDATA[In this paper we introduce a new parallel algorithm MLFPT (Multiple Local Frequent Pattern Tree) [11] for parallel mining of frequent patterns, based on FP-growth mining, that uses only two full I/O scans of the database, eliminating the need for generating the candidate items and distributing the work fairly among processors. We have devised partitioning strategies at different stages of the mining process to achieve near optimal balancing between processors.We have successfully tested our algorithm on datasets larger than 50 million transactions.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P212464</person_id>
				<author_profile_id><![CDATA[81100104421]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Osmar]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Za&#239;ane]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P482063</person_id>
				<author_profile_id><![CDATA[81100461137]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mohammad]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[El-Hajj]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39024994</person_id>
				<author_profile_id><![CDATA[81100052380]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Paul]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657863</article_id>
		<sort_key>669</sort_key>
		<display_label></display_label>
		<pages>669</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>115</seq_no>
		<title><![CDATA[A Comparison of Stacking with Meta Decision Trees to Bagging, Boosting, and Stacking with other Methods]]></title>
		<page_from>669</page_from>
		<page_to>670</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657863</url>
		<abstract>
			<par><![CDATA[Abstract. Meta decision trees (MTs) are a method for combining multiple classifiers. We present an integration of the algorithm MLC4.5 for learning MTs into the Weka data mining suite. We compare classifier ensembles combined with MDTs to bagged and boosted decision trees, and to classifier ensembles combined with other methods: voting and stacking with three different meta-level classifiers (ordinary decision trees, naive Bayes, and multi-response linear regression -MLR).]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P446218</person_id>
				<author_profile_id><![CDATA[81100263323]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Bernard]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zenko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP42051768</person_id>
				<author_profile_id><![CDATA[81339532626]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ljupco]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Todorovski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14183917</person_id>
				<author_profile_id><![CDATA[81100529929]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Saso]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dzeroski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657729</article_id>
		<sort_key>671</sort_key>
		<display_label></display_label>
		<pages>671</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>116</seq_no>
		<title><![CDATA[Mining California Vital Statistics Data]]></title>
		<page_from>671</page_from>
		<page_to>672</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657729</url>
		<abstract>
			<par><![CDATA[Vital statistics data offer a fertile ground for data mining.In this paper, we discuss the results of a data miningproject on the causes of death aspect of the vital statisticsdata in the state of California. A data mining tool calledCubist is used to build predictive models out of two millioncases over a nine-year period. The objective of our studyis to discover knowledge that can be used to gain insightinto various aspects of mortality in California, to predicthealth issues related to the causes of death, to offer an aidto decision-or policy-making process, and to provideuseful information services to the customers. The resultsobtained in our study contain valuable new information.]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Vital statistics data, causes of death, data mining, predictive models, Cubist.]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>PP95039833</person_id>
				<author_profile_id><![CDATA[81453626125]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Du]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P487940</person_id>
				<author_profile_id><![CDATA[81100467116]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Quoc]]></first_name>
				<middle_name><![CDATA[Luan]]></middle_name>
				<last_name><![CDATA[Ha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39025037</person_id>
				<author_profile_id><![CDATA[81100052936]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Meiliu]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>657730</article_id>
		<sort_key>673</sort_key>
		<display_label></display_label>
		<pages>673</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>117</seq_no>
		<title><![CDATA[A Pattern Decomposition (PD) Algorithm for Finding All Frequent Patterns in Large Datasets]]></title>
		<page_from>673</page_from>
		<page_to>674</page_to>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=657730</url>
		<abstract>
			<par><![CDATA[Efficient algorithms to mine frequent patterns are crucial to many tasks in data mining. Since the Apriori algorithm was proposed in 1994, there have been several methods proposed to improve its performance. However, most still adopt its candidate set generation-and-testapproach. We propose a pattern decomposition (PD) algorithm that can significantly reduce the size of the dataset on each pass making it more efficient to mine frequent patterns in a large dataset. The proposed algorithm avoids the costly process of candidate set generation and saves time by reducing dataset. Our empirical evaluation shows that the algorithmoutperforms Apriori by one order of magnitude and is faster than FP-tree. Further, PD is more scalable than both Apriori and FP-tree.]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P315403</person_id>
				<author_profile_id><![CDATA[81100263550]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Qinghua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP95033668</person_id>
				<author_profile_id><![CDATA[81451597041]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wesley]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Chu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP67022614</person_id>
				<author_profile_id><![CDATA[81502659944]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Johnson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP310760300</person_id>
				<author_profile_id><![CDATA[81546782756]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Henry]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chiu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
	</article_rec>
	<article_rec>
		<article_id>878517</article_id>
		<sort_key>675</sort_key>
		<display_label></display_label>
		<pages>0675</pages>
		<article_publication_date>11-29-2001</article_publication_date>
		<seq_no>118</seq_no>
		<title><![CDATA[Author Index]]></title>
		<page_from>675</page_from>
		<doi_number></doi_number>
		<url>http://dl.acm.org/citation.cfm?id=878517</url>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<seq_no />
				<first_name />
				<middle_name />
				<last_name />
				<suffix />
				<role />
			</au>
		</authors>
	</article_rec>
</content>
</proceeding>
